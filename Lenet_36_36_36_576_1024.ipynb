{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 497528,
     "status": "ok",
     "timestamp": 1553967273003,
     "user": {
      "displayName": "yusuke yakuwa",
      "photoUrl": "",
      "userId": "15933669924163222944"
     },
     "user_tz": 420
    },
    "id": "_tJKMpm7rAdV",
    "outputId": "46f3a8f4-620e-4b62-aa1c-fea0b90736d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-41ac4272-86ca-4ef0-a971-cf09592c3fea\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-41ac4272-86ca-4ef0-a971-cf09592c3fea\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving X.npy to X.npy\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9968,
     "status": "ok",
     "timestamp": 1553967286557,
     "user": {
      "displayName": "yusuke yakuwa",
      "photoUrl": "",
      "userId": "15933669924163222944"
     },
     "user_tz": 420
    },
    "id": "sy-UJtg0tXYZ",
    "outputId": "88736759-899d-44be-b780-c25b009e4786"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-e1f89224-55c3-4049-bdca-3390ed591540\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-e1f89224-55c3-4049-bdca-3390ed591540\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Y.npy to Y.npy\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168331
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3275,
     "status": "error",
     "timestamp": 1553981960213,
     "user": {
      "displayName": "yusuke yakuwa",
      "photoUrl": "",
      "userId": "15933669924163222944"
     },
     "user_tz": 420
    },
    "id": "3UrfaZuKnfT8",
    "outputId": "a5bfc5cd-f569-42d8-8c88-35980c0d8843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2078\n",
      "2082\n",
      "(4160, 50, 50, 3)\n",
      "(4160,)\n",
      "max_value -> 255\n",
      "*****   num_batches: 0.31189799308776855  *****\n",
      "NO OF BATCHES: 80\n",
      "*****   NO OF BATCHES: 0.313065767288208  *****\n",
      "conv1.get_shape():  (?, 50, 50, 36)\n",
      "conv1.get_shape() after maxpool :  (?, 25, 25, 36)\n",
      "conv2.get_shape():  (?, 25, 25, 36)\n",
      "conv2.get_shape() after maxpool :  (?, 13, 13, 36)\n",
      "conv3.get_shape():  (?, 13, 13, 36)\n",
      "conv3.get_shape() after maxpool :  (?, 7, 7, 36)\n",
      "Epoch: 0, Loss: 8254691.5000, Train_Acc: 0.5577, TEST_Acc: 0.4867, Time: 3.6548\n",
      "Epoch: 1, Loss: 5762106.5000, Train_Acc: 0.5385, TEST_Acc: 0.4833, Time: 4.8012\n",
      "Epoch: 2, Loss: 4209255.0000, Train_Acc: 0.5192, TEST_Acc: 0.4800, Time: 5.9327\n",
      "Epoch: 3, Loss: 3472066.5000, Train_Acc: 0.4808, TEST_Acc: 0.4867, Time: 7.0714\n",
      "Epoch: 4, Loss: 3017952.5000, Train_Acc: 0.4808, TEST_Acc: 0.4600, Time: 8.2106\n",
      "Epoch: 5, Loss: 2874835.7500, Train_Acc: 0.5000, TEST_Acc: 0.4733, Time: 9.3420\n",
      "Epoch: 6, Loss: 2910552.0000, Train_Acc: 0.5000, TEST_Acc: 0.4800, Time: 10.4756\n",
      "Epoch: 7, Loss: 2874981.2500, Train_Acc: 0.4808, TEST_Acc: 0.4867, Time: 11.6093\n",
      "Epoch: 8, Loss: 2775477.7500, Train_Acc: 0.4808, TEST_Acc: 0.4767, Time: 12.7402\n",
      "Epoch: 9, Loss: 2866934.7500, Train_Acc: 0.5000, TEST_Acc: 0.4933, Time: 13.8763\n",
      "Epoch: 10, Loss: 2496678.0000, Train_Acc: 0.5000, TEST_Acc: 0.4867, Time: 15.0129\n",
      "Epoch: 11, Loss: 2254936.7500, Train_Acc: 0.4808, TEST_Acc: 0.4833, Time: 16.1494\n",
      "Epoch: 12, Loss: 2295950.7500, Train_Acc: 0.4615, TEST_Acc: 0.4933, Time: 17.2791\n",
      "Epoch: 13, Loss: 2253677.7500, Train_Acc: 0.4808, TEST_Acc: 0.4967, Time: 18.4134\n",
      "Epoch: 14, Loss: 2039991.5000, Train_Acc: 0.4808, TEST_Acc: 0.5067, Time: 19.5513\n",
      "Epoch: 15, Loss: 2005228.2500, Train_Acc: 0.4808, TEST_Acc: 0.5200, Time: 20.6867\n",
      "Epoch: 16, Loss: 1928190.7500, Train_Acc: 0.4615, TEST_Acc: 0.5233, Time: 21.8204\n",
      "Epoch: 17, Loss: 2026946.0000, Train_Acc: 0.4808, TEST_Acc: 0.5300, Time: 22.9559\n",
      "Epoch: 18, Loss: 1970090.7500, Train_Acc: 0.4808, TEST_Acc: 0.5300, Time: 24.0950\n",
      "Epoch: 19, Loss: 1827213.2500, Train_Acc: 0.5000, TEST_Acc: 0.5567, Time: 25.2273\n",
      "Epoch: 20, Loss: 1853203.1250, Train_Acc: 0.4808, TEST_Acc: 0.5667, Time: 26.3626\n",
      "Epoch: 21, Loss: 1741588.2500, Train_Acc: 0.5192, TEST_Acc: 0.5833, Time: 27.4979\n",
      "Epoch: 22, Loss: 1688558.0000, Train_Acc: 0.4808, TEST_Acc: 0.5667, Time: 28.6257\n",
      "Epoch: 23, Loss: 1734554.1250, Train_Acc: 0.5000, TEST_Acc: 0.5900, Time: 29.7620\n",
      "Epoch: 24, Loss: 1746270.0000, Train_Acc: 0.5000, TEST_Acc: 0.6100, Time: 30.9001\n",
      "Epoch: 25, Loss: 1756298.2500, Train_Acc: 0.5000, TEST_Acc: 0.6200, Time: 32.0336\n",
      "Epoch: 26, Loss: 1746420.8750, Train_Acc: 0.4808, TEST_Acc: 0.6267, Time: 33.1678\n",
      "Epoch: 27, Loss: 1683083.3750, Train_Acc: 0.4808, TEST_Acc: 0.6100, Time: 34.3096\n",
      "Epoch: 28, Loss: 1677294.1250, Train_Acc: 0.4808, TEST_Acc: 0.6167, Time: 35.4470\n",
      "Epoch: 29, Loss: 1676978.2500, Train_Acc: 0.4808, TEST_Acc: 0.6300, Time: 36.5814\n",
      "Epoch: 30, Loss: 1657713.2500, Train_Acc: 0.4808, TEST_Acc: 0.6400, Time: 37.7179\n",
      "Epoch: 31, Loss: 1627472.7500, Train_Acc: 0.5192, TEST_Acc: 0.6300, Time: 38.8524\n",
      "Epoch: 32, Loss: 1629133.2500, Train_Acc: 0.5385, TEST_Acc: 0.6400, Time: 39.9852\n",
      "Epoch: 33, Loss: 1596421.8750, Train_Acc: 0.5385, TEST_Acc: 0.6333, Time: 41.1169\n",
      "Epoch: 34, Loss: 1550563.1250, Train_Acc: 0.5192, TEST_Acc: 0.6267, Time: 42.2553\n",
      "Epoch: 35, Loss: 1635483.5000, Train_Acc: 0.5385, TEST_Acc: 0.6533, Time: 43.3887\n",
      "Epoch: 36, Loss: 1584466.0000, Train_Acc: 0.5385, TEST_Acc: 0.6367, Time: 44.5239\n",
      "Epoch: 37, Loss: 1587246.5000, Train_Acc: 0.5385, TEST_Acc: 0.6433, Time: 45.6589\n",
      "Epoch: 38, Loss: 1585579.3750, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 46.8049\n",
      "Epoch: 39, Loss: 1630128.2500, Train_Acc: 0.5577, TEST_Acc: 0.6467, Time: 47.9464\n",
      "Epoch: 40, Loss: 1644141.3750, Train_Acc: 0.5385, TEST_Acc: 0.6500, Time: 49.0844\n",
      "Epoch: 41, Loss: 1564230.0000, Train_Acc: 0.5577, TEST_Acc: 0.6333, Time: 50.2168\n",
      "Epoch: 42, Loss: 1499842.5000, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 51.3532\n",
      "Epoch: 43, Loss: 1489565.5000, Train_Acc: 0.5962, TEST_Acc: 0.6133, Time: 52.4881\n",
      "Epoch: 44, Loss: 1533569.8750, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 53.6275\n",
      "Epoch: 45, Loss: 1553710.5000, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 54.7617\n",
      "Epoch: 46, Loss: 1547938.7500, Train_Acc: 0.5962, TEST_Acc: 0.6167, Time: 55.9000\n",
      "Epoch: 47, Loss: 1533083.7500, Train_Acc: 0.5962, TEST_Acc: 0.6167, Time: 57.0382\n",
      "Epoch: 48, Loss: 1554024.8750, Train_Acc: 0.5962, TEST_Acc: 0.6167, Time: 58.1693\n",
      "Epoch: 49, Loss: 1601150.1250, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 59.3045\n",
      "Epoch: 50, Loss: 1623643.7500, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 60.4342\n",
      "Epoch: 51, Loss: 1612986.6250, Train_Acc: 0.6154, TEST_Acc: 0.6233, Time: 61.5674\n",
      "Epoch: 52, Loss: 1625771.7500, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 62.7041\n",
      "Epoch: 53, Loss: 1607067.3750, Train_Acc: 0.6154, TEST_Acc: 0.6033, Time: 63.8366\n",
      "Epoch: 54, Loss: 1638949.2500, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 64.9734\n",
      "Epoch: 55, Loss: 1637417.2500, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 66.1062\n",
      "Epoch: 56, Loss: 1647212.0000, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 67.2404\n",
      "Epoch: 57, Loss: 1691753.5000, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 68.3829\n",
      "Epoch: 58, Loss: 1697363.3750, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 69.5221\n",
      "Epoch: 59, Loss: 1681300.6250, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 70.6580\n",
      "Epoch: 60, Loss: 1703012.8750, Train_Acc: 0.6538, TEST_Acc: 0.6167, Time: 71.7941\n",
      "Epoch: 61, Loss: 1690501.2500, Train_Acc: 0.6346, TEST_Acc: 0.6200, Time: 72.9286\n",
      "Epoch: 62, Loss: 1714648.0000, Train_Acc: 0.6538, TEST_Acc: 0.6167, Time: 74.0635\n",
      "Epoch: 63, Loss: 1680740.6250, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 75.1984\n",
      "Epoch: 64, Loss: 1678712.0000, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 76.3363\n",
      "Epoch: 65, Loss: 1717484.0000, Train_Acc: 0.6346, TEST_Acc: 0.6200, Time: 77.4661\n",
      "Epoch: 66, Loss: 1695741.5000, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 78.6068\n",
      "Epoch: 67, Loss: 1735782.5000, Train_Acc: 0.6346, TEST_Acc: 0.6233, Time: 79.7363\n",
      "Epoch: 68, Loss: 1716496.7500, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 80.8685\n",
      "Epoch: 69, Loss: 1762985.7500, Train_Acc: 0.6346, TEST_Acc: 0.6233, Time: 82.0010\n",
      "Epoch: 70, Loss: 1748382.7500, Train_Acc: 0.6346, TEST_Acc: 0.6233, Time: 83.1364\n",
      "Epoch: 71, Loss: 1735989.8750, Train_Acc: 0.6346, TEST_Acc: 0.6200, Time: 84.2719\n",
      "Epoch: 72, Loss: 1745755.8750, Train_Acc: 0.6346, TEST_Acc: 0.6200, Time: 85.4160\n",
      "Epoch: 73, Loss: 1710018.5000, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 86.5489\n",
      "Epoch: 74, Loss: 1739089.7500, Train_Acc: 0.6346, TEST_Acc: 0.6200, Time: 87.6865\n",
      "Epoch: 75, Loss: 1751448.6250, Train_Acc: 0.6346, TEST_Acc: 0.6200, Time: 88.8341\n",
      "Epoch: 76, Loss: 1749627.1250, Train_Acc: 0.6538, TEST_Acc: 0.6200, Time: 89.9671\n",
      "Epoch: 77, Loss: 1752413.7500, Train_Acc: 0.6538, TEST_Acc: 0.6200, Time: 91.1029\n",
      "Epoch: 78, Loss: 1741574.7500, Train_Acc: 0.6538, TEST_Acc: 0.6200, Time: 92.2315\n",
      "Epoch: 79, Loss: 1738417.2500, Train_Acc: 0.6538, TEST_Acc: 0.6200, Time: 93.3654\n",
      "Epoch: 80, Loss: 1762734.1250, Train_Acc: 0.6538, TEST_Acc: 0.6233, Time: 94.5054\n",
      "Epoch: 81, Loss: 1762610.0000, Train_Acc: 0.6538, TEST_Acc: 0.6267, Time: 95.6389\n",
      "Epoch: 82, Loss: 1735502.7500, Train_Acc: 0.6731, TEST_Acc: 0.6200, Time: 96.7738\n",
      "Epoch: 83, Loss: 1744658.0000, Train_Acc: 0.6538, TEST_Acc: 0.6267, Time: 97.9069\n",
      "Epoch: 84, Loss: 1759926.5000, Train_Acc: 0.6346, TEST_Acc: 0.6267, Time: 99.0392\n",
      "Epoch: 85, Loss: 1759535.7500, Train_Acc: 0.6346, TEST_Acc: 0.6267, Time: 100.1796\n",
      "Epoch: 86, Loss: 1771599.1250, Train_Acc: 0.6346, TEST_Acc: 0.6300, Time: 101.3166\n",
      "Epoch: 87, Loss: 1752644.0000, Train_Acc: 0.6538, TEST_Acc: 0.6300, Time: 102.4549\n",
      "Epoch: 88, Loss: 1751928.2500, Train_Acc: 0.6538, TEST_Acc: 0.6300, Time: 103.5962\n",
      "Epoch: 89, Loss: 1777466.7500, Train_Acc: 0.6346, TEST_Acc: 0.6367, Time: 104.7307\n",
      "Epoch: 90, Loss: 1764397.5000, Train_Acc: 0.6538, TEST_Acc: 0.6300, Time: 105.8653\n",
      "Epoch: 91, Loss: 1765190.2500, Train_Acc: 0.6538, TEST_Acc: 0.6267, Time: 106.9995\n",
      "Epoch: 92, Loss: 1770472.2500, Train_Acc: 0.6538, TEST_Acc: 0.6233, Time: 108.1391\n",
      "Epoch: 93, Loss: 1782934.5000, Train_Acc: 0.6346, TEST_Acc: 0.6333, Time: 109.2747\n",
      "Epoch: 94, Loss: 1771055.1250, Train_Acc: 0.6538, TEST_Acc: 0.6200, Time: 110.4135\n",
      "Epoch: 95, Loss: 1797959.8750, Train_Acc: 0.6346, TEST_Acc: 0.6433, Time: 111.5468\n",
      "Epoch: 96, Loss: 1784926.5000, Train_Acc: 0.6346, TEST_Acc: 0.6433, Time: 112.6795\n",
      "Epoch: 97, Loss: 1785786.5000, Train_Acc: 0.6346, TEST_Acc: 0.6433, Time: 113.8115\n",
      "Epoch: 98, Loss: 1782317.8750, Train_Acc: 0.6346, TEST_Acc: 0.6400, Time: 114.9425\n",
      "Epoch: 99, Loss: 1765067.7500, Train_Acc: 0.6346, TEST_Acc: 0.6267, Time: 116.0796\n",
      "Epoch: 100, Loss: 1776145.5000, Train_Acc: 0.6538, TEST_Acc: 0.6433, Time: 117.2176\n",
      "Epoch: 101, Loss: 1801006.7500, Train_Acc: 0.6346, TEST_Acc: 0.6433, Time: 118.3558\n",
      "Epoch: 102, Loss: 1811819.1250, Train_Acc: 0.6346, TEST_Acc: 0.6500, Time: 119.4975\n",
      "Epoch: 103, Loss: 1801629.5000, Train_Acc: 0.6346, TEST_Acc: 0.6467, Time: 120.6351\n",
      "Epoch: 104, Loss: 1844697.1250, Train_Acc: 0.6346, TEST_Acc: 0.6567, Time: 121.7711\n",
      "Epoch: 105, Loss: 1813701.3750, Train_Acc: 0.6346, TEST_Acc: 0.6533, Time: 122.9066\n",
      "Epoch: 106, Loss: 1785158.2500, Train_Acc: 0.6346, TEST_Acc: 0.6367, Time: 124.0439\n",
      "Epoch: 107, Loss: 1776426.5000, Train_Acc: 0.6346, TEST_Acc: 0.6367, Time: 125.1821\n",
      "Epoch: 108, Loss: 1757042.0000, Train_Acc: 0.6154, TEST_Acc: 0.6300, Time: 126.3159\n",
      "Epoch: 109, Loss: 1790492.5000, Train_Acc: 0.6346, TEST_Acc: 0.6500, Time: 127.4472\n",
      "Epoch: 110, Loss: 1818798.7500, Train_Acc: 0.6346, TEST_Acc: 0.6500, Time: 128.5811\n",
      "Epoch: 111, Loss: 1817673.7500, Train_Acc: 0.6346, TEST_Acc: 0.6533, Time: 129.7146\n",
      "Epoch: 112, Loss: 1812091.7500, Train_Acc: 0.6346, TEST_Acc: 0.6533, Time: 130.8524\n",
      "Epoch: 113, Loss: 1768523.3750, Train_Acc: 0.6346, TEST_Acc: 0.6467, Time: 131.9887\n",
      "Epoch: 114, Loss: 1792010.1250, Train_Acc: 0.6346, TEST_Acc: 0.6500, Time: 133.1247\n",
      "Epoch: 115, Loss: 1767337.2500, Train_Acc: 0.6346, TEST_Acc: 0.6467, Time: 134.2633\n",
      "Epoch: 116, Loss: 1814223.3750, Train_Acc: 0.6346, TEST_Acc: 0.6500, Time: 135.4012\n",
      "Epoch: 117, Loss: 1774183.8750, Train_Acc: 0.6346, TEST_Acc: 0.6467, Time: 136.5410\n",
      "Epoch: 118, Loss: 1783154.5000, Train_Acc: 0.6346, TEST_Acc: 0.6500, Time: 137.6835\n",
      "Epoch: 119, Loss: 1798799.5000, Train_Acc: 0.6346, TEST_Acc: 0.6533, Time: 138.8229\n",
      "Epoch: 120, Loss: 1794850.5000, Train_Acc: 0.6346, TEST_Acc: 0.6533, Time: 139.9610\n",
      "Epoch: 121, Loss: 1794609.2500, Train_Acc: 0.6346, TEST_Acc: 0.6500, Time: 141.1026\n",
      "Epoch: 122, Loss: 1801964.8750, Train_Acc: 0.6346, TEST_Acc: 0.6533, Time: 142.2418\n",
      "Epoch: 123, Loss: 1787224.1250, Train_Acc: 0.6346, TEST_Acc: 0.6433, Time: 143.3734\n",
      "Epoch: 124, Loss: 1828826.8750, Train_Acc: 0.6538, TEST_Acc: 0.6667, Time: 144.5099\n",
      "Epoch: 125, Loss: 1753360.7500, Train_Acc: 0.5962, TEST_Acc: 0.6400, Time: 145.6441\n",
      "Epoch: 126, Loss: 1757816.6250, Train_Acc: 0.5962, TEST_Acc: 0.6433, Time: 146.7828\n",
      "Epoch: 127, Loss: 1749462.7500, Train_Acc: 0.5962, TEST_Acc: 0.6400, Time: 147.9157\n",
      "Epoch: 128, Loss: 1750291.7500, Train_Acc: 0.6154, TEST_Acc: 0.6433, Time: 149.0503\n",
      "Epoch: 129, Loss: 1753085.7500, Train_Acc: 0.6346, TEST_Acc: 0.6467, Time: 150.1850\n",
      "Epoch: 130, Loss: 1755944.2500, Train_Acc: 0.6538, TEST_Acc: 0.6500, Time: 151.3336\n",
      "Epoch: 131, Loss: 1777296.8750, Train_Acc: 0.6538, TEST_Acc: 0.6567, Time: 152.4663\n",
      "Epoch: 132, Loss: 1804602.5000, Train_Acc: 0.6538, TEST_Acc: 0.6700, Time: 153.5989\n",
      "Epoch: 133, Loss: 1758547.5000, Train_Acc: 0.6346, TEST_Acc: 0.6533, Time: 154.7312\n",
      "Epoch: 134, Loss: 1772965.8750, Train_Acc: 0.6538, TEST_Acc: 0.6633, Time: 155.8652\n",
      "Epoch: 135, Loss: 1750823.7500, Train_Acc: 0.6346, TEST_Acc: 0.6500, Time: 157.0019\n",
      "Epoch: 136, Loss: 1752953.2500, Train_Acc: 0.6346, TEST_Acc: 0.6533, Time: 158.1369\n",
      "Epoch: 137, Loss: 1767720.8750, Train_Acc: 0.6538, TEST_Acc: 0.6667, Time: 159.2684\n",
      "Epoch: 138, Loss: 1743870.2500, Train_Acc: 0.6346, TEST_Acc: 0.6567, Time: 160.4044\n",
      "Epoch: 139, Loss: 1747856.1250, Train_Acc: 0.6346, TEST_Acc: 0.6633, Time: 161.5420\n",
      "Epoch: 140, Loss: 1754568.2500, Train_Acc: 0.6346, TEST_Acc: 0.6633, Time: 162.6880\n",
      "Epoch: 141, Loss: 1738308.2500, Train_Acc: 0.6346, TEST_Acc: 0.6600, Time: 163.8264\n",
      "Epoch: 142, Loss: 1713215.3750, Train_Acc: 0.6346, TEST_Acc: 0.6533, Time: 164.9640\n",
      "Epoch: 143, Loss: 1707204.0000, Train_Acc: 0.6346, TEST_Acc: 0.6533, Time: 166.1046\n",
      "Epoch: 144, Loss: 1707982.5000, Train_Acc: 0.6346, TEST_Acc: 0.6500, Time: 167.2367\n",
      "Epoch: 145, Loss: 1735518.1250, Train_Acc: 0.6346, TEST_Acc: 0.6667, Time: 168.3711\n",
      "Epoch: 146, Loss: 1735658.7500, Train_Acc: 0.6346, TEST_Acc: 0.6667, Time: 169.5069\n",
      "Epoch: 147, Loss: 1697328.0000, Train_Acc: 0.6346, TEST_Acc: 0.6567, Time: 170.6427\n",
      "Epoch: 148, Loss: 1717122.1250, Train_Acc: 0.6346, TEST_Acc: 0.6700, Time: 171.7797\n",
      "Epoch: 149, Loss: 1688317.8750, Train_Acc: 0.6346, TEST_Acc: 0.6667, Time: 172.9091\n",
      "Epoch: 150, Loss: 1663207.8750, Train_Acc: 0.6346, TEST_Acc: 0.6567, Time: 174.0390\n",
      "Epoch: 151, Loss: 1648489.5000, Train_Acc: 0.6346, TEST_Acc: 0.6600, Time: 175.1729\n",
      "Epoch: 152, Loss: 1628811.1250, Train_Acc: 0.6154, TEST_Acc: 0.6567, Time: 176.3054\n",
      "Epoch: 153, Loss: 1658490.5000, Train_Acc: 0.6538, TEST_Acc: 0.6700, Time: 177.4406\n",
      "Epoch: 154, Loss: 1660164.0000, Train_Acc: 0.6538, TEST_Acc: 0.6700, Time: 178.5779\n",
      "Epoch: 155, Loss: 1646925.2500, Train_Acc: 0.6538, TEST_Acc: 0.6700, Time: 179.7139\n",
      "Epoch: 156, Loss: 1626120.0000, Train_Acc: 0.6538, TEST_Acc: 0.6700, Time: 180.8512\n",
      "Epoch: 157, Loss: 1619134.7500, Train_Acc: 0.6538, TEST_Acc: 0.6700, Time: 181.9878\n",
      "Epoch: 158, Loss: 1651136.0000, Train_Acc: 0.6538, TEST_Acc: 0.6733, Time: 183.1194\n",
      "Epoch: 159, Loss: 1590903.2500, Train_Acc: 0.6538, TEST_Acc: 0.6633, Time: 184.2541\n",
      "Epoch: 160, Loss: 1610412.7500, Train_Acc: 0.6538, TEST_Acc: 0.6700, Time: 185.3887\n",
      "Epoch: 161, Loss: 1567899.5000, Train_Acc: 0.6346, TEST_Acc: 0.6600, Time: 186.5212\n",
      "Epoch: 162, Loss: 1609099.7500, Train_Acc: 0.6538, TEST_Acc: 0.6700, Time: 187.6548\n",
      "Epoch: 163, Loss: 1574800.2500, Train_Acc: 0.6538, TEST_Acc: 0.6733, Time: 188.7876\n",
      "Epoch: 164, Loss: 1552293.3750, Train_Acc: 0.6346, TEST_Acc: 0.6700, Time: 189.9196\n",
      "Epoch: 165, Loss: 1567118.5000, Train_Acc: 0.6538, TEST_Acc: 0.6700, Time: 191.0585\n",
      "Epoch: 166, Loss: 1549577.3750, Train_Acc: 0.6538, TEST_Acc: 0.6700, Time: 192.1930\n",
      "Epoch: 167, Loss: 1522860.2500, Train_Acc: 0.6346, TEST_Acc: 0.6700, Time: 193.3395\n",
      "Epoch: 168, Loss: 1479849.5000, Train_Acc: 0.5962, TEST_Acc: 0.6600, Time: 194.4895\n",
      "Epoch: 169, Loss: 1536843.5000, Train_Acc: 0.6538, TEST_Acc: 0.6767, Time: 195.6357\n",
      "Epoch: 170, Loss: 1493463.2500, Train_Acc: 0.6346, TEST_Acc: 0.6733, Time: 196.7831\n",
      "Epoch: 171, Loss: 1457902.1250, Train_Acc: 0.6154, TEST_Acc: 0.6667, Time: 197.9214\n",
      "Epoch: 172, Loss: 1470758.5000, Train_Acc: 0.6154, TEST_Acc: 0.6700, Time: 199.0621\n",
      "Epoch: 173, Loss: 1508600.1250, Train_Acc: 0.6538, TEST_Acc: 0.6833, Time: 200.1953\n",
      "Epoch: 174, Loss: 1480172.1250, Train_Acc: 0.6346, TEST_Acc: 0.6800, Time: 201.3280\n",
      "Epoch: 175, Loss: 1460267.5000, Train_Acc: 0.6346, TEST_Acc: 0.6767, Time: 202.4588\n",
      "Epoch: 176, Loss: 1439945.2500, Train_Acc: 0.6154, TEST_Acc: 0.6667, Time: 203.5922\n",
      "Epoch: 177, Loss: 1432040.0000, Train_Acc: 0.6154, TEST_Acc: 0.6667, Time: 204.7354\n",
      "Epoch: 178, Loss: 1441622.2500, Train_Acc: 0.6346, TEST_Acc: 0.6800, Time: 205.8626\n",
      "Epoch: 179, Loss: 1410305.2500, Train_Acc: 0.6154, TEST_Acc: 0.6733, Time: 206.9969\n",
      "Epoch: 180, Loss: 1402370.8750, Train_Acc: 0.6154, TEST_Acc: 0.6733, Time: 208.1295\n",
      "Epoch: 181, Loss: 1385393.5000, Train_Acc: 0.6154, TEST_Acc: 0.6700, Time: 209.2626\n",
      "Epoch: 182, Loss: 1373663.2500, Train_Acc: 0.6154, TEST_Acc: 0.6733, Time: 210.3997\n",
      "Epoch: 183, Loss: 1366533.5000, Train_Acc: 0.6154, TEST_Acc: 0.6733, Time: 211.5338\n",
      "Epoch: 184, Loss: 1361721.5000, Train_Acc: 0.6154, TEST_Acc: 0.6767, Time: 212.6728\n",
      "Epoch: 185, Loss: 1333017.3750, Train_Acc: 0.6154, TEST_Acc: 0.6667, Time: 213.8062\n",
      "Epoch: 186, Loss: 1341389.7500, Train_Acc: 0.5962, TEST_Acc: 0.6800, Time: 214.9362\n",
      "Epoch: 187, Loss: 1333906.1250, Train_Acc: 0.5962, TEST_Acc: 0.6800, Time: 216.0683\n",
      "Epoch: 188, Loss: 1318775.5000, Train_Acc: 0.5962, TEST_Acc: 0.6767, Time: 217.2034\n",
      "Epoch: 189, Loss: 1322604.6250, Train_Acc: 0.5962, TEST_Acc: 0.6800, Time: 218.3340\n",
      "Epoch: 190, Loss: 1316217.5000, Train_Acc: 0.5962, TEST_Acc: 0.6833, Time: 219.4657\n",
      "Epoch: 191, Loss: 1301730.1250, Train_Acc: 0.5962, TEST_Acc: 0.6867, Time: 220.6034\n",
      "Epoch: 192, Loss: 1286083.6250, Train_Acc: 0.5962, TEST_Acc: 0.6800, Time: 221.7340\n",
      "Epoch: 193, Loss: 1271148.1250, Train_Acc: 0.6154, TEST_Acc: 0.6767, Time: 222.8706\n",
      "Epoch: 194, Loss: 1275322.6250, Train_Acc: 0.5962, TEST_Acc: 0.6767, Time: 224.0079\n",
      "Epoch: 195, Loss: 1283355.8750, Train_Acc: 0.6154, TEST_Acc: 0.6767, Time: 225.1473\n",
      "Epoch: 196, Loss: 1266928.2500, Train_Acc: 0.5962, TEST_Acc: 0.6767, Time: 226.2853\n",
      "Epoch: 197, Loss: 1269591.1250, Train_Acc: 0.6154, TEST_Acc: 0.6767, Time: 227.4191\n",
      "Epoch: 198, Loss: 1245272.8750, Train_Acc: 0.5962, TEST_Acc: 0.6767, Time: 228.5527\n",
      "Epoch: 199, Loss: 1233132.5000, Train_Acc: 0.5962, TEST_Acc: 0.6733, Time: 229.6945\n",
      "Epoch: 200, Loss: 1240558.0000, Train_Acc: 0.6154, TEST_Acc: 0.6800, Time: 230.8300\n",
      "Epoch: 201, Loss: 1217812.5000, Train_Acc: 0.6154, TEST_Acc: 0.6733, Time: 231.9630\n",
      "Epoch: 202, Loss: 1212766.8750, Train_Acc: 0.6154, TEST_Acc: 0.6733, Time: 233.0988\n",
      "Epoch: 203, Loss: 1207262.6250, Train_Acc: 0.5962, TEST_Acc: 0.6733, Time: 234.2321\n",
      "Epoch: 204, Loss: 1194243.7500, Train_Acc: 0.5962, TEST_Acc: 0.6767, Time: 235.3652\n",
      "Epoch: 205, Loss: 1172592.0000, Train_Acc: 0.6154, TEST_Acc: 0.6767, Time: 236.4968\n",
      "Epoch: 206, Loss: 1171976.2500, Train_Acc: 0.5962, TEST_Acc: 0.6733, Time: 237.6310\n",
      "Epoch: 207, Loss: 1167033.7500, Train_Acc: 0.5962, TEST_Acc: 0.6733, Time: 238.7671\n",
      "Epoch: 208, Loss: 1169831.1250, Train_Acc: 0.6154, TEST_Acc: 0.6833, Time: 239.9067\n",
      "Epoch: 209, Loss: 1151007.0000, Train_Acc: 0.5962, TEST_Acc: 0.6733, Time: 241.0410\n",
      "Epoch: 210, Loss: 1158371.2500, Train_Acc: 0.6154, TEST_Acc: 0.6800, Time: 242.1767\n",
      "Epoch: 211, Loss: 1132725.1250, Train_Acc: 0.5962, TEST_Acc: 0.6767, Time: 243.3113\n",
      "Epoch: 212, Loss: 1140593.1250, Train_Acc: 0.6154, TEST_Acc: 0.6733, Time: 244.4433\n",
      "Epoch: 213, Loss: 1137490.0000, Train_Acc: 0.6154, TEST_Acc: 0.6767, Time: 245.5781\n",
      "Epoch: 214, Loss: 1117707.3750, Train_Acc: 0.5962, TEST_Acc: 0.6733, Time: 246.7162\n",
      "Epoch: 215, Loss: 1110603.8750, Train_Acc: 0.5962, TEST_Acc: 0.6700, Time: 247.8503\n",
      "Epoch: 216, Loss: 1101600.7500, Train_Acc: 0.5962, TEST_Acc: 0.6667, Time: 248.9855\n",
      "Epoch: 217, Loss: 1098388.0000, Train_Acc: 0.6154, TEST_Acc: 0.6633, Time: 250.1207\n",
      "Epoch: 218, Loss: 1085642.5000, Train_Acc: 0.6154, TEST_Acc: 0.6700, Time: 251.2552\n",
      "Epoch: 219, Loss: 1077267.3750, Train_Acc: 0.6154, TEST_Acc: 0.6667, Time: 252.3898\n",
      "Epoch: 220, Loss: 1074828.0000, Train_Acc: 0.6154, TEST_Acc: 0.6667, Time: 253.5244\n",
      "Epoch: 221, Loss: 1059726.2500, Train_Acc: 0.6154, TEST_Acc: 0.6667, Time: 254.6671\n",
      "Epoch: 222, Loss: 1034166.0625, Train_Acc: 0.5962, TEST_Acc: 0.6667, Time: 255.8015\n",
      "Epoch: 223, Loss: 1042215.3125, Train_Acc: 0.6154, TEST_Acc: 0.6667, Time: 256.9406\n",
      "Epoch: 224, Loss: 1042181.1250, Train_Acc: 0.6154, TEST_Acc: 0.6733, Time: 258.0782\n",
      "Epoch: 225, Loss: 1040205.3750, Train_Acc: 0.6154, TEST_Acc: 0.6700, Time: 259.2154\n",
      "Epoch: 226, Loss: 1039838.6250, Train_Acc: 0.6154, TEST_Acc: 0.6800, Time: 260.3534\n",
      "Epoch: 227, Loss: 1020600.6250, Train_Acc: 0.6154, TEST_Acc: 0.6667, Time: 261.4884\n",
      "Epoch: 228, Loss: 1009966.1250, Train_Acc: 0.6154, TEST_Acc: 0.6667, Time: 262.6224\n",
      "Epoch: 229, Loss: 984495.8750, Train_Acc: 0.5769, TEST_Acc: 0.6667, Time: 263.7560\n",
      "Epoch: 230, Loss: 979894.7500, Train_Acc: 0.5769, TEST_Acc: 0.6667, Time: 264.8877\n",
      "Epoch: 231, Loss: 985502.1250, Train_Acc: 0.5962, TEST_Acc: 0.6667, Time: 266.0194\n",
      "Epoch: 232, Loss: 966243.6875, Train_Acc: 0.5962, TEST_Acc: 0.6633, Time: 267.1537\n",
      "Epoch: 233, Loss: 964547.3125, Train_Acc: 0.5962, TEST_Acc: 0.6667, Time: 268.2856\n",
      "Epoch: 234, Loss: 955373.2500, Train_Acc: 0.5769, TEST_Acc: 0.6700, Time: 269.4303\n",
      "Epoch: 235, Loss: 945572.6250, Train_Acc: 0.5577, TEST_Acc: 0.6633, Time: 270.5637\n",
      "Epoch: 236, Loss: 949897.0000, Train_Acc: 0.5962, TEST_Acc: 0.6633, Time: 271.7157\n",
      "Epoch: 237, Loss: 954101.2500, Train_Acc: 0.6154, TEST_Acc: 0.6633, Time: 272.8512\n",
      "Epoch: 238, Loss: 950112.6250, Train_Acc: 0.6154, TEST_Acc: 0.6700, Time: 273.9863\n",
      "Epoch: 239, Loss: 926087.1250, Train_Acc: 0.5962, TEST_Acc: 0.6633, Time: 275.1181\n",
      "Epoch: 240, Loss: 923949.4375, Train_Acc: 0.6154, TEST_Acc: 0.6633, Time: 276.2533\n",
      "Epoch: 241, Loss: 938416.2500, Train_Acc: 0.6154, TEST_Acc: 0.6833, Time: 277.3859\n",
      "Epoch: 242, Loss: 899966.7500, Train_Acc: 0.5577, TEST_Acc: 0.6600, Time: 278.5161\n",
      "Epoch: 243, Loss: 928800.0625, Train_Acc: 0.6154, TEST_Acc: 0.6833, Time: 279.6541\n",
      "Epoch: 244, Loss: 898442.9375, Train_Acc: 0.5962, TEST_Acc: 0.6767, Time: 280.7883\n",
      "Epoch: 245, Loss: 888256.4375, Train_Acc: 0.5769, TEST_Acc: 0.6667, Time: 281.9201\n",
      "Epoch: 246, Loss: 886036.5625, Train_Acc: 0.5962, TEST_Acc: 0.6767, Time: 283.0534\n",
      "Epoch: 247, Loss: 872658.4375, Train_Acc: 0.5577, TEST_Acc: 0.6600, Time: 284.1855\n",
      "Epoch: 248, Loss: 856222.9375, Train_Acc: 0.5385, TEST_Acc: 0.6633, Time: 285.3208\n",
      "Epoch: 249, Loss: 866319.2500, Train_Acc: 0.5962, TEST_Acc: 0.6767, Time: 286.4571\n",
      "Epoch: 250, Loss: 862520.1250, Train_Acc: 0.5962, TEST_Acc: 0.6733, Time: 287.5916\n",
      "Epoch: 251, Loss: 864961.6875, Train_Acc: 0.5962, TEST_Acc: 0.6767, Time: 288.7338\n",
      "Epoch: 252, Loss: 869534.0000, Train_Acc: 0.5962, TEST_Acc: 0.6933, Time: 289.8736\n",
      "Epoch: 253, Loss: 843596.1250, Train_Acc: 0.5769, TEST_Acc: 0.6733, Time: 291.0134\n",
      "Epoch: 254, Loss: 831732.0000, Train_Acc: 0.5385, TEST_Acc: 0.6667, Time: 292.1460\n",
      "Epoch: 255, Loss: 826730.4375, Train_Acc: 0.5385, TEST_Acc: 0.6733, Time: 293.2784\n",
      "Epoch: 256, Loss: 824851.0625, Train_Acc: 0.5385, TEST_Acc: 0.6700, Time: 294.4133\n",
      "Epoch: 257, Loss: 826655.3750, Train_Acc: 0.5769, TEST_Acc: 0.6700, Time: 295.5455\n",
      "Epoch: 258, Loss: 813666.9375, Train_Acc: 0.5385, TEST_Acc: 0.6733, Time: 296.6763\n",
      "Epoch: 259, Loss: 810030.9375, Train_Acc: 0.5577, TEST_Acc: 0.6700, Time: 297.8086\n",
      "Epoch: 260, Loss: 808951.7500, Train_Acc: 0.5577, TEST_Acc: 0.6767, Time: 298.9407\n",
      "Epoch: 261, Loss: 798772.0000, Train_Acc: 0.5385, TEST_Acc: 0.6700, Time: 300.0800\n",
      "Epoch: 262, Loss: 805531.3750, Train_Acc: 0.5769, TEST_Acc: 0.6867, Time: 301.2173\n",
      "Epoch: 263, Loss: 790511.6875, Train_Acc: 0.5385, TEST_Acc: 0.6700, Time: 302.3568\n",
      "Epoch: 264, Loss: 783912.6250, Train_Acc: 0.5385, TEST_Acc: 0.6700, Time: 303.4960\n",
      "Epoch: 265, Loss: 785548.0000, Train_Acc: 0.5385, TEST_Acc: 0.6700, Time: 304.6310\n",
      "Epoch: 266, Loss: 782487.5625, Train_Acc: 0.5385, TEST_Acc: 0.6667, Time: 305.7684\n",
      "Epoch: 267, Loss: 784019.9375, Train_Acc: 0.5577, TEST_Acc: 0.6833, Time: 306.9060\n",
      "Epoch: 268, Loss: 780335.3750, Train_Acc: 0.5577, TEST_Acc: 0.6867, Time: 308.0371\n",
      "Epoch: 269, Loss: 764316.9375, Train_Acc: 0.5385, TEST_Acc: 0.6700, Time: 309.1718\n",
      "Epoch: 270, Loss: 756129.3125, Train_Acc: 0.5385, TEST_Acc: 0.6733, Time: 310.3001\n",
      "Epoch: 271, Loss: 755699.4375, Train_Acc: 0.5385, TEST_Acc: 0.6733, Time: 311.4395\n",
      "Epoch: 272, Loss: 749926.3750, Train_Acc: 0.5577, TEST_Acc: 0.6700, Time: 312.5724\n",
      "Epoch: 273, Loss: 746025.7500, Train_Acc: 0.5577, TEST_Acc: 0.6700, Time: 313.7064\n",
      "Epoch: 274, Loss: 743561.6875, Train_Acc: 0.5577, TEST_Acc: 0.6700, Time: 314.8410\n",
      "Epoch: 275, Loss: 738742.0625, Train_Acc: 0.5577, TEST_Acc: 0.6733, Time: 315.9745\n",
      "Epoch: 276, Loss: 737911.5625, Train_Acc: 0.5577, TEST_Acc: 0.6700, Time: 317.1074\n",
      "Epoch: 277, Loss: 734929.3750, Train_Acc: 0.5577, TEST_Acc: 0.6700, Time: 318.2426\n",
      "Epoch: 278, Loss: 738320.6250, Train_Acc: 0.5577, TEST_Acc: 0.6833, Time: 319.3807\n",
      "Epoch: 279, Loss: 726289.6875, Train_Acc: 0.5577, TEST_Acc: 0.6667, Time: 320.5235\n",
      "Epoch: 280, Loss: 710347.0625, Train_Acc: 0.5385, TEST_Acc: 0.6667, Time: 321.6623\n",
      "Epoch: 281, Loss: 707415.8750, Train_Acc: 0.5577, TEST_Acc: 0.6667, Time: 322.7997\n",
      "Epoch: 282, Loss: 700776.2500, Train_Acc: 0.5385, TEST_Acc: 0.6700, Time: 323.9334\n",
      "Epoch: 283, Loss: 703942.1250, Train_Acc: 0.5577, TEST_Acc: 0.6700, Time: 325.0646\n",
      "Epoch: 284, Loss: 705093.2500, Train_Acc: 0.5577, TEST_Acc: 0.6767, Time: 326.1932\n",
      "Epoch: 285, Loss: 702852.2500, Train_Acc: 0.5577, TEST_Acc: 0.6767, Time: 327.3244\n",
      "Epoch: 286, Loss: 696597.3125, Train_Acc: 0.5577, TEST_Acc: 0.6767, Time: 328.4626\n",
      "Epoch: 287, Loss: 695216.3750, Train_Acc: 0.5577, TEST_Acc: 0.6733, Time: 329.5938\n",
      "Epoch: 288, Loss: 697792.3750, Train_Acc: 0.5577, TEST_Acc: 0.6867, Time: 330.7233\n",
      "Epoch: 289, Loss: 686209.5625, Train_Acc: 0.5577, TEST_Acc: 0.6767, Time: 331.8616\n",
      "Epoch: 290, Loss: 677508.7500, Train_Acc: 0.5577, TEST_Acc: 0.6700, Time: 332.9948\n",
      "Epoch: 291, Loss: 678106.3125, Train_Acc: 0.5769, TEST_Acc: 0.6767, Time: 334.1321\n",
      "Epoch: 292, Loss: 675078.7500, Train_Acc: 0.5769, TEST_Acc: 0.6800, Time: 335.2671\n",
      "Epoch: 293, Loss: 674180.6250, Train_Acc: 0.5769, TEST_Acc: 0.6800, Time: 336.4075\n",
      "Epoch: 294, Loss: 666322.3750, Train_Acc: 0.5577, TEST_Acc: 0.6767, Time: 337.5397\n",
      "Epoch: 295, Loss: 668227.3750, Train_Acc: 0.5577, TEST_Acc: 0.6867, Time: 338.6668\n",
      "Epoch: 296, Loss: 664192.9375, Train_Acc: 0.5577, TEST_Acc: 0.6833, Time: 339.7997\n",
      "Epoch: 297, Loss: 653574.7500, Train_Acc: 0.5577, TEST_Acc: 0.6767, Time: 340.9329\n",
      "Epoch: 298, Loss: 652116.7500, Train_Acc: 0.5769, TEST_Acc: 0.6733, Time: 342.0606\n",
      "Epoch: 299, Loss: 657540.7500, Train_Acc: 0.5577, TEST_Acc: 0.6900, Time: 343.1902\n",
      "Epoch: 300, Loss: 648608.0000, Train_Acc: 0.5577, TEST_Acc: 0.6700, Time: 344.3256\n",
      "Epoch: 301, Loss: 648952.2500, Train_Acc: 0.5769, TEST_Acc: 0.6800, Time: 345.4587\n",
      "Epoch: 302, Loss: 646513.5625, Train_Acc: 0.5769, TEST_Acc: 0.6800, Time: 346.5934\n",
      "Epoch: 303, Loss: 644244.4375, Train_Acc: 0.5769, TEST_Acc: 0.6800, Time: 347.7270\n",
      "Epoch: 304, Loss: 647300.2500, Train_Acc: 0.5769, TEST_Acc: 0.6867, Time: 348.8621\n",
      "Epoch: 305, Loss: 640704.3750, Train_Acc: 0.5769, TEST_Acc: 0.6800, Time: 350.0001\n",
      "Epoch: 306, Loss: 637333.5625, Train_Acc: 0.5769, TEST_Acc: 0.6800, Time: 351.1398\n",
      "Epoch: 307, Loss: 637659.0625, Train_Acc: 0.5769, TEST_Acc: 0.6833, Time: 352.2755\n",
      "Epoch: 308, Loss: 633709.8750, Train_Acc: 0.5769, TEST_Acc: 0.6867, Time: 353.4080\n",
      "Epoch: 309, Loss: 639775.5625, Train_Acc: 0.5962, TEST_Acc: 0.6900, Time: 354.5479\n",
      "Epoch: 310, Loss: 635488.8750, Train_Acc: 0.5962, TEST_Acc: 0.6867, Time: 355.6823\n",
      "Epoch: 311, Loss: 630049.0625, Train_Acc: 0.5769, TEST_Acc: 0.6900, Time: 356.8155\n",
      "Epoch: 312, Loss: 623515.0625, Train_Acc: 0.5962, TEST_Acc: 0.6867, Time: 357.9382\n",
      "Epoch: 313, Loss: 622948.5625, Train_Acc: 0.5769, TEST_Acc: 0.6833, Time: 359.0712\n",
      "Epoch: 314, Loss: 629958.6250, Train_Acc: 0.5769, TEST_Acc: 0.6867, Time: 360.2027\n",
      "Epoch: 315, Loss: 622959.2500, Train_Acc: 0.5769, TEST_Acc: 0.6933, Time: 361.3373\n",
      "Epoch: 316, Loss: 624183.8125, Train_Acc: 0.5769, TEST_Acc: 0.6900, Time: 362.4740\n",
      "Epoch: 317, Loss: 623134.7500, Train_Acc: 0.5769, TEST_Acc: 0.6867, Time: 363.6082\n",
      "Epoch: 318, Loss: 618618.5625, Train_Acc: 0.5769, TEST_Acc: 0.6900, Time: 364.7422\n",
      "Epoch: 319, Loss: 617527.5625, Train_Acc: 0.5769, TEST_Acc: 0.6900, Time: 365.8808\n",
      "Epoch: 320, Loss: 617891.9375, Train_Acc: 0.5769, TEST_Acc: 0.6833, Time: 367.0094\n",
      "Epoch: 321, Loss: 617973.2500, Train_Acc: 0.5962, TEST_Acc: 0.6933, Time: 368.1372\n",
      "Epoch: 322, Loss: 614438.3750, Train_Acc: 0.5769, TEST_Acc: 0.6900, Time: 369.2644\n",
      "Epoch: 323, Loss: 610338.1250, Train_Acc: 0.5769, TEST_Acc: 0.6933, Time: 370.3904\n",
      "Epoch: 324, Loss: 605467.1250, Train_Acc: 0.5769, TEST_Acc: 0.6867, Time: 371.5262\n",
      "Epoch: 325, Loss: 606676.5625, Train_Acc: 0.5769, TEST_Acc: 0.6900, Time: 372.6607\n",
      "Epoch: 326, Loss: 601848.1875, Train_Acc: 0.5769, TEST_Acc: 0.6867, Time: 373.7909\n",
      "Epoch: 327, Loss: 603142.4375, Train_Acc: 0.5962, TEST_Acc: 0.6933, Time: 374.9274\n",
      "Epoch: 328, Loss: 591809.1250, Train_Acc: 0.5769, TEST_Acc: 0.6900, Time: 376.0609\n",
      "Epoch: 329, Loss: 593623.3750, Train_Acc: 0.5769, TEST_Acc: 0.6900, Time: 377.1917\n",
      "Epoch: 330, Loss: 588512.6875, Train_Acc: 0.5769, TEST_Acc: 0.6833, Time: 378.3284\n",
      "Epoch: 331, Loss: 590309.1250, Train_Acc: 0.5962, TEST_Acc: 0.6933, Time: 379.4719\n",
      "Epoch: 332, Loss: 584716.6250, Train_Acc: 0.5962, TEST_Acc: 0.6800, Time: 380.6042\n",
      "Epoch: 333, Loss: 578540.0625, Train_Acc: 0.5962, TEST_Acc: 0.6833, Time: 381.7403\n",
      "Epoch: 334, Loss: 578056.2500, Train_Acc: 0.5962, TEST_Acc: 0.6833, Time: 382.8715\n",
      "Epoch: 335, Loss: 575856.7500, Train_Acc: 0.5962, TEST_Acc: 0.6867, Time: 383.9955\n",
      "Epoch: 336, Loss: 576045.4375, Train_Acc: 0.5962, TEST_Acc: 0.6867, Time: 385.1262\n",
      "Epoch: 337, Loss: 576939.8750, Train_Acc: 0.5962, TEST_Acc: 0.6900, Time: 386.2578\n",
      "Epoch: 338, Loss: 575062.6250, Train_Acc: 0.5962, TEST_Acc: 0.6833, Time: 387.3923\n",
      "Epoch: 339, Loss: 571248.6250, Train_Acc: 0.5962, TEST_Acc: 0.6800, Time: 388.5259\n",
      "Epoch: 340, Loss: 570743.5625, Train_Acc: 0.5962, TEST_Acc: 0.6800, Time: 389.6587\n",
      "Epoch: 341, Loss: 574359.7500, Train_Acc: 0.5962, TEST_Acc: 0.6933, Time: 390.7927\n",
      "Epoch: 342, Loss: 571699.9375, Train_Acc: 0.5962, TEST_Acc: 0.6967, Time: 391.9334\n",
      "Epoch: 343, Loss: 572915.3750, Train_Acc: 0.5962, TEST_Acc: 0.6933, Time: 393.0676\n",
      "Epoch: 344, Loss: 568411.7500, Train_Acc: 0.5769, TEST_Acc: 0.6967, Time: 394.2060\n",
      "Epoch: 345, Loss: 561805.1250, Train_Acc: 0.5962, TEST_Acc: 0.6900, Time: 395.3423\n",
      "Epoch: 346, Loss: 558515.6875, Train_Acc: 0.5962, TEST_Acc: 0.6867, Time: 396.4858\n",
      "Epoch: 347, Loss: 556355.3750, Train_Acc: 0.5962, TEST_Acc: 0.6900, Time: 397.6298\n",
      "Epoch: 348, Loss: 557798.7500, Train_Acc: 0.5962, TEST_Acc: 0.6967, Time: 398.7620\n",
      "Epoch: 349, Loss: 549251.5625, Train_Acc: 0.5962, TEST_Acc: 0.6933, Time: 399.8942\n",
      "Epoch: 350, Loss: 548893.0625, Train_Acc: 0.5962, TEST_Acc: 0.6933, Time: 401.0282\n",
      "Epoch: 351, Loss: 551394.2500, Train_Acc: 0.5962, TEST_Acc: 0.6933, Time: 402.1643\n",
      "Epoch: 352, Loss: 544527.4375, Train_Acc: 0.5962, TEST_Acc: 0.6933, Time: 403.2951\n",
      "Epoch: 353, Loss: 544011.6250, Train_Acc: 0.5962, TEST_Acc: 0.6900, Time: 404.4283\n",
      "Epoch: 354, Loss: 538314.9375, Train_Acc: 0.5962, TEST_Acc: 0.6833, Time: 405.5607\n",
      "Epoch: 355, Loss: 537360.0625, Train_Acc: 0.5962, TEST_Acc: 0.6867, Time: 406.6947\n",
      "Epoch: 356, Loss: 534520.7500, Train_Acc: 0.6154, TEST_Acc: 0.6967, Time: 407.8324\n",
      "Epoch: 357, Loss: 536788.4375, Train_Acc: 0.6154, TEST_Acc: 0.6967, Time: 408.9727\n",
      "Epoch: 358, Loss: 534237.0625, Train_Acc: 0.6154, TEST_Acc: 0.7000, Time: 410.1096\n",
      "Epoch: 359, Loss: 537274.8125, Train_Acc: 0.6154, TEST_Acc: 0.6967, Time: 411.2477\n",
      "Epoch: 360, Loss: 530201.5000, Train_Acc: 0.6154, TEST_Acc: 0.6933, Time: 412.3805\n",
      "Epoch: 361, Loss: 528640.9375, Train_Acc: 0.6154, TEST_Acc: 0.6933, Time: 413.5161\n",
      "Epoch: 362, Loss: 523234.0000, Train_Acc: 0.6154, TEST_Acc: 0.6933, Time: 414.6481\n",
      "Epoch: 363, Loss: 523828.1562, Train_Acc: 0.6154, TEST_Acc: 0.6933, Time: 415.7824\n",
      "Epoch: 364, Loss: 521709.6250, Train_Acc: 0.6154, TEST_Acc: 0.7000, Time: 416.9126\n",
      "Epoch: 365, Loss: 518474.4688, Train_Acc: 0.6154, TEST_Acc: 0.7000, Time: 418.0469\n",
      "Epoch: 366, Loss: 519100.6250, Train_Acc: 0.6154, TEST_Acc: 0.7000, Time: 419.1851\n",
      "Epoch: 367, Loss: 522461.6562, Train_Acc: 0.6154, TEST_Acc: 0.7000, Time: 420.3161\n",
      "Epoch: 368, Loss: 510048.3750, Train_Acc: 0.6154, TEST_Acc: 0.7000, Time: 421.4432\n",
      "Epoch: 369, Loss: 505886.7812, Train_Acc: 0.6154, TEST_Acc: 0.7000, Time: 422.5775\n",
      "Epoch: 370, Loss: 506573.7812, Train_Acc: 0.6154, TEST_Acc: 0.7033, Time: 423.7086\n",
      "Epoch: 371, Loss: 497474.8438, Train_Acc: 0.6154, TEST_Acc: 0.7000, Time: 424.8451\n",
      "Epoch: 372, Loss: 493459.9688, Train_Acc: 0.6154, TEST_Acc: 0.7000, Time: 425.9774\n",
      "Epoch: 373, Loss: 494272.7812, Train_Acc: 0.6154, TEST_Acc: 0.7000, Time: 427.1077\n",
      "Epoch: 374, Loss: 491220.3125, Train_Acc: 0.6154, TEST_Acc: 0.6967, Time: 428.2537\n",
      "Epoch: 375, Loss: 492930.4375, Train_Acc: 0.6154, TEST_Acc: 0.7000, Time: 429.3937\n",
      "Epoch: 376, Loss: 495872.9375, Train_Acc: 0.6154, TEST_Acc: 0.7033, Time: 430.5250\n",
      "Epoch: 377, Loss: 488165.8750, Train_Acc: 0.6154, TEST_Acc: 0.6967, Time: 431.6568\n",
      "Epoch: 378, Loss: 485233.9375, Train_Acc: 0.6154, TEST_Acc: 0.6967, Time: 432.7844\n",
      "Epoch: 379, Loss: 483945.5625, Train_Acc: 0.6154, TEST_Acc: 0.6967, Time: 433.9171\n",
      "Epoch: 380, Loss: 483656.0000, Train_Acc: 0.6154, TEST_Acc: 0.7000, Time: 435.0450\n",
      "Epoch: 381, Loss: 476709.2188, Train_Acc: 0.6154, TEST_Acc: 0.6967, Time: 436.1782\n",
      "Epoch: 382, Loss: 475822.9375, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 437.3060\n",
      "Epoch: 383, Loss: 473159.6875, Train_Acc: 0.6154, TEST_Acc: 0.7000, Time: 438.4428\n",
      "Epoch: 384, Loss: 467132.1562, Train_Acc: 0.6346, TEST_Acc: 0.6967, Time: 439.5770\n",
      "Epoch: 385, Loss: 474777.4688, Train_Acc: 0.6346, TEST_Acc: 0.7067, Time: 440.7220\n",
      "Epoch: 386, Loss: 464948.1250, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 441.8568\n",
      "Epoch: 387, Loss: 464507.0625, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 442.9938\n",
      "Epoch: 388, Loss: 463851.4375, Train_Acc: 0.6538, TEST_Acc: 0.7067, Time: 444.1307\n",
      "Epoch: 389, Loss: 456112.5312, Train_Acc: 0.6346, TEST_Acc: 0.6967, Time: 445.2623\n",
      "Epoch: 390, Loss: 456593.0625, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 446.3925\n",
      "Epoch: 391, Loss: 451826.2188, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 447.5270\n",
      "Epoch: 392, Loss: 445923.0625, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 448.6619\n",
      "Epoch: 393, Loss: 451756.7188, Train_Acc: 0.6154, TEST_Acc: 0.7033, Time: 449.8229\n",
      "Epoch: 394, Loss: 440804.3750, Train_Acc: 0.6154, TEST_Acc: 0.6967, Time: 450.9614\n",
      "Epoch: 395, Loss: 443186.1562, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 452.0943\n",
      "Epoch: 396, Loss: 443256.3125, Train_Acc: 0.6154, TEST_Acc: 0.6967, Time: 453.2299\n",
      "Epoch: 397, Loss: 438086.1562, Train_Acc: 0.6154, TEST_Acc: 0.6967, Time: 454.3685\n",
      "Epoch: 398, Loss: 438988.2812, Train_Acc: 0.6154, TEST_Acc: 0.6967, Time: 455.5034\n",
      "Epoch: 399, Loss: 437532.8125, Train_Acc: 0.6154, TEST_Acc: 0.6967, Time: 456.6401\n",
      "Epoch: 400, Loss: 439043.0000, Train_Acc: 0.6154, TEST_Acc: 0.7000, Time: 457.7776\n",
      "Epoch: 401, Loss: 446034.3750, Train_Acc: 0.6346, TEST_Acc: 0.7100, Time: 458.9110\n",
      "Epoch: 402, Loss: 434048.5312, Train_Acc: 0.6346, TEST_Acc: 0.7100, Time: 460.0443\n",
      "Epoch: 403, Loss: 429648.6250, Train_Acc: 0.6538, TEST_Acc: 0.7067, Time: 461.1724\n",
      "Epoch: 404, Loss: 429265.5312, Train_Acc: 0.6538, TEST_Acc: 0.7033, Time: 462.3099\n",
      "Epoch: 405, Loss: 437716.3125, Train_Acc: 0.6346, TEST_Acc: 0.7067, Time: 463.4411\n",
      "Epoch: 406, Loss: 436180.1562, Train_Acc: 0.6346, TEST_Acc: 0.7067, Time: 464.5797\n",
      "Epoch: 407, Loss: 426918.0000, Train_Acc: 0.6538, TEST_Acc: 0.7033, Time: 465.7111\n",
      "Epoch: 408, Loss: 424070.1562, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 466.8395\n",
      "Epoch: 409, Loss: 413949.6875, Train_Acc: 0.6346, TEST_Acc: 0.6967, Time: 467.9743\n",
      "Epoch: 410, Loss: 420615.2188, Train_Acc: 0.6346, TEST_Acc: 0.7067, Time: 469.1084\n",
      "Epoch: 411, Loss: 407434.4688, Train_Acc: 0.6346, TEST_Acc: 0.6967, Time: 470.2455\n",
      "Epoch: 412, Loss: 404354.8438, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 471.3843\n",
      "Epoch: 413, Loss: 407004.6562, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 472.5299\n",
      "Epoch: 414, Loss: 413344.6562, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 473.6627\n",
      "Epoch: 415, Loss: 409506.0625, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 474.7892\n",
      "Epoch: 416, Loss: 398732.1562, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 475.9218\n",
      "Epoch: 417, Loss: 392257.4375, Train_Acc: 0.6538, TEST_Acc: 0.6967, Time: 477.0494\n",
      "Epoch: 418, Loss: 392995.3438, Train_Acc: 0.6538, TEST_Acc: 0.7000, Time: 478.1800\n",
      "Epoch: 419, Loss: 401292.6562, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 479.3147\n",
      "Epoch: 420, Loss: 403899.0625, Train_Acc: 0.6346, TEST_Acc: 0.7100, Time: 480.4463\n",
      "Epoch: 421, Loss: 395353.7812, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 481.5754\n",
      "Epoch: 422, Loss: 397404.0000, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 482.7108\n",
      "Epoch: 423, Loss: 385556.2812, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 483.8479\n",
      "Epoch: 424, Loss: 384083.4688, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 484.9791\n",
      "Epoch: 425, Loss: 378296.1562, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 486.1158\n",
      "Epoch: 426, Loss: 396791.8438, Train_Acc: 0.6346, TEST_Acc: 0.7133, Time: 487.2505\n",
      "Epoch: 427, Loss: 389133.6875, Train_Acc: 0.6346, TEST_Acc: 0.7100, Time: 488.3808\n",
      "Epoch: 428, Loss: 377778.4688, Train_Acc: 0.6346, TEST_Acc: 0.7067, Time: 489.5105\n",
      "Epoch: 429, Loss: 381874.9688, Train_Acc: 0.6346, TEST_Acc: 0.7067, Time: 490.6462\n",
      "Epoch: 430, Loss: 379733.0625, Train_Acc: 0.6346, TEST_Acc: 0.7067, Time: 491.7787\n",
      "Epoch: 431, Loss: 374298.8438, Train_Acc: 0.6538, TEST_Acc: 0.7000, Time: 492.9063\n",
      "Epoch: 432, Loss: 381634.5000, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 494.0419\n",
      "Epoch: 433, Loss: 378186.5312, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 495.1734\n",
      "Epoch: 434, Loss: 381617.0625, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 496.3034\n",
      "Epoch: 435, Loss: 368691.1562, Train_Acc: 0.6538, TEST_Acc: 0.7033, Time: 497.4337\n",
      "Epoch: 436, Loss: 373968.0000, Train_Acc: 0.6538, TEST_Acc: 0.7033, Time: 498.5731\n",
      "Epoch: 437, Loss: 377328.4688, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 499.7066\n",
      "Epoch: 438, Loss: 373062.6875, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 500.8431\n",
      "Epoch: 439, Loss: 367474.7812, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 501.9860\n",
      "Epoch: 440, Loss: 363482.1250, Train_Acc: 0.6346, TEST_Acc: 0.6967, Time: 503.1272\n",
      "Epoch: 441, Loss: 370315.6875, Train_Acc: 0.6346, TEST_Acc: 0.7100, Time: 504.2578\n",
      "Epoch: 442, Loss: 362137.4688, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 505.3968\n",
      "Epoch: 443, Loss: 365891.9375, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 506.5282\n",
      "Epoch: 444, Loss: 371870.0625, Train_Acc: 0.6346, TEST_Acc: 0.7100, Time: 507.6574\n",
      "Epoch: 445, Loss: 368142.8438, Train_Acc: 0.6346, TEST_Acc: 0.7133, Time: 508.7965\n",
      "Epoch: 446, Loss: 370923.5625, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 509.9446\n",
      "Epoch: 447, Loss: 358616.2188, Train_Acc: 0.6346, TEST_Acc: 0.7100, Time: 511.0784\n",
      "Epoch: 448, Loss: 350549.6250, Train_Acc: 0.6346, TEST_Acc: 0.7067, Time: 512.2201\n",
      "Epoch: 449, Loss: 350900.6562, Train_Acc: 0.6346, TEST_Acc: 0.7067, Time: 513.3508\n",
      "Epoch: 450, Loss: 354938.4688, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 514.4905\n",
      "Epoch: 451, Loss: 344398.1875, Train_Acc: 0.6346, TEST_Acc: 0.7067, Time: 515.6298\n",
      "Epoch: 452, Loss: 353722.1562, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 516.7642\n",
      "Epoch: 453, Loss: 350129.8438, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 517.9001\n",
      "Epoch: 454, Loss: 343806.5625, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 519.0375\n",
      "Epoch: 455, Loss: 332651.3750, Train_Acc: 0.6154, TEST_Acc: 0.7067, Time: 520.1755\n",
      "Epoch: 456, Loss: 337527.8438, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 521.3053\n",
      "Epoch: 457, Loss: 328945.2188, Train_Acc: 0.6346, TEST_Acc: 0.7000, Time: 522.4317\n",
      "Epoch: 458, Loss: 320741.0625, Train_Acc: 0.6154, TEST_Acc: 0.7067, Time: 523.5596\n",
      "Epoch: 459, Loss: 328282.8750, Train_Acc: 0.6346, TEST_Acc: 0.6967, Time: 524.6958\n",
      "Epoch: 460, Loss: 319602.9062, Train_Acc: 0.6346, TEST_Acc: 0.7033, Time: 525.8252\n",
      "Epoch: 461, Loss: 320966.1250, Train_Acc: 0.6346, TEST_Acc: 0.6933, Time: 526.9601\n",
      "Epoch: 462, Loss: 325041.2812, Train_Acc: 0.6346, TEST_Acc: 0.6967, Time: 528.0905\n",
      "Epoch: 463, Loss: 321770.7812, Train_Acc: 0.6346, TEST_Acc: 0.6967, Time: 529.2265\n",
      "Epoch: 464, Loss: 326380.0000, Train_Acc: 0.6538, TEST_Acc: 0.6933, Time: 530.3656\n",
      "Epoch: 465, Loss: 320027.8125, Train_Acc: 0.6538, TEST_Acc: 0.6933, Time: 531.5007\n",
      "Epoch: 466, Loss: 314109.3438, Train_Acc: 0.6538, TEST_Acc: 0.7000, Time: 532.6489\n",
      "Epoch: 467, Loss: 314053.5000, Train_Acc: 0.6538, TEST_Acc: 0.6967, Time: 533.7889\n",
      "Epoch: 468, Loss: 308352.2812, Train_Acc: 0.6538, TEST_Acc: 0.7000, Time: 534.9195\n",
      "Epoch: 469, Loss: 308130.6875, Train_Acc: 0.6538, TEST_Acc: 0.7000, Time: 536.0533\n",
      "Epoch: 470, Loss: 311430.1875, Train_Acc: 0.6538, TEST_Acc: 0.6967, Time: 537.1875\n",
      "Epoch: 471, Loss: 312938.8750, Train_Acc: 0.6538, TEST_Acc: 0.6933, Time: 538.3203\n",
      "Epoch: 472, Loss: 314597.1250, Train_Acc: 0.6923, TEST_Acc: 0.6967, Time: 539.4524\n",
      "Epoch: 473, Loss: 319112.4062, Train_Acc: 0.6731, TEST_Acc: 0.6967, Time: 540.5846\n",
      "Epoch: 474, Loss: 310467.4688, Train_Acc: 0.6731, TEST_Acc: 0.6933, Time: 541.7146\n",
      "Epoch: 475, Loss: 304128.8438, Train_Acc: 0.6538, TEST_Acc: 0.7000, Time: 542.8463\n",
      "Epoch: 476, Loss: 303937.8438, Train_Acc: 0.6731, TEST_Acc: 0.6933, Time: 543.9863\n",
      "Epoch: 477, Loss: 297707.3750, Train_Acc: 0.6538, TEST_Acc: 0.6967, Time: 545.1247\n",
      "Epoch: 478, Loss: 295321.8438, Train_Acc: 0.6731, TEST_Acc: 0.6967, Time: 546.2599\n",
      "Epoch: 479, Loss: 294948.1875, Train_Acc: 0.6923, TEST_Acc: 0.6967, Time: 547.4036\n",
      "Epoch: 480, Loss: 299680.7188, Train_Acc: 0.6923, TEST_Acc: 0.6967, Time: 548.5433\n",
      "Epoch: 481, Loss: 299297.3125, Train_Acc: 0.6923, TEST_Acc: 0.6933, Time: 549.6764\n",
      "Epoch: 482, Loss: 299310.7500, Train_Acc: 0.6731, TEST_Acc: 0.6967, Time: 550.8156\n",
      "Epoch: 483, Loss: 300885.0938, Train_Acc: 0.6923, TEST_Acc: 0.7033, Time: 551.9469\n",
      "Epoch: 484, Loss: 295580.1875, Train_Acc: 0.6731, TEST_Acc: 0.7000, Time: 553.0799\n",
      "Epoch: 485, Loss: 293957.1250, Train_Acc: 0.6538, TEST_Acc: 0.6967, Time: 554.2127\n",
      "Epoch: 486, Loss: 291757.6562, Train_Acc: 0.6538, TEST_Acc: 0.6967, Time: 555.3458\n",
      "Epoch: 487, Loss: 292383.2188, Train_Acc: 0.6923, TEST_Acc: 0.7000, Time: 556.4832\n",
      "Epoch: 488, Loss: 294167.6562, Train_Acc: 0.6923, TEST_Acc: 0.7000, Time: 557.6220\n",
      "Epoch: 489, Loss: 285603.4375, Train_Acc: 0.6731, TEST_Acc: 0.7000, Time: 558.7622\n",
      "Epoch: 490, Loss: 292284.3125, Train_Acc: 0.7115, TEST_Acc: 0.7000, Time: 559.9035\n",
      "Epoch: 491, Loss: 294411.6250, Train_Acc: 0.7115, TEST_Acc: 0.7000, Time: 561.0465\n",
      "Epoch: 492, Loss: 296771.7500, Train_Acc: 0.7115, TEST_Acc: 0.7000, Time: 562.1857\n",
      "Epoch: 493, Loss: 288721.2188, Train_Acc: 0.6731, TEST_Acc: 0.7000, Time: 563.3286\n",
      "Epoch: 494, Loss: 288443.6250, Train_Acc: 0.6731, TEST_Acc: 0.7000, Time: 564.4634\n",
      "Epoch: 495, Loss: 282166.9062, Train_Acc: 0.6538, TEST_Acc: 0.6967, Time: 565.6020\n",
      "Epoch: 496, Loss: 282412.5625, Train_Acc: 0.6731, TEST_Acc: 0.7033, Time: 566.7344\n",
      "Epoch: 497, Loss: 290247.9375, Train_Acc: 0.7115, TEST_Acc: 0.6967, Time: 567.8713\n",
      "Epoch: 498, Loss: 280522.1875, Train_Acc: 0.6923, TEST_Acc: 0.7033, Time: 569.0087\n",
      "Epoch: 499, Loss: 281814.9688, Train_Acc: 0.7115, TEST_Acc: 0.6933, Time: 570.1397\n",
      "Epoch: 500, Loss: 276437.3125, Train_Acc: 0.6923, TEST_Acc: 0.6933, Time: 571.2680\n",
      "Epoch: 501, Loss: 275492.7812, Train_Acc: 0.6923, TEST_Acc: 0.6933, Time: 572.4013\n",
      "Epoch: 502, Loss: 280918.9375, Train_Acc: 0.7115, TEST_Acc: 0.6900, Time: 573.5347\n",
      "Epoch: 503, Loss: 279273.7812, Train_Acc: 0.7115, TEST_Acc: 0.6900, Time: 574.6700\n",
      "Epoch: 504, Loss: 278983.5625, Train_Acc: 0.7115, TEST_Acc: 0.6900, Time: 575.8064\n",
      "Epoch: 505, Loss: 281258.7188, Train_Acc: 0.7115, TEST_Acc: 0.6900, Time: 576.9425\n",
      "Epoch: 506, Loss: 273376.2188, Train_Acc: 0.6923, TEST_Acc: 0.6900, Time: 578.0824\n",
      "Epoch: 507, Loss: 278929.9375, Train_Acc: 0.7115, TEST_Acc: 0.6867, Time: 579.2192\n",
      "Epoch: 508, Loss: 271038.9375, Train_Acc: 0.7115, TEST_Acc: 0.6867, Time: 580.3538\n",
      "Epoch: 509, Loss: 278796.4375, Train_Acc: 0.7115, TEST_Acc: 0.6833, Time: 581.4891\n",
      "Epoch: 510, Loss: 278427.8125, Train_Acc: 0.7115, TEST_Acc: 0.6800, Time: 582.6252\n",
      "Epoch: 511, Loss: 273987.3438, Train_Acc: 0.7115, TEST_Acc: 0.6867, Time: 583.7550\n",
      "Epoch: 512, Loss: 280461.7188, Train_Acc: 0.7115, TEST_Acc: 0.6800, Time: 584.8908\n",
      "Epoch: 513, Loss: 285099.1875, Train_Acc: 0.7115, TEST_Acc: 0.6767, Time: 586.0220\n",
      "Epoch: 514, Loss: 275609.6250, Train_Acc: 0.7308, TEST_Acc: 0.6800, Time: 587.1556\n",
      "Epoch: 515, Loss: 277298.6250, Train_Acc: 0.7115, TEST_Acc: 0.6800, Time: 588.2912\n",
      "Epoch: 516, Loss: 268444.8750, Train_Acc: 0.7115, TEST_Acc: 0.6800, Time: 589.4378\n",
      "Epoch: 517, Loss: 266706.5938, Train_Acc: 0.7115, TEST_Acc: 0.6767, Time: 590.5746\n",
      "Epoch: 518, Loss: 268719.7188, Train_Acc: 0.7308, TEST_Acc: 0.6767, Time: 591.7084\n",
      "Epoch: 519, Loss: 275214.5625, Train_Acc: 0.7308, TEST_Acc: 0.6700, Time: 592.8494\n",
      "Epoch: 520, Loss: 268767.6875, Train_Acc: 0.7308, TEST_Acc: 0.6733, Time: 593.9899\n",
      "Epoch: 521, Loss: 271906.5625, Train_Acc: 0.7308, TEST_Acc: 0.6700, Time: 595.1227\n",
      "Epoch: 522, Loss: 266833.9688, Train_Acc: 0.7500, TEST_Acc: 0.6733, Time: 596.2596\n",
      "Epoch: 523, Loss: 264761.5312, Train_Acc: 0.7500, TEST_Acc: 0.6767, Time: 597.3902\n",
      "Epoch: 524, Loss: 257405.1875, Train_Acc: 0.7308, TEST_Acc: 0.6800, Time: 598.5221\n",
      "Epoch: 525, Loss: 253190.8438, Train_Acc: 0.7115, TEST_Acc: 0.6767, Time: 599.6576\n",
      "Epoch: 526, Loss: 260534.8125, Train_Acc: 0.7308, TEST_Acc: 0.6700, Time: 600.7969\n",
      "Epoch: 527, Loss: 258359.9062, Train_Acc: 0.7500, TEST_Acc: 0.6700, Time: 601.9316\n",
      "Epoch: 528, Loss: 257599.0000, Train_Acc: 0.7500, TEST_Acc: 0.6700, Time: 603.0658\n",
      "Epoch: 529, Loss: 255366.4688, Train_Acc: 0.7500, TEST_Acc: 0.6733, Time: 604.2106\n",
      "Epoch: 530, Loss: 248871.8906, Train_Acc: 0.7308, TEST_Acc: 0.6767, Time: 605.3450\n",
      "Epoch: 531, Loss: 251672.5156, Train_Acc: 0.7500, TEST_Acc: 0.6700, Time: 606.4820\n",
      "Epoch: 532, Loss: 247982.9219, Train_Acc: 0.7500, TEST_Acc: 0.6700, Time: 607.6174\n",
      "Epoch: 533, Loss: 247777.8594, Train_Acc: 0.7500, TEST_Acc: 0.6733, Time: 608.7533\n",
      "Epoch: 534, Loss: 247653.6094, Train_Acc: 0.7308, TEST_Acc: 0.6667, Time: 609.8932\n",
      "Epoch: 535, Loss: 245242.8906, Train_Acc: 0.7308, TEST_Acc: 0.6667, Time: 611.0262\n",
      "Epoch: 536, Loss: 258956.5000, Train_Acc: 0.7500, TEST_Acc: 0.6567, Time: 612.1710\n",
      "Epoch: 537, Loss: 250066.8906, Train_Acc: 0.7308, TEST_Acc: 0.6667, Time: 613.3024\n",
      "Epoch: 538, Loss: 247413.7344, Train_Acc: 0.7115, TEST_Acc: 0.6667, Time: 614.4395\n",
      "Epoch: 539, Loss: 242744.2188, Train_Acc: 0.6923, TEST_Acc: 0.6733, Time: 615.5738\n",
      "Epoch: 540, Loss: 252779.6562, Train_Acc: 0.7500, TEST_Acc: 0.6667, Time: 616.7079\n",
      "Epoch: 541, Loss: 251690.6719, Train_Acc: 0.7500, TEST_Acc: 0.6667, Time: 617.8413\n",
      "Epoch: 542, Loss: 247335.0312, Train_Acc: 0.7500, TEST_Acc: 0.6667, Time: 618.9788\n",
      "Epoch: 543, Loss: 253685.9375, Train_Acc: 0.7500, TEST_Acc: 0.6600, Time: 620.1218\n",
      "Epoch: 544, Loss: 249786.0000, Train_Acc: 0.7500, TEST_Acc: 0.6600, Time: 621.2618\n",
      "Epoch: 545, Loss: 242405.9219, Train_Acc: 0.7500, TEST_Acc: 0.6633, Time: 622.4004\n",
      "Epoch: 546, Loss: 243376.9844, Train_Acc: 0.7500, TEST_Acc: 0.6600, Time: 623.5496\n",
      "Epoch: 547, Loss: 241895.6719, Train_Acc: 0.7500, TEST_Acc: 0.6600, Time: 624.6836\n",
      "Epoch: 548, Loss: 237347.1875, Train_Acc: 0.7500, TEST_Acc: 0.6633, Time: 625.8203\n",
      "Epoch: 549, Loss: 238437.4219, Train_Acc: 0.7500, TEST_Acc: 0.6633, Time: 626.9501\n",
      "Epoch: 550, Loss: 235089.7812, Train_Acc: 0.7500, TEST_Acc: 0.6633, Time: 628.0813\n",
      "Epoch: 551, Loss: 235360.8906, Train_Acc: 0.7500, TEST_Acc: 0.6600, Time: 629.2154\n",
      "Epoch: 552, Loss: 228100.3594, Train_Acc: 0.6923, TEST_Acc: 0.6667, Time: 630.3568\n",
      "Epoch: 553, Loss: 231710.8125, Train_Acc: 0.7500, TEST_Acc: 0.6633, Time: 631.4882\n",
      "Epoch: 554, Loss: 234968.7656, Train_Acc: 0.7500, TEST_Acc: 0.6633, Time: 632.6249\n",
      "Epoch: 555, Loss: 229821.7188, Train_Acc: 0.7115, TEST_Acc: 0.6700, Time: 633.7635\n",
      "Epoch: 556, Loss: 242514.6406, Train_Acc: 0.7692, TEST_Acc: 0.6633, Time: 634.9017\n",
      "Epoch: 557, Loss: 234352.7656, Train_Acc: 0.7308, TEST_Acc: 0.6700, Time: 636.0361\n",
      "Epoch: 558, Loss: 239007.4219, Train_Acc: 0.7500, TEST_Acc: 0.6667, Time: 637.1752\n",
      "Epoch: 559, Loss: 236181.7656, Train_Acc: 0.7308, TEST_Acc: 0.6733, Time: 638.3116\n",
      "Epoch: 560, Loss: 232181.2344, Train_Acc: 0.7308, TEST_Acc: 0.6667, Time: 639.4533\n",
      "Epoch: 561, Loss: 229922.4219, Train_Acc: 0.7308, TEST_Acc: 0.6700, Time: 640.5908\n",
      "Epoch: 562, Loss: 230426.8125, Train_Acc: 0.7308, TEST_Acc: 0.6667, Time: 641.7202\n",
      "Epoch: 563, Loss: 232746.9375, Train_Acc: 0.7308, TEST_Acc: 0.6600, Time: 642.8521\n",
      "Epoch: 564, Loss: 232049.0312, Train_Acc: 0.7500, TEST_Acc: 0.6567, Time: 643.9831\n",
      "Epoch: 565, Loss: 229657.5625, Train_Acc: 0.7500, TEST_Acc: 0.6600, Time: 645.1178\n",
      "Epoch: 566, Loss: 227247.6094, Train_Acc: 0.7115, TEST_Acc: 0.6633, Time: 646.2500\n",
      "Epoch: 567, Loss: 230992.0000, Train_Acc: 0.7500, TEST_Acc: 0.6567, Time: 647.3831\n",
      "Epoch: 568, Loss: 229336.0312, Train_Acc: 0.7500, TEST_Acc: 0.6567, Time: 648.5193\n",
      "Epoch: 569, Loss: 230233.4688, Train_Acc: 0.7500, TEST_Acc: 0.6533, Time: 649.6582\n",
      "Epoch: 570, Loss: 232302.5000, Train_Acc: 0.7500, TEST_Acc: 0.6500, Time: 650.7929\n",
      "Epoch: 571, Loss: 227708.0312, Train_Acc: 0.7500, TEST_Acc: 0.6533, Time: 651.9322\n",
      "Epoch: 572, Loss: 227874.1875, Train_Acc: 0.7500, TEST_Acc: 0.6533, Time: 653.0748\n",
      "Epoch: 573, Loss: 216871.9062, Train_Acc: 0.7308, TEST_Acc: 0.6633, Time: 654.2203\n",
      "Epoch: 574, Loss: 216792.2656, Train_Acc: 0.7308, TEST_Acc: 0.6567, Time: 655.3571\n",
      "Epoch: 575, Loss: 219587.0156, Train_Acc: 0.7308, TEST_Acc: 0.6567, Time: 656.4889\n",
      "Epoch: 576, Loss: 226601.5781, Train_Acc: 0.7500, TEST_Acc: 0.6500, Time: 657.6178\n",
      "Epoch: 577, Loss: 227092.8438, Train_Acc: 0.7500, TEST_Acc: 0.6500, Time: 658.7524\n",
      "Epoch: 578, Loss: 223570.2188, Train_Acc: 0.7692, TEST_Acc: 0.6500, Time: 659.8817\n",
      "Epoch: 579, Loss: 216633.8906, Train_Acc: 0.7692, TEST_Acc: 0.6467, Time: 661.0122\n",
      "Epoch: 580, Loss: 215274.6719, Train_Acc: 0.7308, TEST_Acc: 0.6500, Time: 662.1483\n",
      "Epoch: 581, Loss: 213813.3906, Train_Acc: 0.7692, TEST_Acc: 0.6533, Time: 663.2872\n",
      "Epoch: 582, Loss: 210949.0625, Train_Acc: 0.7115, TEST_Acc: 0.6500, Time: 664.4222\n",
      "Epoch: 583, Loss: 214554.0938, Train_Acc: 0.7692, TEST_Acc: 0.6500, Time: 665.5571\n",
      "Epoch: 584, Loss: 218002.0781, Train_Acc: 0.7692, TEST_Acc: 0.6433, Time: 666.6976\n",
      "Epoch: 585, Loss: 214604.0938, Train_Acc: 0.7692, TEST_Acc: 0.6467, Time: 667.8442\n",
      "Epoch: 586, Loss: 224003.4844, Train_Acc: 0.7692, TEST_Acc: 0.6467, Time: 668.9785\n",
      "Epoch: 587, Loss: 217111.8594, Train_Acc: 0.7692, TEST_Acc: 0.6467, Time: 670.1141\n",
      "Epoch: 588, Loss: 209432.1562, Train_Acc: 0.7500, TEST_Acc: 0.6433, Time: 671.2443\n",
      "Epoch: 589, Loss: 214226.1406, Train_Acc: 0.7692, TEST_Acc: 0.6433, Time: 672.3776\n",
      "Epoch: 590, Loss: 208867.9844, Train_Acc: 0.7692, TEST_Acc: 0.6433, Time: 673.5106\n",
      "Epoch: 591, Loss: 206112.7344, Train_Acc: 0.7692, TEST_Acc: 0.6400, Time: 674.6522\n",
      "Epoch: 592, Loss: 205641.4219, Train_Acc: 0.7500, TEST_Acc: 0.6433, Time: 675.7841\n",
      "Epoch: 593, Loss: 214188.2656, Train_Acc: 0.7692, TEST_Acc: 0.6433, Time: 676.9212\n",
      "Epoch: 594, Loss: 210221.7344, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 678.0555\n",
      "Epoch: 595, Loss: 207961.0625, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 679.1874\n",
      "Epoch: 596, Loss: 204385.4219, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 680.3226\n",
      "Epoch: 597, Loss: 198500.8438, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 681.4620\n",
      "Epoch: 598, Loss: 198049.3906, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 682.5954\n",
      "Epoch: 599, Loss: 198635.0312, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 683.7389\n",
      "Epoch: 600, Loss: 205946.5312, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 684.8809\n",
      "Epoch: 601, Loss: 202653.0000, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 686.0185\n",
      "Epoch: 602, Loss: 204458.9219, Train_Acc: 0.7692, TEST_Acc: 0.6333, Time: 687.1495\n",
      "Epoch: 603, Loss: 194744.0156, Train_Acc: 0.7885, TEST_Acc: 0.6367, Time: 688.2851\n",
      "Epoch: 604, Loss: 198778.4219, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 689.4196\n",
      "Epoch: 605, Loss: 193161.2656, Train_Acc: 0.7308, TEST_Acc: 0.6367, Time: 690.5530\n",
      "Epoch: 606, Loss: 191887.5312, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 691.6872\n",
      "Epoch: 607, Loss: 192657.3125, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 692.8188\n",
      "Epoch: 608, Loss: 197364.0000, Train_Acc: 0.7692, TEST_Acc: 0.6333, Time: 693.9585\n",
      "Epoch: 609, Loss: 195131.8906, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 695.0998\n",
      "Epoch: 610, Loss: 191972.3594, Train_Acc: 0.7500, TEST_Acc: 0.6367, Time: 696.2386\n",
      "Epoch: 611, Loss: 193154.8125, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 697.3748\n",
      "Epoch: 612, Loss: 190964.9688, Train_Acc: 0.7500, TEST_Acc: 0.6367, Time: 698.5116\n",
      "Epoch: 613, Loss: 195407.0312, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 699.6495\n",
      "Epoch: 614, Loss: 189882.8906, Train_Acc: 0.7500, TEST_Acc: 0.6367, Time: 700.7837\n",
      "Epoch: 615, Loss: 188304.7344, Train_Acc: 0.7500, TEST_Acc: 0.6367, Time: 701.9145\n",
      "Epoch: 616, Loss: 189428.7656, Train_Acc: 0.7500, TEST_Acc: 0.6400, Time: 703.0444\n",
      "Epoch: 617, Loss: 190007.5000, Train_Acc: 0.7692, TEST_Acc: 0.6400, Time: 704.1814\n",
      "Epoch: 618, Loss: 194560.9375, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 705.3208\n",
      "Epoch: 619, Loss: 192379.6094, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 706.4523\n",
      "Epoch: 620, Loss: 192984.6094, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 707.5896\n",
      "Epoch: 621, Loss: 190783.9219, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 708.7246\n",
      "Epoch: 622, Loss: 194509.3438, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 709.8611\n",
      "Epoch: 623, Loss: 189222.7344, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 710.9986\n",
      "Epoch: 624, Loss: 192070.5781, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 712.1353\n",
      "Epoch: 625, Loss: 188779.6875, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 713.2798\n",
      "Epoch: 626, Loss: 185402.6562, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 714.4145\n",
      "Epoch: 627, Loss: 184938.8906, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 715.5584\n",
      "Epoch: 628, Loss: 183059.9688, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 716.6982\n",
      "Epoch: 629, Loss: 177539.1406, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 717.8337\n",
      "Epoch: 630, Loss: 180936.3438, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 718.9672\n",
      "Epoch: 631, Loss: 180582.3125, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 720.1002\n",
      "Epoch: 632, Loss: 178676.5781, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 721.2371\n",
      "Epoch: 633, Loss: 178018.2344, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 722.3700\n",
      "Epoch: 634, Loss: 173232.8906, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 723.5028\n",
      "Epoch: 635, Loss: 174362.1719, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 724.6375\n",
      "Epoch: 636, Loss: 178196.8906, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 725.7696\n",
      "Epoch: 637, Loss: 175010.1094, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 726.9074\n",
      "Epoch: 638, Loss: 177557.9844, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 728.0444\n",
      "Epoch: 639, Loss: 175439.2656, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 729.1775\n",
      "Epoch: 640, Loss: 172315.2812, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 730.3126\n",
      "Epoch: 641, Loss: 168056.2344, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 731.4477\n",
      "Epoch: 642, Loss: 167506.8438, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 732.5773\n",
      "Epoch: 643, Loss: 171921.1875, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 733.7148\n",
      "Epoch: 644, Loss: 171535.6562, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 734.8486\n",
      "Epoch: 645, Loss: 169940.6719, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 735.9832\n",
      "Epoch: 646, Loss: 172072.5000, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 737.1135\n",
      "Epoch: 647, Loss: 169551.6094, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 738.2495\n",
      "Epoch: 648, Loss: 174468.5312, Train_Acc: 0.7692, TEST_Acc: 0.6100, Time: 739.3862\n",
      "Epoch: 649, Loss: 170072.2812, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 740.5170\n",
      "Epoch: 650, Loss: 167526.6406, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 741.6543\n",
      "Epoch: 651, Loss: 171060.5312, Train_Acc: 0.7692, TEST_Acc: 0.6100, Time: 742.7945\n",
      "Epoch: 652, Loss: 168819.0312, Train_Acc: 0.7692, TEST_Acc: 0.6100, Time: 743.9328\n",
      "Epoch: 653, Loss: 164673.1875, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 745.0676\n",
      "Epoch: 654, Loss: 163915.7812, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 746.2075\n",
      "Epoch: 655, Loss: 165032.5625, Train_Acc: 0.7692, TEST_Acc: 0.6100, Time: 747.3426\n",
      "Epoch: 656, Loss: 160561.3125, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 748.4759\n",
      "Epoch: 657, Loss: 164636.4844, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 749.6138\n",
      "Epoch: 658, Loss: 164689.7344, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 750.7446\n",
      "Epoch: 659, Loss: 162773.5000, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 751.8762\n",
      "Epoch: 660, Loss: 162136.9844, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 753.0178\n",
      "Epoch: 661, Loss: 159758.2656, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 754.1526\n",
      "Epoch: 662, Loss: 161463.9688, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 755.2872\n",
      "Epoch: 663, Loss: 159340.2500, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 756.4210\n",
      "Epoch: 664, Loss: 158900.4844, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 757.5538\n",
      "Epoch: 665, Loss: 154305.3906, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 758.6905\n",
      "Epoch: 666, Loss: 156911.0938, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 759.8282\n",
      "Epoch: 667, Loss: 155595.2500, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 760.9637\n",
      "Epoch: 668, Loss: 152473.7812, Train_Acc: 0.7692, TEST_Acc: 0.6100, Time: 762.1030\n",
      "Epoch: 669, Loss: 154320.7656, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 763.2380\n",
      "Epoch: 670, Loss: 158580.9375, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 764.3736\n",
      "Epoch: 671, Loss: 158601.3281, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 765.5055\n",
      "Epoch: 672, Loss: 155617.9375, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 766.6383\n",
      "Epoch: 673, Loss: 154555.6406, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 767.7729\n",
      "Epoch: 674, Loss: 153187.9375, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 768.9154\n",
      "Epoch: 675, Loss: 152219.7344, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 770.0511\n",
      "Epoch: 676, Loss: 152958.2344, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 771.1848\n",
      "Epoch: 677, Loss: 150385.4688, Train_Acc: 0.7885, TEST_Acc: 0.6100, Time: 772.3214\n",
      "Epoch: 678, Loss: 151507.1719, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 773.4567\n",
      "Epoch: 679, Loss: 151036.6719, Train_Acc: 0.7885, TEST_Acc: 0.6100, Time: 774.6004\n",
      "Epoch: 680, Loss: 150187.1562, Train_Acc: 0.7885, TEST_Acc: 0.6100, Time: 775.7410\n",
      "Epoch: 681, Loss: 151066.9531, Train_Acc: 0.7885, TEST_Acc: 0.6067, Time: 776.8745\n",
      "Epoch: 682, Loss: 147839.0938, Train_Acc: 0.7885, TEST_Acc: 0.6100, Time: 778.0160\n",
      "Epoch: 683, Loss: 152111.4062, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 779.1542\n",
      "Epoch: 684, Loss: 150182.7812, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 780.2911\n",
      "Epoch: 685, Loss: 151355.7188, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 781.4251\n",
      "Epoch: 686, Loss: 149922.0625, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 782.5582\n",
      "Epoch: 687, Loss: 149139.1406, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 783.6910\n",
      "Epoch: 688, Loss: 147910.1719, Train_Acc: 0.7885, TEST_Acc: 0.6067, Time: 784.8277\n",
      "Epoch: 689, Loss: 148182.5781, Train_Acc: 0.7885, TEST_Acc: 0.6067, Time: 785.9650\n",
      "Epoch: 690, Loss: 148613.2188, Train_Acc: 0.7885, TEST_Acc: 0.6067, Time: 787.0991\n",
      "Epoch: 691, Loss: 144834.6875, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 788.2394\n",
      "Epoch: 692, Loss: 145730.6719, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 789.3824\n",
      "Epoch: 693, Loss: 145409.3750, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 790.5275\n",
      "Epoch: 694, Loss: 145876.3906, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 791.6685\n",
      "Epoch: 695, Loss: 145620.6094, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 792.8087\n",
      "Epoch: 696, Loss: 144113.1719, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 793.9438\n",
      "Epoch: 697, Loss: 142395.2188, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 795.0812\n",
      "Epoch: 698, Loss: 144136.5156, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 796.2145\n",
      "Epoch: 699, Loss: 146802.8594, Train_Acc: 0.7885, TEST_Acc: 0.6067, Time: 797.3432\n",
      "Epoch: 700, Loss: 146860.9062, Train_Acc: 0.7885, TEST_Acc: 0.6067, Time: 798.4838\n",
      "Epoch: 701, Loss: 145054.4062, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 799.6205\n",
      "Epoch: 702, Loss: 144247.0000, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 800.7544\n",
      "Epoch: 703, Loss: 145036.0312, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 801.8891\n",
      "Epoch: 704, Loss: 142797.4688, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 803.0265\n",
      "Epoch: 705, Loss: 144191.7188, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 804.1703\n",
      "Epoch: 706, Loss: 144272.9062, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 805.3119\n",
      "Epoch: 707, Loss: 144723.9844, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 806.4495\n",
      "Epoch: 708, Loss: 144209.6406, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 807.5915\n",
      "Epoch: 709, Loss: 143845.9062, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 808.7382\n",
      "Epoch: 710, Loss: 144495.8750, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 809.8708\n",
      "Epoch: 711, Loss: 139608.3438, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 811.0057\n",
      "Epoch: 712, Loss: 138925.9062, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 812.1399\n",
      "Epoch: 713, Loss: 137422.3750, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 813.2743\n",
      "Epoch: 714, Loss: 138686.8438, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 814.4029\n",
      "Epoch: 715, Loss: 139585.4844, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 815.5370\n",
      "Epoch: 716, Loss: 137222.1094, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 816.6717\n",
      "Epoch: 717, Loss: 136793.3438, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 817.8077\n",
      "Epoch: 718, Loss: 136601.9062, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 818.9476\n",
      "Epoch: 719, Loss: 137392.3906, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 820.0848\n",
      "Epoch: 720, Loss: 134781.3750, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 821.2214\n",
      "Epoch: 721, Loss: 136422.8594, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 822.3591\n",
      "Epoch: 722, Loss: 137433.0312, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 823.4962\n",
      "Epoch: 723, Loss: 137363.6719, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 824.6345\n",
      "Epoch: 724, Loss: 136417.4844, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 825.7675\n",
      "Epoch: 725, Loss: 134271.5469, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 826.9016\n",
      "Epoch: 726, Loss: 134418.4844, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 828.0345\n",
      "Epoch: 727, Loss: 134682.2656, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 829.1683\n",
      "Epoch: 728, Loss: 134657.8594, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 830.3044\n",
      "Epoch: 729, Loss: 133921.1094, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 831.4406\n",
      "Epoch: 730, Loss: 133258.3906, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 832.5781\n",
      "Epoch: 731, Loss: 132184.9688, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 833.7204\n",
      "Epoch: 732, Loss: 130422.3594, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 834.8622\n",
      "Epoch: 733, Loss: 131637.2969, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 835.9994\n",
      "Epoch: 734, Loss: 131117.3281, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 837.1332\n",
      "Epoch: 735, Loss: 132653.2812, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 838.2681\n",
      "Epoch: 736, Loss: 132737.3906, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 839.4039\n",
      "Epoch: 737, Loss: 129838.0156, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 840.5336\n",
      "Epoch: 738, Loss: 129236.7500, Train_Acc: 0.7692, TEST_Acc: 0.5933, Time: 841.6735\n",
      "Epoch: 739, Loss: 127307.0312, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 842.8153\n",
      "Epoch: 740, Loss: 126323.3203, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 843.9510\n",
      "Epoch: 741, Loss: 128095.5938, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 845.0858\n",
      "Epoch: 742, Loss: 126069.2422, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 846.2190\n",
      "Epoch: 743, Loss: 124693.4141, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 847.3526\n",
      "Epoch: 744, Loss: 125944.0703, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 848.4876\n",
      "Epoch: 745, Loss: 123933.7031, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 849.6253\n",
      "Epoch: 746, Loss: 122850.3672, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 850.7608\n",
      "Epoch: 747, Loss: 121754.0391, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 851.8984\n",
      "Epoch: 748, Loss: 120847.0000, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 853.0416\n",
      "Epoch: 749, Loss: 119738.3750, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 854.1829\n",
      "Epoch: 750, Loss: 118783.9297, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 855.3228\n",
      "Epoch: 751, Loss: 118122.8047, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 856.4572\n",
      "Epoch: 752, Loss: 117088.8281, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 857.5907\n",
      "Epoch: 753, Loss: 115861.5078, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 858.7261\n",
      "Epoch: 754, Loss: 115197.1719, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 859.8631\n",
      "Epoch: 755, Loss: 114107.5000, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 860.9974\n",
      "Epoch: 756, Loss: 115559.6562, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 862.1314\n",
      "Epoch: 757, Loss: 115932.7891, Train_Acc: 0.7692, TEST_Acc: 0.5933, Time: 863.2645\n",
      "Epoch: 758, Loss: 116058.5312, Train_Acc: 0.7692, TEST_Acc: 0.5933, Time: 864.4075\n",
      "Epoch: 759, Loss: 115690.9062, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 865.5451\n",
      "Epoch: 760, Loss: 117176.9844, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 866.6821\n",
      "Epoch: 761, Loss: 116344.2656, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 867.8216\n",
      "Epoch: 762, Loss: 113840.9922, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 868.9649\n",
      "Epoch: 763, Loss: 115383.0156, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 870.0974\n",
      "Epoch: 764, Loss: 114376.8672, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 871.2288\n",
      "Epoch: 765, Loss: 113492.0391, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 872.3680\n",
      "Epoch: 766, Loss: 113308.3672, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 873.5048\n",
      "Epoch: 767, Loss: 113324.3438, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 874.6394\n",
      "Epoch: 768, Loss: 114029.9453, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 875.7735\n",
      "Epoch: 769, Loss: 114005.4844, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 876.9038\n",
      "Epoch: 770, Loss: 113527.2344, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 878.0377\n",
      "Epoch: 771, Loss: 112024.1172, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 879.1718\n",
      "Epoch: 772, Loss: 110127.4922, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 880.3103\n",
      "Epoch: 773, Loss: 109361.7344, Train_Acc: 0.7692, TEST_Acc: 0.5933, Time: 881.4478\n",
      "Epoch: 774, Loss: 109110.1250, Train_Acc: 0.7692, TEST_Acc: 0.5900, Time: 882.5838\n",
      "Epoch: 775, Loss: 108795.8672, Train_Acc: 0.7692, TEST_Acc: 0.5933, Time: 883.7192\n",
      "Epoch: 776, Loss: 107723.9062, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 884.8590\n",
      "Epoch: 777, Loss: 106552.3750, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 885.9968\n",
      "Epoch: 778, Loss: 105864.8594, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 887.1285\n",
      "Epoch: 779, Loss: 104470.3438, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 888.2663\n",
      "Epoch: 780, Loss: 104206.2500, Train_Acc: 0.7692, TEST_Acc: 0.5867, Time: 889.4031\n",
      "Epoch: 781, Loss: 103370.0547, Train_Acc: 0.7692, TEST_Acc: 0.5867, Time: 890.5369\n",
      "Epoch: 782, Loss: 102526.5156, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 891.6725\n",
      "Epoch: 783, Loss: 102129.4453, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 892.8051\n",
      "Epoch: 784, Loss: 102808.5000, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 893.9395\n",
      "Epoch: 785, Loss: 101450.1328, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 895.0839\n",
      "Epoch: 786, Loss: 100938.7344, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 896.2262\n",
      "Epoch: 787, Loss: 100098.7188, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 897.3609\n",
      "Epoch: 788, Loss: 98996.0938, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 898.4970\n",
      "Epoch: 789, Loss: 99749.5469, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 899.6364\n",
      "Epoch: 790, Loss: 99670.1953, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 900.7785\n",
      "Epoch: 791, Loss: 98561.4844, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 901.9192\n",
      "Epoch: 792, Loss: 98084.0703, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 903.0524\n",
      "Epoch: 793, Loss: 97510.8047, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 904.1875\n",
      "Epoch: 794, Loss: 98378.2656, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 905.3213\n",
      "Epoch: 795, Loss: 96810.4141, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 906.4601\n",
      "Epoch: 796, Loss: 96854.9844, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 907.5932\n",
      "Epoch: 797, Loss: 96397.4688, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 908.7259\n",
      "Epoch: 798, Loss: 96749.0781, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 909.8600\n",
      "Epoch: 799, Loss: 96517.0703, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 910.9973\n",
      "Epoch: 800, Loss: 96243.5781, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 912.1342\n",
      "Epoch: 801, Loss: 95785.9297, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 913.2730\n",
      "Epoch: 802, Loss: 95437.9453, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 914.4138\n",
      "Epoch: 803, Loss: 95143.4062, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 915.5509\n",
      "Epoch: 804, Loss: 94626.8906, Train_Acc: 0.7885, TEST_Acc: 0.5767, Time: 916.6985\n",
      "Epoch: 805, Loss: 93835.1562, Train_Acc: 0.7885, TEST_Acc: 0.5733, Time: 917.8391\n",
      "Epoch: 806, Loss: 93996.2969, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 918.9731\n",
      "Epoch: 807, Loss: 94194.7422, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 920.1099\n",
      "Epoch: 808, Loss: 93734.1094, Train_Acc: 0.7885, TEST_Acc: 0.5800, Time: 921.2451\n",
      "Epoch: 809, Loss: 94076.2656, Train_Acc: 0.7885, TEST_Acc: 0.5800, Time: 922.3792\n",
      "Epoch: 810, Loss: 93412.3281, Train_Acc: 0.7885, TEST_Acc: 0.5800, Time: 923.5105\n",
      "Epoch: 811, Loss: 93517.8438, Train_Acc: 0.7885, TEST_Acc: 0.5700, Time: 924.6451\n",
      "Epoch: 812, Loss: 92706.2109, Train_Acc: 0.7885, TEST_Acc: 0.5700, Time: 925.7895\n",
      "Epoch: 813, Loss: 92332.6172, Train_Acc: 0.7885, TEST_Acc: 0.5700, Time: 926.9283\n",
      "Epoch: 814, Loss: 92077.2344, Train_Acc: 0.7885, TEST_Acc: 0.5700, Time: 928.0678\n",
      "Epoch: 815, Loss: 91910.8594, Train_Acc: 0.7885, TEST_Acc: 0.5700, Time: 929.2041\n",
      "Epoch: 816, Loss: 90515.0312, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 930.3414\n",
      "Epoch: 817, Loss: 90805.1719, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 931.4794\n",
      "Epoch: 818, Loss: 89110.2344, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 932.6177\n",
      "Epoch: 819, Loss: 89645.7891, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 933.7517\n",
      "Epoch: 820, Loss: 88682.5312, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 934.8840\n",
      "Epoch: 821, Loss: 87594.2891, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 936.0230\n",
      "Epoch: 822, Loss: 86331.8828, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 937.1635\n",
      "Epoch: 823, Loss: 86321.5703, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 938.2986\n",
      "Epoch: 824, Loss: 87548.4219, Train_Acc: 0.7885, TEST_Acc: 0.5800, Time: 939.4314\n",
      "Epoch: 825, Loss: 87562.2500, Train_Acc: 0.7885, TEST_Acc: 0.5800, Time: 940.5687\n",
      "Epoch: 826, Loss: 86204.7344, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 941.7000\n",
      "Epoch: 827, Loss: 85670.8047, Train_Acc: 0.7885, TEST_Acc: 0.5800, Time: 942.8366\n",
      "Epoch: 828, Loss: 85564.7109, Train_Acc: 0.7885, TEST_Acc: 0.5800, Time: 943.9737\n",
      "Epoch: 829, Loss: 84095.8281, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 945.1133\n",
      "Epoch: 830, Loss: 84782.0547, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 946.2513\n",
      "Epoch: 831, Loss: 84221.0781, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 947.3913\n",
      "Epoch: 832, Loss: 83617.3281, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 948.5241\n",
      "Epoch: 833, Loss: 83136.0703, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 949.6609\n",
      "Epoch: 834, Loss: 82307.1953, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 950.7964\n",
      "Epoch: 835, Loss: 83787.8047, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 951.9294\n",
      "Epoch: 836, Loss: 82053.2891, Train_Acc: 0.7885, TEST_Acc: 0.5800, Time: 953.0647\n",
      "Epoch: 837, Loss: 81495.5156, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 954.2018\n",
      "Epoch: 838, Loss: 80523.4844, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 955.3367\n",
      "Epoch: 839, Loss: 81189.9453, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 956.4687\n",
      "Epoch: 840, Loss: 80365.7969, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 957.6078\n",
      "Epoch: 841, Loss: 80638.3203, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 958.7558\n",
      "Epoch: 842, Loss: 80529.3906, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 959.8933\n",
      "Epoch: 843, Loss: 80154.6797, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 961.0299\n",
      "Epoch: 844, Loss: 78902.7266, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 962.1668\n",
      "Epoch: 845, Loss: 80133.9453, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 963.2994\n",
      "Epoch: 846, Loss: 79177.9766, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 964.4359\n",
      "Epoch: 847, Loss: 77186.1797, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 965.5698\n",
      "Epoch: 848, Loss: 78878.2422, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 966.7052\n",
      "Epoch: 849, Loss: 79149.3594, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 967.8387\n",
      "Epoch: 850, Loss: 79633.1328, Train_Acc: 0.7885, TEST_Acc: 0.5800, Time: 968.9769\n",
      "Epoch: 851, Loss: 80659.0156, Train_Acc: 0.7885, TEST_Acc: 0.5800, Time: 970.1116\n",
      "Epoch: 852, Loss: 79912.5469, Train_Acc: 0.7885, TEST_Acc: 0.5767, Time: 971.2493\n",
      "Epoch: 853, Loss: 79942.4219, Train_Acc: 0.7885, TEST_Acc: 0.5800, Time: 972.3848\n",
      "Epoch: 854, Loss: 79202.1719, Train_Acc: 0.7885, TEST_Acc: 0.5800, Time: 973.5232\n",
      "Epoch: 855, Loss: 80383.4766, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 974.6623\n",
      "Epoch: 856, Loss: 80124.4219, Train_Acc: 0.7885, TEST_Acc: 0.5833, Time: 975.7980\n",
      "Epoch: 857, Loss: 80242.7656, Train_Acc: 0.7885, TEST_Acc: 0.5800, Time: 976.9303\n",
      "Epoch: 858, Loss: 79185.8203, Train_Acc: 0.8077, TEST_Acc: 0.5800, Time: 978.0679\n",
      "Epoch: 859, Loss: 79518.5078, Train_Acc: 0.8077, TEST_Acc: 0.5867, Time: 979.2126\n",
      "Epoch: 860, Loss: 80208.0469, Train_Acc: 0.8077, TEST_Acc: 0.5800, Time: 980.3497\n",
      "Epoch: 861, Loss: 79878.3750, Train_Acc: 0.8269, TEST_Acc: 0.5867, Time: 981.4816\n",
      "Epoch: 862, Loss: 81105.3047, Train_Acc: 0.8077, TEST_Acc: 0.5833, Time: 982.6162\n",
      "Epoch: 863, Loss: 79400.7344, Train_Acc: 0.7885, TEST_Acc: 0.5867, Time: 983.7494\n",
      "Epoch: 864, Loss: 78379.7891, Train_Acc: 0.8077, TEST_Acc: 0.5900, Time: 984.8816\n",
      "Epoch: 865, Loss: 78181.2109, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 986.0186\n",
      "Epoch: 866, Loss: 78137.5781, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 987.1516\n",
      "Epoch: 867, Loss: 77495.7031, Train_Acc: 0.8269, TEST_Acc: 0.5867, Time: 988.2885\n",
      "Epoch: 868, Loss: 77181.1094, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 989.4224\n",
      "Epoch: 869, Loss: 77540.3281, Train_Acc: 0.8269, TEST_Acc: 0.5833, Time: 990.5682\n",
      "Epoch: 870, Loss: 77284.6016, Train_Acc: 0.8269, TEST_Acc: 0.5833, Time: 991.7038\n",
      "Epoch: 871, Loss: 77621.9609, Train_Acc: 0.8269, TEST_Acc: 0.5867, Time: 992.8412\n",
      "Epoch: 872, Loss: 77070.1328, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 993.9805\n",
      "Epoch: 873, Loss: 77717.6406, Train_Acc: 0.8269, TEST_Acc: 0.5833, Time: 995.1139\n",
      "Epoch: 874, Loss: 76856.6250, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 996.2478\n",
      "Epoch: 875, Loss: 76145.3359, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 997.3818\n",
      "Epoch: 876, Loss: 75582.1562, Train_Acc: 0.8269, TEST_Acc: 0.5867, Time: 998.5163\n",
      "Epoch: 877, Loss: 74805.4531, Train_Acc: 0.8269, TEST_Acc: 0.5867, Time: 999.6550\n",
      "Epoch: 878, Loss: 75803.7500, Train_Acc: 0.8269, TEST_Acc: 0.5867, Time: 1000.7959\n",
      "Epoch: 879, Loss: 76837.4062, Train_Acc: 0.8269, TEST_Acc: 0.5833, Time: 1001.9322\n",
      "Epoch: 880, Loss: 75628.9297, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1003.0647\n",
      "Epoch: 881, Loss: 76080.1641, Train_Acc: 0.8269, TEST_Acc: 0.5867, Time: 1004.2022\n",
      "Epoch: 882, Loss: 75927.9609, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1005.3415\n",
      "Epoch: 883, Loss: 76781.9297, Train_Acc: 0.8269, TEST_Acc: 0.5867, Time: 1006.4783\n",
      "Epoch: 884, Loss: 76765.2812, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1007.6158\n",
      "Epoch: 885, Loss: 76392.1172, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1008.7592\n",
      "Epoch: 886, Loss: 76509.9844, Train_Acc: 0.8269, TEST_Acc: 0.5867, Time: 1009.9041\n",
      "Epoch: 887, Loss: 77256.1094, Train_Acc: 0.8269, TEST_Acc: 0.5867, Time: 1011.0432\n",
      "Epoch: 888, Loss: 76921.9688, Train_Acc: 0.8269, TEST_Acc: 0.5867, Time: 1012.1821\n",
      "Epoch: 889, Loss: 76637.6094, Train_Acc: 0.8269, TEST_Acc: 0.5867, Time: 1013.3154\n",
      "Epoch: 890, Loss: 76618.6641, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1014.4506\n",
      "Epoch: 891, Loss: 77168.1172, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1015.5878\n",
      "Epoch: 892, Loss: 76845.8750, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1016.7232\n",
      "Epoch: 893, Loss: 76184.5547, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1017.8576\n",
      "Epoch: 894, Loss: 76482.9062, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1018.9918\n",
      "Epoch: 895, Loss: 77221.3203, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1020.1308\n",
      "Epoch: 896, Loss: 77546.3047, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1021.2673\n",
      "Epoch: 897, Loss: 76763.3750, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1022.4056\n",
      "Epoch: 898, Loss: 77593.2734, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1023.5451\n",
      "Epoch: 899, Loss: 77928.5938, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1024.6822\n",
      "Epoch: 900, Loss: 78247.6797, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1025.8166\n",
      "Epoch: 901, Loss: 78267.9688, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1026.9529\n",
      "Epoch: 902, Loss: 78256.4844, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1028.0856\n",
      "Epoch: 903, Loss: 77453.6094, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1029.2195\n",
      "Epoch: 904, Loss: 77874.1797, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1030.3563\n",
      "Epoch: 905, Loss: 77826.8594, Train_Acc: 0.8269, TEST_Acc: 0.5867, Time: 1031.4999\n",
      "Epoch: 906, Loss: 77358.5703, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1032.6331\n",
      "Epoch: 907, Loss: 77494.2812, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1033.7742\n",
      "Epoch: 908, Loss: 77888.6406, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1034.9167\n",
      "Epoch: 909, Loss: 77087.1172, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1036.0511\n",
      "Epoch: 910, Loss: 77002.3594, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1037.1884\n",
      "Epoch: 911, Loss: 76456.1406, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1038.3278\n",
      "Epoch: 912, Loss: 76471.8047, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1039.4650\n",
      "Epoch: 913, Loss: 77754.5703, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1040.6012\n",
      "Epoch: 914, Loss: 76869.2031, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1041.7354\n",
      "Epoch: 915, Loss: 76098.8359, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1042.8682\n",
      "Epoch: 916, Loss: 75872.9453, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1044.0013\n",
      "Epoch: 917, Loss: 75515.8828, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1045.1353\n",
      "Epoch: 918, Loss: 76640.7969, Train_Acc: 0.8269, TEST_Acc: 0.5967, Time: 1046.2755\n",
      "Epoch: 919, Loss: 76799.0312, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1047.4140\n",
      "Epoch: 920, Loss: 77029.4453, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1048.5465\n",
      "Epoch: 921, Loss: 77017.6406, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1049.6844\n",
      "Epoch: 922, Loss: 77362.9844, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1050.8218\n",
      "Epoch: 923, Loss: 77180.0781, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1051.9623\n",
      "Epoch: 924, Loss: 76069.7734, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1053.1078\n",
      "Epoch: 925, Loss: 76719.2578, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1054.2438\n",
      "Epoch: 926, Loss: 75545.6406, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1055.3808\n",
      "Epoch: 927, Loss: 75089.6250, Train_Acc: 0.8269, TEST_Acc: 0.6000, Time: 1056.5154\n",
      "Epoch: 928, Loss: 74708.4531, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1057.6485\n",
      "Epoch: 929, Loss: 74426.1172, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1058.7854\n",
      "Epoch: 930, Loss: 73357.3047, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1059.9193\n",
      "Epoch: 931, Loss: 72678.3125, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1061.0512\n",
      "Epoch: 932, Loss: 72556.0469, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1062.1894\n",
      "Epoch: 933, Loss: 73308.6328, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1063.3274\n",
      "Epoch: 934, Loss: 72169.7500, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1064.4656\n",
      "Epoch: 935, Loss: 71943.1641, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1065.5978\n",
      "Epoch: 936, Loss: 72143.0469, Train_Acc: 0.8077, TEST_Acc: 0.5900, Time: 1066.7366\n",
      "Epoch: 937, Loss: 71477.1719, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1067.8765\n",
      "Epoch: 938, Loss: 71791.2812, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1069.0139\n",
      "Epoch: 939, Loss: 71518.0703, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1070.1543\n",
      "Epoch: 940, Loss: 72468.4453, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1071.2908\n",
      "Epoch: 941, Loss: 71042.9453, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1072.4238\n",
      "Epoch: 942, Loss: 69997.9531, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1073.5659\n",
      "Epoch: 943, Loss: 70457.1562, Train_Acc: 0.8077, TEST_Acc: 0.5900, Time: 1074.7012\n",
      "Epoch: 944, Loss: 69608.3672, Train_Acc: 0.8077, TEST_Acc: 0.5900, Time: 1075.8375\n",
      "Epoch: 945, Loss: 68885.1562, Train_Acc: 0.8077, TEST_Acc: 0.5900, Time: 1076.9801\n",
      "Epoch: 946, Loss: 67430.8359, Train_Acc: 0.8077, TEST_Acc: 0.5900, Time: 1078.1150\n",
      "Epoch: 947, Loss: 66788.7656, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1079.2509\n",
      "Epoch: 948, Loss: 67016.5859, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1080.3900\n",
      "Epoch: 949, Loss: 66501.1172, Train_Acc: 0.8077, TEST_Acc: 0.5900, Time: 1081.5272\n",
      "Epoch: 950, Loss: 65515.9531, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1082.6688\n",
      "Epoch: 951, Loss: 65128.1836, Train_Acc: 0.8077, TEST_Acc: 0.5900, Time: 1083.8232\n",
      "Epoch: 952, Loss: 65896.7891, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1084.9681\n",
      "Epoch: 953, Loss: 65769.8359, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1086.1025\n",
      "Epoch: 954, Loss: 65366.8320, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1087.2351\n",
      "Epoch: 955, Loss: 65885.9453, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1088.3691\n",
      "Epoch: 956, Loss: 63969.0391, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1089.5052\n",
      "Epoch: 957, Loss: 64715.8672, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1090.6408\n",
      "Epoch: 958, Loss: 64720.4219, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1091.7735\n",
      "Epoch: 959, Loss: 63961.6875, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1092.9106\n",
      "Epoch: 960, Loss: 63341.2305, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1094.0456\n",
      "Epoch: 961, Loss: 62698.4648, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1095.1836\n",
      "Epoch: 962, Loss: 64086.9922, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1096.3212\n",
      "Epoch: 963, Loss: 64524.7773, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1097.4555\n",
      "Epoch: 964, Loss: 63144.0469, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1098.5912\n",
      "Epoch: 965, Loss: 62542.1328, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1099.7305\n",
      "Epoch: 966, Loss: 61776.4922, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1100.8736\n",
      "Epoch: 967, Loss: 61156.3828, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1102.0092\n",
      "Epoch: 968, Loss: 60734.5547, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1103.1424\n",
      "Epoch: 969, Loss: 60439.2500, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1104.2746\n",
      "Epoch: 970, Loss: 59786.2500, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1105.4074\n",
      "Epoch: 971, Loss: 59837.0859, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1106.5458\n",
      "Epoch: 972, Loss: 60155.9727, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1107.6804\n",
      "Epoch: 973, Loss: 61466.8555, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1108.8158\n",
      "Epoch: 974, Loss: 62244.7969, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1109.9552\n",
      "Epoch: 975, Loss: 62565.8086, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1111.0957\n",
      "Epoch: 976, Loss: 62296.6719, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1112.2389\n",
      "Epoch: 977, Loss: 62974.7227, Train_Acc: 0.7885, TEST_Acc: 0.6067, Time: 1113.3870\n",
      "Epoch: 978, Loss: 62228.7695, Train_Acc: 0.7885, TEST_Acc: 0.6067, Time: 1114.5380\n",
      "Epoch: 979, Loss: 62288.7227, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1115.6782\n",
      "Epoch: 980, Loss: 61793.0586, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1116.8137\n",
      "Epoch: 981, Loss: 61411.7031, Train_Acc: 0.7692, TEST_Acc: 0.5900, Time: 1117.9484\n",
      "Epoch: 982, Loss: 62924.1836, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1119.0815\n",
      "Epoch: 983, Loss: 63231.1055, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1120.2162\n",
      "Epoch: 984, Loss: 62953.4453, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1121.3502\n",
      "Epoch: 985, Loss: 62932.7109, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 1122.4817\n",
      "Epoch: 986, Loss: 63432.3086, Train_Acc: 0.7692, TEST_Acc: 0.5900, Time: 1123.6164\n",
      "Epoch: 987, Loss: 62999.8906, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1124.7512\n",
      "Epoch: 988, Loss: 63402.0977, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 1125.8920\n",
      "Epoch: 989, Loss: 63785.6602, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 1127.0279\n",
      "Epoch: 990, Loss: 63245.4727, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 1128.1726\n",
      "Epoch: 991, Loss: 63581.5547, Train_Acc: 0.7500, TEST_Acc: 0.5900, Time: 1129.3086\n",
      "Epoch: 992, Loss: 62668.4414, Train_Acc: 0.7500, TEST_Acc: 0.5900, Time: 1130.4465\n",
      "Epoch: 993, Loss: 61526.4336, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1131.5845\n",
      "Epoch: 994, Loss: 61310.9922, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1132.7175\n",
      "Epoch: 995, Loss: 60672.6914, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1133.8505\n",
      "Epoch: 996, Loss: 59643.8477, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1134.9842\n",
      "Epoch: 997, Loss: 59732.3750, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1136.1222\n",
      "Epoch: 998, Loss: 59140.0273, Train_Acc: 0.7692, TEST_Acc: 0.5933, Time: 1137.2624\n",
      "Epoch: 999, Loss: 59720.6055, Train_Acc: 0.7692, TEST_Acc: 0.5933, Time: 1138.3967\n",
      "Epoch: 1000, Loss: 58897.4375, Train_Acc: 0.7692, TEST_Acc: 0.5933, Time: 1139.5328\n",
      "Epoch: 1001, Loss: 58299.4414, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1140.6695\n",
      "Epoch: 1002, Loss: 58107.5430, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1141.8087\n",
      "Epoch: 1003, Loss: 58739.6875, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1142.9446\n",
      "Epoch: 1004, Loss: 58511.8750, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1144.0808\n",
      "Epoch: 1005, Loss: 59016.4414, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1145.2177\n",
      "Epoch: 1006, Loss: 59299.7969, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1146.3595\n",
      "Epoch: 1007, Loss: 58410.1250, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1147.4962\n",
      "Epoch: 1008, Loss: 58108.2773, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1148.6292\n",
      "Epoch: 1009, Loss: 57714.0000, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1149.7648\n",
      "Epoch: 1010, Loss: 58352.3164, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1150.8991\n",
      "Epoch: 1011, Loss: 59084.4219, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1152.0311\n",
      "Epoch: 1012, Loss: 58011.3750, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1153.1647\n",
      "Epoch: 1013, Loss: 57330.0977, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1154.3005\n",
      "Epoch: 1014, Loss: 56879.1328, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1155.4366\n",
      "Epoch: 1015, Loss: 57394.8086, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1156.5713\n",
      "Epoch: 1016, Loss: 57031.7266, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1157.7096\n",
      "Epoch: 1017, Loss: 57285.2109, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1158.8489\n",
      "Epoch: 1018, Loss: 55179.9219, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1159.9858\n",
      "Epoch: 1019, Loss: 54810.5195, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1161.1279\n",
      "Epoch: 1020, Loss: 54311.5586, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1162.2683\n",
      "Epoch: 1021, Loss: 54697.6250, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1163.4014\n",
      "Epoch: 1022, Loss: 54740.7773, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 1164.5385\n",
      "Epoch: 1023, Loss: 53603.1055, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1165.6798\n",
      "Epoch: 1024, Loss: 54206.5625, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1166.8246\n",
      "Epoch: 1025, Loss: 54835.5078, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1167.9587\n",
      "Epoch: 1026, Loss: 54240.9219, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1169.0902\n",
      "Epoch: 1027, Loss: 54226.1719, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1170.2213\n",
      "Epoch: 1028, Loss: 54659.4023, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1171.3564\n",
      "Epoch: 1029, Loss: 54048.1055, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 1172.4926\n",
      "Epoch: 1030, Loss: 53783.3906, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 1173.6314\n",
      "Epoch: 1031, Loss: 54357.3750, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 1174.7682\n",
      "Epoch: 1032, Loss: 54636.7148, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1175.9058\n",
      "Epoch: 1033, Loss: 56692.3125, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1177.0408\n",
      "Epoch: 1034, Loss: 57577.8477, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1178.1818\n",
      "Epoch: 1035, Loss: 58657.7734, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1179.3157\n",
      "Epoch: 1036, Loss: 57707.3203, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1180.4485\n",
      "Epoch: 1037, Loss: 56760.2500, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1181.5816\n",
      "Epoch: 1038, Loss: 55554.2695, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1182.7178\n",
      "Epoch: 1039, Loss: 55931.6602, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1183.8554\n",
      "Epoch: 1040, Loss: 56246.9180, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1184.9926\n",
      "Epoch: 1041, Loss: 55230.6523, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 1186.1288\n",
      "Epoch: 1042, Loss: 55027.6602, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1187.2612\n",
      "Epoch: 1043, Loss: 54435.1211, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1188.4044\n",
      "Epoch: 1044, Loss: 53493.1953, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 1189.5435\n",
      "Epoch: 1045, Loss: 53411.0898, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1190.6814\n",
      "Epoch: 1046, Loss: 53838.5078, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1191.8252\n",
      "Epoch: 1047, Loss: 52666.0977, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1192.9652\n",
      "Epoch: 1048, Loss: 51591.1016, Train_Acc: 0.8077, TEST_Acc: 0.6033, Time: 1194.0990\n",
      "Epoch: 1049, Loss: 53006.6016, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1195.2345\n",
      "Epoch: 1050, Loss: 53105.1914, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1196.3683\n",
      "Epoch: 1051, Loss: 50950.3906, Train_Acc: 0.8077, TEST_Acc: 0.6033, Time: 1197.5085\n",
      "Epoch: 1052, Loss: 51741.9219, Train_Acc: 0.8077, TEST_Acc: 0.6033, Time: 1198.6439\n",
      "Epoch: 1053, Loss: 51495.7773, Train_Acc: 0.8077, TEST_Acc: 0.6067, Time: 1199.7787\n",
      "Epoch: 1054, Loss: 51524.1445, Train_Acc: 0.7885, TEST_Acc: 0.6067, Time: 1200.9119\n",
      "Epoch: 1055, Loss: 53344.4023, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1202.0449\n",
      "Epoch: 1056, Loss: 54281.3555, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1203.1827\n",
      "Epoch: 1057, Loss: 53996.4727, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1204.3199\n",
      "Epoch: 1058, Loss: 54880.4336, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1205.4579\n",
      "Epoch: 1059, Loss: 54814.3359, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1206.5995\n",
      "Epoch: 1060, Loss: 54423.9023, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1207.7402\n",
      "Epoch: 1061, Loss: 53835.4531, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1208.8791\n",
      "Epoch: 1062, Loss: 53227.1250, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1210.0129\n",
      "Epoch: 1063, Loss: 52867.2969, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 1211.1501\n",
      "Epoch: 1064, Loss: 52978.3320, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1212.2828\n",
      "Epoch: 1065, Loss: 51851.0000, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1213.4146\n",
      "Epoch: 1066, Loss: 51823.2109, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1214.5487\n",
      "Epoch: 1067, Loss: 51908.9336, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 1215.6886\n",
      "Epoch: 1068, Loss: 52445.5703, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1216.8209\n",
      "Epoch: 1069, Loss: 52513.9023, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1217.9584\n",
      "Epoch: 1070, Loss: 52018.0430, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1219.0860\n",
      "Epoch: 1071, Loss: 51964.1836, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 1220.2231\n",
      "Epoch: 1072, Loss: 51767.5000, Train_Acc: 0.7692, TEST_Acc: 0.5933, Time: 1221.3562\n",
      "Epoch: 1073, Loss: 51653.4023, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1222.4942\n",
      "Epoch: 1074, Loss: 51668.5859, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1223.6410\n",
      "Epoch: 1075, Loss: 50423.2734, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1224.7795\n",
      "Epoch: 1076, Loss: 49260.0391, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 1225.9151\n",
      "Epoch: 1077, Loss: 49573.2773, Train_Acc: 0.7500, TEST_Acc: 0.5967, Time: 1227.0501\n",
      "Epoch: 1078, Loss: 50218.7109, Train_Acc: 0.7692, TEST_Acc: 0.5933, Time: 1228.1920\n",
      "Epoch: 1079, Loss: 49513.3555, Train_Acc: 0.7692, TEST_Acc: 0.5867, Time: 1229.3248\n",
      "Epoch: 1080, Loss: 51499.2734, Train_Acc: 0.7692, TEST_Acc: 0.5900, Time: 1230.4613\n",
      "Epoch: 1081, Loss: 50616.3945, Train_Acc: 0.7692, TEST_Acc: 0.5900, Time: 1231.5984\n",
      "Epoch: 1082, Loss: 51365.4180, Train_Acc: 0.7692, TEST_Acc: 0.5867, Time: 1232.7342\n",
      "Epoch: 1083, Loss: 50046.0859, Train_Acc: 0.7692, TEST_Acc: 0.5933, Time: 1233.8803\n",
      "Epoch: 1084, Loss: 49811.1328, Train_Acc: 0.7500, TEST_Acc: 0.5967, Time: 1235.0162\n",
      "Epoch: 1085, Loss: 50229.4805, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1236.1563\n",
      "Epoch: 1086, Loss: 49038.2578, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1237.2952\n",
      "Epoch: 1087, Loss: 48997.9648, Train_Acc: 0.7692, TEST_Acc: 0.5867, Time: 1238.4307\n",
      "Epoch: 1088, Loss: 49105.7422, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 1239.5602\n",
      "Epoch: 1089, Loss: 47953.5977, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 1240.7008\n",
      "Epoch: 1090, Loss: 47473.3789, Train_Acc: 0.7692, TEST_Acc: 0.5867, Time: 1241.8358\n",
      "Epoch: 1091, Loss: 47968.7773, Train_Acc: 0.7692, TEST_Acc: 0.5900, Time: 1242.9658\n",
      "Epoch: 1092, Loss: 48828.5195, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 1244.0969\n",
      "Epoch: 1093, Loss: 51041.6328, Train_Acc: 0.7692, TEST_Acc: 0.5933, Time: 1245.2308\n",
      "Epoch: 1094, Loss: 50373.6172, Train_Acc: 0.7692, TEST_Acc: 0.5933, Time: 1246.3622\n",
      "Epoch: 1095, Loss: 49636.1719, Train_Acc: 0.7692, TEST_Acc: 0.5933, Time: 1247.4999\n",
      "Epoch: 1096, Loss: 48662.0000, Train_Acc: 0.7692, TEST_Acc: 0.5933, Time: 1248.6332\n",
      "Epoch: 1097, Loss: 47875.1445, Train_Acc: 0.7692, TEST_Acc: 0.5933, Time: 1249.7717\n",
      "Epoch: 1098, Loss: 48656.0703, Train_Acc: 0.7692, TEST_Acc: 0.5900, Time: 1250.9052\n",
      "Epoch: 1099, Loss: 48711.6641, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1252.0463\n",
      "Epoch: 1100, Loss: 48191.0977, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1253.1899\n",
      "Epoch: 1101, Loss: 47550.3164, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1254.3255\n",
      "Epoch: 1102, Loss: 46056.9375, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1255.4651\n",
      "Epoch: 1103, Loss: 46184.9141, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1256.5961\n",
      "Epoch: 1104, Loss: 46834.5625, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1257.7402\n",
      "Epoch: 1105, Loss: 46997.9180, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1258.8756\n",
      "Epoch: 1106, Loss: 46122.5625, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1260.0109\n",
      "Epoch: 1107, Loss: 44737.1250, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1261.1496\n",
      "Epoch: 1108, Loss: 46528.8359, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1262.2830\n",
      "Epoch: 1109, Loss: 45399.8672, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1263.4204\n",
      "Epoch: 1110, Loss: 46416.9180, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1264.5567\n",
      "Epoch: 1111, Loss: 46472.1172, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1265.6948\n",
      "Epoch: 1112, Loss: 46927.3750, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1266.8347\n",
      "Epoch: 1113, Loss: 46766.0625, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1267.9741\n",
      "Epoch: 1114, Loss: 45158.1680, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1269.1122\n",
      "Epoch: 1115, Loss: 45186.4414, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 1270.2463\n",
      "Epoch: 1116, Loss: 44371.3984, Train_Acc: 0.8077, TEST_Acc: 0.5900, Time: 1271.3804\n",
      "Epoch: 1117, Loss: 45300.7070, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1272.5180\n",
      "Epoch: 1118, Loss: 46713.8164, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1273.6511\n",
      "Epoch: 1119, Loss: 46071.4961, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1274.7843\n",
      "Epoch: 1120, Loss: 46026.2539, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1275.9204\n",
      "Epoch: 1121, Loss: 45562.2109, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1277.0536\n",
      "Epoch: 1122, Loss: 44607.5352, Train_Acc: 0.8077, TEST_Acc: 0.5900, Time: 1278.1905\n",
      "Epoch: 1123, Loss: 44947.9141, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1279.3265\n",
      "Epoch: 1124, Loss: 44789.3672, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1280.4584\n",
      "Epoch: 1125, Loss: 45610.8711, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1281.5944\n",
      "Epoch: 1126, Loss: 44981.1211, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1282.7402\n",
      "Epoch: 1127, Loss: 45208.6250, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1283.8777\n",
      "Epoch: 1128, Loss: 44207.7031, Train_Acc: 0.8269, TEST_Acc: 0.6000, Time: 1285.0123\n",
      "Epoch: 1129, Loss: 45948.2695, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1286.1467\n",
      "Epoch: 1130, Loss: 46682.1094, Train_Acc: 0.8269, TEST_Acc: 0.6000, Time: 1287.2802\n",
      "Epoch: 1131, Loss: 47085.6797, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1288.4154\n",
      "Epoch: 1132, Loss: 47196.4102, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1289.5459\n",
      "Epoch: 1133, Loss: 45692.3086, Train_Acc: 0.8462, TEST_Acc: 0.5933, Time: 1290.6795\n",
      "Epoch: 1134, Loss: 46204.3672, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1291.8158\n",
      "Epoch: 1135, Loss: 46692.6016, Train_Acc: 0.8462, TEST_Acc: 0.5933, Time: 1292.9565\n",
      "Epoch: 1136, Loss: 47389.4805, Train_Acc: 0.8269, TEST_Acc: 0.5967, Time: 1294.0931\n",
      "Epoch: 1137, Loss: 46599.4102, Train_Acc: 0.8462, TEST_Acc: 0.5967, Time: 1295.2330\n",
      "Epoch: 1138, Loss: 45181.2695, Train_Acc: 0.8462, TEST_Acc: 0.6000, Time: 1296.3754\n",
      "Epoch: 1139, Loss: 44902.4336, Train_Acc: 0.8269, TEST_Acc: 0.5867, Time: 1297.5118\n",
      "Epoch: 1140, Loss: 43670.3086, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1298.6476\n",
      "Epoch: 1141, Loss: 44318.7578, Train_Acc: 0.8269, TEST_Acc: 0.5967, Time: 1299.7862\n",
      "Epoch: 1142, Loss: 44590.2773, Train_Acc: 0.8269, TEST_Acc: 0.6000, Time: 1300.9194\n",
      "Epoch: 1143, Loss: 46159.0781, Train_Acc: 0.8269, TEST_Acc: 0.5967, Time: 1302.0513\n",
      "Epoch: 1144, Loss: 46715.8945, Train_Acc: 0.8269, TEST_Acc: 0.6000, Time: 1303.1832\n",
      "Epoch: 1145, Loss: 46997.5859, Train_Acc: 0.8269, TEST_Acc: 0.5967, Time: 1304.3254\n",
      "Epoch: 1146, Loss: 46740.8789, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1305.4600\n",
      "Epoch: 1147, Loss: 47035.5156, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1306.5968\n",
      "Epoch: 1148, Loss: 47107.0000, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1307.7291\n",
      "Epoch: 1149, Loss: 47563.5391, Train_Acc: 0.8269, TEST_Acc: 0.5967, Time: 1308.8634\n",
      "Epoch: 1150, Loss: 47715.2891, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1310.0011\n",
      "Epoch: 1151, Loss: 47390.0977, Train_Acc: 0.8077, TEST_Acc: 0.6033, Time: 1311.1390\n",
      "Epoch: 1152, Loss: 47669.9453, Train_Acc: 0.8269, TEST_Acc: 0.6033, Time: 1312.2782\n",
      "Epoch: 1153, Loss: 47918.9727, Train_Acc: 0.8269, TEST_Acc: 0.6033, Time: 1313.4123\n",
      "Epoch: 1154, Loss: 48161.7305, Train_Acc: 0.8269, TEST_Acc: 0.6033, Time: 1314.5543\n",
      "Epoch: 1155, Loss: 47712.9141, Train_Acc: 0.8269, TEST_Acc: 0.5967, Time: 1315.6932\n",
      "Epoch: 1156, Loss: 47081.0000, Train_Acc: 0.8269, TEST_Acc: 0.5967, Time: 1316.8291\n",
      "Epoch: 1157, Loss: 46814.2422, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1317.9611\n",
      "Epoch: 1158, Loss: 47803.9805, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1319.0968\n",
      "Epoch: 1159, Loss: 47149.4336, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1320.2378\n",
      "Epoch: 1160, Loss: 47359.4219, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1321.3761\n",
      "Epoch: 1161, Loss: 47204.8555, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1322.5088\n",
      "Epoch: 1162, Loss: 47112.8672, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1323.6427\n",
      "Epoch: 1163, Loss: 47221.6172, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1324.7812\n",
      "Epoch: 1164, Loss: 47303.5000, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1325.9142\n",
      "Epoch: 1165, Loss: 46726.6719, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1327.0613\n",
      "Epoch: 1166, Loss: 46815.2266, Train_Acc: 0.8269, TEST_Acc: 0.5900, Time: 1328.1967\n",
      "Epoch: 1167, Loss: 46446.6719, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1329.3346\n",
      "Epoch: 1168, Loss: 45598.9531, Train_Acc: 0.8269, TEST_Acc: 0.6000, Time: 1330.4726\n",
      "Epoch: 1169, Loss: 45345.9453, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1331.6118\n",
      "Epoch: 1170, Loss: 44449.7578, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1332.7421\n",
      "Epoch: 1171, Loss: 44178.8516, Train_Acc: 0.8269, TEST_Acc: 0.5933, Time: 1333.8827\n",
      "Epoch: 1172, Loss: 44451.8320, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1335.0139\n",
      "Epoch: 1173, Loss: 44970.5664, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1336.1456\n",
      "Epoch: 1174, Loss: 44017.1797, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1337.2778\n",
      "Epoch: 1175, Loss: 43717.5859, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1338.4077\n",
      "Epoch: 1176, Loss: 43121.5273, Train_Acc: 0.7885, TEST_Acc: 0.6100, Time: 1339.5399\n",
      "Epoch: 1177, Loss: 43087.1094, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1340.6748\n",
      "Epoch: 1178, Loss: 43436.4141, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 1341.8085\n",
      "Epoch: 1179, Loss: 43480.2500, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1342.9493\n",
      "Epoch: 1180, Loss: 44092.7891, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 1344.0903\n",
      "Epoch: 1181, Loss: 43191.0391, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1345.2262\n",
      "Epoch: 1182, Loss: 42031.7109, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1346.3649\n",
      "Epoch: 1183, Loss: 41421.5273, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1347.5014\n",
      "Epoch: 1184, Loss: 42423.2656, Train_Acc: 0.7885, TEST_Acc: 0.5900, Time: 1348.6363\n",
      "Epoch: 1185, Loss: 43673.9531, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1349.7747\n",
      "Epoch: 1186, Loss: 43598.5703, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1350.9057\n",
      "Epoch: 1187, Loss: 44412.9023, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1352.0393\n",
      "Epoch: 1188, Loss: 44560.6719, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1353.1766\n",
      "Epoch: 1189, Loss: 42124.2344, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1354.3085\n",
      "Epoch: 1190, Loss: 40882.7305, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1355.4434\n",
      "Epoch: 1191, Loss: 41205.7266, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1356.5729\n",
      "Epoch: 1192, Loss: 40995.1094, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1357.7084\n",
      "Epoch: 1193, Loss: 40434.8555, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1358.8483\n",
      "Epoch: 1194, Loss: 41100.7266, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1359.9858\n",
      "Epoch: 1195, Loss: 41828.5781, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1361.1315\n",
      "Epoch: 1196, Loss: 41718.9375, Train_Acc: 0.7885, TEST_Acc: 0.5933, Time: 1362.2670\n",
      "Epoch: 1197, Loss: 42220.6445, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1363.3986\n",
      "Epoch: 1198, Loss: 41320.6055, Train_Acc: 0.7692, TEST_Acc: 0.6100, Time: 1364.5315\n",
      "Epoch: 1199, Loss: 42016.4961, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1365.6673\n",
      "Epoch: 1200, Loss: 42135.1445, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1366.8086\n",
      "Epoch: 1201, Loss: 42463.4922, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1367.9418\n",
      "Epoch: 1202, Loss: 42117.1250, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1369.0764\n",
      "Epoch: 1203, Loss: 42760.5625, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1370.2187\n",
      "Epoch: 1204, Loss: 44126.5820, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1371.3552\n",
      "Epoch: 1205, Loss: 43640.2109, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1372.4943\n",
      "Epoch: 1206, Loss: 42274.6875, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1373.6296\n",
      "Epoch: 1207, Loss: 42941.7031, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1374.7663\n",
      "Epoch: 1208, Loss: 42980.6680, Train_Acc: 0.7885, TEST_Acc: 0.6067, Time: 1375.9051\n",
      "Epoch: 1209, Loss: 43714.2695, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1377.0427\n",
      "Epoch: 1210, Loss: 43395.2695, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1378.1796\n",
      "Epoch: 1211, Loss: 43549.2305, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1379.3215\n",
      "Epoch: 1212, Loss: 43802.8789, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1380.4557\n",
      "Epoch: 1213, Loss: 44076.4023, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1381.5919\n",
      "Epoch: 1214, Loss: 44586.0781, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1382.7267\n",
      "Epoch: 1215, Loss: 44776.4961, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1383.8606\n",
      "Epoch: 1216, Loss: 45136.9531, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1384.9942\n",
      "Epoch: 1217, Loss: 44990.2227, Train_Acc: 0.8077, TEST_Acc: 0.6033, Time: 1386.1294\n",
      "Epoch: 1218, Loss: 44980.5547, Train_Acc: 0.8077, TEST_Acc: 0.6100, Time: 1387.2650\n",
      "Epoch: 1219, Loss: 44163.1602, Train_Acc: 0.8077, TEST_Acc: 0.6067, Time: 1388.4015\n",
      "Epoch: 1220, Loss: 43840.3320, Train_Acc: 0.8077, TEST_Acc: 0.6100, Time: 1389.5348\n",
      "Epoch: 1221, Loss: 43312.1328, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1390.6713\n",
      "Epoch: 1222, Loss: 43682.4531, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1391.8066\n",
      "Epoch: 1223, Loss: 43197.9531, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1392.9422\n",
      "Epoch: 1224, Loss: 43459.8164, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1394.0779\n",
      "Epoch: 1225, Loss: 43113.0234, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1395.2136\n",
      "Epoch: 1226, Loss: 43179.2773, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1396.3469\n",
      "Epoch: 1227, Loss: 43081.4219, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1397.4807\n",
      "Epoch: 1228, Loss: 42195.7227, Train_Acc: 0.8077, TEST_Acc: 0.6000, Time: 1398.6124\n",
      "Epoch: 1229, Loss: 42038.8398, Train_Acc: 0.8077, TEST_Acc: 0.5967, Time: 1399.7481\n",
      "Epoch: 1230, Loss: 42283.8359, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1400.8822\n",
      "Epoch: 1231, Loss: 42682.9141, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1402.0169\n",
      "Epoch: 1232, Loss: 41764.5586, Train_Acc: 0.7885, TEST_Acc: 0.5967, Time: 1403.1512\n",
      "Epoch: 1233, Loss: 41111.7266, Train_Acc: 0.8077, TEST_Acc: 0.5933, Time: 1404.2923\n",
      "Epoch: 1234, Loss: 41305.2773, Train_Acc: 0.8077, TEST_Acc: 0.6033, Time: 1405.4420\n",
      "Epoch: 1235, Loss: 41319.8555, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1406.5811\n",
      "Epoch: 1236, Loss: 41099.4141, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1407.7213\n",
      "Epoch: 1237, Loss: 41791.9570, Train_Acc: 0.8077, TEST_Acc: 0.6033, Time: 1408.8641\n",
      "Epoch: 1238, Loss: 42265.4336, Train_Acc: 0.8077, TEST_Acc: 0.6033, Time: 1409.9972\n",
      "Epoch: 1239, Loss: 41917.1875, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1411.1264\n",
      "Epoch: 1240, Loss: 42322.8750, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1412.2616\n",
      "Epoch: 1241, Loss: 42353.0391, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1413.3918\n",
      "Epoch: 1242, Loss: 42700.5586, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1414.5249\n",
      "Epoch: 1243, Loss: 42168.7695, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1415.6615\n",
      "Epoch: 1244, Loss: 41985.4844, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1416.8036\n",
      "Epoch: 1245, Loss: 42503.5781, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1417.9420\n",
      "Epoch: 1246, Loss: 42621.6602, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1419.0873\n",
      "Epoch: 1247, Loss: 42658.0391, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1420.2273\n",
      "Epoch: 1248, Loss: 42209.8945, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1421.3664\n",
      "Epoch: 1249, Loss: 41950.1445, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1422.5007\n",
      "Epoch: 1250, Loss: 41293.9609, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1423.6479\n",
      "Epoch: 1251, Loss: 41742.4531, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1424.7812\n",
      "Epoch: 1252, Loss: 42070.7656, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1425.9198\n",
      "Epoch: 1253, Loss: 41782.5469, Train_Acc: 0.7885, TEST_Acc: 0.6000, Time: 1427.0534\n",
      "Epoch: 1254, Loss: 42123.5234, Train_Acc: 0.7885, TEST_Acc: 0.6033, Time: 1428.1893\n",
      "Epoch: 1255, Loss: 41880.7109, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1429.3183\n",
      "Epoch: 1256, Loss: 41130.8477, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1430.4566\n",
      "Epoch: 1257, Loss: 41037.1406, Train_Acc: 0.7885, TEST_Acc: 0.6067, Time: 1431.5893\n",
      "Epoch: 1258, Loss: 41224.3359, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 1432.7256\n",
      "Epoch: 1259, Loss: 41138.3828, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1433.8632\n",
      "Epoch: 1260, Loss: 40515.7109, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1435.0003\n",
      "Epoch: 1261, Loss: 41240.0000, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 1436.1392\n",
      "Epoch: 1262, Loss: 41340.5000, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 1437.2781\n",
      "Epoch: 1263, Loss: 39964.0234, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1438.4158\n",
      "Epoch: 1264, Loss: 39596.9531, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1439.5566\n",
      "Epoch: 1265, Loss: 39321.7227, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 1440.6971\n",
      "Epoch: 1266, Loss: 39413.7578, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1441.8296\n",
      "Epoch: 1267, Loss: 39148.4727, Train_Acc: 0.7500, TEST_Acc: 0.5967, Time: 1442.9601\n",
      "Epoch: 1268, Loss: 39004.6875, Train_Acc: 0.7500, TEST_Acc: 0.5967, Time: 1444.0925\n",
      "Epoch: 1269, Loss: 38518.3711, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 1445.2264\n",
      "Epoch: 1270, Loss: 38928.1914, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1446.3594\n",
      "Epoch: 1271, Loss: 38359.7969, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 1447.4957\n",
      "Epoch: 1272, Loss: 38633.4375, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1448.6334\n",
      "Epoch: 1273, Loss: 39101.1914, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1449.7719\n",
      "Epoch: 1274, Loss: 39170.7461, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 1450.9131\n",
      "Epoch: 1275, Loss: 39423.0625, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1452.0516\n",
      "Epoch: 1276, Loss: 39443.1172, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1453.1872\n",
      "Epoch: 1277, Loss: 39281.3359, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1454.3209\n",
      "Epoch: 1278, Loss: 40534.6289, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1455.4538\n",
      "Epoch: 1279, Loss: 39809.8477, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1456.5882\n",
      "Epoch: 1280, Loss: 38866.0195, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1457.7231\n",
      "Epoch: 1281, Loss: 38315.4766, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1458.8594\n",
      "Epoch: 1282, Loss: 38747.1328, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 1459.9909\n",
      "Epoch: 1283, Loss: 39081.7266, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 1461.1196\n",
      "Epoch: 1284, Loss: 40169.3867, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1462.2632\n",
      "Epoch: 1285, Loss: 40860.4336, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 1463.4009\n",
      "Epoch: 1286, Loss: 39033.0234, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1464.5380\n",
      "Epoch: 1287, Loss: 38772.9609, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 1465.6807\n",
      "Epoch: 1288, Loss: 39491.0938, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 1466.8144\n",
      "Epoch: 1289, Loss: 39705.5234, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 1467.9479\n",
      "Epoch: 1290, Loss: 39910.8711, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 1469.0873\n",
      "Epoch: 1291, Loss: 39543.0547, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 1470.2232\n",
      "Epoch: 1292, Loss: 39899.7773, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 1471.3599\n",
      "Epoch: 1293, Loss: 39086.0312, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1472.4906\n",
      "Epoch: 1294, Loss: 38524.6445, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1473.6269\n",
      "Epoch: 1295, Loss: 37558.9766, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1474.7623\n",
      "Epoch: 1296, Loss: 37565.6914, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1475.8913\n",
      "Epoch: 1297, Loss: 38193.2812, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 1477.0258\n",
      "Epoch: 1298, Loss: 37668.8711, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 1478.1610\n",
      "Epoch: 1299, Loss: 36510.9844, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 1479.3006\n",
      "Epoch: 1300, Loss: 37155.6914, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 1480.4414\n",
      "Epoch: 1301, Loss: 37682.9570, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 1481.5821\n",
      "Epoch: 1302, Loss: 36528.5977, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 1482.7167\n",
      "Epoch: 1303, Loss: 35620.4375, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 1483.8531\n",
      "Epoch: 1304, Loss: 35671.1250, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 1484.9853\n",
      "Epoch: 1305, Loss: 36114.6484, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 1486.1193\n",
      "Epoch: 1306, Loss: 36962.6328, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1487.2559\n",
      "Epoch: 1307, Loss: 37592.5469, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1488.3857\n",
      "Epoch: 1308, Loss: 38533.1758, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1489.5143\n",
      "Epoch: 1309, Loss: 36772.3203, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1490.6478\n",
      "Epoch: 1310, Loss: 37521.6719, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1491.7899\n",
      "Epoch: 1311, Loss: 38147.0312, Train_Acc: 0.7692, TEST_Acc: 0.6100, Time: 1492.9308\n",
      "Epoch: 1312, Loss: 37443.6289, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1494.0722\n",
      "Epoch: 1313, Loss: 38056.4844, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1495.2088\n",
      "Epoch: 1314, Loss: 37525.6836, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1496.3437\n",
      "Epoch: 1315, Loss: 37303.7031, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1497.4803\n",
      "Epoch: 1316, Loss: 38096.4492, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1498.6198\n",
      "Epoch: 1317, Loss: 36647.7266, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 1499.7612\n",
      "Epoch: 1318, Loss: 36027.4570, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1500.8933\n",
      "Epoch: 1319, Loss: 37478.7305, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 1502.0287\n",
      "Epoch: 1320, Loss: 37534.1016, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 1503.1719\n",
      "Epoch: 1321, Loss: 37603.2227, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 1504.3124\n",
      "Epoch: 1322, Loss: 36382.2656, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 1505.4469\n",
      "Epoch: 1323, Loss: 35649.2969, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 1506.5829\n",
      "Epoch: 1324, Loss: 35508.3945, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 1507.7179\n",
      "Epoch: 1325, Loss: 35940.6641, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 1508.8564\n",
      "Epoch: 1326, Loss: 36861.3906, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 1509.9941\n",
      "Epoch: 1327, Loss: 36590.4648, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 1511.1327\n",
      "Epoch: 1328, Loss: 36237.3672, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 1512.2713\n",
      "Epoch: 1329, Loss: 35870.8477, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 1513.4108\n",
      "Epoch: 1330, Loss: 35825.5547, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 1514.5574\n",
      "Epoch: 1331, Loss: 37250.7148, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 1515.6921\n",
      "Epoch: 1332, Loss: 35173.7617, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 1516.8250\n",
      "Epoch: 1333, Loss: 35486.6523, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 1517.9611\n",
      "Epoch: 1334, Loss: 36304.0195, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 1519.0943\n",
      "Epoch: 1335, Loss: 36178.1953, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 1520.2298\n",
      "Epoch: 1336, Loss: 35355.0664, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 1521.3605\n",
      "Epoch: 1337, Loss: 35875.7383, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 1522.4953\n",
      "Epoch: 1338, Loss: 35260.1055, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 1523.6342\n",
      "Epoch: 1339, Loss: 35552.0859, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 1524.7702\n",
      "Epoch: 1340, Loss: 37581.0977, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 1525.9154\n",
      "Epoch: 1341, Loss: 38890.1953, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 1527.0616\n",
      "Epoch: 1342, Loss: 37618.4648, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 1528.2049\n",
      "Epoch: 1343, Loss: 37422.5391, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 1529.3386\n",
      "Epoch: 1344, Loss: 38427.8672, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 1530.4790\n",
      "Epoch: 1345, Loss: 38935.8164, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 1531.6128\n",
      "Epoch: 1346, Loss: 36970.8516, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 1532.7474\n",
      "Epoch: 1347, Loss: 36420.0391, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 1533.8851\n",
      "Epoch: 1348, Loss: 36430.2656, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 1535.0244\n",
      "Epoch: 1349, Loss: 35374.6758, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 1536.1598\n",
      "Epoch: 1350, Loss: 35253.6094, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 1537.2964\n",
      "Epoch: 1351, Loss: 35588.9219, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 1538.4318\n",
      "Epoch: 1352, Loss: 37314.6602, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 1539.5747\n",
      "Epoch: 1353, Loss: 36004.6953, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 1540.7098\n",
      "Epoch: 1354, Loss: 37621.2383, Train_Acc: 0.7115, TEST_Acc: 0.6100, Time: 1541.8475\n",
      "Epoch: 1355, Loss: 36583.0469, Train_Acc: 0.7115, TEST_Acc: 0.6100, Time: 1542.9907\n",
      "Epoch: 1356, Loss: 37180.7266, Train_Acc: 0.7115, TEST_Acc: 0.6133, Time: 1544.1281\n",
      "Epoch: 1357, Loss: 35738.7695, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 1545.2642\n",
      "Epoch: 1358, Loss: 34735.8711, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 1546.4052\n",
      "Epoch: 1359, Loss: 34194.8750, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 1547.5443\n",
      "Epoch: 1360, Loss: 33826.8125, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 1548.6811\n",
      "Epoch: 1361, Loss: 33659.8984, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 1549.8131\n",
      "Epoch: 1362, Loss: 33238.9375, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 1550.9469\n",
      "Epoch: 1363, Loss: 32486.9805, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 1552.0792\n",
      "Epoch: 1364, Loss: 33045.7930, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 1553.2176\n",
      "Epoch: 1365, Loss: 32728.2070, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 1554.3590\n",
      "Epoch: 1366, Loss: 32239.5586, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 1555.4987\n",
      "Epoch: 1367, Loss: 32326.6797, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 1556.6350\n",
      "Epoch: 1368, Loss: 32184.2305, Train_Acc: 0.7115, TEST_Acc: 0.6067, Time: 1557.7734\n",
      "Epoch: 1369, Loss: 31507.3516, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 1558.9047\n",
      "Epoch: 1370, Loss: 31150.1777, Train_Acc: 0.7115, TEST_Acc: 0.6067, Time: 1560.0382\n",
      "Epoch: 1371, Loss: 31526.2070, Train_Acc: 0.7115, TEST_Acc: 0.6067, Time: 1561.1680\n",
      "Epoch: 1372, Loss: 32246.8516, Train_Acc: 0.7115, TEST_Acc: 0.6067, Time: 1562.3045\n",
      "Epoch: 1373, Loss: 31879.0625, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 1563.4425\n",
      "Epoch: 1374, Loss: 30775.9512, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1564.5744\n",
      "Epoch: 1375, Loss: 32056.8359, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 1565.7105\n",
      "Epoch: 1376, Loss: 32542.6230, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 1566.8430\n",
      "Epoch: 1377, Loss: 31669.6445, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 1567.9845\n",
      "Epoch: 1378, Loss: 30861.6465, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 1569.1196\n",
      "Epoch: 1379, Loss: 30539.4668, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 1570.2573\n",
      "Epoch: 1380, Loss: 31385.9023, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 1571.3908\n",
      "Epoch: 1381, Loss: 32227.5488, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 1572.5286\n",
      "Epoch: 1382, Loss: 31753.4141, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 1573.6641\n",
      "Epoch: 1383, Loss: 31827.1777, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 1574.7975\n",
      "Epoch: 1384, Loss: 32640.8633, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 1575.9345\n",
      "Epoch: 1385, Loss: 32946.1953, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 1577.0711\n",
      "Epoch: 1386, Loss: 31849.5859, Train_Acc: 0.7115, TEST_Acc: 0.6200, Time: 1578.2093\n",
      "Epoch: 1387, Loss: 32769.5000, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1579.3446\n",
      "Epoch: 1388, Loss: 31799.5508, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 1580.4790\n",
      "Epoch: 1389, Loss: 31483.3047, Train_Acc: 0.7308, TEST_Acc: 0.6233, Time: 1581.6116\n",
      "Epoch: 1390, Loss: 31846.8223, Train_Acc: 0.7115, TEST_Acc: 0.6167, Time: 1582.7640\n",
      "Epoch: 1391, Loss: 32211.1523, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1583.9000\n",
      "Epoch: 1392, Loss: 31702.2109, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 1585.0345\n",
      "Epoch: 1393, Loss: 32085.1113, Train_Acc: 0.7115, TEST_Acc: 0.6200, Time: 1586.1716\n",
      "Epoch: 1394, Loss: 31417.9043, Train_Acc: 0.7115, TEST_Acc: 0.6200, Time: 1587.3151\n",
      "Epoch: 1395, Loss: 31785.9766, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1588.4524\n",
      "Epoch: 1396, Loss: 31606.1211, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 1589.5864\n",
      "Epoch: 1397, Loss: 31042.4082, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 1590.7337\n",
      "Epoch: 1398, Loss: 31322.5391, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1591.8691\n",
      "Epoch: 1399, Loss: 30805.8457, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 1593.0004\n",
      "Epoch: 1400, Loss: 31163.1445, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 1594.1402\n",
      "Epoch: 1401, Loss: 30950.6270, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 1595.2720\n",
      "Epoch: 1402, Loss: 31737.8359, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1596.4062\n",
      "Epoch: 1403, Loss: 31496.4238, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 1597.5452\n",
      "Epoch: 1404, Loss: 31904.8164, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 1598.6915\n",
      "Epoch: 1405, Loss: 30881.8340, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 1599.8306\n",
      "Epoch: 1406, Loss: 30518.5039, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 1600.9648\n",
      "Epoch: 1407, Loss: 29965.7266, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 1602.1031\n",
      "Epoch: 1408, Loss: 29857.8887, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 1603.2453\n",
      "Epoch: 1409, Loss: 29798.4102, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 1604.3803\n",
      "Epoch: 1410, Loss: 29885.8203, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 1605.5205\n",
      "Epoch: 1411, Loss: 29722.4863, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 1606.6532\n",
      "Epoch: 1412, Loss: 29974.9062, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 1607.7865\n",
      "Epoch: 1413, Loss: 30005.5391, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 1608.9164\n",
      "Epoch: 1414, Loss: 29699.0078, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1610.0570\n",
      "Epoch: 1415, Loss: 29579.4668, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 1611.1921\n",
      "Epoch: 1416, Loss: 29747.5391, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1612.3264\n",
      "Epoch: 1417, Loss: 28915.9238, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1613.4609\n",
      "Epoch: 1418, Loss: 29448.7090, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1614.5961\n",
      "Epoch: 1419, Loss: 29535.5801, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1615.7347\n",
      "Epoch: 1420, Loss: 29730.4297, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1616.8705\n",
      "Epoch: 1421, Loss: 29774.5527, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1618.0073\n",
      "Epoch: 1422, Loss: 28875.6016, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1619.1487\n",
      "Epoch: 1423, Loss: 28414.1660, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1620.2873\n",
      "Epoch: 1424, Loss: 28319.5527, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 1621.4191\n",
      "Epoch: 1425, Loss: 28477.7910, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 1622.5534\n",
      "Epoch: 1426, Loss: 28124.9043, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 1623.6913\n",
      "Epoch: 1427, Loss: 27329.3301, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 1624.8322\n",
      "Epoch: 1428, Loss: 27906.1172, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1625.9641\n",
      "Epoch: 1429, Loss: 27571.4980, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 1627.0988\n",
      "Epoch: 1430, Loss: 26933.7539, Train_Acc: 0.7308, TEST_Acc: 0.6233, Time: 1628.2306\n",
      "Epoch: 1431, Loss: 27087.4707, Train_Acc: 0.7308, TEST_Acc: 0.6233, Time: 1629.3667\n",
      "Epoch: 1432, Loss: 26472.7480, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 1630.5089\n",
      "Epoch: 1433, Loss: 26577.8711, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 1631.6470\n",
      "Epoch: 1434, Loss: 27425.3359, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 1632.7841\n",
      "Epoch: 1435, Loss: 27140.2910, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 1633.9208\n",
      "Epoch: 1436, Loss: 26523.2930, Train_Acc: 0.7308, TEST_Acc: 0.6233, Time: 1635.0549\n",
      "Epoch: 1437, Loss: 26602.0703, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 1636.1893\n",
      "Epoch: 1438, Loss: 25729.5078, Train_Acc: 0.7308, TEST_Acc: 0.6233, Time: 1637.3222\n",
      "Epoch: 1439, Loss: 25679.6152, Train_Acc: 0.7308, TEST_Acc: 0.6233, Time: 1638.4583\n",
      "Epoch: 1440, Loss: 25317.6387, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 1639.5931\n",
      "Epoch: 1441, Loss: 25067.4922, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 1640.7277\n",
      "Epoch: 1442, Loss: 25253.2773, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 1641.8678\n",
      "Epoch: 1443, Loss: 25124.7402, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 1642.9986\n",
      "Epoch: 1444, Loss: 25586.7578, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 1644.1450\n",
      "Epoch: 1445, Loss: 24808.0957, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 1645.2792\n",
      "Epoch: 1446, Loss: 24597.6836, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 1646.4149\n",
      "Epoch: 1447, Loss: 25716.7637, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 1647.5553\n",
      "Epoch: 1448, Loss: 24534.7305, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1648.6930\n",
      "Epoch: 1449, Loss: 24417.5352, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1649.8287\n",
      "Epoch: 1450, Loss: 24024.0527, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1650.9619\n",
      "Epoch: 1451, Loss: 24248.0859, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 1652.0994\n",
      "Epoch: 1452, Loss: 24024.6250, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1653.2328\n",
      "Epoch: 1453, Loss: 24305.4141, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1654.3681\n",
      "Epoch: 1454, Loss: 24892.4395, Train_Acc: 0.7885, TEST_Acc: 0.6200, Time: 1655.5022\n",
      "Epoch: 1455, Loss: 24537.1016, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1656.6362\n",
      "Epoch: 1456, Loss: 24315.2363, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1657.7678\n",
      "Epoch: 1457, Loss: 24268.3125, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1658.9033\n",
      "Epoch: 1458, Loss: 24326.2324, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1660.0401\n",
      "Epoch: 1459, Loss: 24737.1523, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 1661.1771\n",
      "Epoch: 1460, Loss: 23779.5488, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1662.3198\n",
      "Epoch: 1461, Loss: 23518.4375, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 1663.4573\n",
      "Epoch: 1462, Loss: 23949.2930, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 1664.6008\n",
      "Epoch: 1463, Loss: 24009.9277, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 1665.7358\n",
      "Epoch: 1464, Loss: 23355.7598, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 1666.8712\n",
      "Epoch: 1465, Loss: 23241.6250, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1668.0046\n",
      "Epoch: 1466, Loss: 23410.2715, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 1669.1366\n",
      "Epoch: 1467, Loss: 23950.4805, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 1670.2691\n",
      "Epoch: 1468, Loss: 24296.1387, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 1671.4070\n",
      "Epoch: 1469, Loss: 24299.0176, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 1672.5451\n",
      "Epoch: 1470, Loss: 25053.4668, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 1673.6825\n",
      "Epoch: 1471, Loss: 24863.2402, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1674.8170\n",
      "Epoch: 1472, Loss: 24693.2285, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1675.9533\n",
      "Epoch: 1473, Loss: 23912.2461, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1677.0905\n",
      "Epoch: 1474, Loss: 23942.0820, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1678.2251\n",
      "Epoch: 1475, Loss: 23745.1250, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1679.3650\n",
      "Epoch: 1476, Loss: 23059.2637, Train_Acc: 0.8077, TEST_Acc: 0.6267, Time: 1680.5071\n",
      "Epoch: 1477, Loss: 23655.2051, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1681.6433\n",
      "Epoch: 1478, Loss: 23815.9727, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 1682.7852\n",
      "Epoch: 1479, Loss: 23666.4043, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 1683.9187\n",
      "Epoch: 1480, Loss: 23737.7305, Train_Acc: 0.7885, TEST_Acc: 0.6300, Time: 1685.0486\n",
      "Epoch: 1481, Loss: 23149.1875, Train_Acc: 0.8077, TEST_Acc: 0.6300, Time: 1686.1814\n",
      "Epoch: 1482, Loss: 23035.3027, Train_Acc: 0.7885, TEST_Acc: 0.6300, Time: 1687.3156\n",
      "Epoch: 1483, Loss: 23108.9707, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 1688.4482\n",
      "Epoch: 1484, Loss: 23358.6465, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 1689.5843\n",
      "Epoch: 1485, Loss: 22797.5801, Train_Acc: 0.8077, TEST_Acc: 0.6300, Time: 1690.7194\n",
      "Epoch: 1486, Loss: 22934.9336, Train_Acc: 0.8077, TEST_Acc: 0.6267, Time: 1691.8583\n",
      "Epoch: 1487, Loss: 23408.3652, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 1692.9978\n",
      "Epoch: 1488, Loss: 23993.7500, Train_Acc: 0.7500, TEST_Acc: 0.6300, Time: 1694.1376\n",
      "Epoch: 1489, Loss: 23995.0449, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 1695.2784\n",
      "Epoch: 1490, Loss: 23925.2637, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 1696.4205\n",
      "Epoch: 1491, Loss: 23799.3652, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1697.5544\n",
      "Epoch: 1492, Loss: 23592.5293, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1698.6913\n",
      "Epoch: 1493, Loss: 23590.0195, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 1699.8287\n",
      "Epoch: 1494, Loss: 23462.5625, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 1700.9585\n",
      "Epoch: 1495, Loss: 23853.0625, Train_Acc: 0.7500, TEST_Acc: 0.6300, Time: 1702.0911\n",
      "Epoch: 1496, Loss: 23773.1387, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 1703.2286\n",
      "Epoch: 1497, Loss: 23499.4277, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 1704.3703\n",
      "Epoch: 1498, Loss: 23863.2480, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 1705.5100\n",
      "Epoch: 1499, Loss: 23333.6895, Train_Acc: 0.7500, TEST_Acc: 0.6300, Time: 1706.6483\n",
      "Epoch: 1500, Loss: 23652.4512, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 1707.7877\n",
      "Epoch: 1501, Loss: 24034.0586, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 1708.9244\n",
      "Epoch: 1502, Loss: 24771.4141, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 1710.0639\n",
      "Epoch: 1503, Loss: 24201.6484, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 1711.2063\n",
      "Epoch: 1504, Loss: 23931.4590, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 1712.3419\n",
      "Epoch: 1505, Loss: 23351.4766, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 1713.4836\n",
      "Epoch: 1506, Loss: 23807.3613, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1714.6172\n",
      "Epoch: 1507, Loss: 24288.2539, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1715.7518\n",
      "Epoch: 1508, Loss: 24167.4766, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1716.8853\n",
      "Epoch: 1509, Loss: 24436.9238, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1718.0204\n",
      "Epoch: 1510, Loss: 23673.1992, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 1719.1540\n",
      "Epoch: 1511, Loss: 24123.3027, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 1720.2923\n",
      "Epoch: 1512, Loss: 24407.0762, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1721.4330\n",
      "Epoch: 1513, Loss: 24881.6484, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1722.5755\n",
      "Epoch: 1514, Loss: 24082.3945, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1723.7145\n",
      "Epoch: 1515, Loss: 24720.3848, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1724.8589\n",
      "Epoch: 1516, Loss: 24569.9727, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 1726.0035\n",
      "Epoch: 1517, Loss: 24867.4609, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 1727.1379\n",
      "Epoch: 1518, Loss: 24318.7422, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 1728.2731\n",
      "Epoch: 1519, Loss: 23796.4043, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 1729.4061\n",
      "Epoch: 1520, Loss: 23362.3125, Train_Acc: 0.7885, TEST_Acc: 0.6200, Time: 1730.5412\n",
      "Epoch: 1521, Loss: 23881.5293, Train_Acc: 0.7885, TEST_Acc: 0.6200, Time: 1731.6763\n",
      "Epoch: 1522, Loss: 23674.1738, Train_Acc: 0.7885, TEST_Acc: 0.6200, Time: 1732.8092\n",
      "Epoch: 1523, Loss: 24291.1758, Train_Acc: 0.7885, TEST_Acc: 0.6200, Time: 1733.9425\n",
      "Epoch: 1524, Loss: 24110.8848, Train_Acc: 0.8077, TEST_Acc: 0.6200, Time: 1735.0799\n",
      "Epoch: 1525, Loss: 23843.4590, Train_Acc: 0.8077, TEST_Acc: 0.6200, Time: 1736.2183\n",
      "Epoch: 1526, Loss: 24369.9453, Train_Acc: 0.7885, TEST_Acc: 0.6200, Time: 1737.3567\n",
      "Epoch: 1527, Loss: 24482.9414, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1738.4907\n",
      "Epoch: 1528, Loss: 24863.3711, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1739.6287\n",
      "Epoch: 1529, Loss: 25659.7852, Train_Acc: 0.8269, TEST_Acc: 0.6233, Time: 1740.7707\n",
      "Epoch: 1530, Loss: 25105.9922, Train_Acc: 0.8269, TEST_Acc: 0.6233, Time: 1741.9130\n",
      "Epoch: 1531, Loss: 24987.9160, Train_Acc: 0.8269, TEST_Acc: 0.6233, Time: 1743.0462\n",
      "Epoch: 1532, Loss: 25765.5430, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1744.1831\n",
      "Epoch: 1533, Loss: 25422.5957, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1745.3145\n",
      "Epoch: 1534, Loss: 25603.8164, Train_Acc: 0.7885, TEST_Acc: 0.6200, Time: 1746.4508\n",
      "Epoch: 1535, Loss: 25379.4375, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 1747.5816\n",
      "Epoch: 1536, Loss: 25337.6055, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1748.7144\n",
      "Epoch: 1537, Loss: 25435.9766, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1749.8510\n",
      "Epoch: 1538, Loss: 24623.6387, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1750.9853\n",
      "Epoch: 1539, Loss: 24788.0508, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1752.1242\n",
      "Epoch: 1540, Loss: 24856.2109, Train_Acc: 0.7885, TEST_Acc: 0.6200, Time: 1753.2572\n",
      "Epoch: 1541, Loss: 25402.6836, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1754.3941\n",
      "Epoch: 1542, Loss: 25807.9238, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1755.5311\n",
      "Epoch: 1543, Loss: 25802.4355, Train_Acc: 0.8269, TEST_Acc: 0.6233, Time: 1756.6644\n",
      "Epoch: 1544, Loss: 25104.5234, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1757.8089\n",
      "Epoch: 1545, Loss: 25252.0117, Train_Acc: 0.8269, TEST_Acc: 0.6233, Time: 1758.9403\n",
      "Epoch: 1546, Loss: 24891.7598, Train_Acc: 0.8269, TEST_Acc: 0.6267, Time: 1760.0751\n",
      "Epoch: 1547, Loss: 24876.8848, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1761.2094\n",
      "Epoch: 1548, Loss: 24602.3750, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 1762.3446\n",
      "Epoch: 1549, Loss: 24335.9863, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1763.4775\n",
      "Epoch: 1550, Loss: 24575.6113, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 1764.6106\n",
      "Epoch: 1551, Loss: 24757.5234, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1765.7397\n",
      "Epoch: 1552, Loss: 24857.0039, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1766.8767\n",
      "Epoch: 1553, Loss: 24939.8125, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1768.0164\n",
      "Epoch: 1554, Loss: 25196.3145, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1769.1588\n",
      "Epoch: 1555, Loss: 26551.7734, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 1770.2902\n",
      "Epoch: 1556, Loss: 25168.4805, Train_Acc: 0.7885, TEST_Acc: 0.6133, Time: 1771.4294\n",
      "Epoch: 1557, Loss: 24847.0078, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1772.5695\n",
      "Epoch: 1558, Loss: 24666.0352, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1773.7068\n",
      "Epoch: 1559, Loss: 24855.2012, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 1774.8419\n",
      "Epoch: 1560, Loss: 24829.4805, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1775.9744\n",
      "Epoch: 1561, Loss: 24834.7285, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 1777.1135\n",
      "Epoch: 1562, Loss: 25343.4824, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1778.2525\n",
      "Epoch: 1563, Loss: 25120.6230, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1779.3862\n",
      "Epoch: 1564, Loss: 25245.5430, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1780.5225\n",
      "Epoch: 1565, Loss: 25009.8516, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 1781.6564\n",
      "Epoch: 1566, Loss: 24674.9824, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 1782.7966\n",
      "Epoch: 1567, Loss: 24949.7676, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1783.9339\n",
      "Epoch: 1568, Loss: 25089.0488, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1785.0689\n",
      "Epoch: 1569, Loss: 24962.0000, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1786.1990\n",
      "Epoch: 1570, Loss: 25228.4355, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 1787.3368\n",
      "Epoch: 1571, Loss: 25041.3223, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 1788.4671\n",
      "Epoch: 1572, Loss: 25224.7402, Train_Acc: 0.7885, TEST_Acc: 0.6200, Time: 1789.6048\n",
      "Epoch: 1573, Loss: 25204.4043, Train_Acc: 0.7885, TEST_Acc: 0.6200, Time: 1790.7410\n",
      "Epoch: 1574, Loss: 25103.5957, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1791.8750\n",
      "Epoch: 1575, Loss: 24624.1484, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 1793.0093\n",
      "Epoch: 1576, Loss: 24934.2832, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 1794.1445\n",
      "Epoch: 1577, Loss: 24514.8965, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 1795.2836\n",
      "Epoch: 1578, Loss: 24477.9297, Train_Acc: 0.7885, TEST_Acc: 0.6167, Time: 1796.4185\n",
      "Epoch: 1579, Loss: 24194.7188, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1797.5527\n",
      "Epoch: 1580, Loss: 24474.3125, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1798.6966\n",
      "Epoch: 1581, Loss: 24490.2637, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1799.8373\n",
      "Epoch: 1582, Loss: 24394.0137, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1800.9777\n",
      "Epoch: 1583, Loss: 24207.7207, Train_Acc: 0.8077, TEST_Acc: 0.6200, Time: 1802.1220\n",
      "Epoch: 1584, Loss: 23906.1953, Train_Acc: 0.8077, TEST_Acc: 0.6200, Time: 1803.2604\n",
      "Epoch: 1585, Loss: 23758.5840, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1804.3979\n",
      "Epoch: 1586, Loss: 23936.1699, Train_Acc: 0.7885, TEST_Acc: 0.6200, Time: 1805.5323\n",
      "Epoch: 1587, Loss: 23903.2598, Train_Acc: 0.7885, TEST_Acc: 0.6200, Time: 1806.6623\n",
      "Epoch: 1588, Loss: 24025.9648, Train_Acc: 0.7885, TEST_Acc: 0.6200, Time: 1807.7969\n",
      "Epoch: 1589, Loss: 23875.9238, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1808.9338\n",
      "Epoch: 1590, Loss: 23737.7793, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1810.0752\n",
      "Epoch: 1591, Loss: 23855.0391, Train_Acc: 0.7885, TEST_Acc: 0.6200, Time: 1811.2084\n",
      "Epoch: 1592, Loss: 23594.5977, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 1812.3385\n",
      "Epoch: 1593, Loss: 23676.3652, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 1813.4762\n",
      "Epoch: 1594, Loss: 23710.5938, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 1814.6126\n",
      "Epoch: 1595, Loss: 23699.8457, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 1815.7514\n",
      "Epoch: 1596, Loss: 23541.9062, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 1816.8844\n",
      "Epoch: 1597, Loss: 23357.6582, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 1818.0231\n",
      "Epoch: 1598, Loss: 23136.9922, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 1819.1598\n",
      "Epoch: 1599, Loss: 22815.8398, Train_Acc: 0.7885, TEST_Acc: 0.6167, Time: 1820.2975\n",
      "Epoch: 1600, Loss: 22951.7734, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 1821.4266\n",
      "Epoch: 1601, Loss: 23032.5195, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 1822.5616\n",
      "Epoch: 1602, Loss: 22749.0625, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 1823.6997\n",
      "Epoch: 1603, Loss: 22700.5293, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 1824.8361\n",
      "Epoch: 1604, Loss: 22106.8086, Train_Acc: 0.7885, TEST_Acc: 0.6167, Time: 1825.9676\n",
      "Epoch: 1605, Loss: 22172.5820, Train_Acc: 0.8077, TEST_Acc: 0.6133, Time: 1827.1034\n",
      "Epoch: 1606, Loss: 22501.0664, Train_Acc: 0.8077, TEST_Acc: 0.6200, Time: 1828.2381\n",
      "Epoch: 1607, Loss: 22592.8945, Train_Acc: 0.8077, TEST_Acc: 0.6167, Time: 1829.3736\n",
      "Epoch: 1608, Loss: 22007.3711, Train_Acc: 0.8269, TEST_Acc: 0.6133, Time: 1830.5177\n",
      "Epoch: 1609, Loss: 22057.2891, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 1831.6606\n",
      "Epoch: 1610, Loss: 21395.4785, Train_Acc: 0.8077, TEST_Acc: 0.6100, Time: 1832.8083\n",
      "Epoch: 1611, Loss: 21647.8105, Train_Acc: 0.8077, TEST_Acc: 0.6200, Time: 1833.9455\n",
      "Epoch: 1612, Loss: 21647.2363, Train_Acc: 0.8077, TEST_Acc: 0.6200, Time: 1835.0838\n",
      "Epoch: 1613, Loss: 21360.5293, Train_Acc: 0.8077, TEST_Acc: 0.6133, Time: 1836.2187\n",
      "Epoch: 1614, Loss: 21310.7168, Train_Acc: 0.7885, TEST_Acc: 0.6133, Time: 1837.3503\n",
      "Epoch: 1615, Loss: 21222.2539, Train_Acc: 0.7885, TEST_Acc: 0.6200, Time: 1838.4835\n",
      "Epoch: 1616, Loss: 20746.6211, Train_Acc: 0.8077, TEST_Acc: 0.6133, Time: 1839.6154\n",
      "Epoch: 1617, Loss: 20825.3555, Train_Acc: 0.8077, TEST_Acc: 0.6200, Time: 1840.7546\n",
      "Epoch: 1618, Loss: 20433.9688, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1841.8886\n",
      "Epoch: 1619, Loss: 20331.5664, Train_Acc: 0.8269, TEST_Acc: 0.6167, Time: 1843.0312\n",
      "Epoch: 1620, Loss: 20288.9082, Train_Acc: 0.8269, TEST_Acc: 0.6200, Time: 1844.1719\n",
      "Epoch: 1621, Loss: 19953.5938, Train_Acc: 0.8269, TEST_Acc: 0.6267, Time: 1845.3136\n",
      "Epoch: 1622, Loss: 19984.4883, Train_Acc: 0.8269, TEST_Acc: 0.6233, Time: 1846.4506\n",
      "Epoch: 1623, Loss: 20256.6992, Train_Acc: 0.8269, TEST_Acc: 0.6300, Time: 1847.5902\n",
      "Epoch: 1624, Loss: 19976.5215, Train_Acc: 0.8269, TEST_Acc: 0.6300, Time: 1848.7240\n",
      "Epoch: 1625, Loss: 19834.1797, Train_Acc: 0.8269, TEST_Acc: 0.6267, Time: 1849.8603\n",
      "Epoch: 1626, Loss: 20051.0703, Train_Acc: 0.8269, TEST_Acc: 0.6200, Time: 1850.9923\n",
      "Epoch: 1627, Loss: 19897.1738, Train_Acc: 0.8269, TEST_Acc: 0.6233, Time: 1852.1280\n",
      "Epoch: 1628, Loss: 19677.4102, Train_Acc: 0.8077, TEST_Acc: 0.6133, Time: 1853.2623\n",
      "Epoch: 1629, Loss: 19564.3965, Train_Acc: 0.8077, TEST_Acc: 0.6133, Time: 1854.3914\n",
      "Epoch: 1630, Loss: 19426.1816, Train_Acc: 0.8077, TEST_Acc: 0.6167, Time: 1855.5182\n",
      "Epoch: 1631, Loss: 19285.5957, Train_Acc: 0.8269, TEST_Acc: 0.6200, Time: 1856.6474\n",
      "Epoch: 1632, Loss: 18963.3555, Train_Acc: 0.8269, TEST_Acc: 0.6133, Time: 1857.7840\n",
      "Epoch: 1633, Loss: 18871.2930, Train_Acc: 0.8077, TEST_Acc: 0.6133, Time: 1858.9207\n",
      "Epoch: 1634, Loss: 18615.3750, Train_Acc: 0.8077, TEST_Acc: 0.6100, Time: 1860.0560\n",
      "Epoch: 1635, Loss: 18377.0312, Train_Acc: 0.8077, TEST_Acc: 0.6133, Time: 1861.1939\n",
      "Epoch: 1636, Loss: 18352.1348, Train_Acc: 0.8077, TEST_Acc: 0.6100, Time: 1862.3363\n",
      "Epoch: 1637, Loss: 18457.2109, Train_Acc: 0.7885, TEST_Acc: 0.6167, Time: 1863.4705\n",
      "Epoch: 1638, Loss: 18136.0820, Train_Acc: 0.7885, TEST_Acc: 0.6133, Time: 1864.6023\n",
      "Epoch: 1639, Loss: 18221.7051, Train_Acc: 0.8077, TEST_Acc: 0.6133, Time: 1865.7383\n",
      "Epoch: 1640, Loss: 18003.1660, Train_Acc: 0.8077, TEST_Acc: 0.6133, Time: 1866.8714\n",
      "Epoch: 1641, Loss: 17859.4668, Train_Acc: 0.8077, TEST_Acc: 0.6200, Time: 1868.0032\n",
      "Epoch: 1642, Loss: 17750.9902, Train_Acc: 0.8077, TEST_Acc: 0.6267, Time: 1869.1374\n",
      "Epoch: 1643, Loss: 18027.5273, Train_Acc: 0.8077, TEST_Acc: 0.6267, Time: 1870.2712\n",
      "Epoch: 1644, Loss: 18022.6016, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1871.4033\n",
      "Epoch: 1645, Loss: 17734.0410, Train_Acc: 0.8077, TEST_Acc: 0.6267, Time: 1872.5324\n",
      "Epoch: 1646, Loss: 17951.1777, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1873.6746\n",
      "Epoch: 1647, Loss: 18108.7344, Train_Acc: 0.7885, TEST_Acc: 0.6300, Time: 1874.8135\n",
      "Epoch: 1648, Loss: 17619.9375, Train_Acc: 0.8077, TEST_Acc: 0.6300, Time: 1875.9497\n",
      "Epoch: 1649, Loss: 17959.0547, Train_Acc: 0.8077, TEST_Acc: 0.6267, Time: 1877.0847\n",
      "Epoch: 1650, Loss: 17938.4453, Train_Acc: 0.8077, TEST_Acc: 0.6267, Time: 1878.2193\n",
      "Epoch: 1651, Loss: 17771.4883, Train_Acc: 0.8077, TEST_Acc: 0.6267, Time: 1879.3545\n",
      "Epoch: 1652, Loss: 17187.6953, Train_Acc: 0.8269, TEST_Acc: 0.6200, Time: 1880.4925\n",
      "Epoch: 1653, Loss: 17357.9746, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 1881.6228\n",
      "Epoch: 1654, Loss: 16906.2754, Train_Acc: 0.7885, TEST_Acc: 0.6167, Time: 1882.7588\n",
      "Epoch: 1655, Loss: 17169.5742, Train_Acc: 0.8269, TEST_Acc: 0.6200, Time: 1883.8956\n",
      "Epoch: 1656, Loss: 16785.9297, Train_Acc: 0.8269, TEST_Acc: 0.6167, Time: 1885.0285\n",
      "Epoch: 1657, Loss: 16853.6855, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 1886.1624\n",
      "Epoch: 1658, Loss: 16803.6309, Train_Acc: 0.7692, TEST_Acc: 0.6100, Time: 1887.2959\n",
      "Epoch: 1659, Loss: 16513.4707, Train_Acc: 0.7885, TEST_Acc: 0.6133, Time: 1888.4334\n",
      "Epoch: 1660, Loss: 16507.1797, Train_Acc: 0.7692, TEST_Acc: 0.6100, Time: 1889.5716\n",
      "Epoch: 1661, Loss: 16348.7021, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 1890.7166\n",
      "Epoch: 1662, Loss: 16239.2021, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 1891.8554\n",
      "Epoch: 1663, Loss: 16348.5068, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 1892.9929\n",
      "Epoch: 1664, Loss: 16713.6289, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 1894.1280\n",
      "Epoch: 1665, Loss: 17068.9414, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 1895.2652\n",
      "Epoch: 1666, Loss: 17159.8008, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 1896.3975\n",
      "Epoch: 1667, Loss: 17074.1973, Train_Acc: 0.8269, TEST_Acc: 0.6200, Time: 1897.5282\n",
      "Epoch: 1668, Loss: 17089.9805, Train_Acc: 0.8269, TEST_Acc: 0.6200, Time: 1898.6611\n",
      "Epoch: 1669, Loss: 16753.9316, Train_Acc: 0.8269, TEST_Acc: 0.6133, Time: 1899.7952\n",
      "Epoch: 1670, Loss: 16240.7305, Train_Acc: 0.8077, TEST_Acc: 0.6133, Time: 1900.9313\n",
      "Epoch: 1671, Loss: 15726.0215, Train_Acc: 0.8077, TEST_Acc: 0.6167, Time: 1902.0661\n",
      "Epoch: 1672, Loss: 15857.0068, Train_Acc: 0.8077, TEST_Acc: 0.6200, Time: 1903.1978\n",
      "Epoch: 1673, Loss: 15658.0557, Train_Acc: 0.8077, TEST_Acc: 0.6167, Time: 1904.3288\n",
      "Epoch: 1674, Loss: 15669.5430, Train_Acc: 0.8077, TEST_Acc: 0.6167, Time: 1905.4705\n",
      "Epoch: 1675, Loss: 15931.8271, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1906.6046\n",
      "Epoch: 1676, Loss: 15753.4287, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1907.7461\n",
      "Epoch: 1677, Loss: 15400.6631, Train_Acc: 0.8077, TEST_Acc: 0.6200, Time: 1908.8837\n",
      "Epoch: 1678, Loss: 15240.8760, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1910.0187\n",
      "Epoch: 1679, Loss: 15458.6543, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1911.1516\n",
      "Epoch: 1680, Loss: 15116.8145, Train_Acc: 0.8077, TEST_Acc: 0.6267, Time: 1912.2849\n",
      "Epoch: 1681, Loss: 14678.6240, Train_Acc: 0.8077, TEST_Acc: 0.6267, Time: 1913.4165\n",
      "Epoch: 1682, Loss: 14972.0840, Train_Acc: 0.8077, TEST_Acc: 0.6267, Time: 1914.5487\n",
      "Epoch: 1683, Loss: 14692.9355, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1915.6774\n",
      "Epoch: 1684, Loss: 14352.7930, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1916.8186\n",
      "Epoch: 1685, Loss: 14772.4756, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 1917.9563\n",
      "Epoch: 1686, Loss: 14473.8818, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1919.0857\n",
      "Epoch: 1687, Loss: 14215.4531, Train_Acc: 0.7885, TEST_Acc: 0.6300, Time: 1920.2186\n",
      "Epoch: 1688, Loss: 13941.9258, Train_Acc: 0.7885, TEST_Acc: 0.6300, Time: 1921.3531\n",
      "Epoch: 1689, Loss: 13771.9258, Train_Acc: 0.7885, TEST_Acc: 0.6300, Time: 1922.4916\n",
      "Epoch: 1690, Loss: 14045.8867, Train_Acc: 0.7885, TEST_Acc: 0.6300, Time: 1923.6248\n",
      "Epoch: 1691, Loss: 13949.7646, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1924.7684\n",
      "Epoch: 1692, Loss: 13834.3867, Train_Acc: 0.7885, TEST_Acc: 0.6333, Time: 1925.9020\n",
      "Epoch: 1693, Loss: 13630.5273, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1927.0352\n",
      "Epoch: 1694, Loss: 12931.0449, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1928.1706\n",
      "Epoch: 1695, Loss: 13367.5723, Train_Acc: 0.7885, TEST_Acc: 0.6300, Time: 1929.3007\n",
      "Epoch: 1696, Loss: 13519.8584, Train_Acc: 0.7885, TEST_Acc: 0.6367, Time: 1930.4367\n",
      "Epoch: 1697, Loss: 13769.6855, Train_Acc: 0.7885, TEST_Acc: 0.6333, Time: 1931.5684\n",
      "Epoch: 1698, Loss: 13203.9395, Train_Acc: 0.7885, TEST_Acc: 0.6233, Time: 1932.7041\n",
      "Epoch: 1699, Loss: 13191.7344, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1933.8435\n",
      "Epoch: 1700, Loss: 13451.3057, Train_Acc: 0.7885, TEST_Acc: 0.6333, Time: 1934.9794\n",
      "Epoch: 1701, Loss: 13491.7832, Train_Acc: 0.7885, TEST_Acc: 0.6367, Time: 1936.1229\n",
      "Epoch: 1702, Loss: 13471.1133, Train_Acc: 0.7885, TEST_Acc: 0.6367, Time: 1937.2594\n",
      "Epoch: 1703, Loss: 13479.9932, Train_Acc: 0.7885, TEST_Acc: 0.6367, Time: 1938.3955\n",
      "Epoch: 1704, Loss: 13093.9854, Train_Acc: 0.7885, TEST_Acc: 0.6333, Time: 1939.5336\n",
      "Epoch: 1705, Loss: 12943.3457, Train_Acc: 0.7692, TEST_Acc: 0.6333, Time: 1940.6694\n",
      "Epoch: 1706, Loss: 12960.4961, Train_Acc: 0.7885, TEST_Acc: 0.6333, Time: 1941.8033\n",
      "Epoch: 1707, Loss: 12722.0986, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 1942.9376\n",
      "Epoch: 1708, Loss: 12494.4697, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 1944.0689\n",
      "Epoch: 1709, Loss: 12723.6670, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 1945.2006\n",
      "Epoch: 1710, Loss: 12825.5527, Train_Acc: 0.8269, TEST_Acc: 0.6367, Time: 1946.3340\n",
      "Epoch: 1711, Loss: 12405.6709, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1947.4638\n",
      "Epoch: 1712, Loss: 12367.9492, Train_Acc: 0.7692, TEST_Acc: 0.6333, Time: 1948.5968\n",
      "Epoch: 1713, Loss: 11766.8193, Train_Acc: 0.8077, TEST_Acc: 0.6233, Time: 1949.7274\n",
      "Epoch: 1714, Loss: 11940.0576, Train_Acc: 0.7885, TEST_Acc: 0.6267, Time: 1950.8576\n",
      "Epoch: 1715, Loss: 11899.2510, Train_Acc: 0.7885, TEST_Acc: 0.6333, Time: 1951.9983\n",
      "Epoch: 1716, Loss: 11582.0635, Train_Acc: 0.7885, TEST_Acc: 0.6300, Time: 1953.1417\n",
      "Epoch: 1717, Loss: 12122.8916, Train_Acc: 0.7885, TEST_Acc: 0.6333, Time: 1954.2894\n",
      "Epoch: 1718, Loss: 12270.1816, Train_Acc: 0.8077, TEST_Acc: 0.6400, Time: 1955.4268\n",
      "Epoch: 1719, Loss: 11988.7725, Train_Acc: 0.8077, TEST_Acc: 0.6400, Time: 1956.5645\n",
      "Epoch: 1720, Loss: 11701.0244, Train_Acc: 0.8077, TEST_Acc: 0.6367, Time: 1957.6964\n",
      "Epoch: 1721, Loss: 11496.5137, Train_Acc: 0.8077, TEST_Acc: 0.6333, Time: 1958.8316\n",
      "Epoch: 1722, Loss: 11727.1611, Train_Acc: 0.8077, TEST_Acc: 0.6333, Time: 1959.9680\n",
      "Epoch: 1723, Loss: 11099.1084, Train_Acc: 0.8077, TEST_Acc: 0.6300, Time: 1961.1014\n",
      "Epoch: 1724, Loss: 11040.6162, Train_Acc: 0.8077, TEST_Acc: 0.6333, Time: 1962.2331\n",
      "Epoch: 1725, Loss: 10962.7227, Train_Acc: 0.8077, TEST_Acc: 0.6367, Time: 1963.3642\n",
      "Epoch: 1726, Loss: 10995.2246, Train_Acc: 0.7885, TEST_Acc: 0.6400, Time: 1964.4998\n",
      "Epoch: 1727, Loss: 11142.6475, Train_Acc: 0.8077, TEST_Acc: 0.6400, Time: 1965.6358\n",
      "Epoch: 1728, Loss: 11735.2812, Train_Acc: 0.8077, TEST_Acc: 0.6400, Time: 1966.7658\n",
      "Epoch: 1729, Loss: 11496.9209, Train_Acc: 0.8077, TEST_Acc: 0.6400, Time: 1967.9027\n",
      "Epoch: 1730, Loss: 11372.4746, Train_Acc: 0.8077, TEST_Acc: 0.6300, Time: 1969.0412\n",
      "Epoch: 1731, Loss: 11522.9316, Train_Acc: 0.8077, TEST_Acc: 0.6333, Time: 1970.1807\n",
      "Epoch: 1732, Loss: 10871.8105, Train_Acc: 0.8077, TEST_Acc: 0.6267, Time: 1971.3187\n",
      "Epoch: 1733, Loss: 10817.2959, Train_Acc: 0.8077, TEST_Acc: 0.6300, Time: 1972.4529\n",
      "Epoch: 1734, Loss: 10558.4395, Train_Acc: 0.8077, TEST_Acc: 0.6267, Time: 1973.5857\n",
      "Epoch: 1735, Loss: 10559.0400, Train_Acc: 0.8077, TEST_Acc: 0.6300, Time: 1974.7182\n",
      "Epoch: 1736, Loss: 10785.6572, Train_Acc: 0.8077, TEST_Acc: 0.6367, Time: 1975.8522\n",
      "Epoch: 1737, Loss: 10622.0918, Train_Acc: 0.8077, TEST_Acc: 0.6367, Time: 1976.9878\n",
      "Epoch: 1738, Loss: 10754.9521, Train_Acc: 0.8077, TEST_Acc: 0.6367, Time: 1978.1185\n",
      "Epoch: 1739, Loss: 11114.0244, Train_Acc: 0.7885, TEST_Acc: 0.6367, Time: 1979.2495\n",
      "Epoch: 1740, Loss: 10926.2090, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 1980.3927\n",
      "Epoch: 1741, Loss: 10510.2793, Train_Acc: 0.8077, TEST_Acc: 0.6367, Time: 1981.5249\n",
      "Epoch: 1742, Loss: 10772.7119, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 1982.6622\n",
      "Epoch: 1743, Loss: 10408.8896, Train_Acc: 0.8077, TEST_Acc: 0.6333, Time: 1983.8022\n",
      "Epoch: 1744, Loss: 10364.9902, Train_Acc: 0.8077, TEST_Acc: 0.6333, Time: 1984.9402\n",
      "Epoch: 1745, Loss: 9923.1191, Train_Acc: 0.8077, TEST_Acc: 0.6333, Time: 1986.0786\n",
      "Epoch: 1746, Loss: 10108.6250, Train_Acc: 0.7308, TEST_Acc: 0.6300, Time: 1987.2143\n",
      "Epoch: 1747, Loss: 9915.6982, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 1988.3445\n",
      "Epoch: 1748, Loss: 9882.7090, Train_Acc: 0.7500, TEST_Acc: 0.6300, Time: 1989.4735\n",
      "Epoch: 1749, Loss: 9864.4199, Train_Acc: 0.7500, TEST_Acc: 0.6367, Time: 1990.6095\n",
      "Epoch: 1750, Loss: 10350.7812, Train_Acc: 0.7500, TEST_Acc: 0.6367, Time: 1991.7421\n",
      "Epoch: 1751, Loss: 10625.1680, Train_Acc: 0.7500, TEST_Acc: 0.6367, Time: 1992.8705\n",
      "Epoch: 1752, Loss: 10106.9961, Train_Acc: 0.7308, TEST_Acc: 0.6367, Time: 1994.0027\n",
      "Epoch: 1753, Loss: 10093.8643, Train_Acc: 0.7500, TEST_Acc: 0.6367, Time: 1995.1360\n",
      "Epoch: 1754, Loss: 9885.2529, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 1996.2750\n",
      "Epoch: 1755, Loss: 9269.5801, Train_Acc: 0.7692, TEST_Acc: 0.6333, Time: 1997.4062\n",
      "Epoch: 1756, Loss: 9471.0820, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 1998.5426\n",
      "Epoch: 1757, Loss: 9590.7500, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 1999.6794\n",
      "Epoch: 1758, Loss: 9671.9141, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 2000.8189\n",
      "Epoch: 1759, Loss: 10111.3887, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 2001.9558\n",
      "Epoch: 1760, Loss: 10073.2979, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 2003.0911\n",
      "Epoch: 1761, Loss: 10651.1152, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 2004.2214\n",
      "Epoch: 1762, Loss: 10265.4619, Train_Acc: 0.7308, TEST_Acc: 0.6367, Time: 2005.3526\n",
      "Epoch: 1763, Loss: 10387.5537, Train_Acc: 0.7308, TEST_Acc: 0.6367, Time: 2006.4842\n",
      "Epoch: 1764, Loss: 10677.4355, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 2007.6153\n",
      "Epoch: 1765, Loss: 10934.0615, Train_Acc: 0.7500, TEST_Acc: 0.6400, Time: 2008.7502\n",
      "Epoch: 1766, Loss: 10836.7246, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 2009.8812\n",
      "Epoch: 1767, Loss: 10388.9531, Train_Acc: 0.7308, TEST_Acc: 0.6400, Time: 2011.0172\n",
      "Epoch: 1768, Loss: 10703.8330, Train_Acc: 0.7308, TEST_Acc: 0.6367, Time: 2012.1522\n",
      "Epoch: 1769, Loss: 11407.0176, Train_Acc: 0.7500, TEST_Acc: 0.6400, Time: 2013.3016\n",
      "Epoch: 1770, Loss: 11331.2129, Train_Acc: 0.7692, TEST_Acc: 0.6400, Time: 2014.4376\n",
      "Epoch: 1771, Loss: 10796.0713, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 2015.5707\n",
      "Epoch: 1772, Loss: 10731.9316, Train_Acc: 0.7500, TEST_Acc: 0.6367, Time: 2016.7065\n",
      "Epoch: 1773, Loss: 10336.6875, Train_Acc: 0.7500, TEST_Acc: 0.6367, Time: 2017.8429\n",
      "Epoch: 1774, Loss: 10674.4883, Train_Acc: 0.7500, TEST_Acc: 0.6367, Time: 2018.9747\n",
      "Epoch: 1775, Loss: 10559.5957, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 2020.1095\n",
      "Epoch: 1776, Loss: 10618.1992, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 2021.2403\n",
      "Epoch: 1777, Loss: 10837.6963, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 2022.3700\n",
      "Epoch: 1778, Loss: 10749.5869, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 2023.4980\n",
      "Epoch: 1779, Loss: 10344.1758, Train_Acc: 0.7500, TEST_Acc: 0.6400, Time: 2024.6321\n",
      "Epoch: 1780, Loss: 10601.8018, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 2025.7674\n",
      "Epoch: 1781, Loss: 10093.7080, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 2026.9011\n",
      "Epoch: 1782, Loss: 9758.9492, Train_Acc: 0.7308, TEST_Acc: 0.6367, Time: 2028.0379\n",
      "Epoch: 1783, Loss: 9284.8926, Train_Acc: 0.7308, TEST_Acc: 0.6300, Time: 2029.1730\n",
      "Epoch: 1784, Loss: 10159.5117, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 2030.3120\n",
      "Epoch: 1785, Loss: 10018.4307, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 2031.4479\n",
      "Epoch: 1786, Loss: 10454.2461, Train_Acc: 0.7500, TEST_Acc: 0.6367, Time: 2032.5852\n",
      "Epoch: 1787, Loss: 10194.5430, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 2033.7272\n",
      "Epoch: 1788, Loss: 10158.3174, Train_Acc: 0.7500, TEST_Acc: 0.6400, Time: 2034.8598\n",
      "Epoch: 1789, Loss: 10149.1504, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 2035.9920\n",
      "Epoch: 1790, Loss: 9864.3232, Train_Acc: 0.7500, TEST_Acc: 0.6367, Time: 2037.1237\n",
      "Epoch: 1791, Loss: 10207.0928, Train_Acc: 0.7500, TEST_Acc: 0.6367, Time: 2038.2568\n",
      "Epoch: 1792, Loss: 10461.3926, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 2039.3906\n",
      "Epoch: 1793, Loss: 10056.4668, Train_Acc: 0.7500, TEST_Acc: 0.6367, Time: 2040.5259\n",
      "Epoch: 1794, Loss: 9967.9512, Train_Acc: 0.7500, TEST_Acc: 0.6367, Time: 2041.6599\n",
      "Epoch: 1795, Loss: 9956.5527, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 2042.8012\n",
      "Epoch: 1796, Loss: 10069.7295, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 2043.9435\n",
      "Epoch: 1797, Loss: 9743.7080, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 2045.0839\n",
      "Epoch: 1798, Loss: 9740.0381, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 2046.2251\n",
      "Epoch: 1799, Loss: 9831.8594, Train_Acc: 0.7692, TEST_Acc: 0.6333, Time: 2047.3627\n",
      "Epoch: 1800, Loss: 9932.2383, Train_Acc: 0.7692, TEST_Acc: 0.6367, Time: 2048.5000\n",
      "Epoch: 1801, Loss: 9906.9092, Train_Acc: 0.7692, TEST_Acc: 0.6333, Time: 2049.6303\n",
      "Epoch: 1802, Loss: 9476.9492, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 2050.7629\n",
      "Epoch: 1803, Loss: 9519.8008, Train_Acc: 0.7692, TEST_Acc: 0.6333, Time: 2051.8932\n",
      "Epoch: 1804, Loss: 9285.6426, Train_Acc: 0.7692, TEST_Acc: 0.6333, Time: 2053.0266\n",
      "Epoch: 1805, Loss: 9394.0020, Train_Acc: 0.7692, TEST_Acc: 0.6333, Time: 2054.1557\n",
      "Epoch: 1806, Loss: 9307.7754, Train_Acc: 0.7692, TEST_Acc: 0.6333, Time: 2055.2961\n",
      "Epoch: 1807, Loss: 9579.0469, Train_Acc: 0.7692, TEST_Acc: 0.6333, Time: 2056.4305\n",
      "Epoch: 1808, Loss: 9490.5488, Train_Acc: 0.7692, TEST_Acc: 0.6333, Time: 2057.5626\n",
      "Epoch: 1809, Loss: 9636.4541, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 2058.6998\n",
      "Epoch: 1810, Loss: 9690.7070, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 2059.8369\n",
      "Epoch: 1811, Loss: 9760.7725, Train_Acc: 0.7500, TEST_Acc: 0.6300, Time: 2060.9719\n",
      "Epoch: 1812, Loss: 9848.3848, Train_Acc: 0.7500, TEST_Acc: 0.6300, Time: 2062.1091\n",
      "Epoch: 1813, Loss: 10013.7881, Train_Acc: 0.7500, TEST_Acc: 0.6300, Time: 2063.2406\n",
      "Epoch: 1814, Loss: 9743.0771, Train_Acc: 0.7500, TEST_Acc: 0.6300, Time: 2064.3767\n",
      "Epoch: 1815, Loss: 9395.8105, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 2065.5127\n",
      "Epoch: 1816, Loss: 9659.0410, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 2066.6468\n",
      "Epoch: 1817, Loss: 9582.3076, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 2067.7806\n",
      "Epoch: 1818, Loss: 9626.8320, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2068.9137\n",
      "Epoch: 1819, Loss: 9822.3838, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2070.0500\n",
      "Epoch: 1820, Loss: 9928.3281, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 2071.1808\n",
      "Epoch: 1821, Loss: 9886.4941, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 2072.3145\n",
      "Epoch: 1822, Loss: 9870.9209, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2073.4505\n",
      "Epoch: 1823, Loss: 9588.0801, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2074.6038\n",
      "Epoch: 1824, Loss: 9888.4346, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2075.7458\n",
      "Epoch: 1825, Loss: 9820.7344, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 2076.8848\n",
      "Epoch: 1826, Loss: 9777.6182, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2078.0199\n",
      "Epoch: 1827, Loss: 9481.7305, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2079.1529\n",
      "Epoch: 1828, Loss: 9776.8926, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2080.2891\n",
      "Epoch: 1829, Loss: 9732.4883, Train_Acc: 0.7500, TEST_Acc: 0.6300, Time: 2081.4247\n",
      "Epoch: 1830, Loss: 9435.5107, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2082.5569\n",
      "Epoch: 1831, Loss: 9572.3125, Train_Acc: 0.7500, TEST_Acc: 0.6300, Time: 2083.6914\n",
      "Epoch: 1832, Loss: 9834.8301, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2084.8237\n",
      "Epoch: 1833, Loss: 9591.9941, Train_Acc: 0.7500, TEST_Acc: 0.6300, Time: 2085.9586\n",
      "Epoch: 1834, Loss: 9480.5166, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 2087.0994\n",
      "Epoch: 1835, Loss: 9868.9980, Train_Acc: 0.7500, TEST_Acc: 0.6300, Time: 2088.2360\n",
      "Epoch: 1836, Loss: 9811.2969, Train_Acc: 0.7308, TEST_Acc: 0.6300, Time: 2089.3712\n",
      "Epoch: 1837, Loss: 9888.1631, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 2090.5051\n",
      "Epoch: 1838, Loss: 10151.4268, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 2091.6400\n",
      "Epoch: 1839, Loss: 10166.7666, Train_Acc: 0.7308, TEST_Acc: 0.6400, Time: 2092.7749\n",
      "Epoch: 1840, Loss: 10109.4258, Train_Acc: 0.7308, TEST_Acc: 0.6400, Time: 2093.9080\n",
      "Epoch: 1841, Loss: 10062.6055, Train_Acc: 0.7308, TEST_Acc: 0.6400, Time: 2095.0428\n",
      "Epoch: 1842, Loss: 10165.0410, Train_Acc: 0.7500, TEST_Acc: 0.6400, Time: 2096.1784\n",
      "Epoch: 1843, Loss: 9695.9551, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 2097.3161\n",
      "Epoch: 1844, Loss: 9985.9287, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 2098.4520\n",
      "Epoch: 1845, Loss: 10094.5537, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 2099.5843\n",
      "Epoch: 1846, Loss: 9554.6455, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 2100.7170\n",
      "Epoch: 1847, Loss: 9534.2773, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 2101.8483\n",
      "Epoch: 1848, Loss: 9434.5977, Train_Acc: 0.7308, TEST_Acc: 0.6367, Time: 2102.9859\n",
      "Epoch: 1849, Loss: 9480.2285, Train_Acc: 0.7308, TEST_Acc: 0.6367, Time: 2104.1252\n",
      "Epoch: 1850, Loss: 9489.3057, Train_Acc: 0.7308, TEST_Acc: 0.6300, Time: 2105.2637\n",
      "Epoch: 1851, Loss: 9821.6133, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 2106.4032\n",
      "Epoch: 1852, Loss: 10126.2207, Train_Acc: 0.7308, TEST_Acc: 0.6367, Time: 2107.5471\n",
      "Epoch: 1853, Loss: 10549.3701, Train_Acc: 0.7308, TEST_Acc: 0.6367, Time: 2108.6801\n",
      "Epoch: 1854, Loss: 10430.5957, Train_Acc: 0.7500, TEST_Acc: 0.6333, Time: 2109.8112\n",
      "Epoch: 1855, Loss: 10379.5801, Train_Acc: 0.7308, TEST_Acc: 0.6367, Time: 2110.9430\n",
      "Epoch: 1856, Loss: 10047.9648, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 2112.0798\n",
      "Epoch: 1857, Loss: 10456.1270, Train_Acc: 0.7308, TEST_Acc: 0.6367, Time: 2113.2133\n",
      "Epoch: 1858, Loss: 9883.8809, Train_Acc: 0.7308, TEST_Acc: 0.6300, Time: 2114.3447\n",
      "Epoch: 1859, Loss: 9843.2412, Train_Acc: 0.7308, TEST_Acc: 0.6300, Time: 2115.4755\n",
      "Epoch: 1860, Loss: 9738.8555, Train_Acc: 0.7308, TEST_Acc: 0.6300, Time: 2116.6079\n",
      "Epoch: 1861, Loss: 9815.5811, Train_Acc: 0.7308, TEST_Acc: 0.6300, Time: 2117.7379\n",
      "Epoch: 1862, Loss: 9458.1484, Train_Acc: 0.7308, TEST_Acc: 0.6300, Time: 2118.8823\n",
      "Epoch: 1863, Loss: 9442.1240, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 2120.0224\n",
      "Epoch: 1864, Loss: 9351.9619, Train_Acc: 0.7308, TEST_Acc: 0.6233, Time: 2121.1563\n",
      "Epoch: 1865, Loss: 9205.9756, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 2122.2925\n",
      "Epoch: 1866, Loss: 9122.0264, Train_Acc: 0.7308, TEST_Acc: 0.6333, Time: 2123.4298\n",
      "Epoch: 1867, Loss: 8382.4746, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 2124.5610\n",
      "Epoch: 1868, Loss: 8873.4590, Train_Acc: 0.7308, TEST_Acc: 0.6300, Time: 2125.6937\n",
      "Epoch: 1869, Loss: 9159.3223, Train_Acc: 0.7308, TEST_Acc: 0.6300, Time: 2126.8263\n",
      "Epoch: 1870, Loss: 9176.8525, Train_Acc: 0.7308, TEST_Acc: 0.6300, Time: 2127.9553\n",
      "Epoch: 1871, Loss: 8962.7393, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 2129.0912\n",
      "Epoch: 1872, Loss: 9310.3711, Train_Acc: 0.7308, TEST_Acc: 0.6233, Time: 2130.2240\n",
      "Epoch: 1873, Loss: 9600.6816, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 2131.3560\n",
      "Epoch: 1874, Loss: 9689.8867, Train_Acc: 0.7308, TEST_Acc: 0.6233, Time: 2132.4888\n",
      "Epoch: 1875, Loss: 9708.5879, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 2133.6223\n",
      "Epoch: 1876, Loss: 9639.6270, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 2134.7607\n",
      "Epoch: 1877, Loss: 10134.5869, Train_Acc: 0.7308, TEST_Acc: 0.6233, Time: 2135.8959\n",
      "Epoch: 1878, Loss: 10265.2090, Train_Acc: 0.7308, TEST_Acc: 0.6233, Time: 2137.0311\n",
      "Epoch: 1879, Loss: 9967.6777, Train_Acc: 0.7308, TEST_Acc: 0.6233, Time: 2138.1689\n",
      "Epoch: 1880, Loss: 9956.1709, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 2139.3103\n",
      "Epoch: 1881, Loss: 9970.6270, Train_Acc: 0.7308, TEST_Acc: 0.6233, Time: 2140.4527\n",
      "Epoch: 1882, Loss: 9534.1396, Train_Acc: 0.7308, TEST_Acc: 0.6233, Time: 2141.5886\n",
      "Epoch: 1883, Loss: 9336.9385, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 2142.7243\n",
      "Epoch: 1884, Loss: 9166.6914, Train_Acc: 0.7115, TEST_Acc: 0.6233, Time: 2143.8544\n",
      "Epoch: 1885, Loss: 9357.8291, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 2144.9885\n",
      "Epoch: 1886, Loss: 9557.5176, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 2146.1214\n",
      "Epoch: 1887, Loss: 9450.0605, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 2147.2591\n",
      "Epoch: 1888, Loss: 9401.7119, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2148.3911\n",
      "Epoch: 1889, Loss: 9412.5469, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2149.5207\n",
      "Epoch: 1890, Loss: 9530.4443, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 2150.6643\n",
      "Epoch: 1891, Loss: 9707.6260, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2151.8019\n",
      "Epoch: 1892, Loss: 10071.4912, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 2152.9356\n",
      "Epoch: 1893, Loss: 10097.1416, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 2154.0724\n",
      "Epoch: 1894, Loss: 10121.7256, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 2155.2122\n",
      "Epoch: 1895, Loss: 9688.5732, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 2156.3445\n",
      "Epoch: 1896, Loss: 10327.1787, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2157.4777\n",
      "Epoch: 1897, Loss: 10147.7090, Train_Acc: 0.7308, TEST_Acc: 0.6300, Time: 2158.6119\n",
      "Epoch: 1898, Loss: 10263.1650, Train_Acc: 0.7500, TEST_Acc: 0.6300, Time: 2159.7481\n",
      "Epoch: 1899, Loss: 9928.7910, Train_Acc: 0.7308, TEST_Acc: 0.6267, Time: 2160.8794\n",
      "Epoch: 1900, Loss: 9575.9668, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2162.0135\n",
      "Epoch: 1901, Loss: 9538.0928, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2163.1473\n",
      "Epoch: 1902, Loss: 9366.6416, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2164.2823\n",
      "Epoch: 1903, Loss: 8950.7363, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2165.4222\n",
      "Epoch: 1904, Loss: 8485.6279, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 2166.5543\n",
      "Epoch: 1905, Loss: 8785.7773, Train_Acc: 0.7500, TEST_Acc: 0.6233, Time: 2167.6970\n",
      "Epoch: 1906, Loss: 9032.1514, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2168.8332\n",
      "Epoch: 1907, Loss: 8956.5469, Train_Acc: 0.7500, TEST_Acc: 0.6267, Time: 2169.9717\n",
      "Epoch: 1908, Loss: 8838.4219, Train_Acc: 0.7500, TEST_Acc: 0.6300, Time: 2171.1012\n",
      "Epoch: 1909, Loss: 8666.0107, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 2172.2397\n",
      "Epoch: 1910, Loss: 8653.5322, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 2173.3715\n",
      "Epoch: 1911, Loss: 8680.1719, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 2174.5048\n",
      "Epoch: 1912, Loss: 8966.1807, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 2175.6401\n",
      "Epoch: 1913, Loss: 8850.7451, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 2176.7716\n",
      "Epoch: 1914, Loss: 8688.9980, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 2177.9051\n",
      "Epoch: 1915, Loss: 8449.1367, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 2179.0382\n",
      "Epoch: 1916, Loss: 8516.2822, Train_Acc: 0.7692, TEST_Acc: 0.6300, Time: 2180.1738\n",
      "Epoch: 1917, Loss: 8525.3320, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 2181.3095\n",
      "Epoch: 1918, Loss: 8221.5869, Train_Acc: 0.7692, TEST_Acc: 0.6267, Time: 2182.4504\n",
      "Epoch: 1919, Loss: 7814.1011, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 2183.5906\n",
      "Epoch: 1920, Loss: 7987.6152, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 2184.7271\n",
      "Epoch: 1921, Loss: 8233.8115, Train_Acc: 0.7692, TEST_Acc: 0.6233, Time: 2185.8650\n",
      "Epoch: 1922, Loss: 8453.4209, Train_Acc: 0.7692, TEST_Acc: 0.6200, Time: 2186.9986\n",
      "Epoch: 1923, Loss: 8415.5430, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 2188.1340\n",
      "Epoch: 1924, Loss: 8301.6152, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 2189.2706\n",
      "Epoch: 1925, Loss: 8114.6719, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 2190.4038\n",
      "Epoch: 1926, Loss: 8203.6377, Train_Acc: 0.7692, TEST_Acc: 0.6167, Time: 2191.5378\n",
      "Epoch: 1927, Loss: 8459.2637, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 2192.6736\n",
      "Epoch: 1928, Loss: 8578.3535, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 2193.8062\n",
      "Epoch: 1929, Loss: 8437.3818, Train_Acc: 0.7692, TEST_Acc: 0.6100, Time: 2194.9482\n",
      "Epoch: 1930, Loss: 8401.5664, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 2196.0846\n",
      "Epoch: 1931, Loss: 8275.1680, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 2197.2185\n",
      "Epoch: 1932, Loss: 7899.0283, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2198.3567\n",
      "Epoch: 1933, Loss: 7817.1958, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2199.4969\n",
      "Epoch: 1934, Loss: 7949.9038, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2200.6283\n",
      "Epoch: 1935, Loss: 7932.7920, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2201.7611\n",
      "Epoch: 1936, Loss: 7929.9160, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2202.8981\n",
      "Epoch: 1937, Loss: 8096.2417, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 2204.0290\n",
      "Epoch: 1938, Loss: 8093.9404, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 2205.1653\n",
      "Epoch: 1939, Loss: 8049.4868, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2206.2963\n",
      "Epoch: 1940, Loss: 8291.9629, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 2207.4336\n",
      "Epoch: 1941, Loss: 8470.3252, Train_Acc: 0.7500, TEST_Acc: 0.6200, Time: 2208.5680\n",
      "Epoch: 1942, Loss: 8574.5156, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2209.7053\n",
      "Epoch: 1943, Loss: 8806.6270, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2210.8395\n",
      "Epoch: 1944, Loss: 8190.5732, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2211.9765\n",
      "Epoch: 1945, Loss: 8071.9473, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2213.1110\n",
      "Epoch: 1946, Loss: 8008.3149, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2214.2535\n",
      "Epoch: 1947, Loss: 8031.6011, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2215.3914\n",
      "Epoch: 1948, Loss: 7947.9741, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2216.5254\n",
      "Epoch: 1949, Loss: 8047.7266, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2217.6571\n",
      "Epoch: 1950, Loss: 8281.0430, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2218.7924\n",
      "Epoch: 1951, Loss: 8292.2432, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2219.9309\n",
      "Epoch: 1952, Loss: 8048.3340, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2221.0663\n",
      "Epoch: 1953, Loss: 8263.0566, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2222.2015\n",
      "Epoch: 1954, Loss: 8120.8779, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2223.3323\n",
      "Epoch: 1955, Loss: 8297.6934, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2224.4694\n",
      "Epoch: 1956, Loss: 8219.7256, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2225.6171\n",
      "Epoch: 1957, Loss: 8117.8745, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2226.7547\n",
      "Epoch: 1958, Loss: 7781.8984, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2227.8913\n",
      "Epoch: 1959, Loss: 7774.9932, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2229.0333\n",
      "Epoch: 1960, Loss: 7951.6011, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2230.1706\n",
      "Epoch: 1961, Loss: 8316.8184, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2231.3045\n",
      "Epoch: 1962, Loss: 8356.4814, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 2232.4369\n",
      "Epoch: 1963, Loss: 8151.2075, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2233.5683\n",
      "Epoch: 1964, Loss: 8153.7090, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2234.6990\n",
      "Epoch: 1965, Loss: 8177.1372, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 2235.8307\n",
      "Epoch: 1966, Loss: 8122.1226, Train_Acc: 0.7115, TEST_Acc: 0.6167, Time: 2236.9629\n",
      "Epoch: 1967, Loss: 8087.3750, Train_Acc: 0.7115, TEST_Acc: 0.6133, Time: 2238.0965\n",
      "Epoch: 1968, Loss: 8131.3652, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2239.2478\n",
      "Epoch: 1969, Loss: 8053.4072, Train_Acc: 0.7115, TEST_Acc: 0.6133, Time: 2240.3882\n",
      "Epoch: 1970, Loss: 7937.0132, Train_Acc: 0.7115, TEST_Acc: 0.6167, Time: 2241.5246\n",
      "Epoch: 1971, Loss: 7908.0903, Train_Acc: 0.7115, TEST_Acc: 0.6133, Time: 2242.6584\n",
      "Epoch: 1972, Loss: 7685.9604, Train_Acc: 0.7115, TEST_Acc: 0.6100, Time: 2243.7966\n",
      "Epoch: 1973, Loss: 7414.3799, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2244.9295\n",
      "Epoch: 1974, Loss: 7342.3135, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2246.0698\n",
      "Epoch: 1975, Loss: 7228.1558, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2247.2052\n",
      "Epoch: 1976, Loss: 7257.5337, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2248.3349\n",
      "Epoch: 1977, Loss: 7530.3965, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2249.4689\n",
      "Epoch: 1978, Loss: 7513.1851, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2250.6045\n",
      "Epoch: 1979, Loss: 7443.0986, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2251.7402\n",
      "Epoch: 1980, Loss: 7419.7178, Train_Acc: 0.7692, TEST_Acc: 0.6100, Time: 2252.8717\n",
      "Epoch: 1981, Loss: 7293.3872, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2254.0022\n",
      "Epoch: 1982, Loss: 7358.9131, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2255.1480\n",
      "Epoch: 1983, Loss: 7104.9087, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2256.2887\n",
      "Epoch: 1984, Loss: 7228.3882, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2257.4292\n",
      "Epoch: 1985, Loss: 7116.2061, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2258.5673\n",
      "Epoch: 1986, Loss: 6894.5825, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2259.7095\n",
      "Epoch: 1987, Loss: 6594.5239, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2260.8415\n",
      "Epoch: 1988, Loss: 6384.9604, Train_Acc: 0.7115, TEST_Acc: 0.5967, Time: 2261.9725\n",
      "Epoch: 1989, Loss: 6358.9917, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2263.1051\n",
      "Epoch: 1990, Loss: 6240.2837, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2264.2471\n",
      "Epoch: 1991, Loss: 6049.6650, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2265.3801\n",
      "Epoch: 1992, Loss: 6031.3853, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2266.5121\n",
      "Epoch: 1993, Loss: 5816.3638, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2267.6459\n",
      "Epoch: 1994, Loss: 5763.6616, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2268.7848\n",
      "Epoch: 1995, Loss: 5848.2783, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2269.9177\n",
      "Epoch: 1996, Loss: 5788.1616, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2271.0554\n",
      "Epoch: 1997, Loss: 5736.0146, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2272.1925\n",
      "Epoch: 1998, Loss: 5865.8521, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2273.3252\n",
      "Epoch: 1999, Loss: 5775.5312, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2274.4667\n",
      "Epoch: 2000, Loss: 5862.2778, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 2275.6024\n",
      "Epoch: 2001, Loss: 6126.9580, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2276.7328\n",
      "Epoch: 2002, Loss: 5672.3618, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2277.8714\n",
      "Epoch: 2003, Loss: 5850.9551, Train_Acc: 0.7115, TEST_Acc: 0.6100, Time: 2279.0032\n",
      "Epoch: 2004, Loss: 5524.6841, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2280.1358\n",
      "Epoch: 2005, Loss: 5496.0786, Train_Acc: 0.7115, TEST_Acc: 0.6067, Time: 2281.2714\n",
      "Epoch: 2006, Loss: 5579.3394, Train_Acc: 0.7115, TEST_Acc: 0.6100, Time: 2282.4074\n",
      "Epoch: 2007, Loss: 5593.7310, Train_Acc: 0.7115, TEST_Acc: 0.6100, Time: 2283.5390\n",
      "Epoch: 2008, Loss: 5730.5596, Train_Acc: 0.7115, TEST_Acc: 0.6067, Time: 2284.6765\n",
      "Epoch: 2009, Loss: 5415.9458, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2285.8172\n",
      "Epoch: 2010, Loss: 5461.6348, Train_Acc: 0.7115, TEST_Acc: 0.6100, Time: 2286.9588\n",
      "Epoch: 2011, Loss: 5566.0713, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2288.1016\n",
      "Epoch: 2012, Loss: 5684.9614, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2289.2397\n",
      "Epoch: 2013, Loss: 5667.2925, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2290.3751\n",
      "Epoch: 2014, Loss: 5572.3003, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2291.5053\n",
      "Epoch: 2015, Loss: 5410.8594, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2292.6376\n",
      "Epoch: 2016, Loss: 5214.4844, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2293.7744\n",
      "Epoch: 2017, Loss: 4966.4077, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2294.9102\n",
      "Epoch: 2018, Loss: 4580.8779, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2296.0425\n",
      "Epoch: 2019, Loss: 4487.3560, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2297.1725\n",
      "Epoch: 2020, Loss: 4469.9839, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2298.3094\n",
      "Epoch: 2021, Loss: 4608.0977, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2299.4449\n",
      "Epoch: 2022, Loss: 4512.7920, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2300.5814\n",
      "Epoch: 2023, Loss: 4324.4365, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2301.7213\n",
      "Epoch: 2024, Loss: 4534.7632, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2302.8585\n",
      "Epoch: 2025, Loss: 4304.6943, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2303.9947\n",
      "Epoch: 2026, Loss: 4118.7124, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2305.1319\n",
      "Epoch: 2027, Loss: 4106.4453, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2306.2644\n",
      "Epoch: 2028, Loss: 4042.7917, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2307.4012\n",
      "Epoch: 2029, Loss: 4147.4653, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2308.5388\n",
      "Epoch: 2030, Loss: 4105.7026, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2309.6736\n",
      "Epoch: 2031, Loss: 4055.6040, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2310.8058\n",
      "Epoch: 2032, Loss: 4032.0745, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2311.9372\n",
      "Epoch: 2033, Loss: 4041.4951, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2313.0716\n",
      "Epoch: 2034, Loss: 3926.3721, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2314.2078\n",
      "Epoch: 2035, Loss: 4082.4351, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2315.3516\n",
      "Epoch: 2036, Loss: 4141.4683, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2316.4887\n",
      "Epoch: 2037, Loss: 3984.5986, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2317.6212\n",
      "Epoch: 2038, Loss: 4005.5312, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 2318.7634\n",
      "Epoch: 2039, Loss: 3865.1641, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2319.9145\n",
      "Epoch: 2040, Loss: 3865.1982, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2321.0487\n",
      "Epoch: 2041, Loss: 3991.9771, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2322.1813\n",
      "Epoch: 2042, Loss: 3930.7590, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2323.3104\n",
      "Epoch: 2043, Loss: 3774.3591, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2324.4457\n",
      "Epoch: 2044, Loss: 3784.1482, Train_Acc: 0.7692, TEST_Acc: 0.6133, Time: 2325.5765\n",
      "Epoch: 2045, Loss: 3853.9495, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 2326.7098\n",
      "Epoch: 2046, Loss: 3791.9373, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2327.8463\n",
      "Epoch: 2047, Loss: 3751.8638, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2328.9810\n",
      "Epoch: 2048, Loss: 3658.7710, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 2330.1196\n",
      "Epoch: 2049, Loss: 3757.8755, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 2331.2595\n",
      "Epoch: 2050, Loss: 3606.5103, Train_Acc: 0.7500, TEST_Acc: 0.5967, Time: 2332.3961\n",
      "Epoch: 2051, Loss: 3629.6382, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2333.5303\n",
      "Epoch: 2052, Loss: 3516.5886, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2334.6664\n",
      "Epoch: 2053, Loss: 3555.6709, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2335.8060\n",
      "Epoch: 2054, Loss: 3738.2996, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2336.9442\n",
      "Epoch: 2055, Loss: 3679.2153, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2338.0750\n",
      "Epoch: 2056, Loss: 3616.7866, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2339.2054\n",
      "Epoch: 2057, Loss: 3500.8823, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2340.3390\n",
      "Epoch: 2058, Loss: 3446.5649, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2341.4803\n",
      "Epoch: 2059, Loss: 3483.9651, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2342.6172\n",
      "Epoch: 2060, Loss: 3521.1436, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2343.7445\n",
      "Epoch: 2061, Loss: 3511.1760, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2344.8796\n",
      "Epoch: 2062, Loss: 3681.9736, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2346.0191\n",
      "Epoch: 2063, Loss: 3778.6941, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2347.1525\n",
      "Epoch: 2064, Loss: 3887.2236, Train_Acc: 0.7500, TEST_Acc: 0.5967, Time: 2348.2902\n",
      "Epoch: 2065, Loss: 3671.9670, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2349.4244\n",
      "Epoch: 2066, Loss: 3489.1040, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2350.5634\n",
      "Epoch: 2067, Loss: 3247.5901, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2351.7042\n",
      "Epoch: 2068, Loss: 3473.1929, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2352.8355\n",
      "Epoch: 2069, Loss: 3353.9170, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2353.9663\n",
      "Epoch: 2070, Loss: 3595.6040, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2355.1009\n",
      "Epoch: 2071, Loss: 3714.7776, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2356.2339\n",
      "Epoch: 2072, Loss: 3695.4346, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2357.3634\n",
      "Epoch: 2073, Loss: 3535.9285, Train_Acc: 0.7500, TEST_Acc: 0.5933, Time: 2358.4964\n",
      "Epoch: 2074, Loss: 3330.2981, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2359.6288\n",
      "Epoch: 2075, Loss: 3382.6624, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2360.7631\n",
      "Epoch: 2076, Loss: 3161.8455, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2361.8963\n",
      "Epoch: 2077, Loss: 3087.5811, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2363.0313\n",
      "Epoch: 2078, Loss: 3028.1016, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2364.1682\n",
      "Epoch: 2079, Loss: 3126.8906, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2365.3062\n",
      "Epoch: 2080, Loss: 3028.7842, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2366.4472\n",
      "Epoch: 2081, Loss: 3161.4822, Train_Acc: 0.7500, TEST_Acc: 0.5967, Time: 2367.5862\n",
      "Epoch: 2082, Loss: 3225.0376, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2368.7183\n",
      "Epoch: 2083, Loss: 3225.6929, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2369.8500\n",
      "Epoch: 2084, Loss: 3276.0667, Train_Acc: 0.7692, TEST_Acc: 0.5967, Time: 2370.9802\n",
      "Epoch: 2085, Loss: 3148.4319, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2372.1127\n",
      "Epoch: 2086, Loss: 3073.3215, Train_Acc: 0.7500, TEST_Acc: 0.5967, Time: 2373.2455\n",
      "Epoch: 2087, Loss: 3044.6255, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2374.3879\n",
      "Epoch: 2088, Loss: 3152.5042, Train_Acc: 0.7500, TEST_Acc: 0.5867, Time: 2375.5193\n",
      "Epoch: 2089, Loss: 3294.0718, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2376.6691\n",
      "Epoch: 2090, Loss: 3273.1958, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2377.8116\n",
      "Epoch: 2091, Loss: 3161.2383, Train_Acc: 0.7500, TEST_Acc: 0.5900, Time: 2378.9506\n",
      "Epoch: 2092, Loss: 3190.0112, Train_Acc: 0.7500, TEST_Acc: 0.5967, Time: 2380.0884\n",
      "Epoch: 2093, Loss: 3274.1802, Train_Acc: 0.7500, TEST_Acc: 0.5933, Time: 2381.2313\n",
      "Epoch: 2094, Loss: 3157.7048, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2382.3656\n",
      "Epoch: 2095, Loss: 3130.5208, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2383.5018\n",
      "Epoch: 2096, Loss: 3008.4092, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2384.6401\n",
      "Epoch: 2097, Loss: 2999.2896, Train_Acc: 0.7500, TEST_Acc: 0.5967, Time: 2385.7757\n",
      "Epoch: 2098, Loss: 2985.9219, Train_Acc: 0.7692, TEST_Acc: 0.5900, Time: 2386.9134\n",
      "Epoch: 2099, Loss: 2999.6597, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2388.0465\n",
      "Epoch: 2100, Loss: 2915.3755, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2389.1808\n",
      "Epoch: 2101, Loss: 2797.7686, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2390.3172\n",
      "Epoch: 2102, Loss: 2897.4087, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2391.4534\n",
      "Epoch: 2103, Loss: 2971.7712, Train_Acc: 0.7500, TEST_Acc: 0.5933, Time: 2392.5891\n",
      "Epoch: 2104, Loss: 3067.8125, Train_Acc: 0.7500, TEST_Acc: 0.5933, Time: 2393.7295\n",
      "Epoch: 2105, Loss: 2968.3689, Train_Acc: 0.7500, TEST_Acc: 0.5933, Time: 2394.8726\n",
      "Epoch: 2106, Loss: 2953.6089, Train_Acc: 0.7500, TEST_Acc: 0.5900, Time: 2396.0081\n",
      "Epoch: 2107, Loss: 2771.2241, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2397.1413\n",
      "Epoch: 2108, Loss: 2822.3232, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2398.2778\n",
      "Epoch: 2109, Loss: 2867.0374, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2399.4093\n",
      "Epoch: 2110, Loss: 2931.8599, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2400.5462\n",
      "Epoch: 2111, Loss: 2982.1331, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2401.6818\n",
      "Epoch: 2112, Loss: 2885.0679, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2402.8143\n",
      "Epoch: 2113, Loss: 2710.9722, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2403.9509\n",
      "Epoch: 2114, Loss: 2782.1221, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2405.0868\n",
      "Epoch: 2115, Loss: 2906.8037, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2406.2250\n",
      "Epoch: 2116, Loss: 2752.7776, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2407.3623\n",
      "Epoch: 2117, Loss: 2837.7344, Train_Acc: 0.7500, TEST_Acc: 0.5900, Time: 2408.5000\n",
      "Epoch: 2118, Loss: 2797.1724, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2409.6365\n",
      "Epoch: 2119, Loss: 2583.6411, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2410.7784\n",
      "Epoch: 2120, Loss: 2609.0322, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2411.9170\n",
      "Epoch: 2121, Loss: 2608.1099, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2413.0555\n",
      "Epoch: 2122, Loss: 2668.2373, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2414.1896\n",
      "Epoch: 2123, Loss: 2609.0457, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2415.3267\n",
      "Epoch: 2124, Loss: 2581.1526, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2416.4649\n",
      "Epoch: 2125, Loss: 2692.0854, Train_Acc: 0.7115, TEST_Acc: 0.5967, Time: 2417.5971\n",
      "Epoch: 2126, Loss: 2539.6770, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2418.7337\n",
      "Epoch: 2127, Loss: 2399.7871, Train_Acc: 0.7692, TEST_Acc: 0.6000, Time: 2419.8688\n",
      "Epoch: 2128, Loss: 2476.4072, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2421.0033\n",
      "Epoch: 2129, Loss: 2376.2622, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2422.1344\n",
      "Epoch: 2130, Loss: 2343.0737, Train_Acc: 0.7692, TEST_Acc: 0.6033, Time: 2423.2741\n",
      "Epoch: 2131, Loss: 2377.1917, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2424.4114\n",
      "Epoch: 2132, Loss: 2426.7434, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 2425.5442\n",
      "Epoch: 2133, Loss: 2546.7048, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2426.6894\n",
      "Epoch: 2134, Loss: 2634.3025, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 2427.8285\n",
      "Epoch: 2135, Loss: 2757.9404, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2428.9590\n",
      "Epoch: 2136, Loss: 2706.4392, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2430.0940\n",
      "Epoch: 2137, Loss: 2673.5806, Train_Acc: 0.7115, TEST_Acc: 0.5967, Time: 2431.2263\n",
      "Epoch: 2138, Loss: 2495.5823, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2432.3615\n",
      "Epoch: 2139, Loss: 2635.8872, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2433.4971\n",
      "Epoch: 2140, Loss: 2596.9526, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2434.6444\n",
      "Epoch: 2141, Loss: 2686.9321, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2435.7787\n",
      "Epoch: 2142, Loss: 2657.8076, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2436.9195\n",
      "Epoch: 2143, Loss: 2698.5459, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2438.0576\n",
      "Epoch: 2144, Loss: 2664.0024, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2439.1975\n",
      "Epoch: 2145, Loss: 2495.0283, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2440.3361\n",
      "Epoch: 2146, Loss: 2511.0510, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2441.4728\n",
      "Epoch: 2147, Loss: 2468.6118, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2442.6133\n",
      "Epoch: 2148, Loss: 2365.9502, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2443.7503\n",
      "Epoch: 2149, Loss: 2402.5527, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2444.8835\n",
      "Epoch: 2150, Loss: 2269.3713, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2446.0191\n",
      "Epoch: 2151, Loss: 2169.7100, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 2447.1503\n",
      "Epoch: 2152, Loss: 2154.5549, Train_Acc: 0.6731, TEST_Acc: 0.5933, Time: 2448.2842\n",
      "Epoch: 2153, Loss: 2164.4165, Train_Acc: 0.6731, TEST_Acc: 0.5967, Time: 2449.4293\n",
      "Epoch: 2154, Loss: 2192.1357, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2450.5661\n",
      "Epoch: 2155, Loss: 2176.2937, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2451.6992\n",
      "Epoch: 2156, Loss: 2135.5269, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 2452.8337\n",
      "Epoch: 2157, Loss: 2120.0027, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 2453.9690\n",
      "Epoch: 2158, Loss: 2111.5286, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 2455.1064\n",
      "Epoch: 2159, Loss: 2018.9470, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 2456.2512\n",
      "Epoch: 2160, Loss: 2029.0315, Train_Acc: 0.7115, TEST_Acc: 0.5933, Time: 2457.3868\n",
      "Epoch: 2161, Loss: 2115.0161, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2458.5241\n",
      "Epoch: 2162, Loss: 2092.2017, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2459.6623\n",
      "Epoch: 2163, Loss: 2082.2236, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2460.7970\n",
      "Epoch: 2164, Loss: 2076.3250, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2461.9313\n",
      "Epoch: 2165, Loss: 1973.3898, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2463.0671\n",
      "Epoch: 2166, Loss: 2087.7800, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2464.2031\n",
      "Epoch: 2167, Loss: 2007.0676, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2465.3408\n",
      "Epoch: 2168, Loss: 1994.9392, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2466.4816\n",
      "Epoch: 2169, Loss: 1927.5782, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2467.6128\n",
      "Epoch: 2170, Loss: 1809.7533, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2468.7506\n",
      "Epoch: 2171, Loss: 1854.1682, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2469.8946\n",
      "Epoch: 2172, Loss: 1821.8562, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2471.0316\n",
      "Epoch: 2173, Loss: 1841.5559, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2472.1682\n",
      "Epoch: 2174, Loss: 1662.1509, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2473.3039\n",
      "Epoch: 2175, Loss: 1760.7576, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2474.4408\n",
      "Epoch: 2176, Loss: 1762.2083, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2475.5765\n",
      "Epoch: 2177, Loss: 1705.8882, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2476.7081\n",
      "Epoch: 2178, Loss: 1721.0597, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2477.8410\n",
      "Epoch: 2179, Loss: 1714.3445, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2478.9772\n",
      "Epoch: 2180, Loss: 1787.5204, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2480.1091\n",
      "Epoch: 2181, Loss: 1738.2283, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2481.2454\n",
      "Epoch: 2182, Loss: 1817.3960, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2482.3791\n",
      "Epoch: 2183, Loss: 1772.0477, Train_Acc: 0.7500, TEST_Acc: 0.5900, Time: 2483.5132\n",
      "Epoch: 2184, Loss: 1874.0487, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2484.6474\n",
      "Epoch: 2185, Loss: 1874.5259, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2485.7840\n",
      "Epoch: 2186, Loss: 1821.9940, Train_Acc: 0.7500, TEST_Acc: 0.5900, Time: 2486.9206\n",
      "Epoch: 2187, Loss: 1620.6990, Train_Acc: 0.7500, TEST_Acc: 0.5867, Time: 2488.0609\n",
      "Epoch: 2188, Loss: 1598.6213, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2489.1967\n",
      "Epoch: 2189, Loss: 1575.8684, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2490.3357\n",
      "Epoch: 2190, Loss: 1621.8541, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2491.4683\n",
      "Epoch: 2191, Loss: 1664.9451, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2492.6050\n",
      "Epoch: 2192, Loss: 1553.1804, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2493.7366\n",
      "Epoch: 2193, Loss: 1688.0796, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2494.8702\n",
      "Epoch: 2194, Loss: 1822.0139, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2496.0015\n",
      "Epoch: 2195, Loss: 1839.1526, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2497.1358\n",
      "Epoch: 2196, Loss: 1749.3354, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2498.2719\n",
      "Epoch: 2197, Loss: 1641.3831, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2499.4093\n",
      "Epoch: 2198, Loss: 1574.0833, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2500.5409\n",
      "Epoch: 2199, Loss: 1612.4786, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2501.6813\n",
      "Epoch: 2200, Loss: 1553.1057, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2502.8218\n",
      "Epoch: 2201, Loss: 1532.2644, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2503.9581\n",
      "Epoch: 2202, Loss: 1579.3142, Train_Acc: 0.7308, TEST_Acc: 0.5833, Time: 2505.0955\n",
      "Epoch: 2203, Loss: 1507.9305, Train_Acc: 0.7308, TEST_Acc: 0.5800, Time: 2506.2321\n",
      "Epoch: 2204, Loss: 1516.6091, Train_Acc: 0.7308, TEST_Acc: 0.5833, Time: 2507.3639\n",
      "Epoch: 2205, Loss: 1505.8228, Train_Acc: 0.7308, TEST_Acc: 0.5800, Time: 2508.4961\n",
      "Epoch: 2206, Loss: 1516.6063, Train_Acc: 0.7308, TEST_Acc: 0.5767, Time: 2509.6340\n",
      "Epoch: 2207, Loss: 1493.1522, Train_Acc: 0.7308, TEST_Acc: 0.5833, Time: 2510.7651\n",
      "Epoch: 2208, Loss: 1450.5308, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2511.9032\n",
      "Epoch: 2209, Loss: 1511.3229, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2513.0396\n",
      "Epoch: 2210, Loss: 1446.8325, Train_Acc: 0.7308, TEST_Acc: 0.5800, Time: 2514.1778\n",
      "Epoch: 2211, Loss: 1581.7455, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2515.3116\n",
      "Epoch: 2212, Loss: 1596.5916, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2516.4454\n",
      "Epoch: 2213, Loss: 1499.0222, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2517.5813\n",
      "Epoch: 2214, Loss: 1486.5171, Train_Acc: 0.7308, TEST_Acc: 0.5767, Time: 2518.7194\n",
      "Epoch: 2215, Loss: 1629.8131, Train_Acc: 0.7308, TEST_Acc: 0.5800, Time: 2519.8612\n",
      "Epoch: 2216, Loss: 1623.3472, Train_Acc: 0.7308, TEST_Acc: 0.5767, Time: 2521.0115\n",
      "Epoch: 2217, Loss: 1498.0568, Train_Acc: 0.7308, TEST_Acc: 0.5800, Time: 2522.1471\n",
      "Epoch: 2218, Loss: 1468.8765, Train_Acc: 0.7500, TEST_Acc: 0.5767, Time: 2523.2816\n",
      "Epoch: 2219, Loss: 1469.3047, Train_Acc: 0.7500, TEST_Acc: 0.5767, Time: 2524.4143\n",
      "Epoch: 2220, Loss: 1428.9081, Train_Acc: 0.7308, TEST_Acc: 0.5733, Time: 2525.5479\n",
      "Epoch: 2221, Loss: 1419.0526, Train_Acc: 0.7308, TEST_Acc: 0.5767, Time: 2526.6786\n",
      "Epoch: 2222, Loss: 1534.5775, Train_Acc: 0.7308, TEST_Acc: 0.5767, Time: 2527.8183\n",
      "Epoch: 2223, Loss: 1436.3800, Train_Acc: 0.7308, TEST_Acc: 0.5767, Time: 2528.9485\n",
      "Epoch: 2224, Loss: 1388.1882, Train_Acc: 0.7500, TEST_Acc: 0.5767, Time: 2530.0833\n",
      "Epoch: 2225, Loss: 1421.9539, Train_Acc: 0.7308, TEST_Acc: 0.5767, Time: 2531.2138\n",
      "Epoch: 2226, Loss: 1295.8436, Train_Acc: 0.7500, TEST_Acc: 0.5800, Time: 2532.3615\n",
      "Epoch: 2227, Loss: 1326.6984, Train_Acc: 0.7500, TEST_Acc: 0.5800, Time: 2533.4951\n",
      "Epoch: 2228, Loss: 1395.8549, Train_Acc: 0.7308, TEST_Acc: 0.5767, Time: 2534.6333\n",
      "Epoch: 2229, Loss: 1355.5911, Train_Acc: 0.7308, TEST_Acc: 0.5767, Time: 2535.7686\n",
      "Epoch: 2230, Loss: 1420.3425, Train_Acc: 0.7308, TEST_Acc: 0.5767, Time: 2536.9085\n",
      "Epoch: 2231, Loss: 1442.8318, Train_Acc: 0.7308, TEST_Acc: 0.5767, Time: 2538.0446\n",
      "Epoch: 2232, Loss: 1428.1300, Train_Acc: 0.7308, TEST_Acc: 0.5767, Time: 2539.1756\n",
      "Epoch: 2233, Loss: 1339.8068, Train_Acc: 0.7308, TEST_Acc: 0.5800, Time: 2540.3094\n",
      "Epoch: 2234, Loss: 1416.8151, Train_Acc: 0.7308, TEST_Acc: 0.5833, Time: 2541.4443\n",
      "Epoch: 2235, Loss: 1319.9512, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2542.5832\n",
      "Epoch: 2236, Loss: 1277.5598, Train_Acc: 0.7308, TEST_Acc: 0.5867, Time: 2543.7198\n",
      "Epoch: 2237, Loss: 1237.9379, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2544.8493\n",
      "Epoch: 2238, Loss: 1238.8329, Train_Acc: 0.7500, TEST_Acc: 0.5867, Time: 2545.9858\n",
      "Epoch: 2239, Loss: 1256.8357, Train_Acc: 0.7500, TEST_Acc: 0.5933, Time: 2547.1187\n",
      "Epoch: 2240, Loss: 1231.6265, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2548.2547\n",
      "Epoch: 2241, Loss: 1155.8525, Train_Acc: 0.7500, TEST_Acc: 0.5800, Time: 2549.3967\n",
      "Epoch: 2242, Loss: 1326.5577, Train_Acc: 0.7115, TEST_Acc: 0.5933, Time: 2550.5336\n",
      "Epoch: 2243, Loss: 1210.1210, Train_Acc: 0.7500, TEST_Acc: 0.5867, Time: 2551.6706\n",
      "Epoch: 2244, Loss: 1132.3396, Train_Acc: 0.7500, TEST_Acc: 0.5833, Time: 2552.8142\n",
      "Epoch: 2245, Loss: 1195.6576, Train_Acc: 0.7500, TEST_Acc: 0.5833, Time: 2553.9492\n",
      "Epoch: 2246, Loss: 1202.9910, Train_Acc: 0.7500, TEST_Acc: 0.5833, Time: 2555.0919\n",
      "Epoch: 2247, Loss: 1199.0310, Train_Acc: 0.7500, TEST_Acc: 0.5767, Time: 2556.2232\n",
      "Epoch: 2248, Loss: 1213.9978, Train_Acc: 0.7500, TEST_Acc: 0.5833, Time: 2557.3601\n",
      "Epoch: 2249, Loss: 1212.3765, Train_Acc: 0.7500, TEST_Acc: 0.5900, Time: 2558.4936\n",
      "Epoch: 2250, Loss: 1179.8622, Train_Acc: 0.7500, TEST_Acc: 0.5867, Time: 2559.6292\n",
      "Epoch: 2251, Loss: 1106.7330, Train_Acc: 0.7500, TEST_Acc: 0.5900, Time: 2560.7656\n",
      "Epoch: 2252, Loss: 1080.8220, Train_Acc: 0.7500, TEST_Acc: 0.5833, Time: 2561.9038\n",
      "Epoch: 2253, Loss: 1044.0741, Train_Acc: 0.7500, TEST_Acc: 0.5867, Time: 2563.0383\n",
      "Epoch: 2254, Loss: 993.9464, Train_Acc: 0.7500, TEST_Acc: 0.5867, Time: 2564.1834\n",
      "Epoch: 2255, Loss: 982.0111, Train_Acc: 0.7500, TEST_Acc: 0.5900, Time: 2565.3196\n",
      "Epoch: 2256, Loss: 1129.0917, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2566.4557\n",
      "Epoch: 2257, Loss: 1082.7845, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2567.5928\n",
      "Epoch: 2258, Loss: 1039.1555, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2568.7285\n",
      "Epoch: 2259, Loss: 995.7867, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2569.8613\n",
      "Epoch: 2260, Loss: 976.9611, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2570.9954\n",
      "Epoch: 2261, Loss: 895.7214, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2572.1303\n",
      "Epoch: 2262, Loss: 854.2422, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2573.2638\n",
      "Epoch: 2263, Loss: 863.6737, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2574.4078\n",
      "Epoch: 2264, Loss: 788.2567, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2575.5432\n",
      "Epoch: 2265, Loss: 718.7104, Train_Acc: 0.7115, TEST_Acc: 0.5900, Time: 2576.6774\n",
      "Epoch: 2266, Loss: 665.3751, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2577.8095\n",
      "Epoch: 2267, Loss: 623.0025, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2578.9456\n",
      "Epoch: 2268, Loss: 639.6157, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2580.0820\n",
      "Epoch: 2269, Loss: 634.5493, Train_Acc: 0.7115, TEST_Acc: 0.5900, Time: 2581.2176\n",
      "Epoch: 2270, Loss: 720.1367, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 2582.3599\n",
      "Epoch: 2271, Loss: 838.7117, Train_Acc: 0.7115, TEST_Acc: 0.5933, Time: 2583.5034\n",
      "Epoch: 2272, Loss: 875.1341, Train_Acc: 0.7115, TEST_Acc: 0.5900, Time: 2584.6450\n",
      "Epoch: 2273, Loss: 755.4307, Train_Acc: 0.7115, TEST_Acc: 0.5967, Time: 2585.7800\n",
      "Epoch: 2274, Loss: 709.6765, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2586.9114\n",
      "Epoch: 2275, Loss: 836.8392, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2588.0538\n",
      "Epoch: 2276, Loss: 777.2140, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2589.1872\n",
      "Epoch: 2277, Loss: 675.0588, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2590.3230\n",
      "Epoch: 2278, Loss: 615.2936, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 2591.4574\n",
      "Epoch: 2279, Loss: 575.8206, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 2592.5919\n",
      "Epoch: 2280, Loss: 526.6292, Train_Acc: 0.6923, TEST_Acc: 0.5900, Time: 2593.7380\n",
      "Epoch: 2281, Loss: 471.5210, Train_Acc: 0.6923, TEST_Acc: 0.5900, Time: 2594.8813\n",
      "Epoch: 2282, Loss: 470.0798, Train_Acc: 0.7115, TEST_Acc: 0.5900, Time: 2596.0191\n",
      "Epoch: 2283, Loss: 496.0770, Train_Acc: 0.7115, TEST_Acc: 0.5933, Time: 2597.1545\n",
      "Epoch: 2284, Loss: 504.8192, Train_Acc: 0.6923, TEST_Acc: 0.5867, Time: 2598.2989\n",
      "Epoch: 2285, Loss: 526.5961, Train_Acc: 0.7115, TEST_Acc: 0.5900, Time: 2599.4333\n",
      "Epoch: 2286, Loss: 635.4763, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2600.5663\n",
      "Epoch: 2287, Loss: 589.4318, Train_Acc: 0.7115, TEST_Acc: 0.5867, Time: 2601.7018\n",
      "Epoch: 2288, Loss: 659.7207, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 2602.8371\n",
      "Epoch: 2289, Loss: 684.5389, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2603.9761\n",
      "Epoch: 2290, Loss: 635.6921, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2605.1155\n",
      "Epoch: 2291, Loss: 565.6788, Train_Acc: 0.7115, TEST_Acc: 0.5933, Time: 2606.2501\n",
      "Epoch: 2292, Loss: 488.2785, Train_Acc: 0.7115, TEST_Acc: 0.5933, Time: 2607.3862\n",
      "Epoch: 2293, Loss: 500.7953, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2608.5189\n",
      "Epoch: 2294, Loss: 428.2015, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2609.6608\n",
      "Epoch: 2295, Loss: 313.2641, Train_Acc: 0.7308, TEST_Acc: 0.5900, Time: 2610.7973\n",
      "Epoch: 2296, Loss: 300.0337, Train_Acc: 0.7115, TEST_Acc: 0.5933, Time: 2611.9350\n",
      "Epoch: 2297, Loss: 308.2146, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2613.0728\n",
      "Epoch: 2298, Loss: 405.6899, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2614.2123\n",
      "Epoch: 2299, Loss: 385.0171, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2615.3493\n",
      "Epoch: 2300, Loss: 465.2295, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2616.4833\n",
      "Epoch: 2301, Loss: 510.5386, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2617.6236\n",
      "Epoch: 2302, Loss: 500.1736, Train_Acc: 0.7115, TEST_Acc: 0.5967, Time: 2618.7572\n",
      "Epoch: 2303, Loss: 589.8297, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2619.8903\n",
      "Epoch: 2304, Loss: 572.1282, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2621.0250\n",
      "Epoch: 2305, Loss: 565.7325, Train_Acc: 0.7115, TEST_Acc: 0.6067, Time: 2622.1554\n",
      "Epoch: 2306, Loss: 527.9742, Train_Acc: 0.7115, TEST_Acc: 0.6067, Time: 2623.2923\n",
      "Epoch: 2307, Loss: 520.9031, Train_Acc: 0.7115, TEST_Acc: 0.5933, Time: 2624.4244\n",
      "Epoch: 2308, Loss: 471.3706, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2625.5626\n",
      "Epoch: 2309, Loss: 426.2750, Train_Acc: 0.7115, TEST_Acc: 0.5933, Time: 2626.7055\n",
      "Epoch: 2310, Loss: 367.0080, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2627.8399\n",
      "Epoch: 2311, Loss: 388.6089, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2628.9756\n",
      "Epoch: 2312, Loss: 396.9822, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2630.1098\n",
      "Epoch: 2313, Loss: 413.4246, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2631.2455\n",
      "Epoch: 2314, Loss: 467.5138, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2632.3803\n",
      "Epoch: 2315, Loss: 466.6421, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2633.5131\n",
      "Epoch: 2316, Loss: 508.0286, Train_Acc: 0.7115, TEST_Acc: 0.5967, Time: 2634.6602\n",
      "Epoch: 2317, Loss: 508.6965, Train_Acc: 0.7115, TEST_Acc: 0.5967, Time: 2635.7944\n",
      "Epoch: 2318, Loss: 600.9510, Train_Acc: 0.7115, TEST_Acc: 0.5967, Time: 2636.9348\n",
      "Epoch: 2319, Loss: 545.5030, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2638.0736\n",
      "Epoch: 2320, Loss: 516.9726, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2639.2082\n",
      "Epoch: 2321, Loss: 517.3329, Train_Acc: 0.7115, TEST_Acc: 0.5967, Time: 2640.3440\n",
      "Epoch: 2322, Loss: 560.8012, Train_Acc: 0.7115, TEST_Acc: 0.5967, Time: 2641.4839\n",
      "Epoch: 2323, Loss: 538.6360, Train_Acc: 0.7115, TEST_Acc: 0.5967, Time: 2642.6282\n",
      "Epoch: 2324, Loss: 443.0736, Train_Acc: 0.7115, TEST_Acc: 0.5933, Time: 2643.7647\n",
      "Epoch: 2325, Loss: 479.4012, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2644.9035\n",
      "Epoch: 2326, Loss: 358.5003, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2646.0458\n",
      "Epoch: 2327, Loss: 366.8664, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2647.1814\n",
      "Epoch: 2328, Loss: 320.8188, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2648.3231\n",
      "Epoch: 2329, Loss: 357.9379, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2649.4553\n",
      "Epoch: 2330, Loss: 350.5949, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2650.5874\n",
      "Epoch: 2331, Loss: 327.6176, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2651.7247\n",
      "Epoch: 2332, Loss: 381.7936, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2652.8600\n",
      "Epoch: 2333, Loss: 346.8955, Train_Acc: 0.7500, TEST_Acc: 0.5900, Time: 2653.9937\n",
      "Epoch: 2334, Loss: 346.7713, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2655.1300\n",
      "Epoch: 2335, Loss: 342.6653, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2656.2664\n",
      "Epoch: 2336, Loss: 352.5889, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2657.4083\n",
      "Epoch: 2337, Loss: 336.4507, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2658.5420\n",
      "Epoch: 2338, Loss: 379.3130, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2659.6765\n",
      "Epoch: 2339, Loss: 376.4932, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2660.8140\n",
      "Epoch: 2340, Loss: 404.1508, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2661.9507\n",
      "Epoch: 2341, Loss: 340.9781, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2663.0821\n",
      "Epoch: 2342, Loss: 277.7953, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2664.2134\n",
      "Epoch: 2343, Loss: 309.4076, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2665.3477\n",
      "Epoch: 2344, Loss: 286.5842, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2666.4821\n",
      "Epoch: 2345, Loss: 269.0130, Train_Acc: 0.7500, TEST_Acc: 0.5933, Time: 2667.6191\n",
      "Epoch: 2346, Loss: 390.7588, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2668.7648\n",
      "Epoch: 2347, Loss: 410.4827, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2669.8966\n",
      "Epoch: 2348, Loss: 474.9082, Train_Acc: 0.7115, TEST_Acc: 0.5967, Time: 2671.0317\n",
      "Epoch: 2349, Loss: 389.8365, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2672.1672\n",
      "Epoch: 2350, Loss: 390.7872, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2673.3071\n",
      "Epoch: 2351, Loss: 401.7236, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2674.4475\n",
      "Epoch: 2352, Loss: 277.9572, Train_Acc: 0.7500, TEST_Acc: 0.5967, Time: 2675.5937\n",
      "Epoch: 2353, Loss: 308.4051, Train_Acc: 0.7500, TEST_Acc: 0.5967, Time: 2676.7347\n",
      "Epoch: 2354, Loss: 302.7478, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2677.8682\n",
      "Epoch: 2355, Loss: 273.0756, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2679.0109\n",
      "Epoch: 2356, Loss: 319.2965, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2680.1475\n",
      "Epoch: 2357, Loss: 277.6661, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2681.2805\n",
      "Epoch: 2358, Loss: 329.4361, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2682.4104\n",
      "Epoch: 2359, Loss: 372.6568, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2683.5453\n",
      "Epoch: 2360, Loss: 400.3969, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2684.6882\n",
      "Epoch: 2361, Loss: 344.0783, Train_Acc: 0.7308, TEST_Acc: 0.5933, Time: 2685.8252\n",
      "Epoch: 2362, Loss: 303.0064, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2686.9607\n",
      "Epoch: 2363, Loss: 266.7062, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2688.0990\n",
      "Epoch: 2364, Loss: 235.2312, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2689.2416\n",
      "Epoch: 2365, Loss: 245.5425, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2690.3742\n",
      "Epoch: 2366, Loss: 199.5062, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2691.5094\n",
      "Epoch: 2367, Loss: 188.9762, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2692.6471\n",
      "Epoch: 2368, Loss: 216.4254, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2693.7778\n",
      "Epoch: 2369, Loss: 212.0395, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2694.9126\n",
      "Epoch: 2370, Loss: 114.6037, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2696.0457\n",
      "Epoch: 2371, Loss: 87.8262, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2697.1810\n",
      "Epoch: 2372, Loss: 145.0852, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2698.3157\n",
      "Epoch: 2373, Loss: 185.6377, Train_Acc: 0.7115, TEST_Acc: 0.6000, Time: 2699.4543\n",
      "Epoch: 2374, Loss: 139.4144, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2700.5903\n",
      "Epoch: 2375, Loss: 27.0163, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2701.7220\n",
      "Epoch: 2376, Loss: 45.0367, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2702.8591\n",
      "Epoch: 2377, Loss: 13.1207, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2704.0061\n",
      "Epoch: 2378, Loss: 80.9506, Train_Acc: 0.7115, TEST_Acc: 0.6067, Time: 2705.1451\n",
      "Epoch: 2379, Loss: 100.2611, Train_Acc: 0.7115, TEST_Acc: 0.6067, Time: 2706.2904\n",
      "Epoch: 2380, Loss: 55.1868, Train_Acc: 0.7115, TEST_Acc: 0.6067, Time: 2707.4277\n",
      "Epoch: 2381, Loss: 0.5820, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2708.5672\n",
      "Epoch: 2382, Loss: 26.5576, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2709.6982\n",
      "Epoch: 2383, Loss: 88.4644, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2710.8385\n",
      "Epoch: 2384, Loss: 109.8839, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2711.9753\n",
      "Epoch: 2385, Loss: 187.7580, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2713.1099\n",
      "Epoch: 2386, Loss: 214.3775, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2714.2463\n",
      "Epoch: 2387, Loss: 27.3321, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2715.3819\n",
      "Epoch: 2388, Loss: 53.7141, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2716.5147\n",
      "Epoch: 2389, Loss: 110.9054, Train_Acc: 0.7115, TEST_Acc: 0.6067, Time: 2717.6506\n",
      "Epoch: 2390, Loss: 74.6776, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2718.7884\n",
      "Epoch: 2391, Loss: 59.5694, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2719.9293\n",
      "Epoch: 2392, Loss: 75.8279, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2721.0733\n",
      "Epoch: 2393, Loss: 105.9602, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2722.2144\n",
      "Epoch: 2394, Loss: 147.1989, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2723.3492\n",
      "Epoch: 2395, Loss: 113.1906, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2724.4876\n",
      "Epoch: 2396, Loss: 102.6747, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2725.6214\n",
      "Epoch: 2397, Loss: 44.3534, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2726.7557\n",
      "Epoch: 2398, Loss: 0.5739, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2727.8889\n",
      "Epoch: 2399, Loss: 49.9707, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2729.0237\n",
      "Epoch: 2400, Loss: 12.3618, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2730.1560\n",
      "Epoch: 2401, Loss: 0.5657, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2731.2996\n",
      "Epoch: 2402, Loss: 0.5629, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2732.4320\n",
      "Epoch: 2403, Loss: 0.5647, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2733.5681\n",
      "Epoch: 2404, Loss: 0.5648, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2734.7056\n",
      "Epoch: 2405, Loss: 0.5626, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2735.8422\n",
      "Epoch: 2406, Loss: 0.5610, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 2736.9837\n",
      "Epoch: 2407, Loss: 0.5608, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2738.1247\n",
      "Epoch: 2408, Loss: 0.5640, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2739.2654\n",
      "Epoch: 2409, Loss: 0.5678, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 2740.4007\n",
      "Epoch: 2410, Loss: 21.6622, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2741.5390\n",
      "Epoch: 2411, Loss: 0.5654, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2742.6726\n",
      "Epoch: 2412, Loss: 0.5640, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2743.8077\n",
      "Epoch: 2413, Loss: 0.5602, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2744.9489\n",
      "Epoch: 2414, Loss: 0.5654, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2746.0875\n",
      "Epoch: 2415, Loss: 0.5701, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2747.2212\n",
      "Epoch: 2416, Loss: 0.5734, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2748.3575\n",
      "Epoch: 2417, Loss: 17.5415, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 2749.4933\n",
      "Epoch: 2418, Loss: 129.9875, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 2750.6288\n",
      "Epoch: 2419, Loss: 40.3099, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2751.7724\n",
      "Epoch: 2420, Loss: 88.3803, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2752.9101\n",
      "Epoch: 2421, Loss: 47.1715, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2754.0536\n",
      "Epoch: 2422, Loss: 139.1310, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2755.1870\n",
      "Epoch: 2423, Loss: 100.8923, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2756.3227\n",
      "Epoch: 2424, Loss: 0.5948, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2757.4563\n",
      "Epoch: 2425, Loss: 0.5901, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2758.5922\n",
      "Epoch: 2426, Loss: 0.5855, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2759.7295\n",
      "Epoch: 2427, Loss: 14.6067, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 2760.8634\n",
      "Epoch: 2428, Loss: 0.5897, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 2761.9977\n",
      "Epoch: 2429, Loss: 0.5897, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2763.1431\n",
      "Epoch: 2430, Loss: 0.5876, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2764.2809\n",
      "Epoch: 2431, Loss: 0.5818, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2765.4175\n",
      "Epoch: 2432, Loss: 0.5788, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2766.5542\n",
      "Epoch: 2433, Loss: 0.5752, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2767.6877\n",
      "Epoch: 2434, Loss: 0.5760, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 2768.8306\n",
      "Epoch: 2435, Loss: 0.5775, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 2769.9606\n",
      "Epoch: 2436, Loss: 0.5815, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2771.0958\n",
      "Epoch: 2437, Loss: 0.5759, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2772.2277\n",
      "Epoch: 2438, Loss: 0.5720, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2773.3596\n",
      "Epoch: 2439, Loss: 0.5716, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2774.4910\n",
      "Epoch: 2440, Loss: 0.5329, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 2775.6274\n",
      "Epoch: 2441, Loss: 0.5775, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2776.7601\n",
      "Epoch: 2442, Loss: 0.5411, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 2777.8939\n",
      "Epoch: 2443, Loss: 0.5804, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2779.0360\n",
      "Epoch: 2444, Loss: 0.5353, Train_Acc: 0.7692, TEST_Acc: 0.6067, Time: 2780.1700\n",
      "Epoch: 2445, Loss: 0.5757, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2781.3067\n",
      "Epoch: 2446, Loss: 0.5285, Train_Acc: 0.7692, TEST_Acc: 0.6100, Time: 2782.4434\n",
      "Epoch: 2447, Loss: 0.5640, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2783.5774\n",
      "Epoch: 2448, Loss: 0.5690, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2784.7147\n",
      "Epoch: 2449, Loss: 0.5676, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2785.8432\n",
      "Epoch: 2450, Loss: 0.5650, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2786.9831\n",
      "Epoch: 2451, Loss: 0.5662, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2788.1171\n",
      "Epoch: 2452, Loss: 0.5643, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2789.2487\n",
      "Epoch: 2453, Loss: 0.5652, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2790.3872\n",
      "Epoch: 2454, Loss: 0.5668, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2791.5178\n",
      "Epoch: 2455, Loss: 0.5629, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 2792.6570\n",
      "Epoch: 2456, Loss: 0.5643, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 2793.7963\n",
      "Epoch: 2457, Loss: 0.5650, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2794.9352\n",
      "Epoch: 2458, Loss: 0.5649, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2796.0816\n",
      "Epoch: 2459, Loss: 0.5601, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2797.2182\n",
      "Epoch: 2460, Loss: 0.5583, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2798.3547\n",
      "Epoch: 2461, Loss: 0.5506, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2799.4946\n",
      "Epoch: 2462, Loss: 0.5501, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2800.6316\n",
      "Epoch: 2463, Loss: 0.5521, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2801.7649\n",
      "Epoch: 2464, Loss: 0.5544, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2802.9004\n",
      "Epoch: 2465, Loss: 0.5537, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 2804.0347\n",
      "Epoch: 2466, Loss: 0.5458, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2805.1708\n",
      "Epoch: 2467, Loss: 0.5432, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2806.3056\n",
      "Epoch: 2468, Loss: 0.5461, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2807.4391\n",
      "Epoch: 2469, Loss: 0.5483, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2808.5725\n",
      "Epoch: 2470, Loss: 0.5449, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2809.7107\n",
      "Epoch: 2471, Loss: 0.5417, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2810.8421\n",
      "Epoch: 2472, Loss: 0.5376, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2811.9798\n",
      "Epoch: 2473, Loss: 0.5385, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 2813.1180\n",
      "Epoch: 2474, Loss: 0.5411, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2814.2546\n",
      "Epoch: 2475, Loss: 0.5362, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2815.3857\n",
      "Epoch: 2476, Loss: 0.5340, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2816.5212\n",
      "Epoch: 2477, Loss: 0.5377, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2817.6551\n",
      "Epoch: 2478, Loss: 0.5384, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2818.7916\n",
      "Epoch: 2479, Loss: 0.5396, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2819.9268\n",
      "Epoch: 2480, Loss: 0.5404, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2821.0585\n",
      "Epoch: 2481, Loss: 0.5408, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2822.1924\n",
      "Epoch: 2482, Loss: 0.5460, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2823.3307\n",
      "Epoch: 2483, Loss: 0.5518, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2824.4626\n",
      "Epoch: 2484, Loss: 0.5515, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2825.6031\n",
      "Epoch: 2485, Loss: 0.5566, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2826.7406\n",
      "Epoch: 2486, Loss: 0.5552, Train_Acc: 0.7500, TEST_Acc: 0.5967, Time: 2827.8793\n",
      "Epoch: 2487, Loss: 0.5526, Train_Acc: 0.7500, TEST_Acc: 0.5967, Time: 2829.0207\n",
      "Epoch: 2488, Loss: 0.5500, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2830.1648\n",
      "Epoch: 2489, Loss: 0.5440, Train_Acc: 0.7500, TEST_Acc: 0.6000, Time: 2831.3008\n",
      "Epoch: 2490, Loss: 0.5425, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2832.4328\n",
      "Epoch: 2491, Loss: 0.5451, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2833.5695\n",
      "Epoch: 2492, Loss: 0.5410, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2834.7039\n",
      "Epoch: 2493, Loss: 0.5357, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2835.8431\n",
      "Epoch: 2494, Loss: 0.5337, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2836.9737\n",
      "Epoch: 2495, Loss: 0.5360, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2838.1090\n",
      "Epoch: 2496, Loss: 0.5379, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2839.2448\n",
      "Epoch: 2497, Loss: 0.5764, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2840.3825\n",
      "Epoch: 2498, Loss: 0.5483, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2841.5164\n",
      "Epoch: 2499, Loss: 0.5517, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2842.6528\n",
      "Epoch: 2500, Loss: 37.9120, Train_Acc: 0.7308, TEST_Acc: 0.6033, Time: 2843.7892\n",
      "Epoch: 2501, Loss: 90.2987, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 2844.9238\n",
      "Epoch: 2502, Loss: 56.4671, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 2846.0556\n",
      "Epoch: 2503, Loss: 0.5519, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2847.1943\n",
      "Epoch: 2504, Loss: 0.5507, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2848.3393\n",
      "Epoch: 2505, Loss: 0.5485, Train_Acc: 0.7500, TEST_Acc: 0.6033, Time: 2849.4738\n",
      "Epoch: 2506, Loss: 0.5473, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2850.6072\n",
      "Epoch: 2507, Loss: 0.5498, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2851.7402\n",
      "Epoch: 2508, Loss: 0.5502, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2852.8763\n",
      "Epoch: 2509, Loss: 0.5520, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2854.0136\n",
      "Epoch: 2510, Loss: 0.5928, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 2855.1487\n",
      "Epoch: 2511, Loss: 0.5920, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2856.2830\n",
      "Epoch: 2512, Loss: 0.5527, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2857.4186\n",
      "Epoch: 2513, Loss: 0.5880, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 2858.5622\n",
      "Epoch: 2514, Loss: 0.5476, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2859.6962\n",
      "Epoch: 2515, Loss: 0.5527, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2860.8313\n",
      "Epoch: 2516, Loss: 0.5577, Train_Acc: 0.7500, TEST_Acc: 0.6133, Time: 2861.9716\n",
      "Epoch: 2517, Loss: 0.5955, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 2863.1046\n",
      "Epoch: 2518, Loss: 0.5895, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 2864.2391\n",
      "Epoch: 2519, Loss: 0.5861, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 2865.3726\n",
      "Epoch: 2520, Loss: 0.5904, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 2866.5111\n",
      "Epoch: 2521, Loss: 0.5933, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2867.6473\n",
      "Epoch: 2522, Loss: 0.5964, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 2868.7854\n",
      "Epoch: 2523, Loss: 0.5908, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 2869.9263\n",
      "Epoch: 2524, Loss: 0.5839, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 2871.0646\n",
      "Epoch: 2525, Loss: 0.5851, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 2872.1994\n",
      "Epoch: 2526, Loss: 0.5917, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 2873.3395\n",
      "Epoch: 2527, Loss: 0.5943, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 2874.4745\n",
      "Epoch: 2528, Loss: 0.5951, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2875.6099\n",
      "Epoch: 2529, Loss: 0.5992, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 2876.7438\n",
      "Epoch: 2530, Loss: 0.6465, Train_Acc: 0.7115, TEST_Acc: 0.6167, Time: 2877.8791\n",
      "Epoch: 2531, Loss: 0.6430, Train_Acc: 0.7115, TEST_Acc: 0.6167, Time: 2879.0179\n",
      "Epoch: 2532, Loss: 0.6447, Train_Acc: 0.7115, TEST_Acc: 0.6200, Time: 2880.1545\n",
      "Epoch: 2533, Loss: 0.6460, Train_Acc: 0.7115, TEST_Acc: 0.6167, Time: 2881.2891\n",
      "Epoch: 2534, Loss: 0.6020, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 2882.4223\n",
      "Epoch: 2535, Loss: 0.6027, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2883.5537\n",
      "Epoch: 2536, Loss: 0.6054, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2884.6965\n",
      "Epoch: 2537, Loss: 0.5602, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2885.8331\n",
      "Epoch: 2538, Loss: 0.5653, Train_Acc: 0.7500, TEST_Acc: 0.6100, Time: 2886.9666\n",
      "Epoch: 2539, Loss: 0.5634, Train_Acc: 0.7500, TEST_Acc: 0.6167, Time: 2888.1027\n",
      "Epoch: 2540, Loss: 0.5976, Train_Acc: 0.7308, TEST_Acc: 0.6167, Time: 2889.2424\n",
      "Epoch: 2541, Loss: 0.6027, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 2890.3923\n",
      "Epoch: 2542, Loss: 0.6449, Train_Acc: 0.7115, TEST_Acc: 0.6133, Time: 2891.5239\n",
      "Epoch: 2543, Loss: 0.6064, Train_Acc: 0.7308, TEST_Acc: 0.6200, Time: 2892.6598\n",
      "Epoch: 2544, Loss: 0.6102, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2893.7895\n",
      "Epoch: 2545, Loss: 0.6197, Train_Acc: 0.7308, TEST_Acc: 0.6100, Time: 2894.9243\n",
      "Epoch: 2546, Loss: 0.6229, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2896.0578\n",
      "Epoch: 2547, Loss: 0.6654, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2897.1916\n",
      "Epoch: 2548, Loss: 0.6679, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2898.3249\n",
      "Epoch: 2549, Loss: 0.6626, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2899.4634\n",
      "Epoch: 2550, Loss: 0.6204, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2900.5964\n",
      "Epoch: 2551, Loss: 0.5793, Train_Acc: 0.7500, TEST_Acc: 0.6067, Time: 2901.7419\n",
      "Epoch: 2552, Loss: 0.6193, Train_Acc: 0.7308, TEST_Acc: 0.6067, Time: 2902.8778\n",
      "Epoch: 2553, Loss: 0.6576, Train_Acc: 0.7115, TEST_Acc: 0.6100, Time: 2904.0142\n",
      "Epoch: 2554, Loss: 0.6165, Train_Acc: 0.7308, TEST_Acc: 0.6133, Time: 2905.1503\n",
      "Epoch: 2555, Loss: 0.6596, Train_Acc: 0.7115, TEST_Acc: 0.6200, Time: 2906.2823\n",
      "Epoch: 2556, Loss: 0.6587, Train_Acc: 0.7115, TEST_Acc: 0.6167, Time: 2907.4157\n",
      "Epoch: 2557, Loss: 0.6577, Train_Acc: 0.7115, TEST_Acc: 0.6167, Time: 2908.5522\n",
      "Epoch: 2558, Loss: 0.6523, Train_Acc: 0.7115, TEST_Acc: 0.6133, Time: 2909.6856\n",
      "Epoch: 2559, Loss: 0.6562, Train_Acc: 0.7115, TEST_Acc: 0.6100, Time: 2910.8241\n",
      "Epoch: 2560, Loss: 0.6631, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2911.9596\n",
      "Epoch: 2561, Loss: 0.7017, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 2913.0903\n",
      "Epoch: 2562, Loss: 0.6951, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 2914.2234\n",
      "Epoch: 2563, Loss: 0.6970, Train_Acc: 0.6923, TEST_Acc: 0.6100, Time: 2915.3704\n",
      "Epoch: 2564, Loss: 0.6946, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 2916.5066\n",
      "Epoch: 2565, Loss: 0.6549, Train_Acc: 0.7115, TEST_Acc: 0.6067, Time: 2917.6440\n",
      "Epoch: 2566, Loss: 0.6546, Train_Acc: 0.7115, TEST_Acc: 0.6033, Time: 2918.7784\n",
      "Epoch: 2567, Loss: 0.6957, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 2919.9193\n",
      "Epoch: 2568, Loss: 0.6120, Train_Acc: 0.7308, TEST_Acc: 0.5967, Time: 2921.0578\n",
      "Epoch: 2569, Loss: 0.6137, Train_Acc: 0.7308, TEST_Acc: 0.6000, Time: 2922.1930\n",
      "Epoch: 2570, Loss: 0.6463, Train_Acc: 0.7115, TEST_Acc: 0.5967, Time: 2923.3271\n",
      "Epoch: 2571, Loss: 0.6828, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 2924.4640\n",
      "Epoch: 2572, Loss: 0.6817, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 2925.5957\n",
      "Epoch: 2573, Loss: 0.6803, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 2926.7278\n",
      "Epoch: 2574, Loss: 0.6853, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 2927.8614\n",
      "Epoch: 2575, Loss: 0.6800, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 2928.9946\n",
      "Epoch: 2576, Loss: 0.6823, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 2930.1307\n",
      "Epoch: 2577, Loss: 0.6828, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 2931.2624\n",
      "Epoch: 2578, Loss: 0.6815, Train_Acc: 0.6923, TEST_Acc: 0.6133, Time: 2932.4020\n",
      "Epoch: 2579, Loss: 7.1088, Train_Acc: 0.7115, TEST_Acc: 0.6100, Time: 2933.5402\n",
      "Epoch: 2580, Loss: 0.6872, Train_Acc: 0.6923, TEST_Acc: 0.6100, Time: 2934.6818\n",
      "Epoch: 2581, Loss: 0.6842, Train_Acc: 0.6923, TEST_Acc: 0.6067, Time: 2935.8151\n",
      "Epoch: 2582, Loss: 0.6812, Train_Acc: 0.6923, TEST_Acc: 0.6100, Time: 2936.9456\n",
      "Epoch: 2583, Loss: 3.6023, Train_Acc: 0.6923, TEST_Acc: 0.6067, Time: 2938.0783\n",
      "Epoch: 2584, Loss: 0.6844, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 2939.2127\n",
      "Epoch: 2585, Loss: 1.6773, Train_Acc: 0.6923, TEST_Acc: 0.6067, Time: 2940.3457\n",
      "Epoch: 2586, Loss: 0.6783, Train_Acc: 0.6923, TEST_Acc: 0.6067, Time: 2941.4778\n",
      "Epoch: 2587, Loss: 0.6789, Train_Acc: 0.6923, TEST_Acc: 0.6100, Time: 2942.6081\n",
      "Epoch: 2588, Loss: 0.6874, Train_Acc: 0.6923, TEST_Acc: 0.6100, Time: 2943.7505\n",
      "Epoch: 2589, Loss: 0.6802, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 2944.8888\n",
      "Epoch: 2590, Loss: 0.6771, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 2946.0307\n",
      "Epoch: 2591, Loss: 0.6713, Train_Acc: 0.6923, TEST_Acc: 0.6067, Time: 2947.1662\n",
      "Epoch: 2592, Loss: 0.6723, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 2948.3034\n",
      "Epoch: 2593, Loss: 0.6743, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 2949.4397\n",
      "Epoch: 2594, Loss: 0.6751, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 2950.5847\n",
      "Epoch: 2595, Loss: 0.6729, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 2951.7226\n",
      "Epoch: 2596, Loss: 0.6771, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 2952.8561\n",
      "Epoch: 2597, Loss: 0.6765, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 2953.9905\n",
      "Epoch: 2598, Loss: 0.6789, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 2955.1262\n",
      "Epoch: 2599, Loss: 0.6774, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 2956.2608\n",
      "Epoch: 2600, Loss: 0.6756, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 2957.3951\n",
      "Epoch: 2601, Loss: 0.6801, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 2958.5300\n",
      "Epoch: 2602, Loss: 0.6806, Train_Acc: 0.6923, TEST_Acc: 0.5900, Time: 2959.6654\n",
      "Epoch: 2603, Loss: 0.6785, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 2960.8030\n",
      "Epoch: 2604, Loss: 0.6841, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 2961.9385\n",
      "Epoch: 2605, Loss: 0.6811, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 2963.0753\n",
      "Epoch: 2606, Loss: 0.6781, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 2964.2128\n",
      "Epoch: 2607, Loss: 0.6792, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 2965.3537\n",
      "Epoch: 2608, Loss: 0.6810, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 2966.4853\n",
      "Epoch: 2609, Loss: 0.6796, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 2967.6221\n",
      "Epoch: 2610, Loss: 0.6706, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 2968.7522\n",
      "Epoch: 2611, Loss: 0.6662, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 2969.8824\n",
      "Epoch: 2612, Loss: 0.6610, Train_Acc: 0.6923, TEST_Acc: 0.5900, Time: 2971.0140\n",
      "Epoch: 2613, Loss: 0.6634, Train_Acc: 0.6923, TEST_Acc: 0.5900, Time: 2972.1506\n",
      "Epoch: 2614, Loss: 0.6706, Train_Acc: 0.6923, TEST_Acc: 0.5867, Time: 2973.2818\n",
      "Epoch: 2615, Loss: 0.6726, Train_Acc: 0.6923, TEST_Acc: 0.5833, Time: 2974.4125\n",
      "Epoch: 2616, Loss: 0.6726, Train_Acc: 0.6923, TEST_Acc: 0.5800, Time: 2975.5535\n",
      "Epoch: 2617, Loss: 0.6816, Train_Acc: 0.6923, TEST_Acc: 0.5867, Time: 2976.6916\n",
      "Epoch: 2618, Loss: 0.6787, Train_Acc: 0.6923, TEST_Acc: 0.5867, Time: 2977.8277\n",
      "Epoch: 2619, Loss: 0.6771, Train_Acc: 0.6923, TEST_Acc: 0.5867, Time: 2978.9632\n",
      "Epoch: 2620, Loss: 0.6773, Train_Acc: 0.6923, TEST_Acc: 0.5867, Time: 2980.1025\n",
      "Epoch: 2621, Loss: 0.6776, Train_Acc: 0.6923, TEST_Acc: 0.5833, Time: 2981.2502\n",
      "Epoch: 2622, Loss: 0.6779, Train_Acc: 0.6923, TEST_Acc: 0.5867, Time: 2982.3791\n",
      "Epoch: 2623, Loss: 0.6759, Train_Acc: 0.6923, TEST_Acc: 0.5833, Time: 2983.5097\n",
      "Epoch: 2624, Loss: 0.6741, Train_Acc: 0.6923, TEST_Acc: 0.5833, Time: 2984.6408\n",
      "Epoch: 2625, Loss: 0.6692, Train_Acc: 0.6923, TEST_Acc: 0.5900, Time: 2985.7848\n",
      "Epoch: 2626, Loss: 0.6650, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 2986.9152\n",
      "Epoch: 2627, Loss: 0.6615, Train_Acc: 0.6923, TEST_Acc: 0.5800, Time: 2988.0494\n",
      "Epoch: 2628, Loss: 0.6620, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 2989.1801\n",
      "Epoch: 2629, Loss: 0.6571, Train_Acc: 0.6923, TEST_Acc: 0.5900, Time: 2990.3157\n",
      "Epoch: 2630, Loss: 0.6578, Train_Acc: 0.6923, TEST_Acc: 0.5900, Time: 2991.4508\n",
      "Epoch: 2631, Loss: 0.6582, Train_Acc: 0.6923, TEST_Acc: 0.5867, Time: 2992.5866\n",
      "Epoch: 2632, Loss: 0.6614, Train_Acc: 0.6923, TEST_Acc: 0.5867, Time: 2993.7259\n",
      "Epoch: 2633, Loss: 0.6644, Train_Acc: 0.6923, TEST_Acc: 0.5833, Time: 2994.8623\n",
      "Epoch: 2634, Loss: 0.6606, Train_Acc: 0.6923, TEST_Acc: 0.5833, Time: 2995.9990\n",
      "Epoch: 2635, Loss: 0.6671, Train_Acc: 0.6923, TEST_Acc: 0.5867, Time: 2997.1326\n",
      "Epoch: 2636, Loss: 0.6706, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 2998.2676\n",
      "Epoch: 2637, Loss: 0.6690, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 2999.4009\n",
      "Epoch: 2638, Loss: 0.6671, Train_Acc: 0.6923, TEST_Acc: 0.5900, Time: 3000.5345\n",
      "Epoch: 2639, Loss: 0.6613, Train_Acc: 0.6923, TEST_Acc: 0.5833, Time: 3001.6694\n",
      "Epoch: 2640, Loss: 0.6635, Train_Acc: 0.6923, TEST_Acc: 0.5867, Time: 3002.8037\n",
      "Epoch: 2641, Loss: 0.6633, Train_Acc: 0.6923, TEST_Acc: 0.5800, Time: 3003.9366\n",
      "Epoch: 2642, Loss: 0.6650, Train_Acc: 0.6923, TEST_Acc: 0.5767, Time: 3005.0723\n",
      "Epoch: 2643, Loss: 0.6653, Train_Acc: 0.6923, TEST_Acc: 0.5833, Time: 3006.2096\n",
      "Epoch: 2644, Loss: 0.6622, Train_Acc: 0.6923, TEST_Acc: 0.5867, Time: 3007.3475\n",
      "Epoch: 2645, Loss: 0.6551, Train_Acc: 0.6923, TEST_Acc: 0.5900, Time: 3008.4891\n",
      "Epoch: 2646, Loss: 0.6558, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 3009.6257\n",
      "Epoch: 2647, Loss: 0.6509, Train_Acc: 0.6923, TEST_Acc: 0.5900, Time: 3010.7710\n",
      "Epoch: 2648, Loss: 0.6453, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3011.9046\n",
      "Epoch: 2649, Loss: 0.6461, Train_Acc: 0.6923, TEST_Acc: 0.5900, Time: 3013.0348\n",
      "Epoch: 2650, Loss: 0.6444, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 3014.1696\n",
      "Epoch: 2651, Loss: 0.6448, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3015.3064\n",
      "Epoch: 2652, Loss: 0.6516, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3016.4460\n",
      "Epoch: 2653, Loss: 0.6527, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3017.5796\n",
      "Epoch: 2654, Loss: 0.6514, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 3018.7154\n",
      "Epoch: 2655, Loss: 0.6554, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 3019.8503\n",
      "Epoch: 2656, Loss: 0.6528, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 3020.9893\n",
      "Epoch: 2657, Loss: 0.6560, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 3022.1273\n",
      "Epoch: 2658, Loss: 0.6594, Train_Acc: 0.6923, TEST_Acc: 0.5900, Time: 3023.2624\n",
      "Epoch: 2659, Loss: 0.6593, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 3024.3986\n",
      "Epoch: 2660, Loss: 0.6563, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 3025.5361\n",
      "Epoch: 2661, Loss: 0.6551, Train_Acc: 0.6923, TEST_Acc: 0.5867, Time: 3026.6694\n",
      "Epoch: 2662, Loss: 0.6490, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 3027.8051\n",
      "Epoch: 2663, Loss: 0.6490, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 3028.9457\n",
      "Epoch: 2664, Loss: 0.6425, Train_Acc: 0.6923, TEST_Acc: 0.5900, Time: 3030.0803\n",
      "Epoch: 2665, Loss: 0.6397, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3031.2154\n",
      "Epoch: 2666, Loss: 0.6396, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3032.3526\n",
      "Epoch: 2667, Loss: 0.6481, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3033.4838\n",
      "Epoch: 2668, Loss: 0.6480, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3034.6207\n",
      "Epoch: 2669, Loss: 0.6482, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 3035.7615\n",
      "Epoch: 2670, Loss: 0.6498, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3036.8944\n",
      "Epoch: 2671, Loss: 0.6530, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3038.0363\n",
      "Epoch: 2672, Loss: 0.6517, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3039.1793\n",
      "Epoch: 2673, Loss: 0.6544, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3040.3154\n",
      "Epoch: 2674, Loss: 0.6541, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 3041.4568\n",
      "Epoch: 2675, Loss: 0.6557, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 3042.5943\n",
      "Epoch: 2676, Loss: 0.6515, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3043.7281\n",
      "Epoch: 2677, Loss: 0.6465, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3044.8612\n",
      "Epoch: 2678, Loss: 0.6466, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 3045.9984\n",
      "Epoch: 2679, Loss: 0.6416, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3047.1368\n",
      "Epoch: 2680, Loss: 0.6434, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 3048.2731\n",
      "Epoch: 2681, Loss: 0.6422, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 3049.4125\n",
      "Epoch: 2682, Loss: 0.6410, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3050.5451\n",
      "Epoch: 2683, Loss: 0.6317, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3051.6810\n",
      "Epoch: 2684, Loss: 0.6351, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 3052.8195\n",
      "Epoch: 2685, Loss: 0.6757, Train_Acc: 0.6731, TEST_Acc: 0.5933, Time: 3053.9559\n",
      "Epoch: 2686, Loss: 0.6388, Train_Acc: 0.6923, TEST_Acc: 0.5933, Time: 3055.0919\n",
      "Epoch: 2687, Loss: 0.6376, Train_Acc: 0.6923, TEST_Acc: 0.5900, Time: 3056.2291\n",
      "Epoch: 2688, Loss: 0.6746, Train_Acc: 0.6731, TEST_Acc: 0.5933, Time: 3057.3644\n",
      "Epoch: 2689, Loss: 0.6729, Train_Acc: 0.6731, TEST_Acc: 0.5967, Time: 3058.4992\n",
      "Epoch: 2690, Loss: 0.6419, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 3059.6306\n",
      "Epoch: 2691, Loss: 0.6375, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 3060.7699\n",
      "Epoch: 2692, Loss: 0.6377, Train_Acc: 0.6923, TEST_Acc: 0.5967, Time: 3061.9043\n",
      "Epoch: 2693, Loss: 0.6414, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 3063.0402\n",
      "Epoch: 2694, Loss: 0.6377, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 3064.1736\n",
      "Epoch: 2695, Loss: 0.6318, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 3065.3045\n",
      "Epoch: 2696, Loss: 0.6307, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 3066.4402\n",
      "Epoch: 2697, Loss: 0.6361, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 3067.5765\n",
      "Epoch: 2698, Loss: 0.6353, Train_Acc: 0.6923, TEST_Acc: 0.6067, Time: 3068.7161\n",
      "Epoch: 2699, Loss: 0.6450, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 3069.8514\n",
      "Epoch: 2700, Loss: 0.6472, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 3070.9950\n",
      "Epoch: 2701, Loss: 0.6531, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 3072.1384\n",
      "Epoch: 2702, Loss: 0.6548, Train_Acc: 0.6923, TEST_Acc: 0.6033, Time: 3073.2733\n",
      "Epoch: 2703, Loss: 0.6574, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 3074.4069\n",
      "Epoch: 2704, Loss: 0.6538, Train_Acc: 0.6923, TEST_Acc: 0.6000, Time: 3075.5394\n",
      "Epoch: 2705, Loss: 0.6869, Train_Acc: 0.6731, TEST_Acc: 0.6000, Time: 3076.6748\n",
      "Epoch: 2706, Loss: 0.6897, Train_Acc: 0.6731, TEST_Acc: 0.5967, Time: 3077.8099\n",
      "Epoch: 2707, Loss: 0.6967, Train_Acc: 0.6731, TEST_Acc: 0.5967, Time: 3078.9476\n",
      "Epoch: 2708, Loss: 0.6937, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3080.0808\n",
      "Epoch: 2709, Loss: 0.6514, Train_Acc: 0.6923, TEST_Acc: 0.6067, Time: 3081.2154\n",
      "Epoch: 2710, Loss: 0.6459, Train_Acc: 0.6923, TEST_Acc: 0.6100, Time: 3082.3566\n",
      "Epoch: 2711, Loss: 0.6510, Train_Acc: 0.6923, TEST_Acc: 0.6100, Time: 3083.4961\n",
      "Epoch: 2712, Loss: 0.6808, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3084.6347\n",
      "Epoch: 2713, Loss: 0.6762, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3085.7726\n",
      "Epoch: 2714, Loss: 13.1067, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3086.9103\n",
      "Epoch: 2715, Loss: 30.0303, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3088.0416\n",
      "Epoch: 2716, Loss: 22.7544, Train_Acc: 0.6731, TEST_Acc: 0.6000, Time: 3089.1762\n",
      "Epoch: 2717, Loss: 0.6714, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3090.3122\n",
      "Epoch: 2718, Loss: 0.6680, Train_Acc: 0.6731, TEST_Acc: 0.6000, Time: 3091.4450\n",
      "Epoch: 2719, Loss: 0.6690, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3092.5843\n",
      "Epoch: 2720, Loss: 0.6620, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3093.7107\n",
      "Epoch: 2721, Loss: 0.6618, Train_Acc: 0.6731, TEST_Acc: 0.5967, Time: 3094.8443\n",
      "Epoch: 2722, Loss: 0.6644, Train_Acc: 0.6731, TEST_Acc: 0.6000, Time: 3095.9786\n",
      "Epoch: 2723, Loss: 0.6664, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3097.1146\n",
      "Epoch: 2724, Loss: 0.6659, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3098.2521\n",
      "Epoch: 2725, Loss: 0.6624, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3099.3847\n",
      "Epoch: 2726, Loss: 0.6674, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3100.5235\n",
      "Epoch: 2727, Loss: 0.6706, Train_Acc: 0.6731, TEST_Acc: 0.6100, Time: 3101.6633\n",
      "Epoch: 2728, Loss: 0.6658, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3102.7997\n",
      "Epoch: 2729, Loss: 0.6717, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3103.9298\n",
      "Epoch: 2730, Loss: 0.6760, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3105.0638\n",
      "Epoch: 2731, Loss: 0.6733, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3106.1963\n",
      "Epoch: 2732, Loss: 0.6749, Train_Acc: 0.6731, TEST_Acc: 0.6000, Time: 3107.3297\n",
      "Epoch: 2733, Loss: 0.6778, Train_Acc: 0.6731, TEST_Acc: 0.5967, Time: 3108.4636\n",
      "Epoch: 2734, Loss: 0.6730, Train_Acc: 0.6731, TEST_Acc: 0.6100, Time: 3109.6027\n",
      "Epoch: 2735, Loss: 0.6780, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3110.7481\n",
      "Epoch: 2736, Loss: 0.6717, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3111.8848\n",
      "Epoch: 2737, Loss: 0.6702, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3113.0204\n",
      "Epoch: 2738, Loss: 0.6691, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3114.1622\n",
      "Epoch: 2739, Loss: 0.6703, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3115.2981\n",
      "Epoch: 2740, Loss: 0.6686, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3116.4352\n",
      "Epoch: 2741, Loss: 0.6672, Train_Acc: 0.6731, TEST_Acc: 0.6000, Time: 3117.5728\n",
      "Epoch: 2742, Loss: 0.6668, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3118.7064\n",
      "Epoch: 2743, Loss: 0.6675, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3119.8388\n",
      "Epoch: 2744, Loss: 0.6659, Train_Acc: 0.6731, TEST_Acc: 0.6100, Time: 3120.9731\n",
      "Epoch: 2745, Loss: 0.6676, Train_Acc: 0.6731, TEST_Acc: 0.6133, Time: 3122.1054\n",
      "Epoch: 2746, Loss: 0.6701, Train_Acc: 0.6731, TEST_Acc: 0.6100, Time: 3123.2379\n",
      "Epoch: 2747, Loss: 0.6649, Train_Acc: 0.6731, TEST_Acc: 0.6100, Time: 3124.3766\n",
      "Epoch: 2748, Loss: 0.6615, Train_Acc: 0.6731, TEST_Acc: 0.6100, Time: 3125.5088\n",
      "Epoch: 2749, Loss: 0.6616, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3126.6455\n",
      "Epoch: 2750, Loss: 0.6619, Train_Acc: 0.6731, TEST_Acc: 0.6100, Time: 3127.7820\n",
      "Epoch: 2751, Loss: 0.6608, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3128.9163\n",
      "Epoch: 2752, Loss: 0.6648, Train_Acc: 0.6731, TEST_Acc: 0.6100, Time: 3130.0510\n",
      "Epoch: 2753, Loss: 0.6640, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3131.1925\n",
      "Epoch: 2754, Loss: 0.6677, Train_Acc: 0.6731, TEST_Acc: 0.6000, Time: 3132.3349\n",
      "Epoch: 2755, Loss: 0.6678, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3133.4729\n",
      "Epoch: 2756, Loss: 0.6656, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3134.6058\n",
      "Epoch: 2757, Loss: 0.6682, Train_Acc: 0.6731, TEST_Acc: 0.6000, Time: 3135.7425\n",
      "Epoch: 2758, Loss: 0.6624, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3136.8734\n",
      "Epoch: 2759, Loss: 0.6663, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3138.0102\n",
      "Epoch: 2760, Loss: 0.6577, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3139.1404\n",
      "Epoch: 2761, Loss: 0.6554, Train_Acc: 0.6731, TEST_Acc: 0.6100, Time: 3140.2742\n",
      "Epoch: 2762, Loss: 0.6553, Train_Acc: 0.6731, TEST_Acc: 0.6100, Time: 3141.4101\n",
      "Epoch: 2763, Loss: 0.6852, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3142.5503\n",
      "Epoch: 2764, Loss: 0.6493, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3143.6877\n",
      "Epoch: 2765, Loss: 0.6518, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3144.8214\n",
      "Epoch: 2766, Loss: 0.6552, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3145.9635\n",
      "Epoch: 2767, Loss: 0.6525, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3147.1025\n",
      "Epoch: 2768, Loss: 0.6495, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3148.2354\n",
      "Epoch: 2769, Loss: 0.6526, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3149.3694\n",
      "Epoch: 2770, Loss: 0.6591, Train_Acc: 0.6731, TEST_Acc: 0.6100, Time: 3150.5070\n",
      "Epoch: 2771, Loss: 0.6596, Train_Acc: 0.6731, TEST_Acc: 0.6000, Time: 3151.6420\n",
      "Epoch: 2772, Loss: 0.6571, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3152.7735\n",
      "Epoch: 2773, Loss: 0.6619, Train_Acc: 0.6731, TEST_Acc: 0.5967, Time: 3153.9059\n",
      "Epoch: 2774, Loss: 0.6622, Train_Acc: 0.6731, TEST_Acc: 0.6033, Time: 3155.0417\n",
      "Epoch: 2775, Loss: 0.6640, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3156.1904\n",
      "Epoch: 2776, Loss: 0.6650, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3157.3272\n",
      "Epoch: 2777, Loss: 0.6581, Train_Acc: 0.6731, TEST_Acc: 0.6000, Time: 3158.4598\n",
      "Epoch: 2778, Loss: 0.6536, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3159.5974\n",
      "Epoch: 2779, Loss: 0.6611, Train_Acc: 0.6731, TEST_Acc: 0.6100, Time: 3160.7344\n",
      "Epoch: 2780, Loss: 0.6557, Train_Acc: 0.6731, TEST_Acc: 0.6100, Time: 3161.8738\n",
      "Epoch: 2781, Loss: 0.6548, Train_Acc: 0.6731, TEST_Acc: 0.6067, Time: 3163.0105\n",
      "Epoch: 2782, Loss: 0.6509, Train_Acc: 0.6731, TEST_Acc: 0.6100, Time: 3164.1471\n",
      "Epoch: 2783, Loss: 0.6871, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3165.2843\n",
      "Epoch: 2784, Loss: 0.6945, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3166.4162\n",
      "Epoch: 2785, Loss: 0.6950, Train_Acc: 0.6538, TEST_Acc: 0.5967, Time: 3167.5581\n",
      "Epoch: 2786, Loss: 0.6954, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3168.6907\n",
      "Epoch: 2787, Loss: 0.6929, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3169.8253\n",
      "Epoch: 2788, Loss: 0.6945, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3170.9636\n",
      "Epoch: 2789, Loss: 0.6577, Train_Acc: 0.6731, TEST_Acc: 0.6100, Time: 3172.1008\n",
      "Epoch: 2790, Loss: 0.6538, Train_Acc: 0.6731, TEST_Acc: 0.6000, Time: 3173.2332\n",
      "Epoch: 2791, Loss: 0.6932, Train_Acc: 0.6538, TEST_Acc: 0.5967, Time: 3174.3714\n",
      "Epoch: 2792, Loss: 0.6974, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3175.5076\n",
      "Epoch: 2793, Loss: 0.6906, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3176.6474\n",
      "Epoch: 2794, Loss: 0.6772, Train_Acc: 0.6538, TEST_Acc: 0.6000, Time: 3177.7813\n",
      "Epoch: 2795, Loss: 0.6662, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3178.9201\n",
      "Epoch: 2796, Loss: 0.6651, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3180.0570\n",
      "Epoch: 2797, Loss: 0.6656, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3181.1925\n",
      "Epoch: 2798, Loss: 0.6638, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3182.3261\n",
      "Epoch: 2799, Loss: 0.6642, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3183.4598\n",
      "Epoch: 2800, Loss: 0.6600, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3184.5936\n",
      "Epoch: 2801, Loss: 0.6582, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3185.7310\n",
      "Epoch: 2802, Loss: 0.6628, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3186.8699\n",
      "Epoch: 2803, Loss: 0.6634, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3188.0106\n",
      "Epoch: 2804, Loss: 0.6656, Train_Acc: 0.6538, TEST_Acc: 0.6000, Time: 3189.1472\n",
      "Epoch: 2805, Loss: 0.6678, Train_Acc: 0.6538, TEST_Acc: 0.6000, Time: 3190.2862\n",
      "Epoch: 2806, Loss: 0.6631, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3191.4233\n",
      "Epoch: 2807, Loss: 0.6649, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3192.5597\n",
      "Epoch: 2808, Loss: 0.6698, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3193.6928\n",
      "Epoch: 2809, Loss: 0.6668, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3194.8237\n",
      "Epoch: 2810, Loss: 0.6739, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3195.9571\n",
      "Epoch: 2811, Loss: 0.6797, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3197.0902\n",
      "Epoch: 2812, Loss: 0.6774, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3198.2200\n",
      "Epoch: 2813, Loss: 0.6771, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3199.3529\n",
      "Epoch: 2814, Loss: 0.6729, Train_Acc: 0.6538, TEST_Acc: 0.6167, Time: 3200.4906\n",
      "Epoch: 2815, Loss: 0.6755, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3201.6320\n",
      "Epoch: 2816, Loss: 0.6656, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3202.7709\n",
      "Epoch: 2817, Loss: 0.6734, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3203.9077\n",
      "Epoch: 2818, Loss: 0.6758, Train_Acc: 0.6538, TEST_Acc: 0.6200, Time: 3205.0416\n",
      "Epoch: 2819, Loss: 0.6704, Train_Acc: 0.6538, TEST_Acc: 0.5933, Time: 3206.1790\n",
      "Epoch: 2820, Loss: 0.6688, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3207.3138\n",
      "Epoch: 2821, Loss: 0.6737, Train_Acc: 0.6538, TEST_Acc: 0.5967, Time: 3208.4438\n",
      "Epoch: 2822, Loss: 0.6720, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3209.5866\n",
      "Epoch: 2823, Loss: 0.6653, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3210.7212\n",
      "Epoch: 2824, Loss: 0.6690, Train_Acc: 0.6538, TEST_Acc: 0.5933, Time: 3211.8582\n",
      "Epoch: 2825, Loss: 0.6671, Train_Acc: 0.6538, TEST_Acc: 0.5933, Time: 3212.9923\n",
      "Epoch: 2826, Loss: 0.6686, Train_Acc: 0.6538, TEST_Acc: 0.6000, Time: 3214.1282\n",
      "Epoch: 2827, Loss: 0.6725, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3215.2655\n",
      "Epoch: 2828, Loss: 0.6767, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3216.4010\n",
      "Epoch: 2829, Loss: 0.6776, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3217.5367\n",
      "Epoch: 2830, Loss: 0.6807, Train_Acc: 0.6538, TEST_Acc: 0.6000, Time: 3218.6785\n",
      "Epoch: 2831, Loss: 0.6754, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3219.8247\n",
      "Epoch: 2832, Loss: 0.6775, Train_Acc: 0.6538, TEST_Acc: 0.6000, Time: 3220.9618\n",
      "Epoch: 2833, Loss: 0.6723, Train_Acc: 0.6538, TEST_Acc: 0.5967, Time: 3222.0983\n",
      "Epoch: 2834, Loss: 0.6689, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3223.2332\n",
      "Epoch: 2835, Loss: 0.6654, Train_Acc: 0.6538, TEST_Acc: 0.5967, Time: 3224.3665\n",
      "Epoch: 2836, Loss: 0.6633, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3225.5032\n",
      "Epoch: 2837, Loss: 0.6606, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3226.6368\n",
      "Epoch: 2838, Loss: 0.6587, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3227.7690\n",
      "Epoch: 2839, Loss: 0.6536, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3228.9023\n",
      "Epoch: 2840, Loss: 0.6622, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3230.0371\n",
      "Epoch: 2841, Loss: 0.6671, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3231.1864\n",
      "Epoch: 2842, Loss: 0.6599, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3232.3222\n",
      "Epoch: 2843, Loss: 0.6540, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3233.4606\n",
      "Epoch: 2844, Loss: 0.6524, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3234.5978\n",
      "Epoch: 2845, Loss: 0.6496, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3235.7377\n",
      "Epoch: 2846, Loss: 0.6489, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3236.8765\n",
      "Epoch: 2847, Loss: 0.6482, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3238.0154\n",
      "Epoch: 2848, Loss: 0.6489, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3239.1481\n",
      "Epoch: 2849, Loss: 0.6464, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3240.2795\n",
      "Epoch: 2850, Loss: 0.6435, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3241.4166\n",
      "Epoch: 2851, Loss: 0.6398, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3242.5536\n",
      "Epoch: 2852, Loss: 0.6431, Train_Acc: 0.6538, TEST_Acc: 0.6167, Time: 3243.6893\n",
      "Epoch: 2853, Loss: 0.6444, Train_Acc: 0.6538, TEST_Acc: 0.6167, Time: 3244.8237\n",
      "Epoch: 2854, Loss: 0.6448, Train_Acc: 0.6538, TEST_Acc: 0.6200, Time: 3245.9599\n",
      "Epoch: 2855, Loss: 0.6475, Train_Acc: 0.6538, TEST_Acc: 0.6200, Time: 3247.0963\n",
      "Epoch: 2856, Loss: 0.6421, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3248.2327\n",
      "Epoch: 2857, Loss: 0.6444, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3249.3730\n",
      "Epoch: 2858, Loss: 0.6440, Train_Acc: 0.6538, TEST_Acc: 0.6000, Time: 3250.5229\n",
      "Epoch: 2859, Loss: 0.6405, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3251.6806\n",
      "Epoch: 2860, Loss: 0.6418, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3252.8335\n",
      "Epoch: 2861, Loss: 0.6450, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3253.9721\n",
      "Epoch: 2862, Loss: 0.6426, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3255.1104\n",
      "Epoch: 2863, Loss: 0.6456, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3256.2428\n",
      "Epoch: 2864, Loss: 0.6497, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3257.3721\n",
      "Epoch: 2865, Loss: 0.6477, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3258.5030\n",
      "Epoch: 2866, Loss: 0.6500, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3259.6382\n",
      "Epoch: 2867, Loss: 0.6469, Train_Acc: 0.6538, TEST_Acc: 0.6167, Time: 3260.7807\n",
      "Epoch: 2868, Loss: 0.6556, Train_Acc: 0.6538, TEST_Acc: 0.6200, Time: 3261.9153\n",
      "Epoch: 2869, Loss: 0.6537, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3263.0521\n",
      "Epoch: 2870, Loss: 0.6528, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3264.1903\n",
      "Epoch: 2871, Loss: 0.6537, Train_Acc: 0.6538, TEST_Acc: 0.6167, Time: 3265.3201\n",
      "Epoch: 2872, Loss: 0.6522, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3266.4544\n",
      "Epoch: 2873, Loss: 0.6509, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3267.5937\n",
      "Epoch: 2874, Loss: 0.6470, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3268.7308\n",
      "Epoch: 2875, Loss: 0.6473, Train_Acc: 0.6538, TEST_Acc: 0.6000, Time: 3269.8623\n",
      "Epoch: 2876, Loss: 0.6471, Train_Acc: 0.6538, TEST_Acc: 0.6200, Time: 3270.9968\n",
      "Epoch: 2877, Loss: 0.6468, Train_Acc: 0.6538, TEST_Acc: 0.6233, Time: 3272.1367\n",
      "Epoch: 2878, Loss: 18.1521, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3273.2784\n",
      "Epoch: 2879, Loss: 0.6412, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3274.4145\n",
      "Epoch: 2880, Loss: 0.6457, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3275.5467\n",
      "Epoch: 2881, Loss: 0.6489, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3276.6899\n",
      "Epoch: 2882, Loss: 0.6423, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3277.8245\n",
      "Epoch: 2883, Loss: 0.6514, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3278.9594\n",
      "Epoch: 2884, Loss: 0.6611, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3280.0971\n",
      "Epoch: 2885, Loss: 0.6576, Train_Acc: 0.6538, TEST_Acc: 0.6167, Time: 3281.2352\n",
      "Epoch: 2886, Loss: 0.6588, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3282.3735\n",
      "Epoch: 2887, Loss: 0.6597, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3283.5165\n",
      "Epoch: 2888, Loss: 0.6575, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3284.6496\n",
      "Epoch: 2889, Loss: 0.6547, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3285.7858\n",
      "Epoch: 2890, Loss: 0.6529, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3286.9186\n",
      "Epoch: 2891, Loss: 0.6530, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3288.0542\n",
      "Epoch: 2892, Loss: 0.6488, Train_Acc: 0.6538, TEST_Acc: 0.6133, Time: 3289.1921\n",
      "Epoch: 2893, Loss: 0.6463, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3290.3292\n",
      "Epoch: 2894, Loss: 0.6394, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3291.4633\n",
      "Epoch: 2895, Loss: 0.6415, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3292.6066\n",
      "Epoch: 2896, Loss: 0.6414, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3293.7384\n",
      "Epoch: 2897, Loss: 0.6422, Train_Acc: 0.6538, TEST_Acc: 0.5967, Time: 3294.8748\n",
      "Epoch: 2898, Loss: 0.6718, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3296.0121\n",
      "Epoch: 2899, Loss: 0.6703, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3297.1488\n",
      "Epoch: 2900, Loss: 0.6700, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3298.2840\n",
      "Epoch: 2901, Loss: 0.6409, Train_Acc: 0.6538, TEST_Acc: 0.6067, Time: 3299.4181\n",
      "Epoch: 2902, Loss: 0.6348, Train_Acc: 0.6538, TEST_Acc: 0.6100, Time: 3300.5526\n",
      "Epoch: 2903, Loss: 0.6633, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3301.6866\n",
      "Epoch: 2904, Loss: 0.6591, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3302.8222\n",
      "Epoch: 2905, Loss: 0.6600, Train_Acc: 0.6346, TEST_Acc: 0.6167, Time: 3303.9537\n",
      "Epoch: 2906, Loss: 0.6598, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3305.0918\n",
      "Epoch: 2907, Loss: 0.6538, Train_Acc: 0.6346, TEST_Acc: 0.6167, Time: 3306.2261\n",
      "Epoch: 2908, Loss: 0.6545, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3307.3616\n",
      "Epoch: 2909, Loss: 0.6617, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3308.4946\n",
      "Epoch: 2910, Loss: 0.6663, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3309.6322\n",
      "Epoch: 2911, Loss: 0.6615, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3310.7686\n",
      "Epoch: 2912, Loss: 0.6539, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3311.9063\n",
      "Epoch: 2913, Loss: 0.6564, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3313.0442\n",
      "Epoch: 2914, Loss: 0.6590, Train_Acc: 0.6346, TEST_Acc: 0.6167, Time: 3314.1809\n",
      "Epoch: 2915, Loss: 0.6581, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3315.3180\n",
      "Epoch: 2916, Loss: 0.6510, Train_Acc: 0.6346, TEST_Acc: 0.6233, Time: 3316.4557\n",
      "Epoch: 2917, Loss: 0.6572, Train_Acc: 0.6346, TEST_Acc: 0.6200, Time: 3317.5892\n",
      "Epoch: 2918, Loss: 0.6570, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3318.7255\n",
      "Epoch: 2919, Loss: 0.6546, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3319.8608\n",
      "Epoch: 2920, Loss: 0.6557, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3320.9976\n",
      "Epoch: 2921, Loss: 0.6504, Train_Acc: 0.6346, TEST_Acc: 0.6000, Time: 3322.1331\n",
      "Epoch: 2922, Loss: 0.6471, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3323.2664\n",
      "Epoch: 2923, Loss: 0.6499, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3324.4020\n",
      "Epoch: 2924, Loss: 0.6539, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3325.5450\n",
      "Epoch: 2925, Loss: 0.6533, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3326.6826\n",
      "Epoch: 2926, Loss: 0.6803, Train_Acc: 0.6154, TEST_Acc: 0.6000, Time: 3327.8212\n",
      "Epoch: 2927, Loss: 0.6476, Train_Acc: 0.6346, TEST_Acc: 0.5967, Time: 3328.9564\n",
      "Epoch: 2928, Loss: 0.6784, Train_Acc: 0.6154, TEST_Acc: 0.6000, Time: 3330.0939\n",
      "Epoch: 2929, Loss: 0.6737, Train_Acc: 0.6154, TEST_Acc: 0.6000, Time: 3331.2310\n",
      "Epoch: 2930, Loss: 0.6685, Train_Acc: 0.6154, TEST_Acc: 0.6000, Time: 3332.3632\n",
      "Epoch: 2931, Loss: 0.6435, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3333.4952\n",
      "Epoch: 2932, Loss: 0.6696, Train_Acc: 0.6154, TEST_Acc: 0.6067, Time: 3334.6278\n",
      "Epoch: 2933, Loss: 0.6733, Train_Acc: 0.6154, TEST_Acc: 0.6000, Time: 3335.7612\n",
      "Epoch: 2934, Loss: 0.6681, Train_Acc: 0.6154, TEST_Acc: 0.5933, Time: 3336.8942\n",
      "Epoch: 2935, Loss: 0.6415, Train_Acc: 0.6346, TEST_Acc: 0.5967, Time: 3338.0322\n",
      "Epoch: 2936, Loss: 0.6413, Train_Acc: 0.6346, TEST_Acc: 0.5933, Time: 3339.1656\n",
      "Epoch: 2937, Loss: 0.6427, Train_Acc: 0.6346, TEST_Acc: 0.5967, Time: 3340.3007\n",
      "Epoch: 2938, Loss: 0.6383, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3341.4390\n",
      "Epoch: 2939, Loss: 0.6402, Train_Acc: 0.6346, TEST_Acc: 0.5967, Time: 3342.5781\n",
      "Epoch: 2940, Loss: 0.6394, Train_Acc: 0.6346, TEST_Acc: 0.6000, Time: 3343.7193\n",
      "Epoch: 2941, Loss: 0.6383, Train_Acc: 0.6346, TEST_Acc: 0.5967, Time: 3344.8533\n",
      "Epoch: 2942, Loss: 0.6099, Train_Acc: 0.6538, TEST_Acc: 0.5967, Time: 3345.9939\n",
      "Epoch: 2943, Loss: 0.6302, Train_Acc: 0.6346, TEST_Acc: 0.6000, Time: 3347.1287\n",
      "Epoch: 2944, Loss: 0.6292, Train_Acc: 0.6346, TEST_Acc: 0.6000, Time: 3348.2616\n",
      "Epoch: 2945, Loss: 0.6547, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3349.3954\n",
      "Epoch: 2946, Loss: 0.6611, Train_Acc: 0.6154, TEST_Acc: 0.6067, Time: 3350.5277\n",
      "Epoch: 2947, Loss: 0.6626, Train_Acc: 0.6154, TEST_Acc: 0.6033, Time: 3351.6651\n",
      "Epoch: 2948, Loss: 0.6626, Train_Acc: 0.6154, TEST_Acc: 0.6067, Time: 3352.8061\n",
      "Epoch: 2949, Loss: 0.6294, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3353.9444\n",
      "Epoch: 2950, Loss: 0.6544, Train_Acc: 0.6154, TEST_Acc: 0.6033, Time: 3355.0816\n",
      "Epoch: 2951, Loss: 0.6303, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3356.2200\n",
      "Epoch: 2952, Loss: 0.6268, Train_Acc: 0.6346, TEST_Acc: 0.5933, Time: 3357.3658\n",
      "Epoch: 2953, Loss: 0.5955, Train_Acc: 0.6538, TEST_Acc: 0.5967, Time: 3358.5028\n",
      "Epoch: 2954, Loss: 0.5972, Train_Acc: 0.6538, TEST_Acc: 0.6033, Time: 3359.6419\n",
      "Epoch: 2955, Loss: 0.6236, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3360.7772\n",
      "Epoch: 2956, Loss: 0.6264, Train_Acc: 0.6346, TEST_Acc: 0.6000, Time: 3361.9091\n",
      "Epoch: 2957, Loss: 0.6541, Train_Acc: 0.6154, TEST_Acc: 0.6067, Time: 3363.0446\n",
      "Epoch: 2958, Loss: 0.6345, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3364.1832\n",
      "Epoch: 2959, Loss: 0.6347, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3365.3152\n",
      "Epoch: 2960, Loss: 0.6330, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3366.4436\n",
      "Epoch: 2961, Loss: 0.6254, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3367.5745\n",
      "Epoch: 2962, Loss: 0.6296, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3368.7088\n",
      "Epoch: 2963, Loss: 0.6331, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3369.8390\n",
      "Epoch: 2964, Loss: 0.6311, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3370.9737\n",
      "Epoch: 2965, Loss: 0.6353, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3372.1126\n",
      "Epoch: 2966, Loss: 0.6370, Train_Acc: 0.6346, TEST_Acc: 0.6000, Time: 3373.2553\n",
      "Epoch: 2967, Loss: 0.6389, Train_Acc: 0.6346, TEST_Acc: 0.6000, Time: 3374.3943\n",
      "Epoch: 2968, Loss: 0.6436, Train_Acc: 0.6346, TEST_Acc: 0.6000, Time: 3375.5316\n",
      "Epoch: 2969, Loss: 0.6458, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3376.6686\n",
      "Epoch: 2970, Loss: 0.6458, Train_Acc: 0.6346, TEST_Acc: 0.5967, Time: 3377.7983\n",
      "Epoch: 2971, Loss: 0.6458, Train_Acc: 0.6346, TEST_Acc: 0.6000, Time: 3378.9399\n",
      "Epoch: 2972, Loss: 0.6515, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3380.0728\n",
      "Epoch: 2973, Loss: 0.6465, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3381.2095\n",
      "Epoch: 2974, Loss: 0.6454, Train_Acc: 0.6346, TEST_Acc: 0.6000, Time: 3382.3460\n",
      "Epoch: 2975, Loss: 0.6438, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3383.4783\n",
      "Epoch: 2976, Loss: 0.6441, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3384.6127\n",
      "Epoch: 2977, Loss: 0.6481, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3385.7455\n",
      "Epoch: 2978, Loss: 0.6510, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3386.8891\n",
      "Epoch: 2979, Loss: 0.6492, Train_Acc: 0.6346, TEST_Acc: 0.6167, Time: 3388.0271\n",
      "Epoch: 2980, Loss: 0.6509, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3389.1668\n",
      "Epoch: 2981, Loss: 0.6487, Train_Acc: 0.6346, TEST_Acc: 0.6000, Time: 3390.3121\n",
      "Epoch: 2982, Loss: 0.6519, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3391.4464\n",
      "Epoch: 2983, Loss: 0.6549, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3392.5810\n",
      "Epoch: 2984, Loss: 0.6557, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3393.7287\n",
      "Epoch: 2985, Loss: 0.6472, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3394.8609\n",
      "Epoch: 2986, Loss: 0.6484, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3395.9980\n",
      "Epoch: 2987, Loss: 0.6540, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3397.1398\n",
      "Epoch: 2988, Loss: 0.6561, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3398.2767\n",
      "Epoch: 2989, Loss: 0.6633, Train_Acc: 0.6346, TEST_Acc: 0.6000, Time: 3399.4120\n",
      "Epoch: 2990, Loss: 0.6641, Train_Acc: 0.6346, TEST_Acc: 0.6000, Time: 3400.5442\n",
      "Epoch: 2991, Loss: 0.6613, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3401.6799\n",
      "Epoch: 2992, Loss: 0.6651, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3402.8172\n",
      "Epoch: 2993, Loss: 0.6616, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3403.9621\n",
      "Epoch: 2994, Loss: 0.6634, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3405.1018\n",
      "Epoch: 2995, Loss: 0.6563, Train_Acc: 0.6346, TEST_Acc: 0.6000, Time: 3406.2363\n",
      "Epoch: 2996, Loss: 0.6573, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3407.3723\n",
      "Epoch: 2997, Loss: 0.6600, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3408.5066\n",
      "Epoch: 2998, Loss: 0.6616, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3409.6428\n",
      "Epoch: 2999, Loss: 0.6590, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3410.7832\n",
      "Epoch: 3000, Loss: 0.6546, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3411.9188\n",
      "Epoch: 3001, Loss: 0.6551, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3413.0574\n",
      "Epoch: 3002, Loss: 0.6622, Train_Acc: 0.6346, TEST_Acc: 0.6033, Time: 3414.1956\n",
      "Epoch: 3003, Loss: 0.6645, Train_Acc: 0.6346, TEST_Acc: 0.6000, Time: 3415.3313\n",
      "Epoch: 3004, Loss: 0.6963, Train_Acc: 0.6154, TEST_Acc: 0.6000, Time: 3416.4680\n",
      "Epoch: 3005, Loss: 0.6695, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3417.6031\n",
      "Epoch: 3006, Loss: 0.6685, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3418.7417\n",
      "Epoch: 3007, Loss: 0.6727, Train_Acc: 0.6346, TEST_Acc: 0.6167, Time: 3419.8772\n",
      "Epoch: 3008, Loss: 0.6680, Train_Acc: 0.6346, TEST_Acc: 0.6233, Time: 3421.0225\n",
      "Epoch: 3009, Loss: 0.6668, Train_Acc: 0.6346, TEST_Acc: 0.6200, Time: 3422.1627\n",
      "Epoch: 3010, Loss: 0.6731, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3423.2988\n",
      "Epoch: 3011, Loss: 0.6661, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3424.4380\n",
      "Epoch: 3012, Loss: 0.6584, Train_Acc: 0.6346, TEST_Acc: 0.6233, Time: 3425.5712\n",
      "Epoch: 3013, Loss: 0.6613, Train_Acc: 0.6346, TEST_Acc: 0.6200, Time: 3426.7056\n",
      "Epoch: 3014, Loss: 0.6860, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3427.8367\n",
      "Epoch: 3015, Loss: 0.6841, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 3428.9708\n",
      "Epoch: 3016, Loss: 0.6787, Train_Acc: 0.6154, TEST_Acc: 0.6200, Time: 3430.1072\n",
      "Epoch: 3017, Loss: 0.6814, Train_Acc: 0.6154, TEST_Acc: 0.6233, Time: 3431.2346\n",
      "Epoch: 3018, Loss: 0.6454, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3432.3713\n",
      "Epoch: 3019, Loss: 0.6415, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3433.5080\n",
      "Epoch: 3020, Loss: 0.6460, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3434.6542\n",
      "Epoch: 3021, Loss: 0.6472, Train_Acc: 0.6346, TEST_Acc: 0.6167, Time: 3435.7864\n",
      "Epoch: 3022, Loss: 0.6482, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3436.9304\n",
      "Epoch: 3023, Loss: 0.6782, Train_Acc: 0.6154, TEST_Acc: 0.6067, Time: 3438.0669\n",
      "Epoch: 3024, Loss: 0.6384, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3439.2030\n",
      "Epoch: 3025, Loss: 0.6410, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3440.3346\n",
      "Epoch: 3026, Loss: 0.6669, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3441.4723\n",
      "Epoch: 3027, Loss: 0.6406, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3442.6151\n",
      "Epoch: 3028, Loss: 0.6351, Train_Acc: 0.6346, TEST_Acc: 0.6067, Time: 3443.7461\n",
      "Epoch: 3029, Loss: 0.6305, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3444.8838\n",
      "Epoch: 3030, Loss: 0.6279, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3446.0166\n",
      "Epoch: 3031, Loss: 0.6347, Train_Acc: 0.6346, TEST_Acc: 0.6167, Time: 3447.1549\n",
      "Epoch: 3032, Loss: 0.6395, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3448.2905\n",
      "Epoch: 3033, Loss: 0.6739, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3449.4272\n",
      "Epoch: 3034, Loss: 0.6766, Train_Acc: 0.6154, TEST_Acc: 0.6067, Time: 3450.5635\n",
      "Epoch: 3035, Loss: 0.6741, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3451.7045\n",
      "Epoch: 3036, Loss: 0.6742, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3452.8462\n",
      "Epoch: 3037, Loss: 0.6606, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 3453.9802\n",
      "Epoch: 3038, Loss: 0.6665, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 3455.1154\n",
      "Epoch: 3039, Loss: 0.6700, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3456.2501\n",
      "Epoch: 3040, Loss: 0.6738, Train_Acc: 0.6154, TEST_Acc: 0.6200, Time: 3457.3835\n",
      "Epoch: 3041, Loss: 0.6709, Train_Acc: 0.6154, TEST_Acc: 0.6200, Time: 3458.5182\n",
      "Epoch: 3042, Loss: 0.6723, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3459.6535\n",
      "Epoch: 3043, Loss: 0.6801, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3460.7903\n",
      "Epoch: 3044, Loss: 0.6763, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3461.9252\n",
      "Epoch: 3045, Loss: 0.6807, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 3463.0624\n",
      "Epoch: 3046, Loss: 0.6848, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3464.2088\n",
      "Epoch: 3047, Loss: 0.6758, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3465.3491\n",
      "Epoch: 3048, Loss: 0.6776, Train_Acc: 0.6154, TEST_Acc: 0.6067, Time: 3466.4857\n",
      "Epoch: 3049, Loss: 0.6753, Train_Acc: 0.6154, TEST_Acc: 0.6033, Time: 3467.6208\n",
      "Epoch: 3050, Loss: 0.6688, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3468.7515\n",
      "Epoch: 3051, Loss: 0.6651, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3469.8851\n",
      "Epoch: 3052, Loss: 0.6666, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3471.0206\n",
      "Epoch: 3053, Loss: 0.6654, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3472.1536\n",
      "Epoch: 3054, Loss: 0.6588, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3473.2855\n",
      "Epoch: 3055, Loss: 0.6550, Train_Acc: 0.6154, TEST_Acc: 0.6200, Time: 3474.4282\n",
      "Epoch: 3056, Loss: 0.6555, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 3475.5676\n",
      "Epoch: 3057, Loss: 0.6530, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3476.7033\n",
      "Epoch: 3058, Loss: 0.6264, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3477.8412\n",
      "Epoch: 3059, Loss: 0.6200, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3478.9782\n",
      "Epoch: 3060, Loss: 0.6432, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3480.1136\n",
      "Epoch: 3061, Loss: 0.6418, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3481.2537\n",
      "Epoch: 3062, Loss: 0.6472, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3482.3924\n",
      "Epoch: 3063, Loss: 0.6499, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3483.5250\n",
      "Epoch: 3064, Loss: 0.6535, Train_Acc: 0.6154, TEST_Acc: 0.6067, Time: 3484.6624\n",
      "Epoch: 3065, Loss: 0.6571, Train_Acc: 0.6154, TEST_Acc: 0.6033, Time: 3485.7993\n",
      "Epoch: 3066, Loss: 0.6600, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3486.9308\n",
      "Epoch: 3067, Loss: 0.6646, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3488.0670\n",
      "Epoch: 3068, Loss: 0.6611, Train_Acc: 0.6154, TEST_Acc: 0.6200, Time: 3489.2022\n",
      "Epoch: 3069, Loss: 0.6657, Train_Acc: 0.6154, TEST_Acc: 0.6200, Time: 3490.3372\n",
      "Epoch: 3070, Loss: 0.6281, Train_Acc: 0.6346, TEST_Acc: 0.6267, Time: 3491.4729\n",
      "Epoch: 3071, Loss: 0.6300, Train_Acc: 0.6346, TEST_Acc: 0.6267, Time: 3492.6047\n",
      "Epoch: 3072, Loss: 0.6341, Train_Acc: 0.6346, TEST_Acc: 0.6233, Time: 3493.7428\n",
      "Epoch: 3073, Loss: 0.6327, Train_Acc: 0.6346, TEST_Acc: 0.6200, Time: 3494.8917\n",
      "Epoch: 3074, Loss: 0.6373, Train_Acc: 0.6346, TEST_Acc: 0.6233, Time: 3496.0288\n",
      "Epoch: 3075, Loss: 0.6705, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3497.1670\n",
      "Epoch: 3076, Loss: 0.6459, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3498.3071\n",
      "Epoch: 3077, Loss: 0.6473, Train_Acc: 0.6346, TEST_Acc: 0.6100, Time: 3499.4460\n",
      "Epoch: 3078, Loss: 0.6439, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3500.5772\n",
      "Epoch: 3079, Loss: 0.6654, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3501.7087\n",
      "Epoch: 3080, Loss: 0.6659, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 3502.8442\n",
      "Epoch: 3081, Loss: 0.6748, Train_Acc: 0.6154, TEST_Acc: 0.6200, Time: 3503.9754\n",
      "Epoch: 3082, Loss: 0.6740, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3505.1053\n",
      "Epoch: 3083, Loss: 0.6742, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3506.2449\n",
      "Epoch: 3084, Loss: 0.6744, Train_Acc: 0.6154, TEST_Acc: 0.6067, Time: 3507.3772\n",
      "Epoch: 3085, Loss: 0.6712, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3508.5127\n",
      "Epoch: 3086, Loss: 0.6686, Train_Acc: 0.6154, TEST_Acc: 0.6067, Time: 3509.6519\n",
      "Epoch: 3087, Loss: 0.6631, Train_Acc: 0.6154, TEST_Acc: 0.6067, Time: 3510.7888\n",
      "Epoch: 3088, Loss: 0.6656, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3511.9266\n",
      "Epoch: 3089, Loss: 0.6661, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3513.0665\n",
      "Epoch: 3090, Loss: 0.6694, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 3514.2045\n",
      "Epoch: 3091, Loss: 0.6780, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 3515.3388\n",
      "Epoch: 3092, Loss: 0.6734, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 3516.4858\n",
      "Epoch: 3093, Loss: 0.6684, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3517.6190\n",
      "Epoch: 3094, Loss: 0.6721, Train_Acc: 0.6154, TEST_Acc: 0.6067, Time: 3518.7559\n",
      "Epoch: 3095, Loss: 0.6656, Train_Acc: 0.6154, TEST_Acc: 0.6067, Time: 3519.8888\n",
      "Epoch: 3096, Loss: 0.6402, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3521.0254\n",
      "Epoch: 3097, Loss: 0.6631, Train_Acc: 0.6154, TEST_Acc: 0.6200, Time: 3522.1582\n",
      "Epoch: 3098, Loss: 0.6312, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3523.2929\n",
      "Epoch: 3099, Loss: 0.6287, Train_Acc: 0.6346, TEST_Acc: 0.6200, Time: 3524.4319\n",
      "Epoch: 3100, Loss: 0.6321, Train_Acc: 0.6346, TEST_Acc: 0.6200, Time: 3525.5750\n",
      "Epoch: 3101, Loss: 0.6355, Train_Acc: 0.6346, TEST_Acc: 0.6167, Time: 3526.7193\n",
      "Epoch: 3102, Loss: 0.6346, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3527.8558\n",
      "Epoch: 3103, Loss: 0.6340, Train_Acc: 0.6346, TEST_Acc: 0.6233, Time: 3528.9941\n",
      "Epoch: 3104, Loss: 0.6609, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3530.1301\n",
      "Epoch: 3105, Loss: 0.6608, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 3531.2650\n",
      "Epoch: 3106, Loss: 0.6556, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3532.3961\n",
      "Epoch: 3107, Loss: 0.6550, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3533.5332\n",
      "Epoch: 3108, Loss: 0.6597, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3534.6660\n",
      "Epoch: 3109, Loss: 0.6611, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3535.8003\n",
      "Epoch: 3110, Loss: 0.6661, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3536.9343\n",
      "Epoch: 3111, Loss: 0.6737, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3538.0645\n",
      "Epoch: 3112, Loss: 0.6725, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3539.1991\n",
      "Epoch: 3113, Loss: 0.6662, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 3540.3384\n",
      "Epoch: 3114, Loss: 0.6642, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3541.4753\n",
      "Epoch: 3115, Loss: 0.6669, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 3542.6144\n",
      "Epoch: 3116, Loss: 0.6665, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3543.7535\n",
      "Epoch: 3117, Loss: 0.6704, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 3544.8904\n",
      "Epoch: 3118, Loss: 0.6767, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3546.0235\n",
      "Epoch: 3119, Loss: 0.6739, Train_Acc: 0.6154, TEST_Acc: 0.6067, Time: 3547.1620\n",
      "Epoch: 3120, Loss: 0.6740, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3548.2965\n",
      "Epoch: 3121, Loss: 0.6744, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3549.4336\n",
      "Epoch: 3122, Loss: 0.6488, Train_Acc: 0.6346, TEST_Acc: 0.6133, Time: 3550.5679\n",
      "Epoch: 3123, Loss: 0.6445, Train_Acc: 0.6346, TEST_Acc: 0.6200, Time: 3551.6993\n",
      "Epoch: 3124, Loss: 0.6401, Train_Acc: 0.6346, TEST_Acc: 0.6233, Time: 3552.8342\n",
      "Epoch: 3125, Loss: 0.6678, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3553.9716\n",
      "Epoch: 3126, Loss: 0.6695, Train_Acc: 0.6154, TEST_Acc: 0.6300, Time: 3555.1142\n",
      "Epoch: 3127, Loss: 0.6692, Train_Acc: 0.6154, TEST_Acc: 0.6233, Time: 3556.2639\n",
      "Epoch: 3128, Loss: 0.6703, Train_Acc: 0.6154, TEST_Acc: 0.6233, Time: 3557.4220\n",
      "Epoch: 3129, Loss: 0.6419, Train_Acc: 0.6346, TEST_Acc: 0.6200, Time: 3558.5875\n",
      "Epoch: 3130, Loss: 0.6450, Train_Acc: 0.6346, TEST_Acc: 0.6167, Time: 3559.7516\n",
      "Epoch: 3131, Loss: 0.6730, Train_Acc: 0.6154, TEST_Acc: 0.6200, Time: 3560.9111\n",
      "Epoch: 3132, Loss: 0.6624, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 3562.0495\n",
      "Epoch: 3133, Loss: 0.6642, Train_Acc: 0.6154, TEST_Acc: 0.6200, Time: 3563.1847\n",
      "Epoch: 3134, Loss: 0.6374, Train_Acc: 0.6346, TEST_Acc: 0.6200, Time: 3564.3185\n",
      "Epoch: 3135, Loss: 0.6428, Train_Acc: 0.6346, TEST_Acc: 0.6200, Time: 3565.4513\n",
      "Epoch: 3136, Loss: 0.6466, Train_Acc: 0.6346, TEST_Acc: 0.6233, Time: 3566.5831\n",
      "Epoch: 3137, Loss: 0.6421, Train_Acc: 0.6346, TEST_Acc: 0.6233, Time: 3567.7213\n",
      "Epoch: 3138, Loss: 0.6680, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3568.8560\n",
      "Epoch: 3139, Loss: 0.6660, Train_Acc: 0.6154, TEST_Acc: 0.6100, Time: 3569.9867\n",
      "Epoch: 3140, Loss: 0.6660, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3571.1213\n",
      "Epoch: 3141, Loss: 0.6626, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 3572.2573\n",
      "Epoch: 3142, Loss: 0.6595, Train_Acc: 0.6154, TEST_Acc: 0.6233, Time: 3573.3923\n",
      "Epoch: 3143, Loss: 0.6570, Train_Acc: 0.6154, TEST_Acc: 0.6233, Time: 3574.5371\n",
      "Epoch: 3144, Loss: 0.6633, Train_Acc: 0.6154, TEST_Acc: 0.6133, Time: 3575.6775\n",
      "Epoch: 3145, Loss: 0.6717, Train_Acc: 0.6154, TEST_Acc: 0.6200, Time: 3576.8052\n",
      "Epoch: 3146, Loss: 0.6658, Train_Acc: 0.6154, TEST_Acc: 0.6233, Time: 3577.9427\n",
      "Epoch: 3147, Loss: 0.6663, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3579.0814\n",
      "Epoch: 3148, Loss: 0.6666, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3580.2160\n",
      "Epoch: 3149, Loss: 0.6669, Train_Acc: 0.6154, TEST_Acc: 0.6200, Time: 3581.3475\n",
      "Epoch: 3150, Loss: 0.6716, Train_Acc: 0.6154, TEST_Acc: 0.6233, Time: 3582.4823\n",
      "Epoch: 3151, Loss: 0.6733, Train_Acc: 0.6154, TEST_Acc: 0.6233, Time: 3583.6182\n",
      "Epoch: 3152, Loss: 21.8150, Train_Acc: 0.6154, TEST_Acc: 0.6167, Time: 3584.7526\n",
      "Epoch: 3153, Loss: 0.6717, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3585.8904\n",
      "Epoch: 3154, Loss: 0.6713, Train_Acc: 0.6154, TEST_Acc: 0.6300, Time: 3587.0225\n",
      "Epoch: 3155, Loss: 0.6693, Train_Acc: 0.6154, TEST_Acc: 0.6233, Time: 3588.1616\n",
      "Epoch: 3156, Loss: 0.6644, Train_Acc: 0.6154, TEST_Acc: 0.6233, Time: 3589.3006\n",
      "Epoch: 3157, Loss: 0.6676, Train_Acc: 0.6154, TEST_Acc: 0.6233, Time: 3590.4406\n",
      "Epoch: 3158, Loss: 0.6687, Train_Acc: 0.6154, TEST_Acc: 0.6300, Time: 3591.5730\n",
      "Epoch: 3159, Loss: 0.6640, Train_Acc: 0.6154, TEST_Acc: 0.6300, Time: 3592.7087\n",
      "Epoch: 3160, Loss: 0.6917, Train_Acc: 0.5962, TEST_Acc: 0.6133, Time: 3593.8420\n",
      "Epoch: 3161, Loss: 0.6894, Train_Acc: 0.5962, TEST_Acc: 0.6133, Time: 3594.9755\n",
      "Epoch: 3162, Loss: 0.6334, Train_Acc: 0.6346, TEST_Acc: 0.6233, Time: 3596.1092\n",
      "Epoch: 3163, Loss: 0.6689, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3597.2413\n",
      "Epoch: 3164, Loss: 0.6693, Train_Acc: 0.6154, TEST_Acc: 0.6300, Time: 3598.3732\n",
      "Epoch: 3165, Loss: 0.6696, Train_Acc: 0.6154, TEST_Acc: 0.6300, Time: 3599.5125\n",
      "Epoch: 3166, Loss: 0.7054, Train_Acc: 0.5962, TEST_Acc: 0.6267, Time: 3600.6596\n",
      "Epoch: 3167, Loss: 0.7030, Train_Acc: 0.5962, TEST_Acc: 0.6267, Time: 3601.8017\n",
      "Epoch: 3168, Loss: 0.7037, Train_Acc: 0.5962, TEST_Acc: 0.6267, Time: 3602.9394\n",
      "Epoch: 3169, Loss: 0.7041, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3604.0778\n",
      "Epoch: 3170, Loss: 0.7013, Train_Acc: 0.5962, TEST_Acc: 0.6200, Time: 3605.2146\n",
      "Epoch: 3171, Loss: 0.6941, Train_Acc: 0.5962, TEST_Acc: 0.6267, Time: 3606.3496\n",
      "Epoch: 3172, Loss: 0.6628, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3607.4754\n",
      "Epoch: 3173, Loss: 0.6629, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3608.6098\n",
      "Epoch: 3174, Loss: 0.6566, Train_Acc: 0.6154, TEST_Acc: 0.6300, Time: 3609.7419\n",
      "Epoch: 3175, Loss: 0.6602, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3610.8781\n",
      "Epoch: 3176, Loss: 0.6588, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3612.0122\n",
      "Epoch: 3177, Loss: 0.6599, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3613.1436\n",
      "Epoch: 3178, Loss: 0.6601, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3614.2792\n",
      "Epoch: 3179, Loss: 0.6612, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3615.4183\n",
      "Epoch: 3180, Loss: 0.6915, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3616.5527\n",
      "Epoch: 3181, Loss: 0.6898, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3617.6914\n",
      "Epoch: 3182, Loss: 0.6578, Train_Acc: 0.6154, TEST_Acc: 0.6200, Time: 3618.8247\n",
      "Epoch: 3183, Loss: 0.6573, Train_Acc: 0.6154, TEST_Acc: 0.6200, Time: 3619.9613\n",
      "Epoch: 3184, Loss: 0.6853, Train_Acc: 0.5962, TEST_Acc: 0.6300, Time: 3621.1056\n",
      "Epoch: 3185, Loss: 0.6861, Train_Acc: 0.5962, TEST_Acc: 0.6200, Time: 3622.2404\n",
      "Epoch: 3186, Loss: 0.6816, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3623.3723\n",
      "Epoch: 3187, Loss: 0.6851, Train_Acc: 0.5962, TEST_Acc: 0.6267, Time: 3624.5108\n",
      "Epoch: 3188, Loss: 0.6786, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3625.6433\n",
      "Epoch: 3189, Loss: 0.6757, Train_Acc: 0.5962, TEST_Acc: 0.6267, Time: 3626.7770\n",
      "Epoch: 3190, Loss: 0.6747, Train_Acc: 0.5962, TEST_Acc: 0.6267, Time: 3627.9132\n",
      "Epoch: 3191, Loss: 0.6802, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3629.0460\n",
      "Epoch: 3192, Loss: 0.6877, Train_Acc: 0.5962, TEST_Acc: 0.6267, Time: 3630.1809\n",
      "Epoch: 3193, Loss: 0.6792, Train_Acc: 0.5962, TEST_Acc: 0.6200, Time: 3631.3163\n",
      "Epoch: 3194, Loss: 0.6779, Train_Acc: 0.5962, TEST_Acc: 0.6167, Time: 3632.4543\n",
      "Epoch: 3195, Loss: 0.6817, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3633.5953\n",
      "Epoch: 3196, Loss: 0.6872, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3634.7318\n",
      "Epoch: 3197, Loss: 0.6871, Train_Acc: 0.5962, TEST_Acc: 0.6200, Time: 3635.8685\n",
      "Epoch: 3198, Loss: 0.6856, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3637.0118\n",
      "Epoch: 3199, Loss: 0.6907, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3638.1492\n",
      "Epoch: 3200, Loss: 0.6928, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3639.2833\n",
      "Epoch: 3201, Loss: 0.6905, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3640.4155\n",
      "Epoch: 3202, Loss: 0.6564, Train_Acc: 0.6154, TEST_Acc: 0.6233, Time: 3641.5454\n",
      "Epoch: 3203, Loss: 0.6894, Train_Acc: 0.5962, TEST_Acc: 0.6267, Time: 3642.6797\n",
      "Epoch: 3204, Loss: 0.6960, Train_Acc: 0.5962, TEST_Acc: 0.6200, Time: 3643.8135\n",
      "Epoch: 3205, Loss: 0.6975, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3644.9474\n",
      "Epoch: 3206, Loss: 0.6955, Train_Acc: 0.5962, TEST_Acc: 0.6200, Time: 3646.0903\n",
      "Epoch: 3207, Loss: 0.6885, Train_Acc: 0.5962, TEST_Acc: 0.6200, Time: 3647.2246\n",
      "Epoch: 3208, Loss: 0.6876, Train_Acc: 0.5962, TEST_Acc: 0.6167, Time: 3648.3606\n",
      "Epoch: 3209, Loss: 0.6815, Train_Acc: 0.5962, TEST_Acc: 0.6300, Time: 3649.4968\n",
      "Epoch: 3210, Loss: 0.6742, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3650.6326\n",
      "Epoch: 3211, Loss: 0.6818, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3651.7753\n",
      "Epoch: 3212, Loss: 13.4465, Train_Acc: 0.5962, TEST_Acc: 0.6167, Time: 3652.9083\n",
      "Epoch: 3213, Loss: 0.6778, Train_Acc: 0.5962, TEST_Acc: 0.6167, Time: 3654.0409\n",
      "Epoch: 3214, Loss: 0.6755, Train_Acc: 0.5962, TEST_Acc: 0.6300, Time: 3655.1708\n",
      "Epoch: 3215, Loss: 0.6762, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3656.3044\n",
      "Epoch: 3216, Loss: 0.6831, Train_Acc: 0.5962, TEST_Acc: 0.6267, Time: 3657.4371\n",
      "Epoch: 3217, Loss: 0.6769, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3658.5750\n",
      "Epoch: 3218, Loss: 0.6463, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3659.7074\n",
      "Epoch: 3219, Loss: 0.6682, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3660.8423\n",
      "Epoch: 3220, Loss: 0.6641, Train_Acc: 0.5962, TEST_Acc: 0.6300, Time: 3661.9804\n",
      "Epoch: 3221, Loss: 0.6386, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3663.1225\n",
      "Epoch: 3222, Loss: 0.6607, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3664.2616\n",
      "Epoch: 3223, Loss: 0.6607, Train_Acc: 0.5962, TEST_Acc: 0.6300, Time: 3665.3972\n",
      "Epoch: 3224, Loss: 0.6673, Train_Acc: 0.5962, TEST_Acc: 0.6267, Time: 3666.5342\n",
      "Epoch: 3225, Loss: 0.6706, Train_Acc: 0.5962, TEST_Acc: 0.6300, Time: 3667.6687\n",
      "Epoch: 3226, Loss: 0.6472, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3668.8045\n",
      "Epoch: 3227, Loss: 0.6550, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3669.9378\n",
      "Epoch: 3228, Loss: 0.6850, Train_Acc: 0.5962, TEST_Acc: 0.6300, Time: 3671.0712\n",
      "Epoch: 3229, Loss: 0.6902, Train_Acc: 0.5962, TEST_Acc: 0.6300, Time: 3672.2088\n",
      "Epoch: 3230, Loss: 0.6913, Train_Acc: 0.5962, TEST_Acc: 0.6300, Time: 3673.3388\n",
      "Epoch: 3231, Loss: 0.6619, Train_Acc: 0.6154, TEST_Acc: 0.6267, Time: 3674.4792\n",
      "Epoch: 3232, Loss: 0.6809, Train_Acc: 0.5962, TEST_Acc: 0.6300, Time: 3675.6157\n",
      "Epoch: 3233, Loss: 0.6782, Train_Acc: 0.5962, TEST_Acc: 0.6300, Time: 3676.7508\n",
      "Epoch: 3234, Loss: 0.6784, Train_Acc: 0.5962, TEST_Acc: 0.6267, Time: 3677.8874\n",
      "Epoch: 3235, Loss: 0.6846, Train_Acc: 0.5962, TEST_Acc: 0.6267, Time: 3679.0264\n",
      "Epoch: 3236, Loss: 0.6859, Train_Acc: 0.5962, TEST_Acc: 0.6267, Time: 3680.1623\n",
      "Epoch: 3237, Loss: 0.6784, Train_Acc: 0.5962, TEST_Acc: 0.6333, Time: 3681.3007\n",
      "Epoch: 3238, Loss: 0.6831, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3682.4381\n",
      "Epoch: 3239, Loss: 0.7090, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3683.5692\n",
      "Epoch: 3240, Loss: 0.6966, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3684.7065\n",
      "Epoch: 3241, Loss: 0.6989, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3685.8400\n",
      "Epoch: 3242, Loss: 0.6749, Train_Acc: 0.5962, TEST_Acc: 0.6067, Time: 3686.9742\n",
      "Epoch: 3243, Loss: 0.6772, Train_Acc: 0.5962, TEST_Acc: 0.6133, Time: 3688.1059\n",
      "Epoch: 3244, Loss: 0.7135, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3689.2375\n",
      "Epoch: 3245, Loss: 0.6874, Train_Acc: 0.5962, TEST_Acc: 0.6200, Time: 3690.3738\n",
      "Epoch: 3246, Loss: 0.6805, Train_Acc: 0.5962, TEST_Acc: 0.6200, Time: 3691.5074\n",
      "Epoch: 3247, Loss: 0.6864, Train_Acc: 0.5962, TEST_Acc: 0.6167, Time: 3692.6382\n",
      "Epoch: 3248, Loss: 0.7135, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3693.7756\n",
      "Epoch: 3249, Loss: 0.7136, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3694.9146\n",
      "Epoch: 3250, Loss: 0.7161, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3696.0535\n",
      "Epoch: 3251, Loss: 0.7240, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3697.1852\n",
      "Epoch: 3252, Loss: 0.7284, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3698.3168\n",
      "Epoch: 3253, Loss: 0.7026, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3699.4506\n",
      "Epoch: 3254, Loss: 0.7293, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3700.5849\n",
      "Epoch: 3255, Loss: 0.7234, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3701.7217\n",
      "Epoch: 3256, Loss: 0.7129, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3702.8550\n",
      "Epoch: 3257, Loss: 0.7172, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3703.9889\n",
      "Epoch: 3258, Loss: 0.7181, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3705.1213\n",
      "Epoch: 3259, Loss: 0.7152, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3706.2630\n",
      "Epoch: 3260, Loss: 0.7161, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3707.3984\n",
      "Epoch: 3261, Loss: 0.7165, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3708.5325\n",
      "Epoch: 3262, Loss: 0.7141, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3709.6684\n",
      "Epoch: 3263, Loss: 0.7184, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3710.8069\n",
      "Epoch: 3264, Loss: 0.7252, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3711.9439\n",
      "Epoch: 3265, Loss: 0.7295, Train_Acc: 0.5769, TEST_Acc: 0.6067, Time: 3713.0764\n",
      "Epoch: 3266, Loss: 0.7363, Train_Acc: 0.5769, TEST_Acc: 0.6067, Time: 3714.2124\n",
      "Epoch: 3267, Loss: 0.7317, Train_Acc: 0.5769, TEST_Acc: 0.6067, Time: 3715.3433\n",
      "Epoch: 3268, Loss: 0.7311, Train_Acc: 0.5769, TEST_Acc: 0.6067, Time: 3716.4735\n",
      "Epoch: 3269, Loss: 0.7252, Train_Acc: 0.5769, TEST_Acc: 0.6067, Time: 3717.6120\n",
      "Epoch: 3270, Loss: 0.7262, Train_Acc: 0.5769, TEST_Acc: 0.6067, Time: 3718.7513\n",
      "Epoch: 3271, Loss: 0.7314, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3719.8837\n",
      "Epoch: 3272, Loss: 0.7261, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3721.0186\n",
      "Epoch: 3273, Loss: 0.7241, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3722.1539\n",
      "Epoch: 3274, Loss: 0.7207, Train_Acc: 0.5769, TEST_Acc: 0.6033, Time: 3723.2902\n",
      "Epoch: 3275, Loss: 0.7180, Train_Acc: 0.5769, TEST_Acc: 0.6033, Time: 3724.4245\n",
      "Epoch: 3276, Loss: 0.7181, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3725.5636\n",
      "Epoch: 3277, Loss: 0.7148, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3726.7048\n",
      "Epoch: 3278, Loss: 0.7136, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3727.8416\n",
      "Epoch: 3279, Loss: 0.7115, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3728.9769\n",
      "Epoch: 3280, Loss: 0.7068, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3730.1109\n",
      "Epoch: 3281, Loss: 0.7016, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3731.2454\n",
      "Epoch: 3282, Loss: 0.6969, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3732.3799\n",
      "Epoch: 3283, Loss: 0.6926, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3733.5142\n",
      "Epoch: 3284, Loss: 0.6948, Train_Acc: 0.5769, TEST_Acc: 0.6067, Time: 3734.6518\n",
      "Epoch: 3285, Loss: 0.6902, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3735.7888\n",
      "Epoch: 3286, Loss: 0.6838, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3736.9191\n",
      "Epoch: 3287, Loss: 0.6794, Train_Acc: 0.5769, TEST_Acc: 0.6067, Time: 3738.0626\n",
      "Epoch: 3288, Loss: 0.6868, Train_Acc: 0.5769, TEST_Acc: 0.6033, Time: 3739.2005\n",
      "Epoch: 3289, Loss: 0.6885, Train_Acc: 0.5769, TEST_Acc: 0.6033, Time: 3740.3355\n",
      "Epoch: 3290, Loss: 0.6852, Train_Acc: 0.5769, TEST_Acc: 0.6033, Time: 3741.4757\n",
      "Epoch: 3291, Loss: 0.6919, Train_Acc: 0.5769, TEST_Acc: 0.6000, Time: 3742.6171\n",
      "Epoch: 3292, Loss: 0.6989, Train_Acc: 0.5769, TEST_Acc: 0.6000, Time: 3743.7526\n",
      "Epoch: 3293, Loss: 0.6994, Train_Acc: 0.5769, TEST_Acc: 0.6000, Time: 3744.8875\n",
      "Epoch: 3294, Loss: 0.7001, Train_Acc: 0.5769, TEST_Acc: 0.6033, Time: 3746.0239\n",
      "Epoch: 3295, Loss: 0.6948, Train_Acc: 0.5769, TEST_Acc: 0.6033, Time: 3747.1591\n",
      "Epoch: 3296, Loss: 0.6955, Train_Acc: 0.5769, TEST_Acc: 0.6067, Time: 3748.2931\n",
      "Epoch: 3297, Loss: 0.6930, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3749.4266\n",
      "Epoch: 3298, Loss: 0.6954, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3750.5633\n",
      "Epoch: 3299, Loss: 0.6904, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3751.6971\n",
      "Epoch: 3300, Loss: 0.6907, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3752.8326\n",
      "Epoch: 3301, Loss: 0.6896, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3753.9721\n",
      "Epoch: 3302, Loss: 0.6798, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3755.1133\n",
      "Epoch: 3303, Loss: 0.6815, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3756.2513\n",
      "Epoch: 3304, Loss: 0.6733, Train_Acc: 0.5769, TEST_Acc: 0.6067, Time: 3757.3956\n",
      "Epoch: 3305, Loss: 0.6771, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3758.5403\n",
      "Epoch: 3306, Loss: 0.6761, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3759.6761\n",
      "Epoch: 3307, Loss: 0.6842, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3760.8118\n",
      "Epoch: 3308, Loss: 0.6899, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3761.9484\n",
      "Epoch: 3309, Loss: 0.6834, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3763.0806\n",
      "Epoch: 3310, Loss: 0.6834, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3764.2164\n",
      "Epoch: 3311, Loss: 0.6758, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3765.3520\n",
      "Epoch: 3312, Loss: 0.6747, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3766.4904\n",
      "Epoch: 3313, Loss: 0.6781, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3767.6241\n",
      "Epoch: 3314, Loss: 0.6698, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3768.7647\n",
      "Epoch: 3315, Loss: 0.6698, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3769.9069\n",
      "Epoch: 3316, Loss: 0.6762, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3771.0425\n",
      "Epoch: 3317, Loss: 0.6779, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3772.1818\n",
      "Epoch: 3318, Loss: 0.6822, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3773.3173\n",
      "Epoch: 3319, Loss: 0.6874, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3774.4501\n",
      "Epoch: 3320, Loss: 0.6886, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3775.5852\n",
      "Epoch: 3321, Loss: 0.6895, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3776.7192\n",
      "Epoch: 3322, Loss: 0.6902, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3777.8546\n",
      "Epoch: 3323, Loss: 0.6917, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3778.9890\n",
      "Epoch: 3324, Loss: 0.6864, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3780.1322\n",
      "Epoch: 3325, Loss: 0.6965, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3781.2663\n",
      "Epoch: 3326, Loss: 0.6929, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3782.3968\n",
      "Epoch: 3327, Loss: 0.6934, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3783.5350\n",
      "Epoch: 3328, Loss: 0.6903, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3784.6710\n",
      "Epoch: 3329, Loss: 0.6932, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3785.8082\n",
      "Epoch: 3330, Loss: 0.6926, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3786.9444\n",
      "Epoch: 3331, Loss: 0.6879, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3788.0823\n",
      "Epoch: 3332, Loss: 0.6860, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3789.2193\n",
      "Epoch: 3333, Loss: 0.6889, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3790.3623\n",
      "Epoch: 3334, Loss: 0.6948, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3791.4974\n",
      "Epoch: 3335, Loss: 0.7000, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3792.6327\n",
      "Epoch: 3336, Loss: 0.6971, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3793.7692\n",
      "Epoch: 3337, Loss: 0.7038, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3794.9064\n",
      "Epoch: 3338, Loss: 0.7070, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3796.0414\n",
      "Epoch: 3339, Loss: 0.7021, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3797.1849\n",
      "Epoch: 3340, Loss: 0.7020, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3798.3217\n",
      "Epoch: 3341, Loss: 0.6879, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3799.4582\n",
      "Epoch: 3342, Loss: 0.6889, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3800.5992\n",
      "Epoch: 3343, Loss: 0.6883, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3801.7337\n",
      "Epoch: 3344, Loss: 0.6889, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3802.8703\n",
      "Epoch: 3345, Loss: 0.6938, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3804.0094\n",
      "Epoch: 3346, Loss: 0.6912, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3805.1424\n",
      "Epoch: 3347, Loss: 0.6870, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3806.2823\n",
      "Epoch: 3348, Loss: 0.6829, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3807.4147\n",
      "Epoch: 3349, Loss: 0.6803, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3808.5476\n",
      "Epoch: 3350, Loss: 0.6795, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3809.6846\n",
      "Epoch: 3351, Loss: 0.6816, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3810.8273\n",
      "Epoch: 3352, Loss: 0.6881, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3811.9628\n",
      "Epoch: 3353, Loss: 0.6822, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3813.0984\n",
      "Epoch: 3354, Loss: 0.6813, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3814.2339\n",
      "Epoch: 3355, Loss: 0.6846, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3815.3757\n",
      "Epoch: 3356, Loss: 0.6809, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3816.5099\n",
      "Epoch: 3357, Loss: 0.6829, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3817.6446\n",
      "Epoch: 3358, Loss: 0.6813, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3818.7793\n",
      "Epoch: 3359, Loss: 0.6786, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 3819.9173\n",
      "Epoch: 3360, Loss: 0.6839, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 3821.0480\n",
      "Epoch: 3361, Loss: 0.6869, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3822.1803\n",
      "Epoch: 3362, Loss: 0.6837, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3823.3122\n",
      "Epoch: 3363, Loss: 0.6880, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3824.4456\n",
      "Epoch: 3364, Loss: 0.6870, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3825.5807\n",
      "Epoch: 3365, Loss: 0.6861, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3826.7193\n",
      "Epoch: 3366, Loss: 0.6805, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3827.8497\n",
      "Epoch: 3367, Loss: 0.6843, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3828.9831\n",
      "Epoch: 3368, Loss: 0.6870, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3830.1194\n",
      "Epoch: 3369, Loss: 0.6903, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3831.2571\n",
      "Epoch: 3370, Loss: 0.6847, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3832.3968\n",
      "Epoch: 3371, Loss: 0.6798, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3833.5329\n",
      "Epoch: 3372, Loss: 0.6766, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3834.6706\n",
      "Epoch: 3373, Loss: 0.6722, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3835.8080\n",
      "Epoch: 3374, Loss: 0.6759, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3836.9430\n",
      "Epoch: 3375, Loss: 0.6734, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3838.0796\n",
      "Epoch: 3376, Loss: 0.6839, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3839.2111\n",
      "Epoch: 3377, Loss: 0.6847, Train_Acc: 0.5769, TEST_Acc: 0.6067, Time: 3840.3474\n",
      "Epoch: 3378, Loss: 0.6882, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3841.4816\n",
      "Epoch: 3379, Loss: 0.6903, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3842.6145\n",
      "Epoch: 3380, Loss: 0.6944, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3843.7552\n",
      "Epoch: 3381, Loss: 0.6963, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3844.8916\n",
      "Epoch: 3382, Loss: 0.6967, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3846.0293\n",
      "Epoch: 3383, Loss: 0.6953, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3847.1627\n",
      "Epoch: 3384, Loss: 0.6943, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3848.2977\n",
      "Epoch: 3385, Loss: 0.6886, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3849.4368\n",
      "Epoch: 3386, Loss: 0.6953, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3850.5738\n",
      "Epoch: 3387, Loss: 0.6964, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3851.7083\n",
      "Epoch: 3388, Loss: 0.7004, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3852.8432\n",
      "Epoch: 3389, Loss: 0.7038, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 3853.9824\n",
      "Epoch: 3390, Loss: 0.6959, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3855.1153\n",
      "Epoch: 3391, Loss: 0.6974, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3856.2502\n",
      "Epoch: 3392, Loss: 0.6926, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3857.3882\n",
      "Epoch: 3393, Loss: 0.6979, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3858.5229\n",
      "Epoch: 3394, Loss: 0.6915, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3859.6556\n",
      "Epoch: 3395, Loss: 0.6915, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3860.7966\n",
      "Epoch: 3396, Loss: 0.6898, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3861.9316\n",
      "Epoch: 3397, Loss: 0.6964, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3863.0764\n",
      "Epoch: 3398, Loss: 0.6970, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3864.2356\n",
      "Epoch: 3399, Loss: 0.6994, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3865.3997\n",
      "Epoch: 3400, Loss: 0.6980, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3866.5628\n",
      "Epoch: 3401, Loss: 0.6879, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3867.7106\n",
      "Epoch: 3402, Loss: 0.6913, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3868.8452\n",
      "Epoch: 3403, Loss: 0.6890, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3869.9825\n",
      "Epoch: 3404, Loss: 0.6926, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3871.1192\n",
      "Epoch: 3405, Loss: 0.6905, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3872.2519\n",
      "Epoch: 3406, Loss: 0.6858, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3873.3866\n",
      "Epoch: 3407, Loss: 0.6848, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 3874.5254\n",
      "Epoch: 3408, Loss: 0.6914, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3875.6557\n",
      "Epoch: 3409, Loss: 0.6944, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3876.7895\n",
      "Epoch: 3410, Loss: 0.6954, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3877.9357\n",
      "Epoch: 3411, Loss: 0.6966, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3879.0720\n",
      "Epoch: 3412, Loss: 0.6969, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3880.2117\n",
      "Epoch: 3413, Loss: 0.7013, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3881.3517\n",
      "Epoch: 3414, Loss: 0.6995, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3882.4839\n",
      "Epoch: 3415, Loss: 0.7022, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3883.6211\n",
      "Epoch: 3416, Loss: 0.7012, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3884.7522\n",
      "Epoch: 3417, Loss: 0.6994, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3885.8834\n",
      "Epoch: 3418, Loss: 0.7030, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3887.0223\n",
      "Epoch: 3419, Loss: 0.6998, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3888.1525\n",
      "Epoch: 3420, Loss: 0.7082, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3889.2857\n",
      "Epoch: 3421, Loss: 0.7031, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3890.4220\n",
      "Epoch: 3422, Loss: 0.7006, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3891.5575\n",
      "Epoch: 3423, Loss: 0.7029, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3892.6937\n",
      "Epoch: 3424, Loss: 0.6942, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3893.8382\n",
      "Epoch: 3425, Loss: 0.6898, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3894.9773\n",
      "Epoch: 3426, Loss: 0.6849, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3896.1178\n",
      "Epoch: 3427, Loss: 0.6794, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3897.2599\n",
      "Epoch: 3428, Loss: 0.6902, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3898.3914\n",
      "Epoch: 3429, Loss: 0.6850, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3899.5231\n",
      "Epoch: 3430, Loss: 0.6860, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3900.6624\n",
      "Epoch: 3431, Loss: 0.6646, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 3901.7999\n",
      "Epoch: 3432, Loss: 0.6638, Train_Acc: 0.5962, TEST_Acc: 0.6200, Time: 3902.9370\n",
      "Epoch: 3433, Loss: 0.6903, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3904.0704\n",
      "Epoch: 3434, Loss: 0.6915, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3905.2034\n",
      "Epoch: 3435, Loss: 0.6941, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3906.3393\n",
      "Epoch: 3436, Loss: 0.6919, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3907.4773\n",
      "Epoch: 3437, Loss: 0.6943, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 3908.6173\n",
      "Epoch: 3438, Loss: 0.6912, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3909.7540\n",
      "Epoch: 3439, Loss: 0.6835, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3910.8923\n",
      "Epoch: 3440, Loss: 0.6796, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3912.0327\n",
      "Epoch: 3441, Loss: 0.6843, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3913.1739\n",
      "Epoch: 3442, Loss: 0.6695, Train_Acc: 0.5962, TEST_Acc: 0.6200, Time: 3914.3093\n",
      "Epoch: 3443, Loss: 0.6716, Train_Acc: 0.5962, TEST_Acc: 0.6200, Time: 3915.4479\n",
      "Epoch: 3444, Loss: 0.6625, Train_Acc: 0.5962, TEST_Acc: 0.6200, Time: 3916.5818\n",
      "Epoch: 3445, Loss: 0.6576, Train_Acc: 0.5962, TEST_Acc: 0.6267, Time: 3917.7201\n",
      "Epoch: 3446, Loss: 0.6868, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3918.8582\n",
      "Epoch: 3447, Loss: 0.6622, Train_Acc: 0.5962, TEST_Acc: 0.6167, Time: 3919.9872\n",
      "Epoch: 3448, Loss: 0.6890, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3921.1190\n",
      "Epoch: 3449, Loss: 0.6880, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3922.2537\n",
      "Epoch: 3450, Loss: 0.6974, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3923.3891\n",
      "Epoch: 3451, Loss: 0.6969, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3924.5268\n",
      "Epoch: 3452, Loss: 0.7011, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3925.6655\n",
      "Epoch: 3453, Loss: 0.7050, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3926.8107\n",
      "Epoch: 3454, Loss: 0.7022, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3927.9506\n",
      "Epoch: 3455, Loss: 0.6996, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3929.0891\n",
      "Epoch: 3456, Loss: 0.6998, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3930.2224\n",
      "Epoch: 3457, Loss: 0.7001, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3931.3569\n",
      "Epoch: 3458, Loss: 0.6992, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3932.4902\n",
      "Epoch: 3459, Loss: 0.7018, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3933.6295\n",
      "Epoch: 3460, Loss: 0.7032, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3934.7643\n",
      "Epoch: 3461, Loss: 0.7015, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3935.9004\n",
      "Epoch: 3462, Loss: 0.7043, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3937.0416\n",
      "Epoch: 3463, Loss: 0.6966, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3938.1801\n",
      "Epoch: 3464, Loss: 0.6999, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3939.3176\n",
      "Epoch: 3465, Loss: 0.7012, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3940.4527\n",
      "Epoch: 3466, Loss: 0.7020, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3941.5921\n",
      "Epoch: 3467, Loss: 0.6985, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3942.7404\n",
      "Epoch: 3468, Loss: 0.7001, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3943.8775\n",
      "Epoch: 3469, Loss: 0.7001, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3945.0124\n",
      "Epoch: 3470, Loss: 0.7006, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3946.1445\n",
      "Epoch: 3471, Loss: 0.6991, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3947.2883\n",
      "Epoch: 3472, Loss: 0.7010, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 3948.4281\n",
      "Epoch: 3473, Loss: 0.6990, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 3949.5645\n",
      "Epoch: 3474, Loss: 0.6981, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3950.7006\n",
      "Epoch: 3475, Loss: 0.6987, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 3951.8374\n",
      "Epoch: 3476, Loss: 0.6846, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 3952.9714\n",
      "Epoch: 3477, Loss: 0.6871, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3954.1109\n",
      "Epoch: 3478, Loss: 0.6873, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3955.2491\n",
      "Epoch: 3479, Loss: 0.6841, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3956.3861\n",
      "Epoch: 3480, Loss: 0.6857, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3957.5243\n",
      "Epoch: 3481, Loss: 0.6859, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3958.6677\n",
      "Epoch: 3482, Loss: 0.6912, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3959.8021\n",
      "Epoch: 3483, Loss: 0.6843, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3960.9331\n",
      "Epoch: 3484, Loss: 0.6827, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3962.0658\n",
      "Epoch: 3485, Loss: 0.6846, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3963.2058\n",
      "Epoch: 3486, Loss: 0.6812, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3964.3412\n",
      "Epoch: 3487, Loss: 0.6733, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3965.4732\n",
      "Epoch: 3488, Loss: 0.6719, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3966.6089\n",
      "Epoch: 3489, Loss: 0.6781, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3967.7462\n",
      "Epoch: 3490, Loss: 0.6843, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3968.8894\n",
      "Epoch: 3491, Loss: 0.6795, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3970.0309\n",
      "Epoch: 3492, Loss: 0.6825, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3971.1721\n",
      "Epoch: 3493, Loss: 0.6842, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3972.3094\n",
      "Epoch: 3494, Loss: 0.6879, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3973.4501\n",
      "Epoch: 3495, Loss: 0.6915, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3974.5875\n",
      "Epoch: 3496, Loss: 0.6866, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3975.7235\n",
      "Epoch: 3497, Loss: 0.6845, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3976.8549\n",
      "Epoch: 3498, Loss: 0.6885, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3977.9951\n",
      "Epoch: 3499, Loss: 0.6929, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3979.1294\n",
      "Epoch: 3500, Loss: 0.6867, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 3980.2708\n",
      "Epoch: 3501, Loss: 0.6749, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 3981.4058\n",
      "Epoch: 3502, Loss: 0.6726, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3982.5441\n",
      "Epoch: 3503, Loss: 0.6732, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3983.6791\n",
      "Epoch: 3504, Loss: 0.6786, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3984.8170\n",
      "Epoch: 3505, Loss: 0.6728, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3985.9525\n",
      "Epoch: 3506, Loss: 0.6725, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3987.0864\n",
      "Epoch: 3507, Loss: 0.6670, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3988.2246\n",
      "Epoch: 3508, Loss: 0.6712, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3989.3650\n",
      "Epoch: 3509, Loss: 0.6740, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 3990.5060\n",
      "Epoch: 3510, Loss: 0.6806, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3991.6427\n",
      "Epoch: 3511, Loss: 0.6890, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 3992.7774\n",
      "Epoch: 3512, Loss: 0.6930, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3993.9121\n",
      "Epoch: 3513, Loss: 0.6984, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 3995.0460\n",
      "Epoch: 3514, Loss: 0.6998, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3996.1783\n",
      "Epoch: 3515, Loss: 0.6968, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 3997.3242\n",
      "Epoch: 3516, Loss: 0.6889, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3998.4592\n",
      "Epoch: 3517, Loss: 0.6926, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 3999.5932\n",
      "Epoch: 3518, Loss: 0.6872, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4000.7371\n",
      "Epoch: 3519, Loss: 0.6918, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4001.8752\n",
      "Epoch: 3520, Loss: 0.6880, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4003.0126\n",
      "Epoch: 3521, Loss: 0.6943, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4004.1509\n",
      "Epoch: 3522, Loss: 0.7002, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4005.2919\n",
      "Epoch: 3523, Loss: 0.6971, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4006.4239\n",
      "Epoch: 3524, Loss: 0.6961, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4007.5580\n",
      "Epoch: 3525, Loss: 0.6978, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4008.6981\n",
      "Epoch: 3526, Loss: 0.7012, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4009.8321\n",
      "Epoch: 3527, Loss: 0.7062, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4010.9740\n",
      "Epoch: 3528, Loss: 0.7113, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4012.1055\n",
      "Epoch: 3529, Loss: 0.7056, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4013.2380\n",
      "Epoch: 3530, Loss: 0.7193, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4014.3762\n",
      "Epoch: 3531, Loss: 0.7159, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4015.5106\n",
      "Epoch: 3532, Loss: 0.7165, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4016.6526\n",
      "Epoch: 3533, Loss: 0.7123, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4017.7901\n",
      "Epoch: 3534, Loss: 0.7103, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4018.9264\n",
      "Epoch: 3535, Loss: 0.7055, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4020.0639\n",
      "Epoch: 3536, Loss: 0.7043, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4021.2059\n",
      "Epoch: 3537, Loss: 0.6976, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4022.3426\n",
      "Epoch: 3538, Loss: 0.6937, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4023.4794\n",
      "Epoch: 3539, Loss: 0.7017, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 4024.6236\n",
      "Epoch: 3540, Loss: 0.7057, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4025.7645\n",
      "Epoch: 3541, Loss: 0.7137, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4026.9002\n",
      "Epoch: 3542, Loss: 0.7150, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4028.0315\n",
      "Epoch: 3543, Loss: 0.7138, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4029.1641\n",
      "Epoch: 3544, Loss: 0.7120, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4030.3063\n",
      "Epoch: 3545, Loss: 0.7150, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4031.4449\n",
      "Epoch: 3546, Loss: 0.7190, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4032.5909\n",
      "Epoch: 3547, Loss: 0.7194, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4033.7275\n",
      "Epoch: 3548, Loss: 0.7125, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4034.8667\n",
      "Epoch: 3549, Loss: 0.7067, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4036.0011\n",
      "Epoch: 3550, Loss: 0.7053, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4037.1323\n",
      "Epoch: 3551, Loss: 0.6956, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4038.2715\n",
      "Epoch: 3552, Loss: 0.6935, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4039.4071\n",
      "Epoch: 3553, Loss: 0.6933, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4040.5422\n",
      "Epoch: 3554, Loss: 0.6917, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4041.6735\n",
      "Epoch: 3555, Loss: 0.6937, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4042.8137\n",
      "Epoch: 3556, Loss: 0.6879, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4043.9470\n",
      "Epoch: 3557, Loss: 0.6847, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4045.0856\n",
      "Epoch: 3558, Loss: 0.6850, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4046.2258\n",
      "Epoch: 3559, Loss: 0.6890, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4047.3675\n",
      "Epoch: 3560, Loss: 0.6889, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4048.5076\n",
      "Epoch: 3561, Loss: 0.6866, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4049.6482\n",
      "Epoch: 3562, Loss: 0.6906, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4050.8134\n",
      "Epoch: 3563, Loss: 0.6930, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4051.9470\n",
      "Epoch: 3564, Loss: 0.6902, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4053.0816\n",
      "Epoch: 3565, Loss: 0.6876, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4054.2163\n",
      "Epoch: 3566, Loss: 0.6864, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4055.3462\n",
      "Epoch: 3567, Loss: 0.6877, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4056.4806\n",
      "Epoch: 3568, Loss: 0.6843, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4057.6141\n",
      "Epoch: 3569, Loss: 0.6890, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4058.7519\n",
      "Epoch: 3570, Loss: 0.6875, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4059.8858\n",
      "Epoch: 3571, Loss: 0.6905, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4061.0249\n",
      "Epoch: 3572, Loss: 0.6839, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4062.1727\n",
      "Epoch: 3573, Loss: 0.6808, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4063.3111\n",
      "Epoch: 3574, Loss: 0.6801, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4064.4551\n",
      "Epoch: 3575, Loss: 0.6809, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4065.5963\n",
      "Epoch: 3576, Loss: 0.6836, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4066.7321\n",
      "Epoch: 3577, Loss: 0.6849, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4067.8657\n",
      "Epoch: 3578, Loss: 0.6892, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4069.0031\n",
      "Epoch: 3579, Loss: 0.6926, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4070.1437\n",
      "Epoch: 3580, Loss: 0.6879, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4071.2768\n",
      "Epoch: 3581, Loss: 0.6870, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4072.4103\n",
      "Epoch: 3582, Loss: 0.6937, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4073.5411\n",
      "Epoch: 3583, Loss: 0.6970, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4074.6829\n",
      "Epoch: 3584, Loss: 0.7015, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4075.8193\n",
      "Epoch: 3585, Loss: 0.6981, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4076.9541\n",
      "Epoch: 3586, Loss: 0.7009, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4078.0913\n",
      "Epoch: 3587, Loss: 0.7019, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4079.2280\n",
      "Epoch: 3588, Loss: 0.7047, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4080.3758\n",
      "Epoch: 3589, Loss: 0.7046, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4081.5145\n",
      "Epoch: 3590, Loss: 0.6981, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4082.6526\n",
      "Epoch: 3591, Loss: 0.6995, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 4083.7911\n",
      "Epoch: 3592, Loss: 0.7003, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4084.9291\n",
      "Epoch: 3593, Loss: 0.7040, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4086.0626\n",
      "Epoch: 3594, Loss: 0.7042, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4087.1947\n",
      "Epoch: 3595, Loss: 0.6976, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4088.3262\n",
      "Epoch: 3596, Loss: 0.6918, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4089.4589\n",
      "Epoch: 3597, Loss: 0.6856, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4090.5903\n",
      "Epoch: 3598, Loss: 0.7002, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4091.7253\n",
      "Epoch: 3599, Loss: 0.6901, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4092.8665\n",
      "Epoch: 3600, Loss: 0.6878, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4094.0074\n",
      "Epoch: 3601, Loss: 0.6819, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4095.1531\n",
      "Epoch: 3602, Loss: 0.6842, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4096.2934\n",
      "Epoch: 3603, Loss: 0.6813, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 4097.4289\n",
      "Epoch: 3604, Loss: 0.6839, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4098.5628\n",
      "Epoch: 3605, Loss: 0.6841, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4099.7070\n",
      "Epoch: 3606, Loss: 0.6845, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 4100.8433\n",
      "Epoch: 3607, Loss: 0.6765, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4101.9784\n",
      "Epoch: 3608, Loss: 0.6857, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4103.1141\n",
      "Epoch: 3609, Loss: 0.6849, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4104.2524\n",
      "Epoch: 3610, Loss: 0.6829, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4105.3878\n",
      "Epoch: 3611, Loss: 0.6851, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4106.5345\n",
      "Epoch: 3612, Loss: 0.6850, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4107.6713\n",
      "Epoch: 3613, Loss: 0.6783, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4108.8114\n",
      "Epoch: 3614, Loss: 0.6815, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4109.9549\n",
      "Epoch: 3615, Loss: 0.6842, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4111.0901\n",
      "Epoch: 3616, Loss: 0.6878, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4112.2364\n",
      "Epoch: 3617, Loss: 0.6839, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4113.3700\n",
      "Epoch: 3618, Loss: 0.6807, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 4114.5076\n",
      "Epoch: 3619, Loss: 0.6856, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4115.6452\n",
      "Epoch: 3620, Loss: 0.6822, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4116.7848\n",
      "Epoch: 3621, Loss: 0.6816, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 4117.9268\n",
      "Epoch: 3622, Loss: 0.6844, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4119.0625\n",
      "Epoch: 3623, Loss: 0.6849, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 4120.2010\n",
      "Epoch: 3624, Loss: 0.6839, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 4121.3378\n",
      "Epoch: 3625, Loss: 0.6841, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 4122.4697\n",
      "Epoch: 3626, Loss: 0.6766, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 4123.6046\n",
      "Epoch: 3627, Loss: 0.6769, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 4124.7397\n",
      "Epoch: 3628, Loss: 0.6805, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 4125.8786\n",
      "Epoch: 3629, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 4127.0194\n",
      "Epoch: 3630, Loss: 0.6750, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 4128.1517\n",
      "Epoch: 3631, Loss: 0.6756, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4129.2929\n",
      "Epoch: 3632, Loss: 0.6757, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4130.4292\n",
      "Epoch: 3633, Loss: 0.6750, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4131.5621\n",
      "Epoch: 3634, Loss: 0.6826, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 4132.6993\n",
      "Epoch: 3635, Loss: 0.6854, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4133.8357\n",
      "Epoch: 3636, Loss: 0.6824, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 4134.9746\n",
      "Epoch: 3637, Loss: 0.6853, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4136.1107\n",
      "Epoch: 3638, Loss: 0.6825, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4137.2540\n",
      "Epoch: 3639, Loss: 0.6844, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4138.3896\n",
      "Epoch: 3640, Loss: 0.6801, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4139.5251\n",
      "Epoch: 3641, Loss: 0.6735, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4140.6608\n",
      "Epoch: 3642, Loss: 0.6759, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4141.7987\n",
      "Epoch: 3643, Loss: 0.6793, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4142.9371\n",
      "Epoch: 3644, Loss: 0.6800, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4144.0777\n",
      "Epoch: 3645, Loss: 0.6847, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4145.2141\n",
      "Epoch: 3646, Loss: 0.6821, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4146.3505\n",
      "Epoch: 3647, Loss: 0.6790, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4147.4906\n",
      "Epoch: 3648, Loss: 0.6791, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4148.6262\n",
      "Epoch: 3649, Loss: 0.6765, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4149.7597\n",
      "Epoch: 3650, Loss: 0.6768, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4150.8934\n",
      "Epoch: 3651, Loss: 0.6818, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4152.0295\n",
      "Epoch: 3652, Loss: 0.6828, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4153.1651\n",
      "Epoch: 3653, Loss: 0.6852, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4154.3019\n",
      "Epoch: 3654, Loss: 0.6799, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4155.4411\n",
      "Epoch: 3655, Loss: 0.6846, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4156.5801\n",
      "Epoch: 3656, Loss: 0.6842, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4157.7208\n",
      "Epoch: 3657, Loss: 0.6869, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4158.8615\n",
      "Epoch: 3658, Loss: 0.6869, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4160.0047\n",
      "Epoch: 3659, Loss: 0.6883, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4161.1409\n",
      "Epoch: 3660, Loss: 0.6902, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4162.2770\n",
      "Epoch: 3661, Loss: 0.6903, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4163.4118\n",
      "Epoch: 3662, Loss: 0.6858, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4164.5453\n",
      "Epoch: 3663, Loss: 0.6826, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4165.6794\n",
      "Epoch: 3664, Loss: 0.6807, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4166.8156\n",
      "Epoch: 3665, Loss: 0.6771, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4167.9503\n",
      "Epoch: 3666, Loss: 0.6715, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4169.0942\n",
      "Epoch: 3667, Loss: 0.6687, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4170.2366\n",
      "Epoch: 3668, Loss: 0.6627, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4171.3765\n",
      "Epoch: 3669, Loss: 0.6639, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4172.5182\n",
      "Epoch: 3670, Loss: 0.6645, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4173.6529\n",
      "Epoch: 3671, Loss: 0.6796, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4174.7938\n",
      "Epoch: 3672, Loss: 0.6788, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4175.9364\n",
      "Epoch: 3673, Loss: 0.6805, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4177.0757\n",
      "Epoch: 3674, Loss: 0.6837, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4178.2132\n",
      "Epoch: 3675, Loss: 0.6861, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 4179.3489\n",
      "Epoch: 3676, Loss: 0.6657, Train_Acc: 0.5962, TEST_Acc: 0.6233, Time: 4180.4858\n",
      "Epoch: 3677, Loss: 0.6877, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4181.6231\n",
      "Epoch: 3678, Loss: 0.6853, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4182.7603\n",
      "Epoch: 3679, Loss: 0.6882, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4183.8963\n",
      "Epoch: 3680, Loss: 0.6982, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4185.0310\n",
      "Epoch: 3681, Loss: 0.6947, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4186.1704\n",
      "Epoch: 3682, Loss: 0.6874, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4187.3083\n",
      "Epoch: 3683, Loss: 0.6924, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4188.4532\n",
      "Epoch: 3684, Loss: 0.6908, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4189.5941\n",
      "Epoch: 3685, Loss: 0.7018, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4190.7406\n",
      "Epoch: 3686, Loss: 0.7015, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4191.8806\n",
      "Epoch: 3687, Loss: 0.7036, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4193.0150\n",
      "Epoch: 3688, Loss: 0.7033, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4194.1574\n",
      "Epoch: 3689, Loss: 0.7090, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4195.2914\n",
      "Epoch: 3690, Loss: 0.7155, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4196.4289\n",
      "Epoch: 3691, Loss: 0.7174, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4197.5635\n",
      "Epoch: 3692, Loss: 0.7134, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4198.7043\n",
      "Epoch: 3693, Loss: 0.7111, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4199.8412\n",
      "Epoch: 3694, Loss: 0.7099, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4200.9814\n",
      "Epoch: 3695, Loss: 0.7115, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4202.1187\n",
      "Epoch: 3696, Loss: 0.7089, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4203.2585\n",
      "Epoch: 3697, Loss: 0.7034, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4204.3984\n",
      "Epoch: 3698, Loss: 0.7017, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4205.5373\n",
      "Epoch: 3699, Loss: 0.7061, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4206.6761\n",
      "Epoch: 3700, Loss: 0.6969, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4207.8178\n",
      "Epoch: 3701, Loss: 0.6954, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4208.9506\n",
      "Epoch: 3702, Loss: 0.6874, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4210.0868\n",
      "Epoch: 3703, Loss: 0.6925, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4211.2201\n",
      "Epoch: 3704, Loss: 0.6927, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4212.3553\n",
      "Epoch: 3705, Loss: 0.6945, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4213.4902\n",
      "Epoch: 3706, Loss: 0.6959, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4214.6216\n",
      "Epoch: 3707, Loss: 0.6967, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4215.7604\n",
      "Epoch: 3708, Loss: 0.6883, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4216.8901\n",
      "Epoch: 3709, Loss: 0.6823, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4218.0246\n",
      "Epoch: 3710, Loss: 0.6802, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4219.1611\n",
      "Epoch: 3711, Loss: 0.6808, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4220.3034\n",
      "Epoch: 3712, Loss: 0.6855, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4221.4468\n",
      "Epoch: 3713, Loss: 0.6857, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4222.5926\n",
      "Epoch: 3714, Loss: 0.6835, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4223.7312\n",
      "Epoch: 3715, Loss: 0.6957, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4224.8661\n",
      "Epoch: 3716, Loss: 0.6958, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4226.0001\n",
      "Epoch: 3717, Loss: 0.7025, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4227.1354\n",
      "Epoch: 3718, Loss: 0.7049, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4228.2722\n",
      "Epoch: 3719, Loss: 0.7111, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4229.4083\n",
      "Epoch: 3720, Loss: 0.7045, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4230.5514\n",
      "Epoch: 3721, Loss: 0.7011, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4231.6956\n",
      "Epoch: 3722, Loss: 0.6885, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4232.8309\n",
      "Epoch: 3723, Loss: 0.6895, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4233.9702\n",
      "Epoch: 3724, Loss: 0.6905, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4235.1082\n",
      "Epoch: 3725, Loss: 0.6930, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4236.2439\n",
      "Epoch: 3726, Loss: 0.6981, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4237.3896\n",
      "Epoch: 3727, Loss: 0.6985, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4238.5304\n",
      "Epoch: 3728, Loss: 0.7037, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4239.6644\n",
      "Epoch: 3729, Loss: 0.6999, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4240.7983\n",
      "Epoch: 3730, Loss: 0.6952, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4241.9420\n",
      "Epoch: 3731, Loss: 0.6939, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4243.0725\n",
      "Epoch: 3732, Loss: 0.6982, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4244.2079\n",
      "Epoch: 3733, Loss: 0.7008, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 4245.3443\n",
      "Epoch: 3734, Loss: 0.6994, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 4246.4836\n",
      "Epoch: 3735, Loss: 0.6983, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4247.6180\n",
      "Epoch: 3736, Loss: 0.6998, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4248.7542\n",
      "Epoch: 3737, Loss: 0.6973, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4249.8942\n",
      "Epoch: 3738, Loss: 0.6963, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4251.0353\n",
      "Epoch: 3739, Loss: 0.6947, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4252.1756\n",
      "Epoch: 3740, Loss: 0.6978, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4253.3136\n",
      "Epoch: 3741, Loss: 0.6965, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 4254.4576\n",
      "Epoch: 3742, Loss: 0.6952, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4255.5956\n",
      "Epoch: 3743, Loss: 0.6953, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4256.7299\n",
      "Epoch: 3744, Loss: 0.7026, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4257.8679\n",
      "Epoch: 3745, Loss: 0.7082, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4259.0019\n",
      "Epoch: 3746, Loss: 0.7114, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4260.1399\n",
      "Epoch: 3747, Loss: 0.7105, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4261.2739\n",
      "Epoch: 3748, Loss: 0.7046, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4262.4153\n",
      "Epoch: 3749, Loss: 0.7024, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4263.5483\n",
      "Epoch: 3750, Loss: 0.7083, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4264.6834\n",
      "Epoch: 3751, Loss: 0.7080, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4265.8236\n",
      "Epoch: 3752, Loss: 0.7064, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4266.9591\n",
      "Epoch: 3753, Loss: 0.7088, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4268.0994\n",
      "Epoch: 3754, Loss: 0.6975, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4269.2347\n",
      "Epoch: 3755, Loss: 0.6958, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4270.3732\n",
      "Epoch: 3756, Loss: 0.6982, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4271.5075\n",
      "Epoch: 3757, Loss: 0.6990, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4272.6402\n",
      "Epoch: 3758, Loss: 0.6929, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4273.7831\n",
      "Epoch: 3759, Loss: 0.6969, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4274.9152\n",
      "Epoch: 3760, Loss: 0.7024, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4276.0559\n",
      "Epoch: 3761, Loss: 0.7008, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4277.1884\n",
      "Epoch: 3762, Loss: 0.6974, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4278.3201\n",
      "Epoch: 3763, Loss: 0.6941, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4279.4524\n",
      "Epoch: 3764, Loss: 0.6930, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4280.5924\n",
      "Epoch: 3765, Loss: 0.6974, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4281.7295\n",
      "Epoch: 3766, Loss: 0.6958, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4282.8657\n",
      "Epoch: 3767, Loss: 0.7036, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4284.0070\n",
      "Epoch: 3768, Loss: 0.7067, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4285.1461\n",
      "Epoch: 3769, Loss: 0.7049, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4286.2839\n",
      "Epoch: 3770, Loss: 0.7071, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4287.4183\n",
      "Epoch: 3771, Loss: 0.7056, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4288.5557\n",
      "Epoch: 3772, Loss: 0.7038, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4289.6907\n",
      "Epoch: 3773, Loss: 0.7018, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4290.8253\n",
      "Epoch: 3774, Loss: 0.7016, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4291.9616\n",
      "Epoch: 3775, Loss: 0.7001, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4293.1036\n",
      "Epoch: 3776, Loss: 0.7015, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4294.2398\n",
      "Epoch: 3777, Loss: 0.6949, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4295.3785\n",
      "Epoch: 3778, Loss: 0.6926, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4296.5147\n",
      "Epoch: 3779, Loss: 0.6953, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4297.6522\n",
      "Epoch: 3780, Loss: 0.6985, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4298.7896\n",
      "Epoch: 3781, Loss: 0.6936, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4299.9294\n",
      "Epoch: 3782, Loss: 0.6943, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4301.0679\n",
      "Epoch: 3783, Loss: 0.6976, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4302.2091\n",
      "Epoch: 3784, Loss: 0.7017, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4303.3437\n",
      "Epoch: 3785, Loss: 0.7067, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4304.4794\n",
      "Epoch: 3786, Loss: 0.7132, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4305.6176\n",
      "Epoch: 3787, Loss: 0.7098, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4306.7506\n",
      "Epoch: 3788, Loss: 0.7138, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4307.8838\n",
      "Epoch: 3789, Loss: 0.7073, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4309.0222\n",
      "Epoch: 3790, Loss: 0.7106, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4310.1582\n",
      "Epoch: 3791, Loss: 0.7113, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4311.3007\n",
      "Epoch: 3792, Loss: 0.7105, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4312.4395\n",
      "Epoch: 3793, Loss: 0.7143, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4313.5762\n",
      "Epoch: 3794, Loss: 0.7176, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4314.7259\n",
      "Epoch: 3795, Loss: 0.7092, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4315.8715\n",
      "Epoch: 3796, Loss: 0.7096, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4317.0072\n",
      "Epoch: 3797, Loss: 0.7085, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4318.1422\n",
      "Epoch: 3798, Loss: 0.7121, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4319.2785\n",
      "Epoch: 3799, Loss: 0.7087, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4320.4147\n",
      "Epoch: 3800, Loss: 0.7070, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4321.5489\n",
      "Epoch: 3801, Loss: 0.7136, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4322.6848\n",
      "Epoch: 3802, Loss: 0.7100, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4323.8231\n",
      "Epoch: 3803, Loss: 0.7074, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4324.9612\n",
      "Epoch: 3804, Loss: 0.7118, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4326.0993\n",
      "Epoch: 3805, Loss: 0.7103, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4327.2353\n",
      "Epoch: 3806, Loss: 0.7125, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4328.3764\n",
      "Epoch: 3807, Loss: 0.7101, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4329.5173\n",
      "Epoch: 3808, Loss: 0.7125, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4330.6572\n",
      "Epoch: 3809, Loss: 0.7166, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4331.7929\n",
      "Epoch: 3810, Loss: 0.7100, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4332.9337\n",
      "Epoch: 3811, Loss: 0.7091, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4334.0660\n",
      "Epoch: 3812, Loss: 0.7104, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4335.2053\n",
      "Epoch: 3813, Loss: 0.7139, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4336.3433\n",
      "Epoch: 3814, Loss: 0.7101, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4337.4746\n",
      "Epoch: 3815, Loss: 0.7021, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4338.6071\n",
      "Epoch: 3816, Loss: 0.7000, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4339.7411\n",
      "Epoch: 3817, Loss: 0.7001, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4340.8770\n",
      "Epoch: 3818, Loss: 0.6999, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4342.0198\n",
      "Epoch: 3819, Loss: 0.6984, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4343.1585\n",
      "Epoch: 3820, Loss: 0.6943, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4344.2974\n",
      "Epoch: 3821, Loss: 0.6978, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4345.4338\n",
      "Epoch: 3822, Loss: 0.6960, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4346.5717\n",
      "Epoch: 3823, Loss: 0.6981, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4347.7102\n",
      "Epoch: 3824, Loss: 0.7040, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4348.8448\n",
      "Epoch: 3825, Loss: 0.7028, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4349.9832\n",
      "Epoch: 3826, Loss: 0.7014, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4351.1213\n",
      "Epoch: 3827, Loss: 0.7006, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4352.2554\n",
      "Epoch: 3828, Loss: 0.7020, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4353.3913\n",
      "Epoch: 3829, Loss: 0.7056, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4354.5273\n",
      "Epoch: 3830, Loss: 0.7090, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4355.6635\n",
      "Epoch: 3831, Loss: 0.7079, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4356.8026\n",
      "Epoch: 3832, Loss: 0.7026, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4357.9544\n",
      "Epoch: 3833, Loss: 0.7054, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4359.0930\n",
      "Epoch: 3834, Loss: 0.7083, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4360.2304\n",
      "Epoch: 3835, Loss: 0.7068, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4361.3667\n",
      "Epoch: 3836, Loss: 0.7119, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4362.5061\n",
      "Epoch: 3837, Loss: 0.7142, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4363.6381\n",
      "Epoch: 3838, Loss: 0.7009, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4364.7764\n",
      "Epoch: 3839, Loss: 0.7020, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4365.9150\n",
      "Epoch: 3840, Loss: 0.7077, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4367.0524\n",
      "Epoch: 3841, Loss: 0.7105, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4368.1962\n",
      "Epoch: 3842, Loss: 0.7151, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4369.3293\n",
      "Epoch: 3843, Loss: 0.7142, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4370.4642\n",
      "Epoch: 3844, Loss: 0.7094, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4371.6065\n",
      "Epoch: 3845, Loss: 0.7066, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4372.7442\n",
      "Epoch: 3846, Loss: 0.7191, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4373.8839\n",
      "Epoch: 3847, Loss: 0.7197, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4375.0216\n",
      "Epoch: 3848, Loss: 0.7178, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4376.1621\n",
      "Epoch: 3849, Loss: 0.7128, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4377.2994\n",
      "Epoch: 3850, Loss: 0.7122, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4378.4395\n",
      "Epoch: 3851, Loss: 0.7123, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4379.5712\n",
      "Epoch: 3852, Loss: 0.7094, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4380.7079\n",
      "Epoch: 3853, Loss: 0.7115, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4381.8421\n",
      "Epoch: 3854, Loss: 0.7040, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4382.9762\n",
      "Epoch: 3855, Loss: 0.7077, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4384.1084\n",
      "Epoch: 3856, Loss: 0.7133, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4385.2457\n",
      "Epoch: 3857, Loss: 0.7136, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4386.3842\n",
      "Epoch: 3858, Loss: 0.7091, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4387.5238\n",
      "Epoch: 3859, Loss: 0.7057, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4388.6657\n",
      "Epoch: 3860, Loss: 0.7073, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4389.8180\n",
      "Epoch: 3861, Loss: 0.7119, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4390.9578\n",
      "Epoch: 3862, Loss: 0.7093, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4392.0928\n",
      "Epoch: 3863, Loss: 0.7014, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4393.2294\n",
      "Epoch: 3864, Loss: 0.7000, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4394.3634\n",
      "Epoch: 3865, Loss: 0.7109, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4395.4998\n",
      "Epoch: 3866, Loss: 0.7127, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4396.6352\n",
      "Epoch: 3867, Loss: 0.7094, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4397.7708\n",
      "Epoch: 3868, Loss: 0.7074, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4398.9060\n",
      "Epoch: 3869, Loss: 0.7076, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4400.0423\n",
      "Epoch: 3870, Loss: 0.7045, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4401.1767\n",
      "Epoch: 3871, Loss: 0.7049, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4402.3242\n",
      "Epoch: 3872, Loss: 0.7097, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4403.4611\n",
      "Epoch: 3873, Loss: 0.7091, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4404.6083\n",
      "Epoch: 3874, Loss: 0.7062, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4405.7488\n",
      "Epoch: 3875, Loss: 0.7046, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4406.8849\n",
      "Epoch: 3876, Loss: 0.7022, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4408.0189\n",
      "Epoch: 3877, Loss: 0.7082, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4409.1537\n",
      "Epoch: 3878, Loss: 0.7025, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4410.2913\n",
      "Epoch: 3879, Loss: 0.7054, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4411.4284\n",
      "Epoch: 3880, Loss: 0.7008, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4412.5632\n",
      "Epoch: 3881, Loss: 0.7006, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4413.6996\n",
      "Epoch: 3882, Loss: 0.7041, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4414.8372\n",
      "Epoch: 3883, Loss: 0.7019, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4415.9731\n",
      "Epoch: 3884, Loss: 0.7003, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4417.1115\n",
      "Epoch: 3885, Loss: 0.6934, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4418.2498\n",
      "Epoch: 3886, Loss: 0.6940, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4419.3874\n",
      "Epoch: 3887, Loss: 0.7011, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4420.5255\n",
      "Epoch: 3888, Loss: 0.6998, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4421.6647\n",
      "Epoch: 3889, Loss: 0.7051, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4422.8029\n",
      "Epoch: 3890, Loss: 0.6996, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4423.9398\n",
      "Epoch: 3891, Loss: 0.6982, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4425.0738\n",
      "Epoch: 3892, Loss: 0.6981, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4426.2102\n",
      "Epoch: 3893, Loss: 0.7003, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4427.3456\n",
      "Epoch: 3894, Loss: 0.7058, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4428.4799\n",
      "Epoch: 3895, Loss: 0.7055, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4429.6118\n",
      "Epoch: 3896, Loss: 0.7072, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4430.7485\n",
      "Epoch: 3897, Loss: 0.7149, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4431.8864\n",
      "Epoch: 3898, Loss: 0.7124, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4433.0239\n",
      "Epoch: 3899, Loss: 0.7075, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4434.1564\n",
      "Epoch: 3900, Loss: 0.7086, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4435.2937\n",
      "Epoch: 3901, Loss: 0.7080, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4436.4306\n",
      "Epoch: 3902, Loss: 0.7083, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4437.5636\n",
      "Epoch: 3903, Loss: 0.7096, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4438.6982\n",
      "Epoch: 3904, Loss: 0.7089, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4439.8323\n",
      "Epoch: 3905, Loss: 0.7059, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4440.9694\n",
      "Epoch: 3906, Loss: 0.7097, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4442.1113\n",
      "Epoch: 3907, Loss: 0.7109, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4443.2460\n",
      "Epoch: 3908, Loss: 0.7066, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4444.3841\n",
      "Epoch: 3909, Loss: 0.7022, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4445.5165\n",
      "Epoch: 3910, Loss: 0.7001, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4446.6491\n",
      "Epoch: 3911, Loss: 0.7038, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4447.7860\n",
      "Epoch: 3912, Loss: 0.6974, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4448.9250\n",
      "Epoch: 3913, Loss: 0.6939, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4450.0636\n",
      "Epoch: 3914, Loss: 0.6943, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4451.2060\n",
      "Epoch: 3915, Loss: 0.6895, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4452.3498\n",
      "Epoch: 3916, Loss: 0.6911, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4453.4875\n",
      "Epoch: 3917, Loss: 0.6874, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4454.6334\n",
      "Epoch: 3918, Loss: 0.6864, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4455.7658\n",
      "Epoch: 3919, Loss: 0.6896, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4456.8984\n",
      "Epoch: 3920, Loss: 0.7019, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4458.0347\n",
      "Epoch: 3921, Loss: 0.7032, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4459.1679\n",
      "Epoch: 3922, Loss: 0.7032, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4460.3043\n",
      "Epoch: 3923, Loss: 0.7008, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4461.4405\n",
      "Epoch: 3924, Loss: 0.6976, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4462.5860\n",
      "Epoch: 3925, Loss: 0.6979, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4463.7209\n",
      "Epoch: 3926, Loss: 0.6989, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4464.8598\n",
      "Epoch: 3927, Loss: 0.6965, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4465.9995\n",
      "Epoch: 3928, Loss: 0.6996, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4467.1377\n",
      "Epoch: 3929, Loss: 0.7090, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4468.2711\n",
      "Epoch: 3930, Loss: 0.7160, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4469.4059\n",
      "Epoch: 3931, Loss: 0.7153, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4470.5312\n",
      "Epoch: 3932, Loss: 0.7086, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4471.6652\n",
      "Epoch: 3933, Loss: 0.7065, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4472.7955\n",
      "Epoch: 3934, Loss: 0.7061, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4473.9362\n",
      "Epoch: 3935, Loss: 0.7077, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4475.0711\n",
      "Epoch: 3936, Loss: 0.7088, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4476.2075\n",
      "Epoch: 3937, Loss: 0.7060, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4477.3433\n",
      "Epoch: 3938, Loss: 0.7042, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4478.4885\n",
      "Epoch: 3939, Loss: 0.7091, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4479.6275\n",
      "Epoch: 3940, Loss: 0.7077, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4480.7640\n",
      "Epoch: 3941, Loss: 0.7004, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4481.8986\n",
      "Epoch: 3942, Loss: 0.7038, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4483.0367\n",
      "Epoch: 3943, Loss: 0.7052, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4484.1826\n",
      "Epoch: 3944, Loss: 0.7126, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4485.3186\n",
      "Epoch: 3945, Loss: 0.7057, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4486.4523\n",
      "Epoch: 3946, Loss: 0.7035, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4487.5879\n",
      "Epoch: 3947, Loss: 0.7046, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4488.7266\n",
      "Epoch: 3948, Loss: 0.7032, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4489.8616\n",
      "Epoch: 3949, Loss: 0.6978, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4490.9976\n",
      "Epoch: 3950, Loss: 0.6935, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4492.1417\n",
      "Epoch: 3951, Loss: 0.6897, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4493.2813\n",
      "Epoch: 3952, Loss: 0.6857, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 4494.4191\n",
      "Epoch: 3953, Loss: 0.6846, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 4495.5642\n",
      "Epoch: 3954, Loss: 0.6852, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4496.6997\n",
      "Epoch: 3955, Loss: 0.6840, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4497.8373\n",
      "Epoch: 3956, Loss: 0.6819, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4498.9739\n",
      "Epoch: 3957, Loss: 0.6804, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 4500.1071\n",
      "Epoch: 3958, Loss: 0.6815, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4501.2404\n",
      "Epoch: 3959, Loss: 0.6800, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4502.3741\n",
      "Epoch: 3960, Loss: 0.6817, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4503.5098\n",
      "Epoch: 3961, Loss: 0.6812, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4504.6473\n",
      "Epoch: 3962, Loss: 0.6765, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4505.7841\n",
      "Epoch: 3963, Loss: 0.6743, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4506.9162\n",
      "Epoch: 3964, Loss: 0.6742, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4508.0549\n",
      "Epoch: 3965, Loss: 0.6738, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4509.1899\n",
      "Epoch: 3966, Loss: 0.6737, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4510.3254\n",
      "Epoch: 3967, Loss: 0.6761, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4511.4629\n",
      "Epoch: 3968, Loss: 0.6745, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4512.6081\n",
      "Epoch: 3969, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4513.7468\n",
      "Epoch: 3970, Loss: 0.6703, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4514.8870\n",
      "Epoch: 3971, Loss: 0.6712, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4516.0283\n",
      "Epoch: 3972, Loss: 0.6716, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4517.1639\n",
      "Epoch: 3973, Loss: 0.6680, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4518.2984\n",
      "Epoch: 3974, Loss: 0.6645, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4519.4292\n",
      "Epoch: 3975, Loss: 0.6591, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4520.5638\n",
      "Epoch: 3976, Loss: 0.6603, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4521.6974\n",
      "Epoch: 3977, Loss: 0.6609, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4522.8361\n",
      "Epoch: 3978, Loss: 0.6660, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4523.9717\n",
      "Epoch: 3979, Loss: 0.6730, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4525.1069\n",
      "Epoch: 3980, Loss: 0.6734, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4526.2504\n",
      "Epoch: 3981, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4527.3868\n",
      "Epoch: 3982, Loss: 0.6750, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4528.5276\n",
      "Epoch: 3983, Loss: 0.6772, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4529.6652\n",
      "Epoch: 3984, Loss: 0.6800, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4530.7995\n",
      "Epoch: 3985, Loss: 0.6780, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4531.9373\n",
      "Epoch: 3986, Loss: 0.6835, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4533.0706\n",
      "Epoch: 3987, Loss: 0.6843, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4534.2017\n",
      "Epoch: 3988, Loss: 0.6904, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4535.3383\n",
      "Epoch: 3989, Loss: 0.6862, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4536.4717\n",
      "Epoch: 3990, Loss: 0.6862, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4537.6077\n",
      "Epoch: 3991, Loss: 0.6844, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4538.7455\n",
      "Epoch: 3992, Loss: 0.6819, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4539.8883\n",
      "Epoch: 3993, Loss: 0.6799, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4541.0262\n",
      "Epoch: 3994, Loss: 0.6775, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4542.1616\n",
      "Epoch: 3995, Loss: 0.6801, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4543.2975\n",
      "Epoch: 3996, Loss: 0.6873, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4544.4383\n",
      "Epoch: 3997, Loss: 0.6854, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4545.5691\n",
      "Epoch: 3998, Loss: 0.6876, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4546.7045\n",
      "Epoch: 3999, Loss: 0.6859, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4547.8480\n",
      "Epoch: 4000, Loss: 0.6871, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4548.9825\n",
      "Epoch: 4001, Loss: 0.6902, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4550.1161\n",
      "Epoch: 4002, Loss: 0.6846, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 4551.2498\n",
      "Epoch: 4003, Loss: 0.6826, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4552.3843\n",
      "Epoch: 4004, Loss: 0.6864, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4553.5236\n",
      "Epoch: 4005, Loss: 0.6886, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 4554.6568\n",
      "Epoch: 4006, Loss: 0.6840, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4555.7921\n",
      "Epoch: 4007, Loss: 0.6889, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 4556.9254\n",
      "Epoch: 4008, Loss: 0.6870, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4558.0629\n",
      "Epoch: 4009, Loss: 0.6900, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4559.2083\n",
      "Epoch: 4010, Loss: 0.6902, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4560.3498\n",
      "Epoch: 4011, Loss: 0.6866, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4561.4865\n",
      "Epoch: 4012, Loss: 0.6786, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4562.6244\n",
      "Epoch: 4013, Loss: 0.6830, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4563.7579\n",
      "Epoch: 4014, Loss: 0.6822, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4564.8939\n",
      "Epoch: 4015, Loss: 0.6840, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4566.0308\n",
      "Epoch: 4016, Loss: 0.6881, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4567.1624\n",
      "Epoch: 4017, Loss: 0.6852, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4568.2952\n",
      "Epoch: 4018, Loss: 0.6834, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4569.4375\n",
      "Epoch: 4019, Loss: 0.6842, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4570.5741\n",
      "Epoch: 4020, Loss: 0.6828, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4571.7106\n",
      "Epoch: 4021, Loss: 0.6800, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4572.8512\n",
      "Epoch: 4022, Loss: 0.6826, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4573.9841\n",
      "Epoch: 4023, Loss: 0.6845, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4575.1194\n",
      "Epoch: 4024, Loss: 0.6888, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4576.2576\n",
      "Epoch: 4025, Loss: 0.6850, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4577.3928\n",
      "Epoch: 4026, Loss: 0.6767, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4578.5276\n",
      "Epoch: 4027, Loss: 0.6764, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4579.6676\n",
      "Epoch: 4028, Loss: 0.6755, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4580.8012\n",
      "Epoch: 4029, Loss: 0.6744, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4581.9395\n",
      "Epoch: 4030, Loss: 0.6685, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4583.0780\n",
      "Epoch: 4031, Loss: 0.6678, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4584.2185\n",
      "Epoch: 4032, Loss: 0.6687, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4585.3525\n",
      "Epoch: 4033, Loss: 0.6735, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4586.4868\n",
      "Epoch: 4034, Loss: 0.6724, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4587.6213\n",
      "Epoch: 4035, Loss: 0.6719, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4588.7644\n",
      "Epoch: 4036, Loss: 0.6726, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4589.9078\n",
      "Epoch: 4037, Loss: 0.6736, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4591.0492\n",
      "Epoch: 4038, Loss: 0.6760, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4592.1836\n",
      "Epoch: 4039, Loss: 0.6727, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4593.3209\n",
      "Epoch: 4040, Loss: 0.6749, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4594.4562\n",
      "Epoch: 4041, Loss: 0.6743, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4595.5904\n",
      "Epoch: 4042, Loss: 0.6764, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4596.7262\n",
      "Epoch: 4043, Loss: 0.6759, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4597.8611\n",
      "Epoch: 4044, Loss: 0.6725, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4598.9983\n",
      "Epoch: 4045, Loss: 0.6690, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4600.1414\n",
      "Epoch: 4046, Loss: 0.6650, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4601.2769\n",
      "Epoch: 4047, Loss: 0.6687, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4602.4134\n",
      "Epoch: 4048, Loss: 0.6734, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4603.5488\n",
      "Epoch: 4049, Loss: 0.6756, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4604.6877\n",
      "Epoch: 4050, Loss: 0.6727, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4605.8314\n",
      "Epoch: 4051, Loss: 0.6700, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4606.9653\n",
      "Epoch: 4052, Loss: 0.6707, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4608.0984\n",
      "Epoch: 4053, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4609.2318\n",
      "Epoch: 4054, Loss: 0.6772, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4610.3642\n",
      "Epoch: 4055, Loss: 0.6786, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4611.5067\n",
      "Epoch: 4056, Loss: 0.6819, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4612.6365\n",
      "Epoch: 4057, Loss: 0.6867, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4613.7758\n",
      "Epoch: 4058, Loss: 0.6873, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4614.9121\n",
      "Epoch: 4059, Loss: 0.6830, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4616.0489\n",
      "Epoch: 4060, Loss: 0.6810, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4617.1846\n",
      "Epoch: 4061, Loss: 0.6796, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4618.3214\n",
      "Epoch: 4062, Loss: 0.6766, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4619.4592\n",
      "Epoch: 4063, Loss: 0.6775, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 4620.5998\n",
      "Epoch: 4064, Loss: 0.6798, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4621.7412\n",
      "Epoch: 4065, Loss: 0.6800, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4622.8782\n",
      "Epoch: 4066, Loss: 0.6809, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4624.0132\n",
      "Epoch: 4067, Loss: 0.6784, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4625.1448\n",
      "Epoch: 4068, Loss: 0.6786, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4626.2782\n",
      "Epoch: 4069, Loss: 0.6744, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4627.4156\n",
      "Epoch: 4070, Loss: 0.6758, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4628.5507\n",
      "Epoch: 4071, Loss: 0.6760, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4629.6833\n",
      "Epoch: 4072, Loss: 0.6772, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4630.8149\n",
      "Epoch: 4073, Loss: 0.6797, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4631.9472\n",
      "Epoch: 4074, Loss: 0.6785, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4633.0868\n",
      "Epoch: 4075, Loss: 0.6807, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4634.2277\n",
      "Epoch: 4076, Loss: 0.6790, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4635.3660\n",
      "Epoch: 4077, Loss: 0.6796, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4636.4968\n",
      "Epoch: 4078, Loss: 0.6755, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4637.6357\n",
      "Epoch: 4079, Loss: 0.6744, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4638.7737\n",
      "Epoch: 4080, Loss: 0.6755, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4639.9076\n",
      "Epoch: 4081, Loss: 0.6758, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4641.0401\n",
      "Epoch: 4082, Loss: 0.6741, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4642.1712\n",
      "Epoch: 4083, Loss: 0.6708, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4643.3092\n",
      "Epoch: 4084, Loss: 0.6698, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4644.4479\n",
      "Epoch: 4085, Loss: 0.6722, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4645.5855\n",
      "Epoch: 4086, Loss: 0.6717, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4646.7205\n",
      "Epoch: 4087, Loss: 0.6671, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4647.8557\n",
      "Epoch: 4088, Loss: 0.6693, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4648.9941\n",
      "Epoch: 4089, Loss: 0.6697, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4650.1326\n",
      "Epoch: 4090, Loss: 0.6712, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4651.2696\n",
      "Epoch: 4091, Loss: 0.6710, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4652.4086\n",
      "Epoch: 4092, Loss: 0.6763, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4653.5572\n",
      "Epoch: 4093, Loss: 0.6768, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4654.6918\n",
      "Epoch: 4094, Loss: 0.6769, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4655.8258\n",
      "Epoch: 4095, Loss: 0.6774, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4656.9615\n",
      "Epoch: 4096, Loss: 0.6723, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4658.0958\n",
      "Epoch: 4097, Loss: 0.6730, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4659.2289\n",
      "Epoch: 4098, Loss: 0.6722, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4660.3627\n",
      "Epoch: 4099, Loss: 0.6757, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4661.4988\n",
      "Epoch: 4100, Loss: 0.6816, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4662.6322\n",
      "Epoch: 4101, Loss: 0.6780, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4663.7725\n",
      "Epoch: 4102, Loss: 0.6791, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4664.9154\n",
      "Epoch: 4103, Loss: 0.6754, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4666.0555\n",
      "Epoch: 4104, Loss: 0.6769, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4667.1914\n",
      "Epoch: 4105, Loss: 0.6777, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4668.3325\n",
      "Epoch: 4106, Loss: 0.6773, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4669.4768\n",
      "Epoch: 4107, Loss: 0.6702, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4670.6118\n",
      "Epoch: 4108, Loss: 0.6664, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4671.7457\n",
      "Epoch: 4109, Loss: 0.6711, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4672.8803\n",
      "Epoch: 4110, Loss: 0.6795, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4674.0176\n",
      "Epoch: 4111, Loss: 0.6768, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4675.1505\n",
      "Epoch: 4112, Loss: 0.6793, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4676.2866\n",
      "Epoch: 4113, Loss: 0.6856, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4677.4199\n",
      "Epoch: 4114, Loss: 0.6893, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4678.5562\n",
      "Epoch: 4115, Loss: 0.6881, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4679.6902\n",
      "Epoch: 4116, Loss: 0.6869, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4680.8249\n",
      "Epoch: 4117, Loss: 0.6867, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4681.9590\n",
      "Epoch: 4118, Loss: 0.6835, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4683.0916\n",
      "Epoch: 4119, Loss: 0.6866, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4684.2303\n",
      "Epoch: 4120, Loss: 0.6903, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4685.3681\n",
      "Epoch: 4121, Loss: 0.6927, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4686.5037\n",
      "Epoch: 4122, Loss: 0.6891, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4687.6366\n",
      "Epoch: 4123, Loss: 0.6861, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4688.7706\n",
      "Epoch: 4124, Loss: 0.6808, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4689.9022\n",
      "Epoch: 4125, Loss: 0.6802, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4691.0348\n",
      "Epoch: 4126, Loss: 0.6712, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4692.1697\n",
      "Epoch: 4127, Loss: 0.6798, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4693.3024\n",
      "Epoch: 4128, Loss: 0.6787, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4694.4323\n",
      "Epoch: 4129, Loss: 0.6771, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4695.5717\n",
      "Epoch: 4130, Loss: 0.6750, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4696.7128\n",
      "Epoch: 4131, Loss: 0.6746, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4697.8497\n",
      "Epoch: 4132, Loss: 0.6688, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4698.9862\n",
      "Epoch: 4133, Loss: 0.6806, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4700.1240\n",
      "Epoch: 4134, Loss: 0.6821, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4701.2652\n",
      "Epoch: 4135, Loss: 0.6924, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4702.3993\n",
      "Epoch: 4136, Loss: 0.6936, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4703.5345\n",
      "Epoch: 4137, Loss: 0.6825, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4704.6771\n",
      "Epoch: 4138, Loss: 0.6883, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4705.8172\n",
      "Epoch: 4139, Loss: 0.6900, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4706.9631\n",
      "Epoch: 4140, Loss: 0.6928, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4708.0998\n",
      "Epoch: 4141, Loss: 0.6912, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4709.2340\n",
      "Epoch: 4142, Loss: 0.6954, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4710.3687\n",
      "Epoch: 4143, Loss: 0.6937, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4711.5061\n",
      "Epoch: 4144, Loss: 0.6911, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4712.6458\n",
      "Epoch: 4145, Loss: 0.6890, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4713.7898\n",
      "Epoch: 4146, Loss: 0.6929, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4714.9244\n",
      "Epoch: 4147, Loss: 0.6893, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4716.0619\n",
      "Epoch: 4148, Loss: 0.6875, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4717.1976\n",
      "Epoch: 4149, Loss: 0.6821, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4718.3417\n",
      "Epoch: 4150, Loss: 0.6754, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4719.4747\n",
      "Epoch: 4151, Loss: 0.6701, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4720.6098\n",
      "Epoch: 4152, Loss: 0.6650, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4721.7431\n",
      "Epoch: 4153, Loss: 0.6687, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4722.8791\n",
      "Epoch: 4154, Loss: 0.6664, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4724.0172\n",
      "Epoch: 4155, Loss: 0.6750, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4725.1513\n",
      "Epoch: 4156, Loss: 0.6754, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4726.2890\n",
      "Epoch: 4157, Loss: 0.6801, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4727.4267\n",
      "Epoch: 4158, Loss: 0.6813, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4728.5618\n",
      "Epoch: 4159, Loss: 0.6832, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4729.7024\n",
      "Epoch: 4160, Loss: 0.6885, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4730.8390\n",
      "Epoch: 4161, Loss: 0.6773, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4731.9738\n",
      "Epoch: 4162, Loss: 0.6738, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4733.1081\n",
      "Epoch: 4163, Loss: 0.6778, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4734.2431\n",
      "Epoch: 4164, Loss: 0.6840, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4735.3778\n",
      "Epoch: 4165, Loss: 0.6827, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4736.5104\n",
      "Epoch: 4166, Loss: 0.6872, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4737.6539\n",
      "Epoch: 4167, Loss: 0.6869, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4738.7911\n",
      "Epoch: 4168, Loss: 0.6871, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4739.9270\n",
      "Epoch: 4169, Loss: 0.6883, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4741.0658\n",
      "Epoch: 4170, Loss: 0.6856, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4742.2000\n",
      "Epoch: 4171, Loss: 0.6871, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4743.3419\n",
      "Epoch: 4172, Loss: 0.6923, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4744.4784\n",
      "Epoch: 4173, Loss: 0.6955, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4745.6175\n",
      "Epoch: 4174, Loss: 0.6854, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4746.7517\n",
      "Epoch: 4175, Loss: 0.6869, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4747.8909\n",
      "Epoch: 4176, Loss: 0.6878, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4749.0268\n",
      "Epoch: 4177, Loss: 0.6879, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4750.1605\n",
      "Epoch: 4178, Loss: 0.6946, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4751.2905\n",
      "Epoch: 4179, Loss: 0.6862, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4752.4230\n",
      "Epoch: 4180, Loss: 0.6829, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4753.5591\n",
      "Epoch: 4181, Loss: 0.6882, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4754.6974\n",
      "Epoch: 4182, Loss: 0.6875, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4755.8355\n",
      "Epoch: 4183, Loss: 0.6845, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4756.9651\n",
      "Epoch: 4184, Loss: 0.6850, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4758.1002\n",
      "Epoch: 4185, Loss: 0.6865, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4759.2396\n",
      "Epoch: 4186, Loss: 0.6860, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4760.3778\n",
      "Epoch: 4187, Loss: 0.6829, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4761.5111\n",
      "Epoch: 4188, Loss: 0.6806, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4762.6506\n",
      "Epoch: 4189, Loss: 0.6805, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4763.7873\n",
      "Epoch: 4190, Loss: 0.6748, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4764.9280\n",
      "Epoch: 4191, Loss: 0.6726, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 4766.0624\n",
      "Epoch: 4192, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4767.1986\n",
      "Epoch: 4193, Loss: 0.6695, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4768.3329\n",
      "Epoch: 4194, Loss: 0.6685, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4769.4652\n",
      "Epoch: 4195, Loss: 0.6719, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4770.6009\n",
      "Epoch: 4196, Loss: 0.6745, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4771.7365\n",
      "Epoch: 4197, Loss: 0.6750, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4772.8717\n",
      "Epoch: 4198, Loss: 0.6756, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4774.0156\n",
      "Epoch: 4199, Loss: 0.6827, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4775.1531\n",
      "Epoch: 4200, Loss: 0.6840, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4776.2924\n",
      "Epoch: 4201, Loss: 0.6822, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4777.4262\n",
      "Epoch: 4202, Loss: 0.6803, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4778.5583\n",
      "Epoch: 4203, Loss: 0.6788, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4779.6924\n",
      "Epoch: 4204, Loss: 0.6822, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4780.8361\n",
      "Epoch: 4205, Loss: 0.6798, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4781.9738\n",
      "Epoch: 4206, Loss: 0.6850, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4783.1112\n",
      "Epoch: 4207, Loss: 0.6891, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4784.2505\n",
      "Epoch: 4208, Loss: 0.6927, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4785.3879\n",
      "Epoch: 4209, Loss: 0.6890, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4786.5267\n",
      "Epoch: 4210, Loss: 0.6903, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4787.6653\n",
      "Epoch: 4211, Loss: 0.6920, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4788.8002\n",
      "Epoch: 4212, Loss: 0.6932, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4789.9349\n",
      "Epoch: 4213, Loss: 0.6913, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4791.0731\n",
      "Epoch: 4214, Loss: 0.6924, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4792.2149\n",
      "Epoch: 4215, Loss: 0.6926, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4793.3461\n",
      "Epoch: 4216, Loss: 0.6927, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4794.4865\n",
      "Epoch: 4217, Loss: 0.6917, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4795.6271\n",
      "Epoch: 4218, Loss: 0.6974, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4796.7655\n",
      "Epoch: 4219, Loss: 0.7050, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4797.8996\n",
      "Epoch: 4220, Loss: 0.7034, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4799.0362\n",
      "Epoch: 4221, Loss: 0.7050, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4800.1714\n",
      "Epoch: 4222, Loss: 0.7078, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4801.3114\n",
      "Epoch: 4223, Loss: 0.7076, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4802.4567\n",
      "Epoch: 4224, Loss: 0.7075, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4803.5964\n",
      "Epoch: 4225, Loss: 0.7057, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4804.7365\n",
      "Epoch: 4226, Loss: 0.7035, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4805.8733\n",
      "Epoch: 4227, Loss: 0.6993, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4807.0135\n",
      "Epoch: 4228, Loss: 0.6920, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4808.1449\n",
      "Epoch: 4229, Loss: 0.6887, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4809.2834\n",
      "Epoch: 4230, Loss: 0.6863, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4810.4184\n",
      "Epoch: 4231, Loss: 0.6841, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4811.5535\n",
      "Epoch: 4232, Loss: 0.6875, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4812.6922\n",
      "Epoch: 4233, Loss: 0.6991, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4813.8325\n",
      "Epoch: 4234, Loss: 0.7037, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4814.9713\n",
      "Epoch: 4235, Loss: 0.7038, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4816.1039\n",
      "Epoch: 4236, Loss: 0.7045, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4817.2398\n",
      "Epoch: 4237, Loss: 0.7075, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4818.3772\n",
      "Epoch: 4238, Loss: 0.7113, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4819.5128\n",
      "Epoch: 4239, Loss: 0.7136, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4820.6527\n",
      "Epoch: 4240, Loss: 0.7075, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4821.7941\n",
      "Epoch: 4241, Loss: 0.7054, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4822.9277\n",
      "Epoch: 4242, Loss: 0.7044, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4824.0706\n",
      "Epoch: 4243, Loss: 0.6991, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4825.2074\n",
      "Epoch: 4244, Loss: 0.6957, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4826.3432\n",
      "Epoch: 4245, Loss: 0.6927, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4827.4759\n",
      "Epoch: 4246, Loss: 0.6915, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4828.6088\n",
      "Epoch: 4247, Loss: 0.6877, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4829.7431\n",
      "Epoch: 4248, Loss: 0.6951, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4830.8794\n",
      "Epoch: 4249, Loss: 0.6928, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4832.0167\n",
      "Epoch: 4250, Loss: 0.6917, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4833.1563\n",
      "Epoch: 4251, Loss: 0.6916, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4834.3012\n",
      "Epoch: 4252, Loss: 0.6912, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4835.4366\n",
      "Epoch: 4253, Loss: 0.6915, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4836.5757\n",
      "Epoch: 4254, Loss: 0.6949, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4837.7174\n",
      "Epoch: 4255, Loss: 0.6980, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4838.8580\n",
      "Epoch: 4256, Loss: 0.6941, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4839.9912\n",
      "Epoch: 4257, Loss: 0.6867, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4841.1279\n",
      "Epoch: 4258, Loss: 0.6891, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4842.2648\n",
      "Epoch: 4259, Loss: 0.6904, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4843.3973\n",
      "Epoch: 4260, Loss: 0.6958, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4844.5364\n",
      "Epoch: 4261, Loss: 0.6940, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4845.6745\n",
      "Epoch: 4262, Loss: 0.6904, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4846.8095\n",
      "Epoch: 4263, Loss: 0.6842, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4847.9488\n",
      "Epoch: 4264, Loss: 0.6815, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4849.0848\n",
      "Epoch: 4265, Loss: 0.6793, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 4850.2227\n",
      "Epoch: 4266, Loss: 0.6852, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4851.3584\n",
      "Epoch: 4267, Loss: 0.6827, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4852.4942\n",
      "Epoch: 4268, Loss: 0.6869, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4853.6310\n",
      "Epoch: 4269, Loss: 0.6841, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 4854.7696\n",
      "Epoch: 4270, Loss: 0.6828, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4855.9128\n",
      "Epoch: 4271, Loss: 0.6793, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4857.0464\n",
      "Epoch: 4272, Loss: 0.6734, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4858.1827\n",
      "Epoch: 4273, Loss: 0.6779, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4859.3203\n",
      "Epoch: 4274, Loss: 0.6748, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4860.4573\n",
      "Epoch: 4275, Loss: 0.6773, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4861.5921\n",
      "Epoch: 4276, Loss: 0.6798, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4862.7271\n",
      "Epoch: 4277, Loss: 0.6761, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4863.8652\n",
      "Epoch: 4278, Loss: 0.6754, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4865.0031\n",
      "Epoch: 4279, Loss: 0.6762, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4866.1468\n",
      "Epoch: 4280, Loss: 0.6743, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4867.2836\n",
      "Epoch: 4281, Loss: 0.6658, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4868.4181\n",
      "Epoch: 4282, Loss: 0.6659, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4869.5545\n",
      "Epoch: 4283, Loss: 0.6643, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4870.6897\n",
      "Epoch: 4284, Loss: 0.6624, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4871.8207\n",
      "Epoch: 4285, Loss: 0.6615, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4872.9564\n",
      "Epoch: 4286, Loss: 0.6706, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4874.0911\n",
      "Epoch: 4287, Loss: 0.6641, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4875.2290\n",
      "Epoch: 4288, Loss: 0.6657, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4876.3736\n",
      "Epoch: 4289, Loss: 0.6730, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4877.5087\n",
      "Epoch: 4290, Loss: 0.6639, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4878.6502\n",
      "Epoch: 4291, Loss: 0.6702, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4879.7878\n",
      "Epoch: 4292, Loss: 0.6653, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4880.9277\n",
      "Epoch: 4293, Loss: 0.6746, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4882.0628\n",
      "Epoch: 4294, Loss: 0.6754, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4883.1934\n",
      "Epoch: 4295, Loss: 0.6817, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4884.3286\n",
      "Epoch: 4296, Loss: 0.6849, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4885.4656\n",
      "Epoch: 4297, Loss: 0.6779, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4886.5989\n",
      "Epoch: 4298, Loss: 0.6817, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4887.7305\n",
      "Epoch: 4299, Loss: 0.6922, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4888.8670\n",
      "Epoch: 4300, Loss: 0.6869, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4890.0003\n",
      "Epoch: 4301, Loss: 0.6902, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4891.1374\n",
      "Epoch: 4302, Loss: 0.6952, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4892.2718\n",
      "Epoch: 4303, Loss: 0.6946, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4893.4077\n",
      "Epoch: 4304, Loss: 0.6958, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4894.5476\n",
      "Epoch: 4305, Loss: 0.6934, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4895.6844\n",
      "Epoch: 4306, Loss: 0.6904, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4896.8267\n",
      "Epoch: 4307, Loss: 0.6931, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4897.9626\n",
      "Epoch: 4308, Loss: 0.6852, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4899.0982\n",
      "Epoch: 4309, Loss: 0.6832, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4900.2333\n",
      "Epoch: 4310, Loss: 0.6813, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4901.3655\n",
      "Epoch: 4311, Loss: 0.6880, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4902.5013\n",
      "Epoch: 4312, Loss: 0.6877, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4903.6374\n",
      "Epoch: 4313, Loss: 0.6851, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4904.7708\n",
      "Epoch: 4314, Loss: 0.6899, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4905.9056\n",
      "Epoch: 4315, Loss: 0.6902, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 4907.0415\n",
      "Epoch: 4316, Loss: 0.6854, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 4908.1845\n",
      "Epoch: 4317, Loss: 0.6811, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 4909.3204\n",
      "Epoch: 4318, Loss: 0.6877, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4910.4570\n",
      "Epoch: 4319, Loss: 0.6803, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4911.5968\n",
      "Epoch: 4320, Loss: 0.6870, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4912.7308\n",
      "Epoch: 4321, Loss: 0.6830, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4913.8695\n",
      "Epoch: 4322, Loss: 0.6820, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4915.0106\n",
      "Epoch: 4323, Loss: 0.6788, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4916.1521\n",
      "Epoch: 4324, Loss: 0.6806, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4917.2896\n",
      "Epoch: 4325, Loss: 0.6774, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4918.4283\n",
      "Epoch: 4326, Loss: 0.6753, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4919.5643\n",
      "Epoch: 4327, Loss: 0.6763, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4920.6973\n",
      "Epoch: 4328, Loss: 0.6768, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4921.8330\n",
      "Epoch: 4329, Loss: 0.6778, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4922.9715\n",
      "Epoch: 4330, Loss: 0.6702, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4924.1082\n",
      "Epoch: 4331, Loss: 0.6731, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4925.2461\n",
      "Epoch: 4332, Loss: 0.6733, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4926.3848\n",
      "Epoch: 4333, Loss: 0.6766, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4927.5204\n",
      "Epoch: 4334, Loss: 0.6781, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4928.6542\n",
      "Epoch: 4335, Loss: 0.6770, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4929.7938\n",
      "Epoch: 4336, Loss: 0.6760, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4930.9303\n",
      "Epoch: 4337, Loss: 0.6806, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4932.0645\n",
      "Epoch: 4338, Loss: 0.6775, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4933.1997\n",
      "Epoch: 4339, Loss: 0.6835, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4934.3348\n",
      "Epoch: 4340, Loss: 0.6855, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4935.4713\n",
      "Epoch: 4341, Loss: 0.6875, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4936.6049\n",
      "Epoch: 4342, Loss: 0.6827, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4937.7362\n",
      "Epoch: 4343, Loss: 0.6822, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 4938.8757\n",
      "Epoch: 4344, Loss: 0.6816, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4940.0137\n",
      "Epoch: 4345, Loss: 0.6760, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4941.1509\n",
      "Epoch: 4346, Loss: 0.6827, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4942.2900\n",
      "Epoch: 4347, Loss: 0.6787, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4943.4293\n",
      "Epoch: 4348, Loss: 0.6776, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4944.5637\n",
      "Epoch: 4349, Loss: 0.6826, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4945.7035\n",
      "Epoch: 4350, Loss: 0.6778, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4946.8397\n",
      "Epoch: 4351, Loss: 0.6736, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4947.9727\n",
      "Epoch: 4352, Loss: 0.6728, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4949.1094\n",
      "Epoch: 4353, Loss: 0.6736, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4950.2533\n",
      "Epoch: 4354, Loss: 0.6718, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4951.3883\n",
      "Epoch: 4355, Loss: 0.6762, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4952.5309\n",
      "Epoch: 4356, Loss: 0.6760, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4953.6651\n",
      "Epoch: 4357, Loss: 0.6739, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4954.8053\n",
      "Epoch: 4358, Loss: 0.6769, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 4955.9473\n",
      "Epoch: 4359, Loss: 0.6757, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 4957.0873\n",
      "Epoch: 4360, Loss: 0.6756, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4958.2227\n",
      "Epoch: 4361, Loss: 0.6719, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4959.3669\n",
      "Epoch: 4362, Loss: 0.6725, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4960.5067\n",
      "Epoch: 4363, Loss: 0.6726, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4961.6420\n",
      "Epoch: 4364, Loss: 0.6725, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4962.7750\n",
      "Epoch: 4365, Loss: 0.6769, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4963.9132\n",
      "Epoch: 4366, Loss: 0.6816, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4965.0458\n",
      "Epoch: 4367, Loss: 0.6801, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4966.1782\n",
      "Epoch: 4368, Loss: 0.6806, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4967.3120\n",
      "Epoch: 4369, Loss: 0.6763, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4968.4478\n",
      "Epoch: 4370, Loss: 0.6785, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4969.5868\n",
      "Epoch: 4371, Loss: 0.6823, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4970.7243\n",
      "Epoch: 4372, Loss: 0.6863, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4971.8696\n",
      "Epoch: 4373, Loss: 0.6880, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4973.0065\n",
      "Epoch: 4374, Loss: 0.6855, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4974.1420\n",
      "Epoch: 4375, Loss: 0.6819, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4975.2753\n",
      "Epoch: 4376, Loss: 0.6825, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4976.4163\n",
      "Epoch: 4377, Loss: 0.6818, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4977.5502\n",
      "Epoch: 4378, Loss: 0.6863, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4978.6846\n",
      "Epoch: 4379, Loss: 0.6873, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4979.8174\n",
      "Epoch: 4380, Loss: 0.6892, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4980.9526\n",
      "Epoch: 4381, Loss: 0.6902, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4982.0947\n",
      "Epoch: 4382, Loss: 0.6859, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4983.2305\n",
      "Epoch: 4383, Loss: 0.6851, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4984.3675\n",
      "Epoch: 4384, Loss: 0.6832, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4985.5043\n",
      "Epoch: 4385, Loss: 0.6831, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4986.6402\n",
      "Epoch: 4386, Loss: 0.6844, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4987.7795\n",
      "Epoch: 4387, Loss: 0.6834, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 4988.9181\n",
      "Epoch: 4388, Loss: 0.6804, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4990.0480\n",
      "Epoch: 4389, Loss: 0.6812, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 4991.1862\n",
      "Epoch: 4390, Loss: 0.6829, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 4992.3283\n",
      "Epoch: 4391, Loss: 0.6771, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4993.4622\n",
      "Epoch: 4392, Loss: 0.6763, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 4994.5968\n",
      "Epoch: 4393, Loss: 0.6763, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4995.7338\n",
      "Epoch: 4394, Loss: 0.6814, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 4996.8643\n",
      "Epoch: 4395, Loss: 0.6784, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4998.0024\n",
      "Epoch: 4396, Loss: 0.6772, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 4999.1370\n",
      "Epoch: 4397, Loss: 0.6768, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5000.2796\n",
      "Epoch: 4398, Loss: 0.6736, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5001.4208\n",
      "Epoch: 4399, Loss: 0.6754, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5002.5622\n",
      "Epoch: 4400, Loss: 0.6783, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5003.7154\n",
      "Epoch: 4401, Loss: 0.6770, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5004.8505\n",
      "Epoch: 4402, Loss: 0.6762, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5005.9927\n",
      "Epoch: 4403, Loss: 0.6771, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5007.1307\n",
      "Epoch: 4404, Loss: 0.6772, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5008.2661\n",
      "Epoch: 4405, Loss: 0.6772, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5009.4012\n",
      "Epoch: 4406, Loss: 0.6756, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5010.5345\n",
      "Epoch: 4407, Loss: 0.6764, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5011.6713\n",
      "Epoch: 4408, Loss: 0.6822, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5012.8048\n",
      "Epoch: 4409, Loss: 0.6867, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5013.9474\n",
      "Epoch: 4410, Loss: 0.6851, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5015.0945\n",
      "Epoch: 4411, Loss: 0.6820, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5016.2348\n",
      "Epoch: 4412, Loss: 0.6843, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5017.3697\n",
      "Epoch: 4413, Loss: 0.6705, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5018.5069\n",
      "Epoch: 4414, Loss: 0.6825, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5019.6493\n",
      "Epoch: 4415, Loss: 0.6853, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5020.7839\n",
      "Epoch: 4416, Loss: 0.6808, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5021.9176\n",
      "Epoch: 4417, Loss: 0.6788, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5023.0558\n",
      "Epoch: 4418, Loss: 0.6841, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5024.1999\n",
      "Epoch: 4419, Loss: 0.6822, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5025.3355\n",
      "Epoch: 4420, Loss: 0.6835, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5026.4719\n",
      "Epoch: 4421, Loss: 0.6844, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5027.6072\n",
      "Epoch: 4422, Loss: 0.6848, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5028.7456\n",
      "Epoch: 4423, Loss: 0.6845, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5029.8825\n",
      "Epoch: 4424, Loss: 0.6808, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5031.0206\n",
      "Epoch: 4425, Loss: 0.6766, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5032.1548\n",
      "Epoch: 4426, Loss: 0.6756, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5033.2899\n",
      "Epoch: 4427, Loss: 0.6749, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5034.4383\n",
      "Epoch: 4428, Loss: 0.6741, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5035.5834\n",
      "Epoch: 4429, Loss: 0.6772, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5036.7197\n",
      "Epoch: 4430, Loss: 0.6766, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5037.8558\n",
      "Epoch: 4431, Loss: 0.6771, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5038.9933\n",
      "Epoch: 4432, Loss: 0.6768, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5040.1275\n",
      "Epoch: 4433, Loss: 0.6789, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5041.2643\n",
      "Epoch: 4434, Loss: 0.6815, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5042.4030\n",
      "Epoch: 4435, Loss: 0.6808, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5043.5371\n",
      "Epoch: 4436, Loss: 0.6744, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5044.6795\n",
      "Epoch: 4437, Loss: 0.6710, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5045.8165\n",
      "Epoch: 4438, Loss: 0.6719, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5046.9507\n",
      "Epoch: 4439, Loss: 0.6687, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5048.0887\n",
      "Epoch: 4440, Loss: 0.6685, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5049.2239\n",
      "Epoch: 4441, Loss: 0.6717, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5050.3580\n",
      "Epoch: 4442, Loss: 0.6728, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5051.4925\n",
      "Epoch: 4443, Loss: 0.6782, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5052.6257\n",
      "Epoch: 4444, Loss: 0.6793, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5053.7649\n",
      "Epoch: 4445, Loss: 0.6837, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5054.8973\n",
      "Epoch: 4446, Loss: 0.6806, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5056.0265\n",
      "Epoch: 4447, Loss: 0.6841, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5057.1556\n",
      "Epoch: 4448, Loss: 0.6821, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5058.2895\n",
      "Epoch: 4449, Loss: 0.6834, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5059.4284\n",
      "Epoch: 4450, Loss: 0.6812, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5060.5670\n",
      "Epoch: 4451, Loss: 0.6785, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5061.7076\n",
      "Epoch: 4452, Loss: 0.6808, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5062.8438\n",
      "Epoch: 4453, Loss: 0.6805, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5063.9834\n",
      "Epoch: 4454, Loss: 0.6844, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5065.1185\n",
      "Epoch: 4455, Loss: 0.6861, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5066.2570\n",
      "Epoch: 4456, Loss: 0.6878, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5067.3972\n",
      "Epoch: 4457, Loss: 0.6893, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5068.5311\n",
      "Epoch: 4458, Loss: 0.6897, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5069.6653\n",
      "Epoch: 4459, Loss: 0.6869, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5070.8014\n",
      "Epoch: 4460, Loss: 0.6864, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5071.9354\n",
      "Epoch: 4461, Loss: 0.6816, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5073.0721\n",
      "Epoch: 4462, Loss: 0.6834, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5074.2076\n",
      "Epoch: 4463, Loss: 0.6841, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5075.3450\n",
      "Epoch: 4464, Loss: 0.6851, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5076.4834\n",
      "Epoch: 4465, Loss: 0.6875, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5077.6203\n",
      "Epoch: 4466, Loss: 0.6867, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5078.7576\n",
      "Epoch: 4467, Loss: 0.6862, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5079.8986\n",
      "Epoch: 4468, Loss: 0.6813, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5081.0375\n",
      "Epoch: 4469, Loss: 0.6796, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5082.1717\n",
      "Epoch: 4470, Loss: 0.6820, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5083.3044\n",
      "Epoch: 4471, Loss: 0.6801, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5084.4362\n",
      "Epoch: 4472, Loss: 0.6836, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5085.5733\n",
      "Epoch: 4473, Loss: 0.6871, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5086.7061\n",
      "Epoch: 4474, Loss: 0.6905, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5087.8498\n",
      "Epoch: 4475, Loss: 0.6908, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5088.9878\n",
      "Epoch: 4476, Loss: 0.6931, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5090.1249\n",
      "Epoch: 4477, Loss: 0.6951, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5091.2612\n",
      "Epoch: 4478, Loss: 0.6886, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5092.3984\n",
      "Epoch: 4479, Loss: 0.6923, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5093.5349\n",
      "Epoch: 4480, Loss: 0.6938, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5094.6696\n",
      "Epoch: 4481, Loss: 0.6946, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5095.8062\n",
      "Epoch: 4482, Loss: 0.6942, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5096.9488\n",
      "Epoch: 4483, Loss: 0.6929, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5098.0835\n",
      "Epoch: 4484, Loss: 0.6955, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5099.2186\n",
      "Epoch: 4485, Loss: 0.6911, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5100.3544\n",
      "Epoch: 4486, Loss: 0.6905, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5101.4879\n",
      "Epoch: 4487, Loss: 0.6922, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5102.6232\n",
      "Epoch: 4488, Loss: 0.6921, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5103.7543\n",
      "Epoch: 4489, Loss: 0.6989, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5104.8964\n",
      "Epoch: 4490, Loss: 0.6996, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5106.0308\n",
      "Epoch: 4491, Loss: 0.6969, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5107.1645\n",
      "Epoch: 4492, Loss: 0.6993, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5108.3046\n",
      "Epoch: 4493, Loss: 0.7035, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5109.4439\n",
      "Epoch: 4494, Loss: 0.7028, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5110.5797\n",
      "Epoch: 4495, Loss: 0.7058, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5111.7108\n",
      "Epoch: 4496, Loss: 0.7067, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5112.8402\n",
      "Epoch: 4497, Loss: 0.7097, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5113.9708\n",
      "Epoch: 4498, Loss: 0.7100, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5115.1033\n",
      "Epoch: 4499, Loss: 0.7080, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5116.2384\n",
      "Epoch: 4500, Loss: 0.7100, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5117.3696\n",
      "Epoch: 4501, Loss: 0.7138, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5118.5014\n",
      "Epoch: 4502, Loss: 0.7132, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5119.6406\n",
      "Epoch: 4503, Loss: 0.7083, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5120.7780\n",
      "Epoch: 4504, Loss: 0.7066, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5121.9137\n",
      "Epoch: 4505, Loss: 0.7054, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5123.0496\n",
      "Epoch: 4506, Loss: 0.7035, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5124.1868\n",
      "Epoch: 4507, Loss: 0.7060, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5125.3252\n",
      "Epoch: 4508, Loss: 0.7065, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5126.4578\n",
      "Epoch: 4509, Loss: 0.7049, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5127.5982\n",
      "Epoch: 4510, Loss: 0.6990, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5128.7321\n",
      "Epoch: 4511, Loss: 0.6993, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5129.8766\n",
      "Epoch: 4512, Loss: 0.6971, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5131.0094\n",
      "Epoch: 4513, Loss: 0.6989, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5132.1419\n",
      "Epoch: 4514, Loss: 0.6984, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5133.2771\n",
      "Epoch: 4515, Loss: 0.6974, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5134.4115\n",
      "Epoch: 4516, Loss: 0.6964, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5135.5461\n",
      "Epoch: 4517, Loss: 0.6910, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5136.6837\n",
      "Epoch: 4518, Loss: 0.6904, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5137.8227\n",
      "Epoch: 4519, Loss: 0.6876, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5138.9603\n",
      "Epoch: 4520, Loss: 0.6882, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5140.1023\n",
      "Epoch: 4521, Loss: 0.6866, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5141.2407\n",
      "Epoch: 4522, Loss: 0.6880, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5142.3751\n",
      "Epoch: 4523, Loss: 0.6979, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5143.5079\n",
      "Epoch: 4524, Loss: 0.6960, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5144.6385\n",
      "Epoch: 4525, Loss: 0.6923, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5145.7717\n",
      "Epoch: 4526, Loss: 0.6901, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5146.9060\n",
      "Epoch: 4527, Loss: 0.6881, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5148.0418\n",
      "Epoch: 4528, Loss: 0.6883, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5149.1758\n",
      "Epoch: 4529, Loss: 0.6877, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5150.3145\n",
      "Epoch: 4530, Loss: 0.6891, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5151.4568\n",
      "Epoch: 4531, Loss: 0.6888, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5152.5915\n",
      "Epoch: 4532, Loss: 0.6869, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5153.7321\n",
      "Epoch: 4533, Loss: 0.6852, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5154.8702\n",
      "Epoch: 4534, Loss: 0.6884, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5156.0101\n",
      "Epoch: 4535, Loss: 0.6968, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 5157.1466\n",
      "Epoch: 4536, Loss: 0.7019, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5158.2774\n",
      "Epoch: 4537, Loss: 0.7033, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5159.4153\n",
      "Epoch: 4538, Loss: 0.7041, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5160.5547\n",
      "Epoch: 4539, Loss: 0.7037, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5161.6904\n",
      "Epoch: 4540, Loss: 0.7010, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5162.8209\n",
      "Epoch: 4541, Loss: 0.6983, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5163.9563\n",
      "Epoch: 4542, Loss: 0.6955, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5165.0907\n",
      "Epoch: 4543, Loss: 0.6951, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5166.2223\n",
      "Epoch: 4544, Loss: 0.6991, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5167.3597\n",
      "Epoch: 4545, Loss: 0.7028, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 5168.5001\n",
      "Epoch: 4546, Loss: 0.7082, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5169.6352\n",
      "Epoch: 4547, Loss: 0.7055, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5170.7736\n",
      "Epoch: 4548, Loss: 0.7080, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5171.9167\n",
      "Epoch: 4549, Loss: 0.7035, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5173.0519\n",
      "Epoch: 4550, Loss: 0.7031, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5174.1818\n",
      "Epoch: 4551, Loss: 0.6983, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5175.3160\n",
      "Epoch: 4552, Loss: 0.6962, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5176.4506\n",
      "Epoch: 4553, Loss: 0.6993, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5177.5872\n",
      "Epoch: 4554, Loss: 0.6924, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5178.7180\n",
      "Epoch: 4555, Loss: 0.6946, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5179.8498\n",
      "Epoch: 4556, Loss: 0.6974, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5180.9785\n",
      "Epoch: 4557, Loss: 0.6970, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5182.1188\n",
      "Epoch: 4558, Loss: 0.6955, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5183.2593\n",
      "Epoch: 4559, Loss: 0.7039, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 5184.3956\n",
      "Epoch: 4560, Loss: 0.7056, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5185.5303\n",
      "Epoch: 4561, Loss: 0.7059, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5186.6702\n",
      "Epoch: 4562, Loss: 0.7151, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5187.8125\n",
      "Epoch: 4563, Loss: 0.7188, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5188.9442\n",
      "Epoch: 4564, Loss: 0.7130, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5190.0781\n",
      "Epoch: 4565, Loss: 0.7070, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5191.2098\n",
      "Epoch: 4566, Loss: 0.7002, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 5192.3468\n",
      "Epoch: 4567, Loss: 0.7038, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5193.4825\n",
      "Epoch: 4568, Loss: 0.6982, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5194.6159\n",
      "Epoch: 4569, Loss: 0.6994, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5195.7485\n",
      "Epoch: 4570, Loss: 0.6986, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5196.8838\n",
      "Epoch: 4571, Loss: 0.6981, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5198.0207\n",
      "Epoch: 4572, Loss: 0.6970, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5199.1643\n",
      "Epoch: 4573, Loss: 0.6939, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5200.3080\n",
      "Epoch: 4574, Loss: 0.6939, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5201.4464\n",
      "Epoch: 4575, Loss: 0.6956, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5202.5777\n",
      "Epoch: 4576, Loss: 0.6956, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5203.7080\n",
      "Epoch: 4577, Loss: 0.6958, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5204.8452\n",
      "Epoch: 4578, Loss: 0.6933, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5205.9779\n",
      "Epoch: 4579, Loss: 0.6939, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 5207.1111\n",
      "Epoch: 4580, Loss: 0.6959, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 5208.2435\n",
      "Epoch: 4581, Loss: 0.6967, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 5209.3773\n",
      "Epoch: 4582, Loss: 0.6964, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 5210.5117\n",
      "Epoch: 4583, Loss: 0.7027, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5211.6445\n",
      "Epoch: 4584, Loss: 0.6962, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5212.7815\n",
      "Epoch: 4585, Loss: 0.6942, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5213.9239\n",
      "Epoch: 4586, Loss: 0.6971, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5215.0666\n",
      "Epoch: 4587, Loss: 0.7087, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5216.2035\n",
      "Epoch: 4588, Loss: 0.7107, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5217.3399\n",
      "Epoch: 4589, Loss: 0.7138, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5218.4749\n",
      "Epoch: 4590, Loss: 0.7223, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5219.6071\n",
      "Epoch: 4591, Loss: 0.7208, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5220.7407\n",
      "Epoch: 4592, Loss: 0.7186, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5221.8723\n",
      "Epoch: 4593, Loss: 0.7198, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5223.0075\n",
      "Epoch: 4594, Loss: 0.7133, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5224.1418\n",
      "Epoch: 4595, Loss: 0.7107, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5225.2714\n",
      "Epoch: 4596, Loss: 0.7083, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5226.4108\n",
      "Epoch: 4597, Loss: 0.7068, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5227.5478\n",
      "Epoch: 4598, Loss: 0.7068, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5228.6881\n",
      "Epoch: 4599, Loss: 0.7000, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5229.8272\n",
      "Epoch: 4600, Loss: 0.6967, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5230.9622\n",
      "Epoch: 4601, Loss: 0.6929, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5232.0995\n",
      "Epoch: 4602, Loss: 0.6880, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5233.2377\n",
      "Epoch: 4603, Loss: 0.6878, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5234.3741\n",
      "Epoch: 4604, Loss: 0.6891, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5235.5078\n",
      "Epoch: 4605, Loss: 0.6894, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5236.6496\n",
      "Epoch: 4606, Loss: 0.6872, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5237.7833\n",
      "Epoch: 4607, Loss: 0.6937, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5238.9171\n",
      "Epoch: 4608, Loss: 0.6931, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5240.0523\n",
      "Epoch: 4609, Loss: 0.6946, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5241.1855\n",
      "Epoch: 4610, Loss: 0.6927, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5242.3219\n",
      "Epoch: 4611, Loss: 0.6926, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5243.4623\n",
      "Epoch: 4612, Loss: 0.6879, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5244.6010\n",
      "Epoch: 4613, Loss: 0.6927, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5245.7361\n",
      "Epoch: 4614, Loss: 0.6964, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5246.8742\n",
      "Epoch: 4615, Loss: 0.6955, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5248.0172\n",
      "Epoch: 4616, Loss: 0.6926, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5249.1506\n",
      "Epoch: 4617, Loss: 0.6992, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5250.2813\n",
      "Epoch: 4618, Loss: 0.6994, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5251.4176\n",
      "Epoch: 4619, Loss: 0.6960, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5252.5485\n",
      "Epoch: 4620, Loss: 0.6870, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5253.6858\n",
      "Epoch: 4621, Loss: 0.6860, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5254.8204\n",
      "Epoch: 4622, Loss: 0.6769, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5255.9499\n",
      "Epoch: 4623, Loss: 0.6775, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5257.0804\n",
      "Epoch: 4624, Loss: 0.6776, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5258.2175\n",
      "Epoch: 4625, Loss: 0.6773, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5259.3589\n",
      "Epoch: 4626, Loss: 0.6758, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5260.4953\n",
      "Epoch: 4627, Loss: 0.6747, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5261.6351\n",
      "Epoch: 4628, Loss: 0.6770, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5262.7730\n",
      "Epoch: 4629, Loss: 0.6746, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5263.9171\n",
      "Epoch: 4630, Loss: 0.6778, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5265.0523\n",
      "Epoch: 4631, Loss: 0.6815, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5266.1879\n",
      "Epoch: 4632, Loss: 0.6828, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5267.3217\n",
      "Epoch: 4633, Loss: 0.6878, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5268.4595\n",
      "Epoch: 4634, Loss: 0.6887, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5269.5972\n",
      "Epoch: 4635, Loss: 0.6891, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5270.7333\n",
      "Epoch: 4636, Loss: 0.6835, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5271.8657\n",
      "Epoch: 4637, Loss: 0.6831, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5273.0009\n",
      "Epoch: 4638, Loss: 0.6842, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5274.1444\n",
      "Epoch: 4639, Loss: 0.6807, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5275.2831\n",
      "Epoch: 4640, Loss: 0.6792, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5276.4224\n",
      "Epoch: 4641, Loss: 0.6800, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5277.5612\n",
      "Epoch: 4642, Loss: 0.6799, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5278.7029\n",
      "Epoch: 4643, Loss: 0.6784, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5279.8454\n",
      "Epoch: 4644, Loss: 0.6787, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5280.9772\n",
      "Epoch: 4645, Loss: 0.6781, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5282.1156\n",
      "Epoch: 4646, Loss: 0.6759, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5283.2517\n",
      "Epoch: 4647, Loss: 0.6748, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5284.3841\n",
      "Epoch: 4648, Loss: 0.6746, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5285.5154\n",
      "Epoch: 4649, Loss: 0.6718, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5286.6491\n",
      "Epoch: 4650, Loss: 0.6701, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5287.7833\n",
      "Epoch: 4651, Loss: 0.6726, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5288.9213\n",
      "Epoch: 4652, Loss: 0.6717, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5290.0677\n",
      "Epoch: 4653, Loss: 0.6660, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5291.2024\n",
      "Epoch: 4654, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 5292.3384\n",
      "Epoch: 4655, Loss: 0.6624, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5293.4773\n",
      "Epoch: 4656, Loss: 0.6634, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5294.6151\n",
      "Epoch: 4657, Loss: 0.6635, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5295.7499\n",
      "Epoch: 4658, Loss: 0.6657, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5296.8832\n",
      "Epoch: 4659, Loss: 0.6694, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5298.0155\n",
      "Epoch: 4660, Loss: 0.6709, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5299.1541\n",
      "Epoch: 4661, Loss: 0.6728, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5300.2944\n",
      "Epoch: 4662, Loss: 0.6739, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5301.4318\n",
      "Epoch: 4663, Loss: 0.6756, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5302.5682\n",
      "Epoch: 4664, Loss: 0.6737, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5303.7064\n",
      "Epoch: 4665, Loss: 0.6771, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5304.8547\n",
      "Epoch: 4666, Loss: 0.6795, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5305.9970\n",
      "Epoch: 4667, Loss: 0.6846, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5307.1305\n",
      "Epoch: 4668, Loss: 0.6843, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5308.2745\n",
      "Epoch: 4669, Loss: 0.6814, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5309.4167\n",
      "Epoch: 4670, Loss: 0.6801, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5310.5520\n",
      "Epoch: 4671, Loss: 0.6817, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5311.6908\n",
      "Epoch: 4672, Loss: 0.6832, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5312.8246\n",
      "Epoch: 4673, Loss: 0.6849, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5313.9606\n",
      "Epoch: 4674, Loss: 0.6861, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5315.0992\n",
      "Epoch: 4675, Loss: 0.6783, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5316.2363\n",
      "Epoch: 4676, Loss: 0.6733, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5317.3736\n",
      "Epoch: 4677, Loss: 0.6720, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5318.5103\n",
      "Epoch: 4678, Loss: 0.6730, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5319.6506\n",
      "Epoch: 4679, Loss: 0.6720, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5320.7906\n",
      "Epoch: 4680, Loss: 0.6728, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5321.9306\n",
      "Epoch: 4681, Loss: 0.6779, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5323.0652\n",
      "Epoch: 4682, Loss: 0.6775, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5324.2073\n",
      "Epoch: 4683, Loss: 0.6838, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5325.3418\n",
      "Epoch: 4684, Loss: 0.6891, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5326.4749\n",
      "Epoch: 4685, Loss: 0.6886, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5327.6072\n",
      "Epoch: 4686, Loss: 0.6832, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5328.7406\n",
      "Epoch: 4687, Loss: 0.6857, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5329.8756\n",
      "Epoch: 4688, Loss: 0.6836, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5331.0089\n",
      "Epoch: 4689, Loss: 0.6853, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5332.1485\n",
      "Epoch: 4690, Loss: 0.6846, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5333.2832\n",
      "Epoch: 4691, Loss: 0.6872, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 5334.4185\n",
      "Epoch: 4692, Loss: 0.6893, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 5335.5588\n",
      "Epoch: 4693, Loss: 0.6879, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 5336.6992\n",
      "Epoch: 4694, Loss: 0.6879, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5337.8351\n",
      "Epoch: 4695, Loss: 0.6892, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5338.9811\n",
      "Epoch: 4696, Loss: 0.6899, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5340.1120\n",
      "Epoch: 4697, Loss: 0.6931, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5341.2508\n",
      "Epoch: 4698, Loss: 0.6909, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5342.3894\n",
      "Epoch: 4699, Loss: 0.6863, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5343.5240\n",
      "Epoch: 4700, Loss: 0.6840, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5344.6581\n",
      "Epoch: 4701, Loss: 0.6811, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5345.7929\n",
      "Epoch: 4702, Loss: 0.6834, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5346.9282\n",
      "Epoch: 4703, Loss: 0.6836, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5348.0657\n",
      "Epoch: 4704, Loss: 0.6874, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5349.1991\n",
      "Epoch: 4705, Loss: 0.6878, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5350.3396\n",
      "Epoch: 4706, Loss: 0.6879, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5351.4769\n",
      "Epoch: 4707, Loss: 0.6896, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5352.6166\n",
      "Epoch: 4708, Loss: 0.6911, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5353.7558\n",
      "Epoch: 4709, Loss: 0.6868, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5354.8980\n",
      "Epoch: 4710, Loss: 0.6853, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5356.0313\n",
      "Epoch: 4711, Loss: 0.6870, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5357.1626\n",
      "Epoch: 4712, Loss: 0.6823, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5358.2959\n",
      "Epoch: 4713, Loss: 0.6824, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5359.4273\n",
      "Epoch: 4714, Loss: 0.6819, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5360.5623\n",
      "Epoch: 4715, Loss: 0.6829, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5361.6972\n",
      "Epoch: 4716, Loss: 0.6803, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5362.8324\n",
      "Epoch: 4717, Loss: 0.6755, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5363.9718\n",
      "Epoch: 4718, Loss: 0.6766, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5365.1081\n",
      "Epoch: 4719, Loss: 0.6800, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5366.2493\n",
      "Epoch: 4720, Loss: 0.6761, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5367.3852\n",
      "Epoch: 4721, Loss: 0.6765, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5368.5195\n",
      "Epoch: 4722, Loss: 0.6795, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5369.6694\n",
      "Epoch: 4723, Loss: 0.6789, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5370.8021\n",
      "Epoch: 4724, Loss: 0.6826, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5371.9383\n",
      "Epoch: 4725, Loss: 0.6784, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5373.0689\n",
      "Epoch: 4726, Loss: 0.6811, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5374.2034\n",
      "Epoch: 4727, Loss: 0.6807, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5375.3369\n",
      "Epoch: 4728, Loss: 0.6829, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5376.4711\n",
      "Epoch: 4729, Loss: 0.6850, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5377.6104\n",
      "Epoch: 4730, Loss: 0.6830, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5378.7458\n",
      "Epoch: 4731, Loss: 0.6819, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5379.8804\n",
      "Epoch: 4732, Loss: 0.6778, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5381.0176\n",
      "Epoch: 4733, Loss: 0.6792, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5382.1514\n",
      "Epoch: 4734, Loss: 0.6786, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5383.2891\n",
      "Epoch: 4735, Loss: 0.6772, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5384.4297\n",
      "Epoch: 4736, Loss: 0.6764, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5385.5657\n",
      "Epoch: 4737, Loss: 0.6730, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5386.7008\n",
      "Epoch: 4738, Loss: 0.6721, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5387.8379\n",
      "Epoch: 4739, Loss: 0.6743, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5388.9706\n",
      "Epoch: 4740, Loss: 0.6703, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5390.1066\n",
      "Epoch: 4741, Loss: 0.6734, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5391.2423\n",
      "Epoch: 4742, Loss: 0.6829, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5392.3784\n",
      "Epoch: 4743, Loss: 0.6811, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5393.5128\n",
      "Epoch: 4744, Loss: 0.6817, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5394.6543\n",
      "Epoch: 4745, Loss: 0.6800, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5395.7988\n",
      "Epoch: 4746, Loss: 0.6785, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5396.9357\n",
      "Epoch: 4747, Loss: 0.6679, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5398.0716\n",
      "Epoch: 4748, Loss: 0.6751, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5399.2123\n",
      "Epoch: 4749, Loss: 0.6749, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5400.3555\n",
      "Epoch: 4750, Loss: 0.6769, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5401.4948\n",
      "Epoch: 4751, Loss: 0.6687, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5402.6273\n",
      "Epoch: 4752, Loss: 0.6722, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5403.7580\n",
      "Epoch: 4753, Loss: 0.6720, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5404.8884\n",
      "Epoch: 4754, Loss: 0.6759, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5406.0186\n",
      "Epoch: 4755, Loss: 0.6745, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5407.1526\n",
      "Epoch: 4756, Loss: 0.6781, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5408.2898\n",
      "Epoch: 4757, Loss: 0.6814, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5409.4209\n",
      "Epoch: 4758, Loss: 0.6830, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5410.5593\n",
      "Epoch: 4759, Loss: 0.6859, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5411.6958\n",
      "Epoch: 4760, Loss: 0.6850, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5412.8318\n",
      "Epoch: 4761, Loss: 0.6890, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5413.9690\n",
      "Epoch: 4762, Loss: 0.6882, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5415.1083\n",
      "Epoch: 4763, Loss: 0.6825, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5416.2395\n",
      "Epoch: 4764, Loss: 0.6834, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5417.3813\n",
      "Epoch: 4765, Loss: 0.6781, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5418.5158\n",
      "Epoch: 4766, Loss: 0.6763, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5419.6518\n",
      "Epoch: 4767, Loss: 0.6785, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5420.7896\n",
      "Epoch: 4768, Loss: 0.6807, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5421.9247\n",
      "Epoch: 4769, Loss: 0.6794, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5423.0623\n",
      "Epoch: 4770, Loss: 0.6823, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5424.1996\n",
      "Epoch: 4771, Loss: 0.6726, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5425.3392\n",
      "Epoch: 4772, Loss: 0.6756, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5426.4746\n",
      "Epoch: 4773, Loss: 0.6735, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5427.6170\n",
      "Epoch: 4774, Loss: 0.6799, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5428.7532\n",
      "Epoch: 4775, Loss: 0.6822, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5429.8967\n",
      "Epoch: 4776, Loss: 0.6912, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5431.0363\n",
      "Epoch: 4777, Loss: 0.6874, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5432.1728\n",
      "Epoch: 4778, Loss: 0.6863, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5433.3076\n",
      "Epoch: 4779, Loss: 0.6875, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5434.4428\n",
      "Epoch: 4780, Loss: 0.6833, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5435.5721\n",
      "Epoch: 4781, Loss: 0.6880, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5436.7123\n",
      "Epoch: 4782, Loss: 0.6883, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5437.8452\n",
      "Epoch: 4783, Loss: 0.6878, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5438.9815\n",
      "Epoch: 4784, Loss: 0.6904, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5440.1290\n",
      "Epoch: 4785, Loss: 0.6864, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5441.2648\n",
      "Epoch: 4786, Loss: 0.6851, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5442.4058\n",
      "Epoch: 4787, Loss: 0.6835, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5443.5500\n",
      "Epoch: 4788, Loss: 0.6844, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5444.6908\n",
      "Epoch: 4789, Loss: 0.6758, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5445.8315\n",
      "Epoch: 4790, Loss: 0.6711, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5446.9687\n",
      "Epoch: 4791, Loss: 0.6712, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5448.1085\n",
      "Epoch: 4792, Loss: 0.6711, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5449.2456\n",
      "Epoch: 4793, Loss: 0.6703, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5450.3801\n",
      "Epoch: 4794, Loss: 0.6703, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5451.5139\n",
      "Epoch: 4795, Loss: 0.6723, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5452.6456\n",
      "Epoch: 4796, Loss: 0.6724, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5453.7802\n",
      "Epoch: 4797, Loss: 0.6721, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5454.9137\n",
      "Epoch: 4798, Loss: 0.6704, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5456.0519\n",
      "Epoch: 4799, Loss: 0.6675, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5457.1846\n",
      "Epoch: 4800, Loss: 0.6695, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5458.3261\n",
      "Epoch: 4801, Loss: 0.6697, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5459.4727\n",
      "Epoch: 4802, Loss: 0.6688, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5460.6104\n",
      "Epoch: 4803, Loss: 0.6670, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5461.7498\n",
      "Epoch: 4804, Loss: 0.6612, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5462.8840\n",
      "Epoch: 4805, Loss: 0.6648, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5464.0167\n",
      "Epoch: 4806, Loss: 0.6744, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5465.1519\n",
      "Epoch: 4807, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5466.2828\n",
      "Epoch: 4808, Loss: 0.6703, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5467.4153\n",
      "Epoch: 4809, Loss: 0.6834, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5468.5508\n",
      "Epoch: 4810, Loss: 0.6802, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5469.6860\n",
      "Epoch: 4811, Loss: 0.6775, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5470.8217\n",
      "Epoch: 4812, Loss: 0.6785, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5471.9576\n",
      "Epoch: 4813, Loss: 0.6781, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5473.0946\n",
      "Epoch: 4814, Loss: 0.6810, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5474.2304\n",
      "Epoch: 4815, Loss: 0.6806, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5475.3665\n",
      "Epoch: 4816, Loss: 0.6748, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5476.5045\n",
      "Epoch: 4817, Loss: 0.6789, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5477.6397\n",
      "Epoch: 4818, Loss: 0.6804, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5478.7715\n",
      "Epoch: 4819, Loss: 0.6806, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5479.9081\n",
      "Epoch: 4820, Loss: 0.6788, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5481.0449\n",
      "Epoch: 4821, Loss: 0.6657, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5482.1773\n",
      "Epoch: 4822, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5483.3132\n",
      "Epoch: 4823, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5484.4488\n",
      "Epoch: 4824, Loss: 0.6720, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5485.5836\n",
      "Epoch: 4825, Loss: 0.6717, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5486.7158\n",
      "Epoch: 4826, Loss: 0.6735, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5487.8535\n",
      "Epoch: 4827, Loss: 0.6671, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 5488.9899\n",
      "Epoch: 4828, Loss: 0.6635, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5490.1314\n",
      "Epoch: 4829, Loss: 0.6629, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5491.2760\n",
      "Epoch: 4830, Loss: 0.6644, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5492.4132\n",
      "Epoch: 4831, Loss: 0.6635, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5493.5522\n",
      "Epoch: 4832, Loss: 0.6631, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5494.6902\n",
      "Epoch: 4833, Loss: 0.6638, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5495.8249\n",
      "Epoch: 4834, Loss: 0.6667, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5496.9594\n",
      "Epoch: 4835, Loss: 0.6726, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5498.0949\n",
      "Epoch: 4836, Loss: 0.6733, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5499.2284\n",
      "Epoch: 4837, Loss: 0.6855, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5500.3683\n",
      "Epoch: 4838, Loss: 0.6906, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5501.5055\n",
      "Epoch: 4839, Loss: 0.6939, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5502.6462\n",
      "Epoch: 4840, Loss: 0.6982, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5503.7835\n",
      "Epoch: 4841, Loss: 0.6950, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5504.9215\n",
      "Epoch: 4842, Loss: 0.6883, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5506.0582\n",
      "Epoch: 4843, Loss: 0.6869, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5507.1957\n",
      "Epoch: 4844, Loss: 0.6838, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5508.3297\n",
      "Epoch: 4845, Loss: 0.6803, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5509.4621\n",
      "Epoch: 4846, Loss: 0.6813, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5510.5995\n",
      "Epoch: 4847, Loss: 0.6787, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5511.7414\n",
      "Epoch: 4848, Loss: 0.6860, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5512.8776\n",
      "Epoch: 4849, Loss: 0.6863, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5514.0131\n",
      "Epoch: 4850, Loss: 0.6897, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5515.1449\n",
      "Epoch: 4851, Loss: 0.6919, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5516.2790\n",
      "Epoch: 4852, Loss: 0.6872, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5517.4161\n",
      "Epoch: 4853, Loss: 0.6824, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5518.5553\n",
      "Epoch: 4854, Loss: 0.6851, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5519.6943\n",
      "Epoch: 4855, Loss: 0.6790, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5520.8365\n",
      "Epoch: 4856, Loss: 0.6791, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5521.9777\n",
      "Epoch: 4857, Loss: 0.6789, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5523.1167\n",
      "Epoch: 4858, Loss: 0.6835, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5524.2565\n",
      "Epoch: 4859, Loss: 0.6857, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5525.3940\n",
      "Epoch: 4860, Loss: 0.6881, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5526.5306\n",
      "Epoch: 4861, Loss: 0.6863, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5527.6649\n",
      "Epoch: 4862, Loss: 0.6812, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5528.7973\n",
      "Epoch: 4863, Loss: 0.6817, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5529.9337\n",
      "Epoch: 4864, Loss: 0.6814, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5531.0688\n",
      "Epoch: 4865, Loss: 0.6802, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5532.1993\n",
      "Epoch: 4866, Loss: 0.6795, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5533.3387\n",
      "Epoch: 4867, Loss: 0.6870, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5534.4715\n",
      "Epoch: 4868, Loss: 0.6816, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5535.6091\n",
      "Epoch: 4869, Loss: 0.6794, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5536.7461\n",
      "Epoch: 4870, Loss: 0.6788, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5537.8878\n",
      "Epoch: 4871, Loss: 0.6804, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5539.0223\n",
      "Epoch: 4872, Loss: 0.6775, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5540.1558\n",
      "Epoch: 4873, Loss: 0.6770, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5541.2905\n",
      "Epoch: 4874, Loss: 0.6775, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5542.4286\n",
      "Epoch: 4875, Loss: 0.6710, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5543.5632\n",
      "Epoch: 4876, Loss: 0.6723, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5544.6982\n",
      "Epoch: 4877, Loss: 0.6791, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5545.8326\n",
      "Epoch: 4878, Loss: 0.6727, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5546.9675\n",
      "Epoch: 4879, Loss: 0.6788, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5548.1019\n",
      "Epoch: 4880, Loss: 0.6739, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5549.2403\n",
      "Epoch: 4881, Loss: 0.6714, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5550.3802\n",
      "Epoch: 4882, Loss: 0.6708, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5551.5181\n",
      "Epoch: 4883, Loss: 0.6681, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5552.6548\n",
      "Epoch: 4884, Loss: 0.6724, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5553.7977\n",
      "Epoch: 4885, Loss: 0.6756, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5554.9374\n",
      "Epoch: 4886, Loss: 0.6777, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5556.0687\n",
      "Epoch: 4887, Loss: 0.6803, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5557.2060\n",
      "Epoch: 4888, Loss: 0.6773, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5558.3465\n",
      "Epoch: 4889, Loss: 0.6779, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5559.4809\n",
      "Epoch: 4890, Loss: 0.6774, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5560.6219\n",
      "Epoch: 4891, Loss: 0.6746, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5561.7548\n",
      "Epoch: 4892, Loss: 0.6816, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5562.8919\n",
      "Epoch: 4893, Loss: 0.6835, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5564.0319\n",
      "Epoch: 4894, Loss: 0.6806, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5565.1696\n",
      "Epoch: 4895, Loss: 0.6821, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5566.3078\n",
      "Epoch: 4896, Loss: 0.6857, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5567.4455\n",
      "Epoch: 4897, Loss: 0.6826, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5568.5841\n",
      "Epoch: 4898, Loss: 0.6853, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5569.7153\n",
      "Epoch: 4899, Loss: 0.6828, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5570.8462\n",
      "Epoch: 4900, Loss: 0.6754, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5571.9797\n",
      "Epoch: 4901, Loss: 0.6741, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5573.1133\n",
      "Epoch: 4902, Loss: 0.6736, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5574.2469\n",
      "Epoch: 4903, Loss: 0.6715, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5575.3837\n",
      "Epoch: 4904, Loss: 0.6714, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5576.5203\n",
      "Epoch: 4905, Loss: 0.6721, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5577.6557\n",
      "Epoch: 4906, Loss: 0.6683, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5578.7892\n",
      "Epoch: 4907, Loss: 0.6708, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5579.9270\n",
      "Epoch: 4908, Loss: 0.6677, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5581.0613\n",
      "Epoch: 4909, Loss: 0.6700, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5582.1984\n",
      "Epoch: 4910, Loss: 0.6655, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5583.3361\n",
      "Epoch: 4911, Loss: 0.6615, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5584.4743\n",
      "Epoch: 4912, Loss: 0.6618, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5585.6113\n",
      "Epoch: 4913, Loss: 0.6652, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5586.7445\n",
      "Epoch: 4914, Loss: 0.6664, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5587.8800\n",
      "Epoch: 4915, Loss: 0.6652, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5589.0178\n",
      "Epoch: 4916, Loss: 0.6648, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5590.1514\n",
      "Epoch: 4917, Loss: 0.6661, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5591.2861\n",
      "Epoch: 4918, Loss: 0.6683, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5592.4228\n",
      "Epoch: 4919, Loss: 0.6640, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5593.5587\n",
      "Epoch: 4920, Loss: 0.6662, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5594.6951\n",
      "Epoch: 4921, Loss: 0.6672, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5595.8349\n",
      "Epoch: 4922, Loss: 0.6697, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5596.9686\n",
      "Epoch: 4923, Loss: 0.6715, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5598.1113\n",
      "Epoch: 4924, Loss: 0.6717, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5599.2512\n",
      "Epoch: 4925, Loss: 0.6698, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5600.3875\n",
      "Epoch: 4926, Loss: 0.6712, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5601.5225\n",
      "Epoch: 4927, Loss: 0.6682, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5602.6542\n",
      "Epoch: 4928, Loss: 0.6714, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5603.7891\n",
      "Epoch: 4929, Loss: 0.6759, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5604.9201\n",
      "Epoch: 4930, Loss: 0.6779, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5606.0548\n",
      "Epoch: 4931, Loss: 0.6839, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5607.1848\n",
      "Epoch: 4932, Loss: 0.6861, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5608.3262\n",
      "Epoch: 4933, Loss: 0.6883, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5609.4612\n",
      "Epoch: 4934, Loss: 0.6909, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5610.5954\n",
      "Epoch: 4935, Loss: 0.6893, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5611.7289\n",
      "Epoch: 4936, Loss: 0.6888, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5612.8637\n",
      "Epoch: 4937, Loss: 0.6860, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5614.0109\n",
      "Epoch: 4938, Loss: 0.6883, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5615.1523\n",
      "Epoch: 4939, Loss: 0.6850, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5616.2884\n",
      "Epoch: 4940, Loss: 0.6867, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5617.4228\n",
      "Epoch: 4941, Loss: 0.6869, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5618.5625\n",
      "Epoch: 4942, Loss: 0.6826, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5619.6965\n",
      "Epoch: 4943, Loss: 0.6787, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5620.8284\n",
      "Epoch: 4944, Loss: 0.6757, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5621.9650\n",
      "Epoch: 4945, Loss: 0.6731, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5623.1043\n",
      "Epoch: 4946, Loss: 0.6817, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5624.2374\n",
      "Epoch: 4947, Loss: 0.6805, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5625.3766\n",
      "Epoch: 4948, Loss: 0.6744, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5626.5163\n",
      "Epoch: 4949, Loss: 0.6740, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5627.6519\n",
      "Epoch: 4950, Loss: 0.6762, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5628.7886\n",
      "Epoch: 4951, Loss: 0.6791, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5629.9345\n",
      "Epoch: 4952, Loss: 0.6767, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5631.0722\n",
      "Epoch: 4953, Loss: 0.6813, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5632.2076\n",
      "Epoch: 4954, Loss: 0.6776, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5633.3400\n",
      "Epoch: 4955, Loss: 0.6752, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5634.4780\n",
      "Epoch: 4956, Loss: 0.6742, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5635.6107\n",
      "Epoch: 4957, Loss: 0.6761, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5636.7456\n",
      "Epoch: 4958, Loss: 0.6777, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5637.8779\n",
      "Epoch: 4959, Loss: 0.6804, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5639.0168\n",
      "Epoch: 4960, Loss: 0.6824, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5640.1517\n",
      "Epoch: 4961, Loss: 0.6817, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5641.2864\n",
      "Epoch: 4962, Loss: 0.6806, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5642.4227\n",
      "Epoch: 4963, Loss: 0.6795, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5643.5606\n",
      "Epoch: 4964, Loss: 0.6734, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5644.6998\n",
      "Epoch: 4965, Loss: 0.6697, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5645.8361\n",
      "Epoch: 4966, Loss: 0.6692, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5646.9713\n",
      "Epoch: 4967, Loss: 0.6682, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5648.1038\n",
      "Epoch: 4968, Loss: 0.6693, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5649.2417\n",
      "Epoch: 4969, Loss: 0.6682, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5650.3794\n",
      "Epoch: 4970, Loss: 0.6620, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5651.5136\n",
      "Epoch: 4971, Loss: 0.6711, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5652.6449\n",
      "Epoch: 4972, Loss: 0.6715, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5653.7793\n",
      "Epoch: 4973, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5654.9152\n",
      "Epoch: 4974, Loss: 0.6617, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5656.0548\n",
      "Epoch: 4975, Loss: 0.6653, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5657.1871\n",
      "Epoch: 4976, Loss: 0.6563, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5658.3233\n",
      "Epoch: 4977, Loss: 0.6570, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5659.4572\n",
      "Epoch: 4978, Loss: 0.6570, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5660.5997\n",
      "Epoch: 4979, Loss: 0.6560, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5661.7440\n",
      "Epoch: 4980, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5662.8806\n",
      "Epoch: 4981, Loss: 0.6534, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5664.0116\n",
      "Epoch: 4982, Loss: 0.6528, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5665.1473\n",
      "Epoch: 4983, Loss: 0.6539, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5666.2846\n",
      "Epoch: 4984, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5667.4166\n",
      "Epoch: 4985, Loss: 0.6541, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5668.5506\n",
      "Epoch: 4986, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5669.6827\n",
      "Epoch: 4987, Loss: 0.6534, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5670.8176\n",
      "Epoch: 4988, Loss: 0.6544, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5671.9624\n",
      "Epoch: 4989, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5673.0991\n",
      "Epoch: 4990, Loss: 0.6621, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5674.2356\n",
      "Epoch: 4991, Loss: 0.6597, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5675.3772\n",
      "Epoch: 4992, Loss: 0.6639, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 5676.5148\n",
      "Epoch: 4993, Loss: 0.6653, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 5677.6533\n",
      "Epoch: 4994, Loss: 0.6659, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5678.7906\n",
      "Epoch: 4995, Loss: 0.6582, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 5679.9268\n",
      "Epoch: 4996, Loss: 0.6568, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5681.0682\n",
      "Epoch: 4997, Loss: 0.6558, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5682.2007\n",
      "Epoch: 4998, Loss: 0.6557, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5683.3366\n",
      "Epoch: 4999, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5684.4754\n",
      "Epoch: 5000, Loss: 0.6632, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5685.6076\n",
      "Epoch: 5001, Loss: 0.6650, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5686.7467\n",
      "Epoch: 5002, Loss: 0.6667, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5687.8814\n",
      "Epoch: 5003, Loss: 0.6686, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5689.0184\n",
      "Epoch: 5004, Loss: 0.6715, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5690.1542\n",
      "Epoch: 5005, Loss: 0.6802, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5691.2929\n",
      "Epoch: 5006, Loss: 0.6813, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5692.4245\n",
      "Epoch: 5007, Loss: 0.6830, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5693.5642\n",
      "Epoch: 5008, Loss: 0.6832, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5694.7006\n",
      "Epoch: 5009, Loss: 0.6860, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5695.8327\n",
      "Epoch: 5010, Loss: 0.6853, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5696.9681\n",
      "Epoch: 5011, Loss: 0.6844, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5698.1046\n",
      "Epoch: 5012, Loss: 0.6874, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5699.2422\n",
      "Epoch: 5013, Loss: 0.6886, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5700.3804\n",
      "Epoch: 5014, Loss: 0.6799, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5701.5159\n",
      "Epoch: 5015, Loss: 0.6792, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5702.6523\n",
      "Epoch: 5016, Loss: 0.6749, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5703.7918\n",
      "Epoch: 5017, Loss: 0.6704, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5704.9254\n",
      "Epoch: 5018, Loss: 0.6721, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5706.0597\n",
      "Epoch: 5019, Loss: 0.6724, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5707.1921\n",
      "Epoch: 5020, Loss: 0.6747, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5708.3261\n",
      "Epoch: 5021, Loss: 0.6717, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5709.4647\n",
      "Epoch: 5022, Loss: 0.6770, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5710.6037\n",
      "Epoch: 5023, Loss: 0.6711, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5711.7408\n",
      "Epoch: 5024, Loss: 0.6724, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5712.8795\n",
      "Epoch: 5025, Loss: 0.6739, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5714.0161\n",
      "Epoch: 5026, Loss: 0.6708, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5715.1539\n",
      "Epoch: 5027, Loss: 0.6737, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5716.2925\n",
      "Epoch: 5028, Loss: 0.6720, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5717.4271\n",
      "Epoch: 5029, Loss: 0.6702, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5718.5635\n",
      "Epoch: 5030, Loss: 0.6703, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5719.6975\n",
      "Epoch: 5031, Loss: 0.6709, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5720.8277\n",
      "Epoch: 5032, Loss: 0.6679, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5721.9628\n",
      "Epoch: 5033, Loss: 0.6677, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5723.0965\n",
      "Epoch: 5034, Loss: 0.6687, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5724.2348\n",
      "Epoch: 5035, Loss: 0.6756, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5725.3784\n",
      "Epoch: 5036, Loss: 0.6694, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5726.5126\n",
      "Epoch: 5037, Loss: 0.6618, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5727.6495\n",
      "Epoch: 5038, Loss: 0.6607, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5728.7889\n",
      "Epoch: 5039, Loss: 0.6623, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5729.9258\n",
      "Epoch: 5040, Loss: 0.6659, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5731.0586\n",
      "Epoch: 5041, Loss: 0.6673, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5732.1955\n",
      "Epoch: 5042, Loss: 0.6673, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5733.3315\n",
      "Epoch: 5043, Loss: 0.6711, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5734.4679\n",
      "Epoch: 5044, Loss: 0.6718, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5735.6054\n",
      "Epoch: 5045, Loss: 0.6715, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5736.7462\n",
      "Epoch: 5046, Loss: 0.6723, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5737.8875\n",
      "Epoch: 5047, Loss: 0.6810, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5739.0220\n",
      "Epoch: 5048, Loss: 0.6816, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5740.1563\n",
      "Epoch: 5049, Loss: 0.6802, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5741.2922\n",
      "Epoch: 5050, Loss: 0.6805, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5742.4294\n",
      "Epoch: 5051, Loss: 0.6816, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5743.5634\n",
      "Epoch: 5052, Loss: 0.6822, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5744.7055\n",
      "Epoch: 5053, Loss: 0.6819, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5745.8378\n",
      "Epoch: 5054, Loss: 0.6815, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5746.9803\n",
      "Epoch: 5055, Loss: 0.6795, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5748.1174\n",
      "Epoch: 5056, Loss: 0.6790, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5749.2546\n",
      "Epoch: 5057, Loss: 0.6775, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5750.3942\n",
      "Epoch: 5058, Loss: 0.6789, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5751.5292\n",
      "Epoch: 5059, Loss: 0.6787, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5752.6651\n",
      "Epoch: 5060, Loss: 0.6750, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 5753.7997\n",
      "Epoch: 5061, Loss: 0.6651, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5754.9399\n",
      "Epoch: 5062, Loss: 0.6670, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5756.0785\n",
      "Epoch: 5063, Loss: 0.6701, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5757.2265\n",
      "Epoch: 5064, Loss: 0.6693, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5758.3671\n",
      "Epoch: 5065, Loss: 0.6646, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5759.5065\n",
      "Epoch: 5066, Loss: 0.6653, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5760.6453\n",
      "Epoch: 5067, Loss: 0.6722, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5761.7797\n",
      "Epoch: 5068, Loss: 0.6680, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5762.9173\n",
      "Epoch: 5069, Loss: 0.6672, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5764.0522\n",
      "Epoch: 5070, Loss: 0.6672, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5765.1917\n",
      "Epoch: 5071, Loss: 0.6691, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5766.3304\n",
      "Epoch: 5072, Loss: 0.6702, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5767.4682\n",
      "Epoch: 5073, Loss: 0.6702, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5768.5990\n",
      "Epoch: 5074, Loss: 0.6721, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5769.7338\n",
      "Epoch: 5075, Loss: 0.6721, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5770.8724\n",
      "Epoch: 5076, Loss: 0.6740, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5772.0112\n",
      "Epoch: 5077, Loss: 0.6736, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5773.1499\n",
      "Epoch: 5078, Loss: 0.6701, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5774.2874\n",
      "Epoch: 5079, Loss: 0.6676, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5775.4303\n",
      "Epoch: 5080, Loss: 0.6655, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5776.5686\n",
      "Epoch: 5081, Loss: 0.6628, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5777.6974\n",
      "Epoch: 5082, Loss: 0.6647, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5778.8335\n",
      "Epoch: 5083, Loss: 0.6673, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5779.9691\n",
      "Epoch: 5084, Loss: 0.6676, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5781.1045\n",
      "Epoch: 5085, Loss: 0.6706, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5782.2417\n",
      "Epoch: 5086, Loss: 0.6709, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5783.3755\n",
      "Epoch: 5087, Loss: 0.6765, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5784.5115\n",
      "Epoch: 5088, Loss: 0.6732, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5785.6496\n",
      "Epoch: 5089, Loss: 0.6717, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5786.7852\n",
      "Epoch: 5090, Loss: 0.6723, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5787.9218\n",
      "Epoch: 5091, Loss: 0.6701, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5789.0670\n",
      "Epoch: 5092, Loss: 0.6652, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5790.2036\n",
      "Epoch: 5093, Loss: 0.6701, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5791.3393\n",
      "Epoch: 5094, Loss: 0.6690, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5792.4755\n",
      "Epoch: 5095, Loss: 0.6729, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5793.6110\n",
      "Epoch: 5096, Loss: 0.6734, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5794.7487\n",
      "Epoch: 5097, Loss: 0.6746, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5795.8840\n",
      "Epoch: 5098, Loss: 0.6762, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5797.0189\n",
      "Epoch: 5099, Loss: 0.6780, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5798.1606\n",
      "Epoch: 5100, Loss: 0.6800, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5799.2971\n",
      "Epoch: 5101, Loss: 0.6799, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5800.4422\n",
      "Epoch: 5102, Loss: 0.6823, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5801.5764\n",
      "Epoch: 5103, Loss: 0.6797, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5802.7164\n",
      "Epoch: 5104, Loss: 0.6893, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5803.8516\n",
      "Epoch: 5105, Loss: 0.6901, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5804.9980\n",
      "Epoch: 5106, Loss: 0.6906, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5806.1355\n",
      "Epoch: 5107, Loss: 0.6878, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5807.2781\n",
      "Epoch: 5108, Loss: 0.6918, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5808.4159\n",
      "Epoch: 5109, Loss: 0.6921, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5809.5541\n",
      "Epoch: 5110, Loss: 0.6886, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5810.6857\n",
      "Epoch: 5111, Loss: 0.6894, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5811.8163\n",
      "Epoch: 5112, Loss: 0.6926, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5812.9520\n",
      "Epoch: 5113, Loss: 0.6943, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5814.0887\n",
      "Epoch: 5114, Loss: 0.6927, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5815.2254\n",
      "Epoch: 5115, Loss: 0.6997, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5816.3632\n",
      "Epoch: 5116, Loss: 0.6893, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5817.5006\n",
      "Epoch: 5117, Loss: 0.6910, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5818.6376\n",
      "Epoch: 5118, Loss: 0.6895, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5819.7785\n",
      "Epoch: 5119, Loss: 0.6864, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5820.9219\n",
      "Epoch: 5120, Loss: 0.6887, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5822.0636\n",
      "Epoch: 5121, Loss: 0.6830, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5823.2003\n",
      "Epoch: 5122, Loss: 0.6847, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5824.3347\n",
      "Epoch: 5123, Loss: 0.6816, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5825.4665\n",
      "Epoch: 5124, Loss: 0.6724, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5826.6010\n",
      "Epoch: 5125, Loss: 0.6725, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5827.7370\n",
      "Epoch: 5126, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5828.8707\n",
      "Epoch: 5127, Loss: 0.6686, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5830.0015\n",
      "Epoch: 5128, Loss: 0.6688, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5831.1420\n",
      "Epoch: 5129, Loss: 0.6683, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5832.2778\n",
      "Epoch: 5130, Loss: 0.6694, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5833.4178\n",
      "Epoch: 5131, Loss: 0.6656, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5834.5592\n",
      "Epoch: 5132, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5835.6990\n",
      "Epoch: 5133, Loss: 0.6717, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5836.8364\n",
      "Epoch: 5134, Loss: 0.6659, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5837.9734\n",
      "Epoch: 5135, Loss: 0.6684, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5839.1089\n",
      "Epoch: 5136, Loss: 0.6670, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5840.2464\n",
      "Epoch: 5137, Loss: 0.6677, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5841.3797\n",
      "Epoch: 5138, Loss: 0.6698, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5842.5115\n",
      "Epoch: 5139, Loss: 0.6743, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5843.6444\n",
      "Epoch: 5140, Loss: 0.6724, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5844.7767\n",
      "Epoch: 5141, Loss: 0.6674, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5845.9142\n",
      "Epoch: 5142, Loss: 0.6767, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5847.0509\n",
      "Epoch: 5143, Loss: 0.6758, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5848.1872\n",
      "Epoch: 5144, Loss: 0.6703, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5849.3225\n",
      "Epoch: 5145, Loss: 0.6690, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5850.4610\n",
      "Epoch: 5146, Loss: 0.6651, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5851.6057\n",
      "Epoch: 5147, Loss: 0.6663, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5852.7512\n",
      "Epoch: 5148, Loss: 0.6669, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5853.8829\n",
      "Epoch: 5149, Loss: 0.6673, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5855.0162\n",
      "Epoch: 5150, Loss: 0.6673, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5856.1516\n",
      "Epoch: 5151, Loss: 0.6741, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5857.2900\n",
      "Epoch: 5152, Loss: 0.6709, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5858.4272\n",
      "Epoch: 5153, Loss: 0.6630, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5859.5625\n",
      "Epoch: 5154, Loss: 0.6619, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5860.6971\n",
      "Epoch: 5155, Loss: 0.6583, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5861.8315\n",
      "Epoch: 5156, Loss: 0.6644, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5862.9687\n",
      "Epoch: 5157, Loss: 0.6576, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5864.1134\n",
      "Epoch: 5158, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5865.2559\n",
      "Epoch: 5159, Loss: 0.6752, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5866.3907\n",
      "Epoch: 5160, Loss: 0.6769, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5867.5337\n",
      "Epoch: 5161, Loss: 0.6758, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5868.6741\n",
      "Epoch: 5162, Loss: 0.6752, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5869.8111\n",
      "Epoch: 5163, Loss: 0.6762, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5870.9461\n",
      "Epoch: 5164, Loss: 0.6777, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5872.0770\n",
      "Epoch: 5165, Loss: 0.6779, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5873.2198\n",
      "Epoch: 5166, Loss: 0.6765, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5874.3566\n",
      "Epoch: 5167, Loss: 0.6750, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5875.4926\n",
      "Epoch: 5168, Loss: 0.6757, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5876.6297\n",
      "Epoch: 5169, Loss: 0.6780, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5877.7687\n",
      "Epoch: 5170, Loss: 0.6845, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5878.9031\n",
      "Epoch: 5171, Loss: 0.6829, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5880.0428\n",
      "Epoch: 5172, Loss: 0.6796, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5881.1796\n",
      "Epoch: 5173, Loss: 0.6784, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5882.3174\n",
      "Epoch: 5174, Loss: 0.6822, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5883.4535\n",
      "Epoch: 5175, Loss: 0.6827, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5884.5890\n",
      "Epoch: 5176, Loss: 0.6810, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5885.7236\n",
      "Epoch: 5177, Loss: 0.6847, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5886.8565\n",
      "Epoch: 5178, Loss: 0.6818, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5887.9924\n",
      "Epoch: 5179, Loss: 0.6800, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5889.1304\n",
      "Epoch: 5180, Loss: 0.6795, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5890.2617\n",
      "Epoch: 5181, Loss: 0.6803, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5891.3944\n",
      "Epoch: 5182, Loss: 0.6817, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5892.5276\n",
      "Epoch: 5183, Loss: 0.6801, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5893.6628\n",
      "Epoch: 5184, Loss: 0.6776, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5894.8042\n",
      "Epoch: 5185, Loss: 0.6737, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5895.9439\n",
      "Epoch: 5186, Loss: 0.6666, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5897.0827\n",
      "Epoch: 5187, Loss: 0.6683, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5898.2245\n",
      "Epoch: 5188, Loss: 0.6643, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5899.3605\n",
      "Epoch: 5189, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5900.4928\n",
      "Epoch: 5190, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5901.6277\n",
      "Epoch: 5191, Loss: 0.6721, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5902.7627\n",
      "Epoch: 5192, Loss: 0.6706, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5903.8932\n",
      "Epoch: 5193, Loss: 0.6689, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5905.0291\n",
      "Epoch: 5194, Loss: 0.6682, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5906.1636\n",
      "Epoch: 5195, Loss: 0.6705, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5907.2986\n",
      "Epoch: 5196, Loss: 0.6685, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5908.4358\n",
      "Epoch: 5197, Loss: 0.6702, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5909.5756\n",
      "Epoch: 5198, Loss: 0.6698, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5910.7235\n",
      "Epoch: 5199, Loss: 0.6697, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5911.8641\n",
      "Epoch: 5200, Loss: 0.6706, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5912.9998\n",
      "Epoch: 5201, Loss: 0.6693, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5914.1364\n",
      "Epoch: 5202, Loss: 0.6614, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5915.2707\n",
      "Epoch: 5203, Loss: 0.6616, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5916.4083\n",
      "Epoch: 5204, Loss: 0.6605, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5917.5426\n",
      "Epoch: 5205, Loss: 0.6583, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5918.6770\n",
      "Epoch: 5206, Loss: 0.6602, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5919.8104\n",
      "Epoch: 5207, Loss: 0.6585, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5920.9522\n",
      "Epoch: 5208, Loss: 0.6578, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5922.0823\n",
      "Epoch: 5209, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5923.2207\n",
      "Epoch: 5210, Loss: 0.6547, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5924.3605\n",
      "Epoch: 5211, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5925.4947\n",
      "Epoch: 5212, Loss: 0.6582, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5926.6362\n",
      "Epoch: 5213, Loss: 0.6598, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5927.7792\n",
      "Epoch: 5214, Loss: 0.6640, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5928.9182\n",
      "Epoch: 5215, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5930.0533\n",
      "Epoch: 5216, Loss: 0.6665, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5931.1887\n",
      "Epoch: 5217, Loss: 0.6654, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5932.3218\n",
      "Epoch: 5218, Loss: 0.6644, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5933.4598\n",
      "Epoch: 5219, Loss: 0.6692, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5934.5923\n",
      "Epoch: 5220, Loss: 0.6734, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5935.7268\n",
      "Epoch: 5221, Loss: 0.6705, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5936.8646\n",
      "Epoch: 5222, Loss: 0.6722, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5938.0067\n",
      "Epoch: 5223, Loss: 0.6706, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 5939.1434\n",
      "Epoch: 5224, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5940.2792\n",
      "Epoch: 5225, Loss: 0.6741, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5941.4166\n",
      "Epoch: 5226, Loss: 0.6739, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5942.5561\n",
      "Epoch: 5227, Loss: 0.6724, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5943.6937\n",
      "Epoch: 5228, Loss: 0.6739, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5944.8337\n",
      "Epoch: 5229, Loss: 0.6669, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5945.9672\n",
      "Epoch: 5230, Loss: 0.6634, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5947.0975\n",
      "Epoch: 5231, Loss: 0.6628, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5948.2283\n",
      "Epoch: 5232, Loss: 0.6656, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5949.3568\n",
      "Epoch: 5233, Loss: 0.6658, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5950.4872\n",
      "Epoch: 5234, Loss: 0.6672, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5951.6224\n",
      "Epoch: 5235, Loss: 0.6677, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5952.7562\n",
      "Epoch: 5236, Loss: 0.6692, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 5953.8922\n",
      "Epoch: 5237, Loss: 0.6657, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5955.0310\n",
      "Epoch: 5238, Loss: 0.6665, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5956.1697\n",
      "Epoch: 5239, Loss: 0.6669, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5957.3033\n",
      "Epoch: 5240, Loss: 0.6669, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5958.4426\n",
      "Epoch: 5241, Loss: 0.6657, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5959.5815\n",
      "Epoch: 5242, Loss: 0.6646, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5960.7146\n",
      "Epoch: 5243, Loss: 0.6628, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5961.8525\n",
      "Epoch: 5244, Loss: 0.6648, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5962.9854\n",
      "Epoch: 5245, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5964.1201\n",
      "Epoch: 5246, Loss: 0.6630, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5965.2582\n",
      "Epoch: 5247, Loss: 0.6647, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5966.3929\n",
      "Epoch: 5248, Loss: 0.6624, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5967.5296\n",
      "Epoch: 5249, Loss: 0.6591, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5968.6676\n",
      "Epoch: 5250, Loss: 0.6636, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5969.8088\n",
      "Epoch: 5251, Loss: 0.6640, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5970.9381\n",
      "Epoch: 5252, Loss: 0.6771, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5972.0753\n",
      "Epoch: 5253, Loss: 0.6721, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5973.2126\n",
      "Epoch: 5254, Loss: 0.6709, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5974.3503\n",
      "Epoch: 5255, Loss: 0.6719, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5975.4850\n",
      "Epoch: 5256, Loss: 0.6726, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5976.6190\n",
      "Epoch: 5257, Loss: 0.6752, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5977.7536\n",
      "Epoch: 5258, Loss: 0.6748, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5978.8879\n",
      "Epoch: 5259, Loss: 0.6715, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 5980.0235\n",
      "Epoch: 5260, Loss: 0.6674, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5981.1556\n",
      "Epoch: 5261, Loss: 0.6686, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5982.2910\n",
      "Epoch: 5262, Loss: 0.6677, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5983.4252\n",
      "Epoch: 5263, Loss: 0.6679, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5984.5622\n",
      "Epoch: 5264, Loss: 0.6691, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5985.7024\n",
      "Epoch: 5265, Loss: 0.6690, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5986.8411\n",
      "Epoch: 5266, Loss: 0.6707, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5987.9754\n",
      "Epoch: 5267, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5989.1232\n",
      "Epoch: 5268, Loss: 0.6695, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 5990.2621\n",
      "Epoch: 5269, Loss: 0.6711, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 5991.4026\n",
      "Epoch: 5270, Loss: 0.6686, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5992.5381\n",
      "Epoch: 5271, Loss: 0.6679, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5993.6686\n",
      "Epoch: 5272, Loss: 0.6652, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5994.8060\n",
      "Epoch: 5273, Loss: 0.6642, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 5995.9412\n",
      "Epoch: 5274, Loss: 0.6629, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5997.0751\n",
      "Epoch: 5275, Loss: 0.6659, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 5998.2063\n",
      "Epoch: 5276, Loss: 0.6645, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 5999.3428\n",
      "Epoch: 5277, Loss: 0.6630, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6000.4847\n",
      "Epoch: 5278, Loss: 0.6601, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6001.6284\n",
      "Epoch: 5279, Loss: 0.6572, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6002.7641\n",
      "Epoch: 5280, Loss: 0.6575, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6003.9005\n",
      "Epoch: 5281, Loss: 0.6581, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6005.0372\n",
      "Epoch: 5282, Loss: 0.6603, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6006.1755\n",
      "Epoch: 5283, Loss: 0.6569, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6007.3081\n",
      "Epoch: 5284, Loss: 0.6549, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6008.4437\n",
      "Epoch: 5285, Loss: 0.6564, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6009.5784\n",
      "Epoch: 5286, Loss: 0.6597, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6010.7107\n",
      "Epoch: 5287, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6011.8443\n",
      "Epoch: 5288, Loss: 0.6623, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6012.9853\n",
      "Epoch: 5289, Loss: 0.6638, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6014.1212\n",
      "Epoch: 5290, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6015.2600\n",
      "Epoch: 5291, Loss: 0.6644, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6016.3971\n",
      "Epoch: 5292, Loss: 0.6669, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6017.5311\n",
      "Epoch: 5293, Loss: 0.6688, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6018.6690\n",
      "Epoch: 5294, Loss: 0.6659, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6019.8071\n",
      "Epoch: 5295, Loss: 0.6638, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6020.9421\n",
      "Epoch: 5296, Loss: 0.6647, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6022.0734\n",
      "Epoch: 5297, Loss: 0.6650, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6023.2051\n",
      "Epoch: 5298, Loss: 0.6670, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6024.3414\n",
      "Epoch: 5299, Loss: 0.6695, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6025.4746\n",
      "Epoch: 5300, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6026.6092\n",
      "Epoch: 5301, Loss: 0.6730, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6027.7446\n",
      "Epoch: 5302, Loss: 0.6747, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6028.8911\n",
      "Epoch: 5303, Loss: 0.6771, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6030.0312\n",
      "Epoch: 5304, Loss: 0.6788, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6031.1645\n",
      "Epoch: 5305, Loss: 0.6785, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6032.3077\n",
      "Epoch: 5306, Loss: 0.6762, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6033.4513\n",
      "Epoch: 5307, Loss: 0.6776, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6034.5931\n",
      "Epoch: 5308, Loss: 0.6757, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6035.7256\n",
      "Epoch: 5309, Loss: 0.6810, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6036.8586\n",
      "Epoch: 5310, Loss: 0.6827, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6037.9931\n",
      "Epoch: 5311, Loss: 0.6844, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6039.1217\n",
      "Epoch: 5312, Loss: 0.6835, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6040.2536\n",
      "Epoch: 5313, Loss: 0.6864, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6041.3954\n",
      "Epoch: 5314, Loss: 0.6802, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6042.5280\n",
      "Epoch: 5315, Loss: 0.6793, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6043.6676\n",
      "Epoch: 5316, Loss: 0.6767, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6044.8030\n",
      "Epoch: 5317, Loss: 0.6698, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6045.9410\n",
      "Epoch: 5318, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6047.0772\n",
      "Epoch: 5319, Loss: 0.6770, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6048.2132\n",
      "Epoch: 5320, Loss: 0.6767, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6049.3505\n",
      "Epoch: 5321, Loss: 0.6774, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6050.4872\n",
      "Epoch: 5322, Loss: 0.6742, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6051.6188\n",
      "Epoch: 5323, Loss: 0.6786, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6052.7596\n",
      "Epoch: 5324, Loss: 0.6769, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6053.8970\n",
      "Epoch: 5325, Loss: 0.6741, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6055.0294\n",
      "Epoch: 5326, Loss: 0.6710, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6056.1653\n",
      "Epoch: 5327, Loss: 0.6663, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6057.2985\n",
      "Epoch: 5328, Loss: 0.6618, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6058.4355\n",
      "Epoch: 5329, Loss: 0.6649, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6059.5732\n",
      "Epoch: 5330, Loss: 0.6638, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6060.7146\n",
      "Epoch: 5331, Loss: 0.6612, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6061.8517\n",
      "Epoch: 5332, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6062.9906\n",
      "Epoch: 5333, Loss: 0.6626, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6064.1302\n",
      "Epoch: 5334, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6065.2654\n",
      "Epoch: 5335, Loss: 0.6619, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6066.4018\n",
      "Epoch: 5336, Loss: 0.6654, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6067.5324\n",
      "Epoch: 5337, Loss: 0.6678, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6068.6691\n",
      "Epoch: 5338, Loss: 0.6582, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6069.8022\n",
      "Epoch: 5339, Loss: 0.6687, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6070.9338\n",
      "Epoch: 5340, Loss: 0.6584, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6072.0717\n",
      "Epoch: 5341, Loss: 0.6617, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6073.2095\n",
      "Epoch: 5342, Loss: 0.6623, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6074.3435\n",
      "Epoch: 5343, Loss: 0.6572, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6075.4812\n",
      "Epoch: 5344, Loss: 0.6503, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6076.6236\n",
      "Epoch: 5345, Loss: 0.6514, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6077.7564\n",
      "Epoch: 5346, Loss: 0.6543, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6078.8946\n",
      "Epoch: 5347, Loss: 0.6620, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6080.0314\n",
      "Epoch: 5348, Loss: 0.6643, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6081.1648\n",
      "Epoch: 5349, Loss: 0.6664, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6082.3007\n",
      "Epoch: 5350, Loss: 0.6648, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6083.4344\n",
      "Epoch: 5351, Loss: 0.6641, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6084.5667\n",
      "Epoch: 5352, Loss: 0.6665, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6085.7046\n",
      "Epoch: 5353, Loss: 0.6690, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6086.8371\n",
      "Epoch: 5354, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6087.9757\n",
      "Epoch: 5355, Loss: 0.6644, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6089.1108\n",
      "Epoch: 5356, Loss: 0.6629, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6090.2481\n",
      "Epoch: 5357, Loss: 0.6659, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6091.3844\n",
      "Epoch: 5358, Loss: 0.6706, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6092.5233\n",
      "Epoch: 5359, Loss: 0.6786, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6093.6587\n",
      "Epoch: 5360, Loss: 0.6802, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6094.7960\n",
      "Epoch: 5361, Loss: 0.6750, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6095.9274\n",
      "Epoch: 5362, Loss: 0.6701, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6097.0586\n",
      "Epoch: 5363, Loss: 0.6724, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6098.1956\n",
      "Epoch: 5364, Loss: 0.6742, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6099.3295\n",
      "Epoch: 5365, Loss: 0.6752, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6100.4659\n",
      "Epoch: 5366, Loss: 0.6742, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 6101.5995\n",
      "Epoch: 5367, Loss: 0.6717, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6102.7333\n",
      "Epoch: 5368, Loss: 0.6739, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6103.8669\n",
      "Epoch: 5369, Loss: 0.6737, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6105.0012\n",
      "Epoch: 5370, Loss: 0.6739, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6106.1383\n",
      "Epoch: 5371, Loss: 0.6737, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 6107.2774\n",
      "Epoch: 5372, Loss: 0.6712, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6108.4187\n",
      "Epoch: 5373, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6109.5578\n",
      "Epoch: 5374, Loss: 0.6673, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6110.6956\n",
      "Epoch: 5375, Loss: 0.6670, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6111.8280\n",
      "Epoch: 5376, Loss: 0.6695, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6112.9654\n",
      "Epoch: 5377, Loss: 0.6679, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6114.0992\n",
      "Epoch: 5378, Loss: 0.6754, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6115.2385\n",
      "Epoch: 5379, Loss: 0.6758, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6116.3729\n",
      "Epoch: 5380, Loss: 0.6765, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6117.5105\n",
      "Epoch: 5381, Loss: 0.6751, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6118.6465\n",
      "Epoch: 5382, Loss: 0.6780, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6119.7870\n",
      "Epoch: 5383, Loss: 0.6673, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6120.9220\n",
      "Epoch: 5384, Loss: 0.6663, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6122.0628\n",
      "Epoch: 5385, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6123.1974\n",
      "Epoch: 5386, Loss: 0.6570, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6124.3328\n",
      "Epoch: 5387, Loss: 0.6545, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6125.4692\n",
      "Epoch: 5388, Loss: 0.6540, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6126.6098\n",
      "Epoch: 5389, Loss: 0.6543, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6127.7401\n",
      "Epoch: 5390, Loss: 0.6554, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6128.8770\n",
      "Epoch: 5391, Loss: 0.6616, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6130.0156\n",
      "Epoch: 5392, Loss: 0.6563, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6131.1488\n",
      "Epoch: 5393, Loss: 0.6578, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6132.2834\n",
      "Epoch: 5394, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6133.4160\n",
      "Epoch: 5395, Loss: 0.6615, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6134.5498\n",
      "Epoch: 5396, Loss: 0.6635, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6135.6810\n",
      "Epoch: 5397, Loss: 0.6632, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6136.8125\n",
      "Epoch: 5398, Loss: 0.6617, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6137.9507\n",
      "Epoch: 5399, Loss: 0.6638, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6139.0862\n",
      "Epoch: 5400, Loss: 0.6656, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6140.2235\n",
      "Epoch: 5401, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6141.3636\n",
      "Epoch: 5402, Loss: 0.6659, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6142.5028\n",
      "Epoch: 5403, Loss: 0.6667, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6143.6401\n",
      "Epoch: 5404, Loss: 0.6660, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6144.7709\n",
      "Epoch: 5405, Loss: 0.6667, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6145.9006\n",
      "Epoch: 5406, Loss: 0.6671, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6147.0338\n",
      "Epoch: 5407, Loss: 0.6667, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6148.1668\n",
      "Epoch: 5408, Loss: 0.6699, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6149.3022\n",
      "Epoch: 5409, Loss: 0.6698, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6150.4435\n",
      "Epoch: 5410, Loss: 0.6699, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6151.5809\n",
      "Epoch: 5411, Loss: 0.6677, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6152.7212\n",
      "Epoch: 5412, Loss: 0.6673, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6153.8536\n",
      "Epoch: 5413, Loss: 0.6678, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6154.9934\n",
      "Epoch: 5414, Loss: 0.6679, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6156.1265\n",
      "Epoch: 5415, Loss: 0.6648, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6157.2657\n",
      "Epoch: 5416, Loss: 0.6638, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6158.4021\n",
      "Epoch: 5417, Loss: 0.6619, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6159.5373\n",
      "Epoch: 5418, Loss: 0.6629, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6160.6767\n",
      "Epoch: 5419, Loss: 0.6603, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6161.8155\n",
      "Epoch: 5420, Loss: 0.6634, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6162.9487\n",
      "Epoch: 5421, Loss: 0.6649, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6164.0802\n",
      "Epoch: 5422, Loss: 0.6621, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6165.2194\n",
      "Epoch: 5423, Loss: 0.6598, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6166.3512\n",
      "Epoch: 5424, Loss: 0.6648, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6167.4839\n",
      "Epoch: 5425, Loss: 0.6624, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6168.6197\n",
      "Epoch: 5426, Loss: 0.6627, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6169.7698\n",
      "Epoch: 5427, Loss: 0.6613, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6170.9065\n",
      "Epoch: 5428, Loss: 0.6612, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6172.0436\n",
      "Epoch: 5429, Loss: 0.6656, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6173.1915\n",
      "Epoch: 5430, Loss: 0.6672, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6174.3227\n",
      "Epoch: 5431, Loss: 0.6642, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6175.4558\n",
      "Epoch: 5432, Loss: 0.6627, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6176.5891\n",
      "Epoch: 5433, Loss: 0.6608, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6177.7232\n",
      "Epoch: 5434, Loss: 0.6575, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6178.8551\n",
      "Epoch: 5435, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6179.9859\n",
      "Epoch: 5436, Loss: 0.6588, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6181.1148\n",
      "Epoch: 5437, Loss: 0.6585, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6182.2576\n",
      "Epoch: 5438, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6183.3974\n",
      "Epoch: 5439, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6184.5301\n",
      "Epoch: 5440, Loss: 0.6537, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6185.6655\n",
      "Epoch: 5441, Loss: 0.6522, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6186.8022\n",
      "Epoch: 5442, Loss: 0.6534, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 6187.9421\n",
      "Epoch: 5443, Loss: 0.6545, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6189.0757\n",
      "Epoch: 5444, Loss: 0.6539, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6190.2085\n",
      "Epoch: 5445, Loss: 0.6559, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6191.3428\n",
      "Epoch: 5446, Loss: 0.6589, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6192.4784\n",
      "Epoch: 5447, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6193.6134\n",
      "Epoch: 5448, Loss: 0.6596, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6194.7512\n",
      "Epoch: 5449, Loss: 0.6596, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6195.8845\n",
      "Epoch: 5450, Loss: 0.6588, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6197.0148\n",
      "Epoch: 5451, Loss: 0.6602, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 6198.1551\n",
      "Epoch: 5452, Loss: 0.6598, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 6199.2864\n",
      "Epoch: 5453, Loss: 0.6638, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 6200.4337\n",
      "Epoch: 5454, Loss: 0.6650, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 6201.5822\n",
      "Epoch: 5455, Loss: 0.6650, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 6202.7434\n",
      "Epoch: 5456, Loss: 0.6651, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 6203.9084\n",
      "Epoch: 5457, Loss: 0.6666, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6205.0555\n",
      "Epoch: 5458, Loss: 0.6615, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 6206.1916\n",
      "Epoch: 5459, Loss: 0.6628, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6207.3198\n",
      "Epoch: 5460, Loss: 0.6617, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6208.4492\n",
      "Epoch: 5461, Loss: 0.6636, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6209.5757\n",
      "Epoch: 5462, Loss: 0.6702, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6210.7093\n",
      "Epoch: 5463, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6211.8442\n",
      "Epoch: 5464, Loss: 0.6678, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6212.9719\n",
      "Epoch: 5465, Loss: 0.6685, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6214.1040\n",
      "Epoch: 5466, Loss: 0.6706, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6215.2399\n",
      "Epoch: 5467, Loss: 0.6720, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6216.3733\n",
      "Epoch: 5468, Loss: 0.6718, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6217.5101\n",
      "Epoch: 5469, Loss: 0.6728, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6218.6464\n",
      "Epoch: 5470, Loss: 0.6740, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6219.7838\n",
      "Epoch: 5471, Loss: 0.6729, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6220.9163\n",
      "Epoch: 5472, Loss: 0.6692, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6222.0516\n",
      "Epoch: 5473, Loss: 0.6673, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6223.1847\n",
      "Epoch: 5474, Loss: 0.6671, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6224.3173\n",
      "Epoch: 5475, Loss: 0.6668, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 6225.4532\n",
      "Epoch: 5476, Loss: 0.6695, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6226.5900\n",
      "Epoch: 5477, Loss: 0.6724, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6227.7217\n",
      "Epoch: 5478, Loss: 0.6751, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6228.8576\n",
      "Epoch: 5479, Loss: 0.6737, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6229.9902\n",
      "Epoch: 5480, Loss: 0.6741, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6231.1247\n",
      "Epoch: 5481, Loss: 0.6746, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6232.2591\n",
      "Epoch: 5482, Loss: 0.6737, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6233.3921\n",
      "Epoch: 5483, Loss: 0.6720, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6234.5447\n",
      "Epoch: 5484, Loss: 0.6757, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6235.6837\n",
      "Epoch: 5485, Loss: 0.6779, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6236.8228\n",
      "Epoch: 5486, Loss: 0.6744, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6237.9544\n",
      "Epoch: 5487, Loss: 0.6755, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6239.0872\n",
      "Epoch: 5488, Loss: 0.6768, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6240.2195\n",
      "Epoch: 5489, Loss: 0.6748, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6241.3542\n",
      "Epoch: 5490, Loss: 0.6764, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6242.4851\n",
      "Epoch: 5491, Loss: 0.6743, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6243.6165\n",
      "Epoch: 5492, Loss: 0.6802, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6244.7545\n",
      "Epoch: 5493, Loss: 0.6798, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6245.8936\n",
      "Epoch: 5494, Loss: 0.6775, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6247.0342\n",
      "Epoch: 5495, Loss: 0.6762, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6248.1682\n",
      "Epoch: 5496, Loss: 0.6735, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6249.3046\n",
      "Epoch: 5497, Loss: 0.6736, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6250.4351\n",
      "Epoch: 5498, Loss: 0.6753, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6251.5711\n",
      "Epoch: 5499, Loss: 0.6718, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6252.7077\n",
      "Epoch: 5500, Loss: 0.6725, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6253.8429\n",
      "Epoch: 5501, Loss: 0.6632, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6254.9752\n",
      "Epoch: 5502, Loss: 0.6679, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6256.1065\n",
      "Epoch: 5503, Loss: 0.6742, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6257.2433\n",
      "Epoch: 5504, Loss: 0.6777, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6258.3791\n",
      "Epoch: 5505, Loss: 0.6763, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6259.5149\n",
      "Epoch: 5506, Loss: 0.6742, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6260.6522\n",
      "Epoch: 5507, Loss: 0.6731, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6261.7880\n",
      "Epoch: 5508, Loss: 0.6745, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6262.9217\n",
      "Epoch: 5509, Loss: 0.6738, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6264.0660\n",
      "Epoch: 5510, Loss: 0.6699, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6265.1996\n",
      "Epoch: 5511, Loss: 0.6649, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6266.3355\n",
      "Epoch: 5512, Loss: 0.6639, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6267.4666\n",
      "Epoch: 5513, Loss: 0.6656, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6268.5991\n",
      "Epoch: 5514, Loss: 0.6629, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6269.7350\n",
      "Epoch: 5515, Loss: 0.6623, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6270.8676\n",
      "Epoch: 5516, Loss: 0.6661, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6272.0001\n",
      "Epoch: 5517, Loss: 0.6652, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6273.1319\n",
      "Epoch: 5518, Loss: 0.6637, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6274.2608\n",
      "Epoch: 5519, Loss: 0.6588, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6275.3964\n",
      "Epoch: 5520, Loss: 0.6590, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6276.5326\n",
      "Epoch: 5521, Loss: 0.6603, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6277.6672\n",
      "Epoch: 5522, Loss: 0.6592, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6278.8031\n",
      "Epoch: 5523, Loss: 0.6603, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6279.9431\n",
      "Epoch: 5524, Loss: 0.6576, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6281.0773\n",
      "Epoch: 5525, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6282.2125\n",
      "Epoch: 5526, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6283.3437\n",
      "Epoch: 5527, Loss: 0.6546, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6284.4739\n",
      "Epoch: 5528, Loss: 0.6557, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6285.6075\n",
      "Epoch: 5529, Loss: 0.6583, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6286.7421\n",
      "Epoch: 5530, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6287.8756\n",
      "Epoch: 5531, Loss: 0.6562, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6289.0086\n",
      "Epoch: 5532, Loss: 0.6557, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6290.1465\n",
      "Epoch: 5533, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6291.2819\n",
      "Epoch: 5534, Loss: 0.6581, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6292.4179\n",
      "Epoch: 5535, Loss: 0.6564, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6293.5523\n",
      "Epoch: 5536, Loss: 0.6575, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6294.6926\n",
      "Epoch: 5537, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6295.8251\n",
      "Epoch: 5538, Loss: 0.6600, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6296.9568\n",
      "Epoch: 5539, Loss: 0.6590, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6298.0906\n",
      "Epoch: 5540, Loss: 0.6608, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6299.2230\n",
      "Epoch: 5541, Loss: 0.6611, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6300.3611\n",
      "Epoch: 5542, Loss: 0.6619, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6301.4910\n",
      "Epoch: 5543, Loss: 0.6607, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6302.6246\n",
      "Epoch: 5544, Loss: 0.6611, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6303.7559\n",
      "Epoch: 5545, Loss: 0.6618, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6304.8887\n",
      "Epoch: 5546, Loss: 0.6617, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6306.0258\n",
      "Epoch: 5547, Loss: 0.6611, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6307.1650\n",
      "Epoch: 5548, Loss: 0.6631, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6308.3042\n",
      "Epoch: 5549, Loss: 0.6613, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6309.4436\n",
      "Epoch: 5550, Loss: 0.6631, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6310.5824\n",
      "Epoch: 5551, Loss: 0.6602, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6311.7230\n",
      "Epoch: 5552, Loss: 0.6637, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6312.8634\n",
      "Epoch: 5553, Loss: 0.6657, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6314.0005\n",
      "Epoch: 5554, Loss: 0.6678, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6315.1347\n",
      "Epoch: 5555, Loss: 0.6687, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6316.2679\n",
      "Epoch: 5556, Loss: 0.6672, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6317.4005\n",
      "Epoch: 5557, Loss: 0.6685, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6318.5335\n",
      "Epoch: 5558, Loss: 0.6699, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6319.6645\n",
      "Epoch: 5559, Loss: 0.6719, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6320.7990\n",
      "Epoch: 5560, Loss: 0.6708, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6321.9339\n",
      "Epoch: 5561, Loss: 0.6757, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6323.0745\n",
      "Epoch: 5562, Loss: 0.6801, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6324.2177\n",
      "Epoch: 5563, Loss: 0.6767, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6325.3548\n",
      "Epoch: 5564, Loss: 0.6740, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6326.4902\n",
      "Epoch: 5565, Loss: 0.6743, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6327.6241\n",
      "Epoch: 5566, Loss: 0.6722, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6328.7575\n",
      "Epoch: 5567, Loss: 0.6733, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6329.8899\n",
      "Epoch: 5568, Loss: 0.6731, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6331.0259\n",
      "Epoch: 5569, Loss: 0.6737, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6332.1600\n",
      "Epoch: 5570, Loss: 0.6717, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6333.2966\n",
      "Epoch: 5571, Loss: 0.6719, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6334.4277\n",
      "Epoch: 5572, Loss: 0.6729, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6335.5594\n",
      "Epoch: 5573, Loss: 0.6742, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6336.6964\n",
      "Epoch: 5574, Loss: 0.6723, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6337.8310\n",
      "Epoch: 5575, Loss: 0.6703, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6338.9704\n",
      "Epoch: 5576, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6340.1086\n",
      "Epoch: 5577, Loss: 0.6688, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6341.2488\n",
      "Epoch: 5578, Loss: 0.6727, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6342.3810\n",
      "Epoch: 5579, Loss: 0.6706, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6343.5125\n",
      "Epoch: 5580, Loss: 0.6643, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6344.6524\n",
      "Epoch: 5581, Loss: 0.6629, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6345.7806\n",
      "Epoch: 5582, Loss: 0.6575, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6346.9152\n",
      "Epoch: 5583, Loss: 0.6700, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6348.0484\n",
      "Epoch: 5584, Loss: 0.6722, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6349.1828\n",
      "Epoch: 5585, Loss: 0.6651, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6350.3192\n",
      "Epoch: 5586, Loss: 0.6671, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6351.4581\n",
      "Epoch: 5587, Loss: 0.6762, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6352.6022\n",
      "Epoch: 5588, Loss: 0.6833, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6353.7387\n",
      "Epoch: 5589, Loss: 0.6784, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6354.8887\n",
      "Epoch: 5590, Loss: 0.6768, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6356.0340\n",
      "Epoch: 5591, Loss: 0.6742, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6357.1682\n",
      "Epoch: 5592, Loss: 0.6739, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6358.3022\n",
      "Epoch: 5593, Loss: 0.6742, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6359.4345\n",
      "Epoch: 5594, Loss: 0.6750, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6360.5650\n",
      "Epoch: 5595, Loss: 0.6706, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6361.6999\n",
      "Epoch: 5596, Loss: 0.6709, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6362.8437\n",
      "Epoch: 5597, Loss: 0.6675, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6363.9787\n",
      "Epoch: 5598, Loss: 0.6685, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6365.1141\n",
      "Epoch: 5599, Loss: 0.6695, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6366.2533\n",
      "Epoch: 5600, Loss: 0.6690, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6367.3849\n",
      "Epoch: 5601, Loss: 0.6711, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6368.5178\n",
      "Epoch: 5602, Loss: 0.6712, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6369.6549\n",
      "Epoch: 5603, Loss: 0.6743, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6370.7890\n",
      "Epoch: 5604, Loss: 0.6768, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6371.9251\n",
      "Epoch: 5605, Loss: 0.6732, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6373.0625\n",
      "Epoch: 5606, Loss: 0.6728, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6374.1930\n",
      "Epoch: 5607, Loss: 0.6739, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6375.3272\n",
      "Epoch: 5608, Loss: 0.6742, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6376.4542\n",
      "Epoch: 5609, Loss: 0.6759, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6377.5880\n",
      "Epoch: 5610, Loss: 0.6709, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6378.7187\n",
      "Epoch: 5611, Loss: 0.6678, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6379.8538\n",
      "Epoch: 5612, Loss: 0.6688, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6380.9873\n",
      "Epoch: 5613, Loss: 0.6670, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6382.1205\n",
      "Epoch: 5614, Loss: 0.6673, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6383.2527\n",
      "Epoch: 5615, Loss: 0.6663, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6384.3878\n",
      "Epoch: 5616, Loss: 0.6634, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6385.5261\n",
      "Epoch: 5617, Loss: 0.6639, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6386.6647\n",
      "Epoch: 5618, Loss: 0.6622, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6387.8078\n",
      "Epoch: 5619, Loss: 0.6631, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6388.9411\n",
      "Epoch: 5620, Loss: 0.6659, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6390.0774\n",
      "Epoch: 5621, Loss: 0.6653, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6391.2114\n",
      "Epoch: 5622, Loss: 0.6651, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6392.3436\n",
      "Epoch: 5623, Loss: 0.6653, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6393.4741\n",
      "Epoch: 5624, Loss: 0.6663, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6394.6081\n",
      "Epoch: 5625, Loss: 0.6644, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6395.7393\n",
      "Epoch: 5626, Loss: 0.6650, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6396.8724\n",
      "Epoch: 5627, Loss: 0.6636, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6398.0022\n",
      "Epoch: 5628, Loss: 0.6626, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6399.1398\n",
      "Epoch: 5629, Loss: 0.6646, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6400.2741\n",
      "Epoch: 5630, Loss: 0.6703, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6401.4075\n",
      "Epoch: 5631, Loss: 0.6703, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6402.5490\n",
      "Epoch: 5632, Loss: 0.6708, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6403.6879\n",
      "Epoch: 5633, Loss: 0.6732, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6404.8215\n",
      "Epoch: 5634, Loss: 0.6743, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6405.9547\n",
      "Epoch: 5635, Loss: 0.6796, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6407.0854\n",
      "Epoch: 5636, Loss: 0.6779, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6408.2188\n",
      "Epoch: 5637, Loss: 0.6815, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6409.3589\n",
      "Epoch: 5638, Loss: 0.6794, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6410.4924\n",
      "Epoch: 5639, Loss: 0.6777, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6411.6242\n",
      "Epoch: 5640, Loss: 0.6749, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6412.7549\n",
      "Epoch: 5641, Loss: 0.6759, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6413.8922\n",
      "Epoch: 5642, Loss: 0.6737, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6415.0318\n",
      "Epoch: 5643, Loss: 0.6732, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6416.1712\n",
      "Epoch: 5644, Loss: 0.6681, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6417.3044\n",
      "Epoch: 5645, Loss: 0.6664, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6418.4438\n",
      "Epoch: 5646, Loss: 0.6682, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6419.5751\n",
      "Epoch: 5647, Loss: 0.6683, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6420.7090\n",
      "Epoch: 5648, Loss: 0.6675, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6421.8431\n",
      "Epoch: 5649, Loss: 0.6702, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6422.9780\n",
      "Epoch: 5650, Loss: 0.6725, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6424.1135\n",
      "Epoch: 5651, Loss: 0.6723, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6425.2500\n",
      "Epoch: 5652, Loss: 0.6746, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6426.3794\n",
      "Epoch: 5653, Loss: 0.6725, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6427.5078\n",
      "Epoch: 5654, Loss: 0.6707, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6428.6432\n",
      "Epoch: 5655, Loss: 0.6708, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6429.7853\n",
      "Epoch: 5656, Loss: 0.6683, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6430.9247\n",
      "Epoch: 5657, Loss: 0.6672, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6432.0660\n",
      "Epoch: 5658, Loss: 0.6701, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6433.2033\n",
      "Epoch: 5659, Loss: 0.6689, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6434.3417\n",
      "Epoch: 5660, Loss: 0.6644, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6435.4751\n",
      "Epoch: 5661, Loss: 0.6647, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6436.6043\n",
      "Epoch: 5662, Loss: 0.6615, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6437.7340\n",
      "Epoch: 5663, Loss: 0.6621, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6438.8657\n",
      "Epoch: 5664, Loss: 0.6660, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6440.0009\n",
      "Epoch: 5665, Loss: 0.6670, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6441.1348\n",
      "Epoch: 5666, Loss: 0.6645, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6442.2717\n",
      "Epoch: 5667, Loss: 0.6636, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6443.4058\n",
      "Epoch: 5668, Loss: 0.6650, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6444.5402\n",
      "Epoch: 5669, Loss: 0.6621, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6445.6746\n",
      "Epoch: 5670, Loss: 0.6602, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6446.8066\n",
      "Epoch: 5671, Loss: 0.6614, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6447.9394\n",
      "Epoch: 5672, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6449.0745\n",
      "Epoch: 5673, Loss: 0.6635, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6450.2067\n",
      "Epoch: 5674, Loss: 0.6613, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6451.3392\n",
      "Epoch: 5675, Loss: 0.6607, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6452.4697\n",
      "Epoch: 5676, Loss: 0.6599, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6453.6015\n",
      "Epoch: 5677, Loss: 0.6622, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6454.7348\n",
      "Epoch: 5678, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6455.8669\n",
      "Epoch: 5679, Loss: 0.6599, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6456.9988\n",
      "Epoch: 5680, Loss: 0.6574, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6458.1312\n",
      "Epoch: 5681, Loss: 0.6534, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6459.2646\n",
      "Epoch: 5682, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6460.3984\n",
      "Epoch: 5683, Loss: 0.6511, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6461.5288\n",
      "Epoch: 5684, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6462.6682\n",
      "Epoch: 5685, Loss: 0.6502, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6463.8116\n",
      "Epoch: 5686, Loss: 0.6521, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6464.9459\n",
      "Epoch: 5687, Loss: 0.6495, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6466.0745\n",
      "Epoch: 5688, Loss: 0.6522, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6467.2082\n",
      "Epoch: 5689, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6468.3419\n",
      "Epoch: 5690, Loss: 0.6513, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6469.4731\n",
      "Epoch: 5691, Loss: 0.6521, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6470.6036\n",
      "Epoch: 5692, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6471.7358\n",
      "Epoch: 5693, Loss: 0.6501, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6472.8672\n",
      "Epoch: 5694, Loss: 0.6510, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6473.9995\n",
      "Epoch: 5695, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6475.1492\n",
      "Epoch: 5696, Loss: 0.6515, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6476.2822\n",
      "Epoch: 5697, Loss: 0.6590, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6477.4213\n",
      "Epoch: 5698, Loss: 0.6559, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6478.5589\n",
      "Epoch: 5699, Loss: 0.6551, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6479.6964\n",
      "Epoch: 5700, Loss: 0.6558, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6480.8277\n",
      "Epoch: 5701, Loss: 0.6592, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6481.9607\n",
      "Epoch: 5702, Loss: 0.6607, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6483.0924\n",
      "Epoch: 5703, Loss: 0.6612, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6484.2211\n",
      "Epoch: 5704, Loss: 0.6617, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6485.3571\n",
      "Epoch: 5705, Loss: 0.6627, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6486.4917\n",
      "Epoch: 5706, Loss: 0.6615, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6487.6221\n",
      "Epoch: 5707, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6488.7555\n",
      "Epoch: 5708, Loss: 0.6621, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6489.8881\n",
      "Epoch: 5709, Loss: 0.6635, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6491.0261\n",
      "Epoch: 5710, Loss: 0.6633, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6492.1608\n",
      "Epoch: 5711, Loss: 0.6667, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6493.2930\n",
      "Epoch: 5712, Loss: 0.6693, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6494.4338\n",
      "Epoch: 5713, Loss: 0.6678, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6495.5715\n",
      "Epoch: 5714, Loss: 0.6686, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6496.7064\n",
      "Epoch: 5715, Loss: 0.6682, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6497.8376\n",
      "Epoch: 5716, Loss: 0.6688, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6498.9656\n",
      "Epoch: 5717, Loss: 0.6670, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6500.0989\n",
      "Epoch: 5718, Loss: 0.6702, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6501.2321\n",
      "Epoch: 5719, Loss: 0.6737, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6502.3638\n",
      "Epoch: 5720, Loss: 0.6690, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6503.4988\n",
      "Epoch: 5721, Loss: 0.6692, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6504.6377\n",
      "Epoch: 5722, Loss: 0.6682, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6505.7733\n",
      "Epoch: 5723, Loss: 0.6708, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6506.9159\n",
      "Epoch: 5724, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6508.0502\n",
      "Epoch: 5725, Loss: 0.6716, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6509.1848\n",
      "Epoch: 5726, Loss: 0.6712, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6510.3187\n",
      "Epoch: 5727, Loss: 0.6743, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6511.4514\n",
      "Epoch: 5728, Loss: 0.6762, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6512.5805\n",
      "Epoch: 5729, Loss: 0.6737, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6513.7127\n",
      "Epoch: 5730, Loss: 0.6750, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6514.8493\n",
      "Epoch: 5731, Loss: 0.6730, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6515.9846\n",
      "Epoch: 5732, Loss: 0.6709, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6517.1137\n",
      "Epoch: 5733, Loss: 0.6755, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6518.2543\n",
      "Epoch: 5734, Loss: 0.6740, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6519.3906\n",
      "Epoch: 5735, Loss: 0.6759, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6520.5296\n",
      "Epoch: 5736, Loss: 0.6740, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6521.6653\n",
      "Epoch: 5737, Loss: 0.6746, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6522.8027\n",
      "Epoch: 5738, Loss: 0.6753, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6523.9403\n",
      "Epoch: 5739, Loss: 0.6744, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6525.0718\n",
      "Epoch: 5740, Loss: 0.6698, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6526.2080\n",
      "Epoch: 5741, Loss: 0.6671, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6527.3452\n",
      "Epoch: 5742, Loss: 0.6679, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6528.4832\n",
      "Epoch: 5743, Loss: 0.6662, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6529.6137\n",
      "Epoch: 5744, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6530.7457\n",
      "Epoch: 5745, Loss: 0.6656, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6531.8757\n",
      "Epoch: 5746, Loss: 0.6654, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6533.0075\n",
      "Epoch: 5747, Loss: 0.6690, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6534.1419\n",
      "Epoch: 5748, Loss: 0.6730, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6535.2734\n",
      "Epoch: 5749, Loss: 0.6707, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6536.4019\n",
      "Epoch: 5750, Loss: 0.6720, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6537.5338\n",
      "Epoch: 5751, Loss: 0.6715, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6538.6726\n",
      "Epoch: 5752, Loss: 0.6691, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6539.8135\n",
      "Epoch: 5753, Loss: 0.6700, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6540.9498\n",
      "Epoch: 5754, Loss: 0.6664, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6542.0886\n",
      "Epoch: 5755, Loss: 0.6666, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6543.2221\n",
      "Epoch: 5756, Loss: 0.6663, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6544.3559\n",
      "Epoch: 5757, Loss: 0.6686, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6545.4926\n",
      "Epoch: 5758, Loss: 0.6706, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6546.6273\n",
      "Epoch: 5759, Loss: 0.6704, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6547.7575\n",
      "Epoch: 5760, Loss: 0.6690, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6548.8875\n",
      "Epoch: 5761, Loss: 0.6703, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6550.0155\n",
      "Epoch: 5762, Loss: 0.6705, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6551.1478\n",
      "Epoch: 5763, Loss: 0.6748, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6552.2830\n",
      "Epoch: 5764, Loss: 0.6726, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6553.4147\n",
      "Epoch: 5765, Loss: 0.6732, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6554.5556\n",
      "Epoch: 5766, Loss: 0.6822, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6555.6833\n",
      "Epoch: 5767, Loss: 0.6823, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6556.8175\n",
      "Epoch: 5768, Loss: 0.6858, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6557.9535\n",
      "Epoch: 5769, Loss: 0.6837, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6559.0852\n",
      "Epoch: 5770, Loss: 0.6818, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6560.2204\n",
      "Epoch: 5771, Loss: 0.6791, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6561.3582\n",
      "Epoch: 5772, Loss: 0.6793, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6562.4897\n",
      "Epoch: 5773, Loss: 0.6789, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6563.6216\n",
      "Epoch: 5774, Loss: 0.6757, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6564.7536\n",
      "Epoch: 5775, Loss: 0.6744, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6565.8797\n",
      "Epoch: 5776, Loss: 0.6763, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6567.0090\n",
      "Epoch: 5777, Loss: 0.6730, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6568.1402\n",
      "Epoch: 5778, Loss: 0.6728, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6569.2653\n",
      "Epoch: 5779, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6570.3854\n",
      "Epoch: 5780, Loss: 0.6732, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6571.5102\n",
      "Epoch: 5781, Loss: 0.6711, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6572.6517\n",
      "Epoch: 5782, Loss: 0.6716, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6573.7890\n",
      "Epoch: 5783, Loss: 0.6717, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6574.9252\n",
      "Epoch: 5784, Loss: 0.6719, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6576.0518\n",
      "Epoch: 5785, Loss: 0.6744, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6577.1811\n",
      "Epoch: 5786, Loss: 0.6732, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6578.3152\n",
      "Epoch: 5787, Loss: 0.6699, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6579.4489\n",
      "Epoch: 5788, Loss: 0.6690, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6580.5816\n",
      "Epoch: 5789, Loss: 0.6707, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6581.7125\n",
      "Epoch: 5790, Loss: 0.6709, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6582.8479\n",
      "Epoch: 5791, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6583.9833\n",
      "Epoch: 5792, Loss: 0.6683, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6585.1199\n",
      "Epoch: 5793, Loss: 0.6631, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6586.2558\n",
      "Epoch: 5794, Loss: 0.6626, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6587.3892\n",
      "Epoch: 5795, Loss: 0.6637, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6588.5256\n",
      "Epoch: 5796, Loss: 0.6613, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6589.6584\n",
      "Epoch: 5797, Loss: 0.6584, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6590.7924\n",
      "Epoch: 5798, Loss: 0.6607, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6591.9280\n",
      "Epoch: 5799, Loss: 0.6624, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6593.0541\n",
      "Epoch: 5800, Loss: 0.6629, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6594.1901\n",
      "Epoch: 5801, Loss: 0.6690, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6595.3282\n",
      "Epoch: 5802, Loss: 0.6692, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6596.4601\n",
      "Epoch: 5803, Loss: 0.6676, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6597.5936\n",
      "Epoch: 5804, Loss: 0.6652, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6598.7245\n",
      "Epoch: 5805, Loss: 0.6702, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6599.8580\n",
      "Epoch: 5806, Loss: 0.6710, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6600.9912\n",
      "Epoch: 5807, Loss: 0.6699, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6602.1273\n",
      "Epoch: 5808, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6603.2717\n",
      "Epoch: 5809, Loss: 0.6663, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6604.4123\n",
      "Epoch: 5810, Loss: 0.6634, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6605.5484\n",
      "Epoch: 5811, Loss: 0.6617, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6606.6816\n",
      "Epoch: 5812, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6607.8137\n",
      "Epoch: 5813, Loss: 0.6600, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6608.9436\n",
      "Epoch: 5814, Loss: 0.6613, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6610.0802\n",
      "Epoch: 5815, Loss: 0.6637, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6611.2133\n",
      "Epoch: 5816, Loss: 0.6671, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6612.3426\n",
      "Epoch: 5817, Loss: 0.6667, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6613.4740\n",
      "Epoch: 5818, Loss: 0.6641, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6614.6112\n",
      "Epoch: 5819, Loss: 0.6616, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6615.7500\n",
      "Epoch: 5820, Loss: 0.6621, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6616.8847\n",
      "Epoch: 5821, Loss: 0.6643, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6618.0203\n",
      "Epoch: 5822, Loss: 0.6638, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6619.1575\n",
      "Epoch: 5823, Loss: 0.6640, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6620.2921\n",
      "Epoch: 5824, Loss: 0.6659, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6621.4236\n",
      "Epoch: 5825, Loss: 0.6636, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6622.5571\n",
      "Epoch: 5826, Loss: 0.6634, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6623.6866\n",
      "Epoch: 5827, Loss: 0.6594, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6624.8189\n",
      "Epoch: 5828, Loss: 0.6617, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6625.9530\n",
      "Epoch: 5829, Loss: 0.6614, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6627.0836\n",
      "Epoch: 5830, Loss: 0.6578, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6628.2132\n",
      "Epoch: 5831, Loss: 0.6570, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6629.3507\n",
      "Epoch: 5832, Loss: 0.6585, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6630.4918\n",
      "Epoch: 5833, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6631.6242\n",
      "Epoch: 5834, Loss: 0.6548, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6632.7628\n",
      "Epoch: 5835, Loss: 0.6548, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6633.9018\n",
      "Epoch: 5836, Loss: 0.6653, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6635.0393\n",
      "Epoch: 5837, Loss: 0.6650, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6636.1701\n",
      "Epoch: 5838, Loss: 0.6590, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6637.3076\n",
      "Epoch: 5839, Loss: 0.6583, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6638.4422\n",
      "Epoch: 5840, Loss: 0.6637, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6639.5767\n",
      "Epoch: 5841, Loss: 0.6643, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6640.7083\n",
      "Epoch: 5842, Loss: 0.6564, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6641.8392\n",
      "Epoch: 5843, Loss: 0.6584, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6642.9755\n",
      "Epoch: 5844, Loss: 0.6661, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6644.1157\n",
      "Epoch: 5845, Loss: 0.6687, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6645.2511\n",
      "Epoch: 5846, Loss: 0.6676, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6646.3881\n",
      "Epoch: 5847, Loss: 0.6624, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6647.5259\n",
      "Epoch: 5848, Loss: 0.6581, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6648.6620\n",
      "Epoch: 5849, Loss: 0.6623, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6649.7986\n",
      "Epoch: 5850, Loss: 0.6630, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6650.9344\n",
      "Epoch: 5851, Loss: 0.6613, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6652.0636\n",
      "Epoch: 5852, Loss: 0.6606, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6653.1869\n",
      "Epoch: 5853, Loss: 0.6643, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6654.3199\n",
      "Epoch: 5854, Loss: 0.6650, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6655.4482\n",
      "Epoch: 5855, Loss: 0.6680, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6656.5758\n",
      "Epoch: 5856, Loss: 0.6661, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6657.7063\n",
      "Epoch: 5857, Loss: 0.6686, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6658.8435\n",
      "Epoch: 5858, Loss: 0.6665, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6659.9784\n",
      "Epoch: 5859, Loss: 0.6704, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6661.1108\n",
      "Epoch: 5860, Loss: 0.6692, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6662.2405\n",
      "Epoch: 5861, Loss: 0.6686, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6663.3804\n",
      "Epoch: 5862, Loss: 0.6619, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6664.5128\n",
      "Epoch: 5863, Loss: 0.6601, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6665.6455\n",
      "Epoch: 5864, Loss: 0.6603, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6666.7786\n",
      "Epoch: 5865, Loss: 0.6589, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6667.9090\n",
      "Epoch: 5866, Loss: 0.6581, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6669.0411\n",
      "Epoch: 5867, Loss: 0.6583, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6670.1771\n",
      "Epoch: 5868, Loss: 0.6576, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6671.3074\n",
      "Epoch: 5869, Loss: 0.6584, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6672.4399\n",
      "Epoch: 5870, Loss: 0.6594, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6673.5762\n",
      "Epoch: 5871, Loss: 0.6595, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6674.7098\n",
      "Epoch: 5872, Loss: 0.6710, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6675.8484\n",
      "Epoch: 5873, Loss: 0.6700, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6676.9807\n",
      "Epoch: 5874, Loss: 0.6715, Train_Acc: 0.5769, TEST_Acc: 0.6567, Time: 6678.1145\n",
      "Epoch: 5875, Loss: 0.6721, Train_Acc: 0.5769, TEST_Acc: 0.6567, Time: 6679.2487\n",
      "Epoch: 5876, Loss: 0.6699, Train_Acc: 0.5769, TEST_Acc: 0.6633, Time: 6680.3877\n",
      "Epoch: 5877, Loss: 0.6683, Train_Acc: 0.5769, TEST_Acc: 0.6633, Time: 6681.5270\n",
      "Epoch: 5878, Loss: 0.6621, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6682.6628\n",
      "Epoch: 5879, Loss: 0.6609, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6683.7868\n",
      "Epoch: 5880, Loss: 0.6605, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6684.9164\n",
      "Epoch: 5881, Loss: 0.6555, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6686.0528\n",
      "Epoch: 5882, Loss: 0.6543, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6687.1835\n",
      "Epoch: 5883, Loss: 0.6546, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6688.3141\n",
      "Epoch: 5884, Loss: 0.6576, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6689.4430\n",
      "Epoch: 5885, Loss: 0.6591, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6690.5734\n",
      "Epoch: 5886, Loss: 0.6552, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6691.7125\n",
      "Epoch: 5887, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6692.8475\n",
      "Epoch: 5888, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6693.9904\n",
      "Epoch: 5889, Loss: 0.6629, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6695.1278\n",
      "Epoch: 5890, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6696.2651\n",
      "Epoch: 5891, Loss: 0.6617, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6697.3945\n",
      "Epoch: 5892, Loss: 0.6691, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6698.5285\n",
      "Epoch: 5893, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6699.6660\n",
      "Epoch: 5894, Loss: 0.6674, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6700.7957\n",
      "Epoch: 5895, Loss: 0.6690, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6701.9325\n",
      "Epoch: 5896, Loss: 0.6665, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6703.0698\n",
      "Epoch: 5897, Loss: 0.6654, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6704.2010\n",
      "Epoch: 5898, Loss: 0.6662, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6705.3333\n",
      "Epoch: 5899, Loss: 0.6662, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6706.4697\n",
      "Epoch: 5900, Loss: 0.6675, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6707.6063\n",
      "Epoch: 5901, Loss: 0.6673, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6708.7395\n",
      "Epoch: 5902, Loss: 0.6651, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6709.8733\n",
      "Epoch: 5903, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6711.0141\n",
      "Epoch: 5904, Loss: 0.6725, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6712.1430\n",
      "Epoch: 5905, Loss: 0.6686, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6713.2809\n",
      "Epoch: 5906, Loss: 0.6711, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6714.4190\n",
      "Epoch: 5907, Loss: 0.6702, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6715.5512\n",
      "Epoch: 5908, Loss: 0.6690, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6716.6852\n",
      "Epoch: 5909, Loss: 0.6687, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6717.8181\n",
      "Epoch: 5910, Loss: 0.6687, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6718.9491\n",
      "Epoch: 5911, Loss: 0.6690, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6720.0834\n",
      "Epoch: 5912, Loss: 0.6684, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6721.2195\n",
      "Epoch: 5913, Loss: 0.6717, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6722.3571\n",
      "Epoch: 5914, Loss: 0.6697, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6723.4931\n",
      "Epoch: 5915, Loss: 0.6687, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6724.6348\n",
      "Epoch: 5916, Loss: 0.6626, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6725.7705\n",
      "Epoch: 5917, Loss: 0.6623, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6726.9018\n",
      "Epoch: 5918, Loss: 0.6687, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6728.0340\n",
      "Epoch: 5919, Loss: 0.6633, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6729.1696\n",
      "Epoch: 5920, Loss: 0.6702, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6730.3044\n",
      "Epoch: 5921, Loss: 0.6624, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6731.4409\n",
      "Epoch: 5922, Loss: 0.6619, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6732.5723\n",
      "Epoch: 5923, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6733.7022\n",
      "Epoch: 5924, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6734.8392\n",
      "Epoch: 5925, Loss: 0.6592, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6735.9818\n",
      "Epoch: 5926, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6737.1150\n",
      "Epoch: 5927, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6738.2487\n",
      "Epoch: 5928, Loss: 0.6581, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6739.3863\n",
      "Epoch: 5929, Loss: 0.6615, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6740.5268\n",
      "Epoch: 5930, Loss: 0.6739, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6741.6614\n",
      "Epoch: 5931, Loss: 0.6738, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6742.7961\n",
      "Epoch: 5932, Loss: 0.6740, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6743.9351\n",
      "Epoch: 5933, Loss: 0.6664, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6745.0673\n",
      "Epoch: 5934, Loss: 0.6659, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6746.2034\n",
      "Epoch: 5935, Loss: 0.6653, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6747.3329\n",
      "Epoch: 5936, Loss: 0.6638, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6748.4653\n",
      "Epoch: 5937, Loss: 0.6605, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6749.6001\n",
      "Epoch: 5938, Loss: 0.6616, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6750.7337\n",
      "Epoch: 5939, Loss: 0.6624, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6751.8708\n",
      "Epoch: 5940, Loss: 0.6633, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6753.0043\n",
      "Epoch: 5941, Loss: 0.6650, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6754.1418\n",
      "Epoch: 5942, Loss: 0.6651, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6755.2823\n",
      "Epoch: 5943, Loss: 0.6699, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6756.4269\n",
      "Epoch: 5944, Loss: 0.6661, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6757.5602\n",
      "Epoch: 5945, Loss: 0.6558, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6758.6914\n",
      "Epoch: 5946, Loss: 0.6541, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6759.8276\n",
      "Epoch: 5947, Loss: 0.6578, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6760.9593\n",
      "Epoch: 5948, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6762.0925\n",
      "Epoch: 5949, Loss: 0.6598, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6763.2343\n",
      "Epoch: 5950, Loss: 0.6566, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6764.3639\n",
      "Epoch: 5951, Loss: 0.6548, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6765.5011\n",
      "Epoch: 5952, Loss: 0.6560, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6766.6407\n",
      "Epoch: 5953, Loss: 0.6528, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6767.7745\n",
      "Epoch: 5954, Loss: 0.6546, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6768.9091\n",
      "Epoch: 5955, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6770.0456\n",
      "Epoch: 5956, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6771.1821\n",
      "Epoch: 5957, Loss: 0.6516, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6772.3124\n",
      "Epoch: 5958, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6773.4413\n",
      "Epoch: 5959, Loss: 0.6611, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6774.5760\n",
      "Epoch: 5960, Loss: 0.6624, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6775.7090\n",
      "Epoch: 5961, Loss: 0.6605, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6776.8448\n",
      "Epoch: 5962, Loss: 0.6554, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6777.9770\n",
      "Epoch: 5963, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6779.1109\n",
      "Epoch: 5964, Loss: 0.6638, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6780.2411\n",
      "Epoch: 5965, Loss: 0.6629, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6781.3779\n",
      "Epoch: 5966, Loss: 0.6606, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6782.5173\n",
      "Epoch: 5967, Loss: 0.6630, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6783.6611\n",
      "Epoch: 5968, Loss: 0.6617, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6784.7957\n",
      "Epoch: 5969, Loss: 0.6645, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6785.9318\n",
      "Epoch: 5970, Loss: 0.6686, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6787.0648\n",
      "Epoch: 5971, Loss: 0.6710, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6788.1925\n",
      "Epoch: 5972, Loss: 0.6709, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6789.3248\n",
      "Epoch: 5973, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6790.4578\n",
      "Epoch: 5974, Loss: 0.6706, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6791.5886\n",
      "Epoch: 5975, Loss: 0.6732, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6792.7214\n",
      "Epoch: 5976, Loss: 0.6744, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6793.8531\n",
      "Epoch: 5977, Loss: 0.6711, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6794.9849\n",
      "Epoch: 5978, Loss: 0.6728, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6796.1186\n",
      "Epoch: 5979, Loss: 0.6710, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6797.2539\n",
      "Epoch: 5980, Loss: 0.6726, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6798.3907\n",
      "Epoch: 5981, Loss: 0.6703, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6799.5308\n",
      "Epoch: 5982, Loss: 0.6717, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6800.6732\n",
      "Epoch: 5983, Loss: 0.6754, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6801.8111\n",
      "Epoch: 5984, Loss: 0.6739, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6802.9435\n",
      "Epoch: 5985, Loss: 0.6729, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6804.0679\n",
      "Epoch: 5986, Loss: 0.6781, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6805.1894\n",
      "Epoch: 5987, Loss: 0.6776, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6806.3143\n",
      "Epoch: 5988, Loss: 0.6747, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6807.4402\n",
      "Epoch: 5989, Loss: 0.6737, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6808.5679\n",
      "Epoch: 5990, Loss: 0.6698, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6809.7033\n",
      "Epoch: 5991, Loss: 0.6703, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6810.8370\n",
      "Epoch: 5992, Loss: 0.6705, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6811.9733\n",
      "Epoch: 5993, Loss: 0.6710, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6813.1047\n",
      "Epoch: 5994, Loss: 0.6709, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6814.2448\n",
      "Epoch: 5995, Loss: 0.6768, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6815.3769\n",
      "Epoch: 5996, Loss: 0.6787, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6816.5016\n",
      "Epoch: 5997, Loss: 0.6808, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6817.6343\n",
      "Epoch: 5998, Loss: 0.6806, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6818.7654\n",
      "Epoch: 5999, Loss: 0.6771, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6819.8996\n",
      "Epoch: 6000, Loss: 0.6761, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6821.0301\n",
      "Epoch: 6001, Loss: 0.6761, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6822.1651\n",
      "Epoch: 6002, Loss: 0.6703, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6823.2967\n",
      "Epoch: 6003, Loss: 0.6675, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6824.4328\n",
      "Epoch: 6004, Loss: 0.6652, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6825.5695\n",
      "Epoch: 6005, Loss: 0.6616, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6826.7046\n",
      "Epoch: 6006, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6827.8395\n",
      "Epoch: 6007, Loss: 0.6634, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6828.9749\n",
      "Epoch: 6008, Loss: 0.6644, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6830.1100\n",
      "Epoch: 6009, Loss: 0.6656, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6831.2390\n",
      "Epoch: 6010, Loss: 0.6627, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6832.3713\n",
      "Epoch: 6011, Loss: 0.6622, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6833.5068\n",
      "Epoch: 6012, Loss: 0.6626, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6834.6437\n",
      "Epoch: 6013, Loss: 0.6646, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6835.7766\n",
      "Epoch: 6014, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6836.9107\n",
      "Epoch: 6015, Loss: 0.6637, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6838.0388\n",
      "Epoch: 6016, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6839.1694\n",
      "Epoch: 6017, Loss: 0.6645, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6840.3091\n",
      "Epoch: 6018, Loss: 0.6664, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6841.4449\n",
      "Epoch: 6019, Loss: 0.6674, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6842.5851\n",
      "Epoch: 6020, Loss: 0.6660, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6843.7294\n",
      "Epoch: 6021, Loss: 0.6672, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6844.8715\n",
      "Epoch: 6022, Loss: 0.6681, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6846.0054\n",
      "Epoch: 6023, Loss: 0.6673, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6847.1381\n",
      "Epoch: 6024, Loss: 0.6647, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6848.2676\n",
      "Epoch: 6025, Loss: 0.6609, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6849.3964\n",
      "Epoch: 6026, Loss: 0.6577, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6850.5276\n",
      "Epoch: 6027, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6851.6565\n",
      "Epoch: 6028, Loss: 0.6592, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6852.7870\n",
      "Epoch: 6029, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6853.9227\n",
      "Epoch: 6030, Loss: 0.6626, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6855.0651\n",
      "Epoch: 6031, Loss: 0.6627, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 6856.2028\n",
      "Epoch: 6032, Loss: 0.6588, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6857.3342\n",
      "Epoch: 6033, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6858.4735\n",
      "Epoch: 6034, Loss: 0.6547, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6859.6134\n",
      "Epoch: 6035, Loss: 0.6539, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6860.7432\n",
      "Epoch: 6036, Loss: 0.6554, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6861.8759\n",
      "Epoch: 6037, Loss: 0.6536, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6863.0061\n",
      "Epoch: 6038, Loss: 0.6522, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6864.1456\n",
      "Epoch: 6039, Loss: 0.6540, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6865.2898\n",
      "Epoch: 6040, Loss: 0.6522, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6866.4204\n",
      "Epoch: 6041, Loss: 0.6516, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6867.5522\n",
      "Epoch: 6042, Loss: 0.6563, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6868.6813\n",
      "Epoch: 6043, Loss: 0.6533, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6869.8108\n",
      "Epoch: 6044, Loss: 0.6573, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6870.9378\n",
      "Epoch: 6045, Loss: 0.6610, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6872.0718\n",
      "Epoch: 6046, Loss: 0.6641, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6873.2083\n",
      "Epoch: 6047, Loss: 0.6644, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6874.3438\n",
      "Epoch: 6048, Loss: 0.6616, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6875.4913\n",
      "Epoch: 6049, Loss: 0.6603, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6876.6296\n",
      "Epoch: 6050, Loss: 0.6638, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6877.7608\n",
      "Epoch: 6051, Loss: 0.6653, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6878.8927\n",
      "Epoch: 6052, Loss: 0.6661, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6880.0261\n",
      "Epoch: 6053, Loss: 0.6659, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6881.1600\n",
      "Epoch: 6054, Loss: 0.6667, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6882.2954\n",
      "Epoch: 6055, Loss: 0.6660, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6883.4364\n",
      "Epoch: 6056, Loss: 0.6667, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6884.5710\n",
      "Epoch: 6057, Loss: 0.6664, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 6885.7064\n",
      "Epoch: 6058, Loss: 0.6696, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6886.8454\n",
      "Epoch: 6059, Loss: 0.6717, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6887.9848\n",
      "Epoch: 6060, Loss: 0.6677, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 6889.1186\n",
      "Epoch: 6061, Loss: 0.6683, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6890.2556\n",
      "Epoch: 6062, Loss: 0.6683, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6891.3891\n",
      "Epoch: 6063, Loss: 0.6660, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6892.5220\n",
      "Epoch: 6064, Loss: 0.6646, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6893.6524\n",
      "Epoch: 6065, Loss: 0.6628, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 6894.7796\n",
      "Epoch: 6066, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6895.9054\n",
      "Epoch: 6067, Loss: 0.6619, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6897.0383\n",
      "Epoch: 6068, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6898.1735\n",
      "Epoch: 6069, Loss: 0.6605, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6899.3019\n",
      "Epoch: 6070, Loss: 0.6548, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6900.4342\n",
      "Epoch: 6071, Loss: 0.6536, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6901.5683\n",
      "Epoch: 6072, Loss: 0.6542, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6902.7022\n",
      "Epoch: 6073, Loss: 0.6569, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6903.8378\n",
      "Epoch: 6074, Loss: 0.6559, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6904.9735\n",
      "Epoch: 6075, Loss: 0.6549, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6906.1203\n",
      "Epoch: 6076, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6907.2487\n",
      "Epoch: 6077, Loss: 0.6570, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6908.3789\n",
      "Epoch: 6078, Loss: 0.6577, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6909.5173\n",
      "Epoch: 6079, Loss: 0.6608, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6910.6482\n",
      "Epoch: 6080, Loss: 0.6599, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6911.7764\n",
      "Epoch: 6081, Loss: 0.6591, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6912.9073\n",
      "Epoch: 6082, Loss: 0.6577, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6914.0362\n",
      "Epoch: 6083, Loss: 0.6591, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6915.1678\n",
      "Epoch: 6084, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6916.3056\n",
      "Epoch: 6085, Loss: 0.6613, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6917.4403\n",
      "Epoch: 6086, Loss: 0.6642, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6918.5765\n",
      "Epoch: 6087, Loss: 0.6634, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6919.7104\n",
      "Epoch: 6088, Loss: 0.6624, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6920.8567\n",
      "Epoch: 6089, Loss: 0.6629, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6921.9915\n",
      "Epoch: 6090, Loss: 0.6646, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6923.1236\n",
      "Epoch: 6091, Loss: 0.6644, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6924.2605\n",
      "Epoch: 6092, Loss: 0.6653, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6925.3956\n",
      "Epoch: 6093, Loss: 0.6662, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6926.5272\n",
      "Epoch: 6094, Loss: 0.6661, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6927.6575\n",
      "Epoch: 6095, Loss: 0.6673, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6928.7910\n",
      "Epoch: 6096, Loss: 0.6684, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6929.9237\n",
      "Epoch: 6097, Loss: 0.6691, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6931.0673\n",
      "Epoch: 6098, Loss: 0.6686, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6932.2042\n",
      "Epoch: 6099, Loss: 0.6691, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6933.3383\n",
      "Epoch: 6100, Loss: 0.6681, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6934.4771\n",
      "Epoch: 6101, Loss: 0.6677, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6935.6170\n",
      "Epoch: 6102, Loss: 0.6683, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6936.7513\n",
      "Epoch: 6103, Loss: 0.6677, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6937.8876\n",
      "Epoch: 6104, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6939.0219\n",
      "Epoch: 6105, Loss: 0.6684, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6940.1502\n",
      "Epoch: 6106, Loss: 0.6678, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6941.2856\n",
      "Epoch: 6107, Loss: 0.6697, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6942.4226\n",
      "Epoch: 6108, Loss: 0.6722, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6943.5491\n",
      "Epoch: 6109, Loss: 0.6776, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6944.6819\n",
      "Epoch: 6110, Loss: 0.6780, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6945.8141\n",
      "Epoch: 6111, Loss: 0.6756, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6946.9520\n",
      "Epoch: 6112, Loss: 0.6736, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6948.0867\n",
      "Epoch: 6113, Loss: 0.6745, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6949.2258\n",
      "Epoch: 6114, Loss: 0.6747, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6950.3638\n",
      "Epoch: 6115, Loss: 0.6740, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6951.5024\n",
      "Epoch: 6116, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6952.6402\n",
      "Epoch: 6117, Loss: 0.6720, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6953.7732\n",
      "Epoch: 6118, Loss: 0.6701, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6954.9144\n",
      "Epoch: 6119, Loss: 0.6694, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6956.0502\n",
      "Epoch: 6120, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6957.1857\n",
      "Epoch: 6121, Loss: 0.6700, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 6958.3180\n",
      "Epoch: 6122, Loss: 0.6686, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6959.4531\n",
      "Epoch: 6123, Loss: 0.6704, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6960.5866\n",
      "Epoch: 6124, Loss: 0.6739, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6961.7236\n",
      "Epoch: 6125, Loss: 0.6725, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6962.8617\n",
      "Epoch: 6126, Loss: 0.6721, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6964.0027\n",
      "Epoch: 6127, Loss: 0.6708, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6965.1351\n",
      "Epoch: 6128, Loss: 0.6735, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6966.2749\n",
      "Epoch: 6129, Loss: 0.6736, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6967.4091\n",
      "Epoch: 6130, Loss: 0.6752, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6968.5388\n",
      "Epoch: 6131, Loss: 0.6752, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6969.6728\n",
      "Epoch: 6132, Loss: 0.6737, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6970.8068\n",
      "Epoch: 6133, Loss: 0.6724, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6971.9429\n",
      "Epoch: 6134, Loss: 0.6740, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6973.0811\n",
      "Epoch: 6135, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 6974.2231\n",
      "Epoch: 6136, Loss: 0.6706, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6975.3587\n",
      "Epoch: 6137, Loss: 0.6713, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6976.4960\n",
      "Epoch: 6138, Loss: 0.6773, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6977.6363\n",
      "Epoch: 6139, Loss: 0.6739, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6978.7740\n",
      "Epoch: 6140, Loss: 0.6745, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6979.9122\n",
      "Epoch: 6141, Loss: 0.6739, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6981.0494\n",
      "Epoch: 6142, Loss: 0.6724, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6982.1825\n",
      "Epoch: 6143, Loss: 0.6744, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6983.3149\n",
      "Epoch: 6144, Loss: 0.6687, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6984.4476\n",
      "Epoch: 6145, Loss: 0.6702, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6985.5810\n",
      "Epoch: 6146, Loss: 0.6685, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6986.7148\n",
      "Epoch: 6147, Loss: 0.6707, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6987.8478\n",
      "Epoch: 6148, Loss: 0.6711, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6988.9837\n",
      "Epoch: 6149, Loss: 0.6760, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6990.1156\n",
      "Epoch: 6150, Loss: 0.6726, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6991.2498\n",
      "Epoch: 6151, Loss: 0.6708, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 6992.3857\n",
      "Epoch: 6152, Loss: 0.6684, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6993.5174\n",
      "Epoch: 6153, Loss: 0.6692, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6994.6557\n",
      "Epoch: 6154, Loss: 0.6699, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 6995.7956\n",
      "Epoch: 6155, Loss: 0.6670, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 6996.9402\n",
      "Epoch: 6156, Loss: 0.6651, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6998.0714\n",
      "Epoch: 6157, Loss: 0.6630, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 6999.2025\n",
      "Epoch: 6158, Loss: 0.6595, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7000.3395\n",
      "Epoch: 6159, Loss: 0.6591, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7001.4685\n",
      "Epoch: 6160, Loss: 0.6584, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7002.5993\n",
      "Epoch: 6161, Loss: 0.6564, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7003.7417\n",
      "Epoch: 6162, Loss: 0.6576, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7004.8778\n",
      "Epoch: 6163, Loss: 0.6577, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 7006.0183\n",
      "Epoch: 6164, Loss: 0.6572, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 7007.1554\n",
      "Epoch: 6165, Loss: 0.6552, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7008.2917\n",
      "Epoch: 6166, Loss: 0.6541, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7009.4301\n",
      "Epoch: 6167, Loss: 0.6539, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7010.5644\n",
      "Epoch: 6168, Loss: 0.6547, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7011.7039\n",
      "Epoch: 6169, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7012.8421\n",
      "Epoch: 6170, Loss: 0.6558, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7013.9735\n",
      "Epoch: 6171, Loss: 0.6579, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7015.1080\n",
      "Epoch: 6172, Loss: 0.6567, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7016.2358\n",
      "Epoch: 6173, Loss: 0.6558, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7017.3786\n",
      "Epoch: 6174, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7018.5143\n",
      "Epoch: 6175, Loss: 0.6609, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7019.6453\n",
      "Epoch: 6176, Loss: 0.6590, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7020.7791\n",
      "Epoch: 6177, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7021.9160\n",
      "Epoch: 6178, Loss: 0.6582, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7023.0505\n",
      "Epoch: 6179, Loss: 0.6610, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7024.1881\n",
      "Epoch: 6180, Loss: 0.6602, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7025.3239\n",
      "Epoch: 6181, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7026.4654\n",
      "Epoch: 6182, Loss: 0.6596, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7027.6007\n",
      "Epoch: 6183, Loss: 0.6618, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7028.7336\n",
      "Epoch: 6184, Loss: 0.6638, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7029.8669\n",
      "Epoch: 6185, Loss: 0.6614, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7031.0009\n",
      "Epoch: 6186, Loss: 0.6610, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7032.1323\n",
      "Epoch: 6187, Loss: 0.6592, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7033.2638\n",
      "Epoch: 6188, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7034.3923\n",
      "Epoch: 6189, Loss: 0.6600, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7035.5248\n",
      "Epoch: 6190, Loss: 0.6571, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7036.6556\n",
      "Epoch: 6191, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7037.7888\n",
      "Epoch: 6192, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7038.9306\n",
      "Epoch: 6193, Loss: 0.6564, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7040.0683\n",
      "Epoch: 6194, Loss: 0.6578, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7041.2045\n",
      "Epoch: 6195, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7042.3421\n",
      "Epoch: 6196, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7043.4771\n",
      "Epoch: 6197, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7044.6086\n",
      "Epoch: 6198, Loss: 0.6608, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7045.7399\n",
      "Epoch: 6199, Loss: 0.6632, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7046.8714\n",
      "Epoch: 6200, Loss: 0.6629, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7048.0044\n",
      "Epoch: 6201, Loss: 0.6589, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7049.1336\n",
      "Epoch: 6202, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7050.2728\n",
      "Epoch: 6203, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7051.4036\n",
      "Epoch: 6204, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7052.5364\n",
      "Epoch: 6205, Loss: 0.6549, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7053.6707\n",
      "Epoch: 6206, Loss: 0.6538, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7054.8069\n",
      "Epoch: 6207, Loss: 0.6474, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7055.9436\n",
      "Epoch: 6208, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7057.0852\n",
      "Epoch: 6209, Loss: 0.6417, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7058.2192\n",
      "Epoch: 6210, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7059.3537\n",
      "Epoch: 6211, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7060.4906\n",
      "Epoch: 6212, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7061.6196\n",
      "Epoch: 6213, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7062.7514\n",
      "Epoch: 6214, Loss: 0.6494, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7063.8789\n",
      "Epoch: 6215, Loss: 0.6525, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7065.0112\n",
      "Epoch: 6216, Loss: 0.6564, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7066.1433\n",
      "Epoch: 6217, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7067.2783\n",
      "Epoch: 6218, Loss: 0.6600, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7068.4123\n",
      "Epoch: 6219, Loss: 0.6596, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7069.5516\n",
      "Epoch: 6220, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7070.6874\n",
      "Epoch: 6221, Loss: 0.6584, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7071.8279\n",
      "Epoch: 6222, Loss: 0.6595, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7072.9644\n",
      "Epoch: 6223, Loss: 0.6579, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7074.1028\n",
      "Epoch: 6224, Loss: 0.6595, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7075.2466\n",
      "Epoch: 6225, Loss: 0.6600, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7076.3816\n",
      "Epoch: 6226, Loss: 0.6582, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7077.5122\n",
      "Epoch: 6227, Loss: 0.6599, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7078.6481\n",
      "Epoch: 6228, Loss: 0.6580, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7079.7809\n",
      "Epoch: 6229, Loss: 0.6547, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7080.9137\n",
      "Epoch: 6230, Loss: 0.6539, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7082.0501\n",
      "Epoch: 6231, Loss: 0.6543, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7083.1823\n",
      "Epoch: 6232, Loss: 0.6543, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7084.3156\n",
      "Epoch: 6233, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7085.4575\n",
      "Epoch: 6234, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7086.5941\n",
      "Epoch: 6235, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7087.7385\n",
      "Epoch: 6236, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7088.8766\n",
      "Epoch: 6237, Loss: 0.6506, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7090.0134\n",
      "Epoch: 6238, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7091.1466\n",
      "Epoch: 6239, Loss: 0.6484, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7092.2796\n",
      "Epoch: 6240, Loss: 0.6492, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7093.4146\n",
      "Epoch: 6241, Loss: 0.6494, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7094.5452\n",
      "Epoch: 6242, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7095.6787\n",
      "Epoch: 6243, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7096.8062\n",
      "Epoch: 6244, Loss: 0.6544, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7097.9392\n",
      "Epoch: 6245, Loss: 0.6537, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7099.0680\n",
      "Epoch: 6246, Loss: 0.6533, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7100.1983\n",
      "Epoch: 6247, Loss: 0.6535, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7101.3312\n",
      "Epoch: 6248, Loss: 0.6533, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7102.4678\n",
      "Epoch: 6249, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7103.6042\n",
      "Epoch: 6250, Loss: 0.6511, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7104.7397\n",
      "Epoch: 6251, Loss: 0.6511, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7105.8725\n",
      "Epoch: 6252, Loss: 0.6517, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7107.0048\n",
      "Epoch: 6253, Loss: 0.6522, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7108.1388\n",
      "Epoch: 6254, Loss: 0.6564, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7109.2699\n",
      "Epoch: 6255, Loss: 0.6596, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7110.4022\n",
      "Epoch: 6256, Loss: 0.6605, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 7111.5318\n",
      "Epoch: 6257, Loss: 0.6622, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 7112.6649\n",
      "Epoch: 6258, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 7113.7963\n",
      "Epoch: 6259, Loss: 0.6607, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 7114.9312\n",
      "Epoch: 6260, Loss: 0.6618, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7116.0777\n",
      "Epoch: 6261, Loss: 0.6635, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7117.2167\n",
      "Epoch: 6262, Loss: 0.6671, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7118.3506\n",
      "Epoch: 6263, Loss: 0.6668, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7119.4869\n",
      "Epoch: 6264, Loss: 0.6683, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7120.6215\n",
      "Epoch: 6265, Loss: 0.6695, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7121.7533\n",
      "Epoch: 6266, Loss: 0.6704, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7122.8831\n",
      "Epoch: 6267, Loss: 0.6690, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7124.0237\n",
      "Epoch: 6268, Loss: 0.6646, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7125.1579\n",
      "Epoch: 6269, Loss: 0.6639, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7126.2989\n",
      "Epoch: 6270, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7127.4329\n",
      "Epoch: 6271, Loss: 0.6630, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7128.5662\n",
      "Epoch: 6272, Loss: 0.6645, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7129.6991\n",
      "Epoch: 6273, Loss: 0.6629, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7130.8327\n",
      "Epoch: 6274, Loss: 0.6619, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7131.9711\n",
      "Epoch: 6275, Loss: 0.6626, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7133.1048\n",
      "Epoch: 6276, Loss: 0.6631, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7134.2414\n",
      "Epoch: 6277, Loss: 0.6618, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7135.3796\n",
      "Epoch: 6278, Loss: 0.6578, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7136.5101\n",
      "Epoch: 6279, Loss: 0.6588, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7137.6427\n",
      "Epoch: 6280, Loss: 0.6557, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7138.7719\n",
      "Epoch: 6281, Loss: 0.6599, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7139.9071\n",
      "Epoch: 6282, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7141.0413\n",
      "Epoch: 6283, Loss: 0.6595, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7142.1699\n",
      "Epoch: 6284, Loss: 0.6598, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7143.2986\n",
      "Epoch: 6285, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7144.4331\n",
      "Epoch: 6286, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7145.5667\n",
      "Epoch: 6287, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7146.7055\n",
      "Epoch: 6288, Loss: 0.6570, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7147.8496\n",
      "Epoch: 6289, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7148.9840\n",
      "Epoch: 6290, Loss: 0.6527, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7150.1215\n",
      "Epoch: 6291, Loss: 0.6511, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7151.2533\n",
      "Epoch: 6292, Loss: 0.6488, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7152.3861\n",
      "Epoch: 6293, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7153.5181\n",
      "Epoch: 6294, Loss: 0.6502, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7154.6526\n",
      "Epoch: 6295, Loss: 0.6473, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7155.7875\n",
      "Epoch: 6296, Loss: 0.6487, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7156.9166\n",
      "Epoch: 6297, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7158.0503\n",
      "Epoch: 6298, Loss: 0.6467, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7159.1879\n",
      "Epoch: 6299, Loss: 0.6455, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7160.3230\n",
      "Epoch: 6300, Loss: 0.6471, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7161.4585\n",
      "Epoch: 6301, Loss: 0.6471, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7162.5970\n",
      "Epoch: 6302, Loss: 0.6463, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 7163.7345\n",
      "Epoch: 6303, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 7164.8676\n",
      "Epoch: 6304, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7166.0016\n",
      "Epoch: 6305, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7167.1352\n",
      "Epoch: 6306, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7168.2675\n",
      "Epoch: 6307, Loss: 0.6457, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7169.4021\n",
      "Epoch: 6308, Loss: 0.6505, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 7170.5304\n",
      "Epoch: 6309, Loss: 0.6491, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 7171.6705\n",
      "Epoch: 6310, Loss: 0.6487, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 7172.8008\n",
      "Epoch: 6311, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7173.9319\n",
      "Epoch: 6312, Loss: 0.6538, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7175.0641\n",
      "Epoch: 6313, Loss: 0.6535, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7176.1992\n",
      "Epoch: 6314, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7177.3331\n",
      "Epoch: 6315, Loss: 0.6548, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7178.4795\n",
      "Epoch: 6316, Loss: 0.6537, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7179.6158\n",
      "Epoch: 6317, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7180.7536\n",
      "Epoch: 6318, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7181.8870\n",
      "Epoch: 6319, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7183.0191\n",
      "Epoch: 6320, Loss: 0.6466, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7184.1529\n",
      "Epoch: 6321, Loss: 0.6466, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7185.2826\n",
      "Epoch: 6322, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7186.4153\n",
      "Epoch: 6323, Loss: 0.6484, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7187.5491\n",
      "Epoch: 6324, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7188.6771\n",
      "Epoch: 6325, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7189.8109\n",
      "Epoch: 6326, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7190.9447\n",
      "Epoch: 6327, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7192.0850\n",
      "Epoch: 6328, Loss: 0.6469, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7193.2218\n",
      "Epoch: 6329, Loss: 0.6467, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7194.3596\n",
      "Epoch: 6330, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7195.5012\n",
      "Epoch: 6331, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7196.6361\n",
      "Epoch: 6332, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7197.7655\n",
      "Epoch: 6333, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7198.8977\n",
      "Epoch: 6334, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7200.0364\n",
      "Epoch: 6335, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7201.1748\n",
      "Epoch: 6336, Loss: 0.6463, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7202.3035\n",
      "Epoch: 6337, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7203.4465\n",
      "Epoch: 6338, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7204.5804\n",
      "Epoch: 6339, Loss: 0.6462, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7205.7171\n",
      "Epoch: 6340, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7206.8511\n",
      "Epoch: 6341, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7207.9875\n",
      "Epoch: 6342, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7209.1273\n",
      "Epoch: 6343, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7210.2649\n",
      "Epoch: 6344, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7211.3979\n",
      "Epoch: 6345, Loss: 0.6468, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7212.5291\n",
      "Epoch: 6346, Loss: 0.6484, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7213.6682\n",
      "Epoch: 6347, Loss: 0.6500, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 7214.8026\n",
      "Epoch: 6348, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7215.9325\n",
      "Epoch: 6349, Loss: 0.6517, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 7217.0626\n",
      "Epoch: 6350, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 7218.1935\n",
      "Epoch: 6351, Loss: 0.6541, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7219.3275\n",
      "Epoch: 6352, Loss: 0.6563, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7220.4628\n",
      "Epoch: 6353, Loss: 0.6544, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7221.5996\n",
      "Epoch: 6354, Loss: 0.6505, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 7222.7369\n",
      "Epoch: 6355, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 7223.8754\n",
      "Epoch: 6356, Loss: 0.6491, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7225.0179\n",
      "Epoch: 6357, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7226.1487\n",
      "Epoch: 6358, Loss: 0.6502, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7227.2804\n",
      "Epoch: 6359, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7228.4159\n",
      "Epoch: 6360, Loss: 0.6551, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 7229.5465\n",
      "Epoch: 6361, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 7230.6808\n",
      "Epoch: 6362, Loss: 0.6554, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 7231.8145\n",
      "Epoch: 6363, Loss: 0.6579, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 7232.9470\n",
      "Epoch: 6364, Loss: 0.6594, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 7234.0795\n",
      "Epoch: 6365, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 7235.2117\n",
      "Epoch: 6366, Loss: 0.6578, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 7236.3476\n",
      "Epoch: 6367, Loss: 0.6581, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 7237.4846\n",
      "Epoch: 6368, Loss: 0.6594, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7238.6244\n",
      "Epoch: 6369, Loss: 0.6594, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7239.7633\n",
      "Epoch: 6370, Loss: 0.6598, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7240.8997\n",
      "Epoch: 6371, Loss: 0.6613, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7242.0311\n",
      "Epoch: 6372, Loss: 0.6637, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7243.1622\n",
      "Epoch: 6373, Loss: 0.6622, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7244.3067\n",
      "Epoch: 6374, Loss: 0.6638, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7245.4352\n",
      "Epoch: 6375, Loss: 0.6628, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7246.5712\n",
      "Epoch: 6376, Loss: 0.6656, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7247.7026\n",
      "Epoch: 6377, Loss: 0.6655, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7248.8322\n",
      "Epoch: 6378, Loss: 0.6650, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7249.9653\n",
      "Epoch: 6379, Loss: 0.6634, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7251.1010\n",
      "Epoch: 6380, Loss: 0.6634, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7252.2356\n",
      "Epoch: 6381, Loss: 0.6628, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7253.3691\n",
      "Epoch: 6382, Loss: 0.6633, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7254.5045\n",
      "Epoch: 6383, Loss: 0.6617, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7255.6405\n",
      "Epoch: 6384, Loss: 0.6629, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7256.7698\n",
      "Epoch: 6385, Loss: 0.6617, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7257.9069\n",
      "Epoch: 6386, Loss: 0.6631, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7259.0359\n",
      "Epoch: 6387, Loss: 0.6648, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7260.1668\n",
      "Epoch: 6388, Loss: 0.6584, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7261.2924\n",
      "Epoch: 6389, Loss: 0.6557, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7262.4238\n",
      "Epoch: 6390, Loss: 0.6564, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7263.5590\n",
      "Epoch: 6391, Loss: 0.6566, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7264.6957\n",
      "Epoch: 6392, Loss: 0.6578, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7265.8340\n",
      "Epoch: 6393, Loss: 0.6555, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7266.9686\n",
      "Epoch: 6394, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7268.1077\n",
      "Epoch: 6395, Loss: 0.6564, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7269.2492\n",
      "Epoch: 6396, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7270.3811\n",
      "Epoch: 6397, Loss: 0.6580, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7271.5104\n",
      "Epoch: 6398, Loss: 0.6589, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7272.6451\n",
      "Epoch: 6399, Loss: 0.6554, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7273.7988\n",
      "Epoch: 6400, Loss: 0.6547, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7274.9315\n",
      "Epoch: 6401, Loss: 0.6543, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7276.0675\n",
      "Epoch: 6402, Loss: 0.6541, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7277.1981\n",
      "Epoch: 6403, Loss: 0.6555, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7278.3310\n",
      "Epoch: 6404, Loss: 0.6566, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7279.4776\n",
      "Epoch: 6405, Loss: 0.6544, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7280.6127\n",
      "Epoch: 6406, Loss: 0.6574, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7281.7447\n",
      "Epoch: 6407, Loss: 0.6568, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7282.8793\n",
      "Epoch: 6408, Loss: 0.6569, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7284.0153\n",
      "Epoch: 6409, Loss: 0.6623, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7285.1495\n",
      "Epoch: 6410, Loss: 0.6551, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7286.2809\n",
      "Epoch: 6411, Loss: 0.6535, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7287.4115\n",
      "Epoch: 6412, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7288.5416\n",
      "Epoch: 6413, Loss: 0.6517, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7289.6758\n",
      "Epoch: 6414, Loss: 0.6474, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7290.8076\n",
      "Epoch: 6415, Loss: 0.6500, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7291.9437\n",
      "Epoch: 6416, Loss: 0.6525, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7293.0771\n",
      "Epoch: 6417, Loss: 0.6525, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7294.2108\n",
      "Epoch: 6418, Loss: 0.6523, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7295.3466\n",
      "Epoch: 6419, Loss: 0.6543, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7296.4826\n",
      "Epoch: 6420, Loss: 0.6536, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7297.6188\n",
      "Epoch: 6421, Loss: 0.6559, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7298.7593\n",
      "Epoch: 6422, Loss: 0.6540, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7299.9016\n",
      "Epoch: 6423, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7301.0445\n",
      "Epoch: 6424, Loss: 0.6551, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7302.1787\n",
      "Epoch: 6425, Loss: 0.6559, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7303.3086\n",
      "Epoch: 6426, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7304.4441\n",
      "Epoch: 6427, Loss: 0.6589, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7305.5800\n",
      "Epoch: 6428, Loss: 0.6595, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7306.7129\n",
      "Epoch: 6429, Loss: 0.6583, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7307.8456\n",
      "Epoch: 6430, Loss: 0.6590, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7308.9787\n",
      "Epoch: 6431, Loss: 0.6579, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7310.1185\n",
      "Epoch: 6432, Loss: 0.6595, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7311.2528\n",
      "Epoch: 6433, Loss: 0.6597, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7312.3932\n",
      "Epoch: 6434, Loss: 0.6580, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7313.5263\n",
      "Epoch: 6435, Loss: 0.6590, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7314.6666\n",
      "Epoch: 6436, Loss: 0.6597, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7315.8015\n",
      "Epoch: 6437, Loss: 0.6585, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7316.9341\n",
      "Epoch: 6438, Loss: 0.6626, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7318.0659\n",
      "Epoch: 6439, Loss: 0.6623, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7319.1990\n",
      "Epoch: 6440, Loss: 0.6601, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7320.3330\n",
      "Epoch: 6441, Loss: 0.6573, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7321.4638\n",
      "Epoch: 6442, Loss: 0.6568, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7322.5990\n",
      "Epoch: 6443, Loss: 0.6551, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7323.7315\n",
      "Epoch: 6444, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7324.8647\n",
      "Epoch: 6445, Loss: 0.6552, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7325.9963\n",
      "Epoch: 6446, Loss: 0.6569, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7327.1467\n",
      "Epoch: 6447, Loss: 0.6575, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7328.2811\n",
      "Epoch: 6448, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7329.4215\n",
      "Epoch: 6449, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7330.5608\n",
      "Epoch: 6450, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7331.7021\n",
      "Epoch: 6451, Loss: 0.6552, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7332.8310\n",
      "Epoch: 6452, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7333.9615\n",
      "Epoch: 6453, Loss: 0.6572, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7335.0921\n",
      "Epoch: 6454, Loss: 0.6541, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7336.2203\n",
      "Epoch: 6455, Loss: 0.6517, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7337.3494\n",
      "Epoch: 6456, Loss: 0.6516, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7338.4801\n",
      "Epoch: 6457, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7339.6073\n",
      "Epoch: 6458, Loss: 0.6526, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7340.7399\n",
      "Epoch: 6459, Loss: 0.6536, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7341.8749\n",
      "Epoch: 6460, Loss: 0.6575, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7343.0136\n",
      "Epoch: 6461, Loss: 0.6539, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7344.1595\n",
      "Epoch: 6462, Loss: 0.6563, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7345.2955\n",
      "Epoch: 6463, Loss: 0.6575, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7346.4337\n",
      "Epoch: 6464, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7347.5630\n",
      "Epoch: 6465, Loss: 0.6536, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7348.6898\n",
      "Epoch: 6466, Loss: 0.6527, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7349.8228\n",
      "Epoch: 6467, Loss: 0.6534, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7350.9568\n",
      "Epoch: 6468, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7352.0874\n",
      "Epoch: 6469, Loss: 0.6543, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7353.2204\n",
      "Epoch: 6470, Loss: 0.6526, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7354.3588\n",
      "Epoch: 6471, Loss: 0.6548, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7355.4932\n",
      "Epoch: 6472, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7356.6207\n",
      "Epoch: 6473, Loss: 0.6559, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7357.7565\n",
      "Epoch: 6474, Loss: 0.6566, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7358.8897\n",
      "Epoch: 6475, Loss: 0.6564, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7360.0334\n",
      "Epoch: 6476, Loss: 0.6532, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7361.1746\n",
      "Epoch: 6477, Loss: 0.6521, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7362.3094\n",
      "Epoch: 6478, Loss: 0.6513, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7363.4491\n",
      "Epoch: 6479, Loss: 0.6527, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7364.5813\n",
      "Epoch: 6480, Loss: 0.6524, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7365.7146\n",
      "Epoch: 6481, Loss: 0.6555, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7366.8470\n",
      "Epoch: 6482, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7367.9779\n",
      "Epoch: 6483, Loss: 0.6542, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7369.1084\n",
      "Epoch: 6484, Loss: 0.6543, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7370.2387\n",
      "Epoch: 6485, Loss: 0.6558, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7371.3694\n",
      "Epoch: 6486, Loss: 0.6551, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7372.5046\n",
      "Epoch: 6487, Loss: 0.6554, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7373.6421\n",
      "Epoch: 6488, Loss: 0.6547, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7374.7804\n",
      "Epoch: 6489, Loss: 0.6551, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7375.9214\n",
      "Epoch: 6490, Loss: 0.6579, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7377.0561\n",
      "Epoch: 6491, Loss: 0.6603, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7378.1941\n",
      "Epoch: 6492, Loss: 0.6600, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7379.3273\n",
      "Epoch: 6493, Loss: 0.6572, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7380.4609\n",
      "Epoch: 6494, Loss: 0.6569, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7381.5996\n",
      "Epoch: 6495, Loss: 0.6596, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7382.7315\n",
      "Epoch: 6496, Loss: 0.6589, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7383.8699\n",
      "Epoch: 6497, Loss: 0.6590, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7385.0051\n",
      "Epoch: 6498, Loss: 0.6608, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7386.1373\n",
      "Epoch: 6499, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7387.2777\n",
      "Epoch: 6500, Loss: 0.6574, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7388.4123\n",
      "Epoch: 6501, Loss: 0.6574, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7389.5576\n",
      "Epoch: 6502, Loss: 0.6609, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7390.6957\n",
      "Epoch: 6503, Loss: 0.6576, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7391.8267\n",
      "Epoch: 6504, Loss: 0.6567, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7392.9573\n",
      "Epoch: 6505, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7394.0902\n",
      "Epoch: 6506, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7395.2229\n",
      "Epoch: 6507, Loss: 0.6574, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7396.3544\n",
      "Epoch: 6508, Loss: 0.6590, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7397.4865\n",
      "Epoch: 6509, Loss: 0.6605, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7398.6263\n",
      "Epoch: 6510, Loss: 0.6655, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7399.7586\n",
      "Epoch: 6511, Loss: 0.6631, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7400.8906\n",
      "Epoch: 6512, Loss: 0.6623, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7402.0306\n",
      "Epoch: 6513, Loss: 0.6602, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7403.1657\n",
      "Epoch: 6514, Loss: 0.6619, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7404.2983\n",
      "Epoch: 6515, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7405.4342\n",
      "Epoch: 6516, Loss: 0.6618, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7406.5694\n",
      "Epoch: 6517, Loss: 0.6608, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7407.6994\n",
      "Epoch: 6518, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7408.8331\n",
      "Epoch: 6519, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7409.9665\n",
      "Epoch: 6520, Loss: 0.6576, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7411.0962\n",
      "Epoch: 6521, Loss: 0.6591, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7412.2277\n",
      "Epoch: 6522, Loss: 0.6685, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7413.3566\n",
      "Epoch: 6523, Loss: 0.6656, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7414.4856\n",
      "Epoch: 6524, Loss: 0.6651, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7415.6164\n",
      "Epoch: 6525, Loss: 0.6619, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7416.7476\n",
      "Epoch: 6526, Loss: 0.6611, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7417.8835\n",
      "Epoch: 6527, Loss: 0.6669, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7419.0192\n",
      "Epoch: 6528, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7420.1625\n",
      "Epoch: 6529, Loss: 0.6623, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7421.2966\n",
      "Epoch: 6530, Loss: 0.6642, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7422.4302\n",
      "Epoch: 6531, Loss: 0.6632, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7423.5659\n",
      "Epoch: 6532, Loss: 0.6622, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7424.7049\n",
      "Epoch: 6533, Loss: 0.6629, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7425.8407\n",
      "Epoch: 6534, Loss: 0.6599, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7426.9760\n",
      "Epoch: 6535, Loss: 0.6585, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7428.1073\n",
      "Epoch: 6536, Loss: 0.6546, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7429.2403\n",
      "Epoch: 6537, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 7430.3738\n",
      "Epoch: 6538, Loss: 0.6558, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7431.5086\n",
      "Epoch: 6539, Loss: 0.6581, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7432.6484\n",
      "Epoch: 6540, Loss: 0.6601, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7433.7849\n",
      "Epoch: 6541, Loss: 0.6616, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7434.9304\n",
      "Epoch: 6542, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7436.0622\n",
      "Epoch: 6543, Loss: 0.6582, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7437.2017\n",
      "Epoch: 6544, Loss: 0.6547, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7438.3335\n",
      "Epoch: 6545, Loss: 0.6566, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7439.4645\n",
      "Epoch: 6546, Loss: 0.6560, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7440.5939\n",
      "Epoch: 6547, Loss: 0.6575, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7441.7252\n",
      "Epoch: 6548, Loss: 0.6590, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7442.8580\n",
      "Epoch: 6549, Loss: 0.6598, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7443.9922\n",
      "Epoch: 6550, Loss: 0.6599, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7445.1216\n",
      "Epoch: 6551, Loss: 0.6583, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7446.2546\n",
      "Epoch: 6552, Loss: 0.6564, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7447.3910\n",
      "Epoch: 6553, Loss: 0.6573, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7448.5276\n",
      "Epoch: 6554, Loss: 0.6559, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7449.6679\n",
      "Epoch: 6555, Loss: 0.6542, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7450.8012\n",
      "Epoch: 6556, Loss: 0.6576, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7451.9367\n",
      "Epoch: 6557, Loss: 0.6541, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7453.0723\n",
      "Epoch: 6558, Loss: 0.6532, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7454.2114\n",
      "Epoch: 6559, Loss: 0.6517, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7455.3440\n",
      "Epoch: 6560, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7456.4732\n",
      "Epoch: 6561, Loss: 0.6523, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7457.5995\n",
      "Epoch: 6562, Loss: 0.6524, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7458.7342\n",
      "Epoch: 6563, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7459.8634\n",
      "Epoch: 6564, Loss: 0.6533, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7460.9953\n",
      "Epoch: 6565, Loss: 0.6522, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7462.1318\n",
      "Epoch: 6566, Loss: 0.6534, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7463.2687\n",
      "Epoch: 6567, Loss: 0.6539, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7464.4066\n",
      "Epoch: 6568, Loss: 0.6557, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7465.5450\n",
      "Epoch: 6569, Loss: 0.6559, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7466.6796\n",
      "Epoch: 6570, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7467.8153\n",
      "Epoch: 6571, Loss: 0.6548, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7468.9458\n",
      "Epoch: 6572, Loss: 0.6547, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7470.0768\n",
      "Epoch: 6573, Loss: 0.6559, Train_Acc: 0.5769, TEST_Acc: 0.6567, Time: 7471.2074\n",
      "Epoch: 6574, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6567, Time: 7472.3379\n",
      "Epoch: 6575, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6567, Time: 7473.4703\n",
      "Epoch: 6576, Loss: 0.6523, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7474.6087\n",
      "Epoch: 6577, Loss: 0.6552, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7475.7476\n",
      "Epoch: 6578, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7476.8784\n",
      "Epoch: 6579, Loss: 0.6521, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7478.0129\n",
      "Epoch: 6580, Loss: 0.6502, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7479.1513\n",
      "Epoch: 6581, Loss: 0.6502, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7480.2894\n",
      "Epoch: 6582, Loss: 0.6533, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7481.4257\n",
      "Epoch: 6583, Loss: 0.6529, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7482.5628\n",
      "Epoch: 6584, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7483.7074\n",
      "Epoch: 6585, Loss: 0.6551, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7484.8410\n",
      "Epoch: 6586, Loss: 0.6536, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7485.9748\n",
      "Epoch: 6587, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7487.1096\n",
      "Epoch: 6588, Loss: 0.6546, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7488.2376\n",
      "Epoch: 6589, Loss: 0.6521, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7489.3721\n",
      "Epoch: 6590, Loss: 0.6548, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7490.5040\n",
      "Epoch: 6591, Loss: 0.6615, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7491.6351\n",
      "Epoch: 6592, Loss: 0.6610, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7492.7704\n",
      "Epoch: 6593, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7493.9069\n",
      "Epoch: 6594, Loss: 0.6582, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7495.0394\n",
      "Epoch: 6595, Loss: 0.6598, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7496.1739\n",
      "Epoch: 6596, Loss: 0.6577, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7497.3189\n",
      "Epoch: 6597, Loss: 0.6589, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7498.4588\n",
      "Epoch: 6598, Loss: 0.6575, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7499.5919\n",
      "Epoch: 6599, Loss: 0.6559, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7500.7205\n",
      "Epoch: 6600, Loss: 0.6566, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7501.8565\n",
      "Epoch: 6601, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7502.9887\n",
      "Epoch: 6602, Loss: 0.6554, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7504.1209\n",
      "Epoch: 6603, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7505.2536\n",
      "Epoch: 6604, Loss: 0.6571, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7506.3876\n",
      "Epoch: 6605, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7507.5216\n",
      "Epoch: 6606, Loss: 0.6595, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7508.6604\n",
      "Epoch: 6607, Loss: 0.6584, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7509.7996\n",
      "Epoch: 6608, Loss: 0.6568, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7510.9378\n",
      "Epoch: 6609, Loss: 0.6557, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7512.0724\n",
      "Epoch: 6610, Loss: 0.6528, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7513.2134\n",
      "Epoch: 6611, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7514.3542\n",
      "Epoch: 6612, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7515.4862\n",
      "Epoch: 6613, Loss: 0.6539, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7516.6149\n",
      "Epoch: 6614, Loss: 0.6546, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7517.7493\n",
      "Epoch: 6615, Loss: 0.6566, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7518.8788\n",
      "Epoch: 6616, Loss: 0.6576, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7520.0096\n",
      "Epoch: 6617, Loss: 0.6570, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7521.1411\n",
      "Epoch: 6618, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7522.2744\n",
      "Epoch: 6619, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7523.4061\n",
      "Epoch: 6620, Loss: 0.6538, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7524.5453\n",
      "Epoch: 6621, Loss: 0.6512, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7525.6823\n",
      "Epoch: 6622, Loss: 0.6552, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7526.8190\n",
      "Epoch: 6623, Loss: 0.6523, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7527.9568\n",
      "Epoch: 6624, Loss: 0.6536, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 7529.0954\n",
      "Epoch: 6625, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7530.2243\n",
      "Epoch: 6626, Loss: 0.6566, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7531.3569\n",
      "Epoch: 6627, Loss: 0.6566, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7532.4905\n",
      "Epoch: 6628, Loss: 0.6585, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7533.6231\n",
      "Epoch: 6629, Loss: 0.6558, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 7534.7581\n",
      "Epoch: 6630, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6567, Time: 7535.8925\n",
      "Epoch: 6631, Loss: 0.6529, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7537.0253\n",
      "Epoch: 6632, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7538.1582\n",
      "Epoch: 6633, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 7539.2943\n",
      "Epoch: 6634, Loss: 0.6503, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 7540.4381\n",
      "Epoch: 6635, Loss: 0.6514, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7541.5742\n",
      "Epoch: 6636, Loss: 0.6521, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7542.7108\n",
      "Epoch: 6637, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7543.8456\n",
      "Epoch: 6638, Loss: 0.6546, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7544.9800\n",
      "Epoch: 6639, Loss: 0.6557, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7546.1101\n",
      "Epoch: 6640, Loss: 0.6549, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7547.2457\n",
      "Epoch: 6641, Loss: 0.6552, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7548.3777\n",
      "Epoch: 6642, Loss: 0.6562, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7549.5098\n",
      "Epoch: 6643, Loss: 0.6584, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7550.6453\n",
      "Epoch: 6644, Loss: 0.6583, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7551.7829\n",
      "Epoch: 6645, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7552.9174\n",
      "Epoch: 6646, Loss: 0.6591, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7554.0517\n",
      "Epoch: 6647, Loss: 0.6607, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7555.1982\n",
      "Epoch: 6648, Loss: 0.6582, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7556.3329\n",
      "Epoch: 6649, Loss: 0.6602, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7557.4642\n",
      "Epoch: 6650, Loss: 0.6639, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7558.6038\n",
      "Epoch: 6651, Loss: 0.6637, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7559.7386\n",
      "Epoch: 6652, Loss: 0.6631, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7560.8732\n",
      "Epoch: 6653, Loss: 0.6611, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7562.0007\n",
      "Epoch: 6654, Loss: 0.6600, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7563.1386\n",
      "Epoch: 6655, Loss: 0.6602, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7564.2671\n",
      "Epoch: 6656, Loss: 0.6609, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7565.4007\n",
      "Epoch: 6657, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7566.5276\n",
      "Epoch: 6658, Loss: 0.6605, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7567.6571\n",
      "Epoch: 6659, Loss: 0.6621, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7568.7901\n",
      "Epoch: 6660, Loss: 0.6623, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7569.9255\n",
      "Epoch: 6661, Loss: 0.6624, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7571.0692\n",
      "Epoch: 6662, Loss: 0.6582, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7572.2084\n",
      "Epoch: 6663, Loss: 0.6579, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7573.3514\n",
      "Epoch: 6664, Loss: 0.6572, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7574.4860\n",
      "Epoch: 6665, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7575.6186\n",
      "Epoch: 6666, Loss: 0.6603, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7576.7483\n",
      "Epoch: 6667, Loss: 0.6588, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7577.8821\n",
      "Epoch: 6668, Loss: 0.6605, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7579.0158\n",
      "Epoch: 6669, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7580.1486\n",
      "Epoch: 6670, Loss: 0.6680, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7581.2752\n",
      "Epoch: 6671, Loss: 0.6685, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7582.4114\n",
      "Epoch: 6672, Loss: 0.6701, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7583.5495\n",
      "Epoch: 6673, Loss: 0.6701, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7584.6935\n",
      "Epoch: 6674, Loss: 0.6722, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7585.8292\n",
      "Epoch: 6675, Loss: 0.6681, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7586.9652\n",
      "Epoch: 6676, Loss: 0.6683, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7588.1025\n",
      "Epoch: 6677, Loss: 0.6692, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7589.2366\n",
      "Epoch: 6678, Loss: 0.6646, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7590.3646\n",
      "Epoch: 6679, Loss: 0.6642, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7591.4973\n",
      "Epoch: 6680, Loss: 0.6637, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7592.6290\n",
      "Epoch: 6681, Loss: 0.6616, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7593.7655\n",
      "Epoch: 6682, Loss: 0.6609, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7594.9015\n",
      "Epoch: 6683, Loss: 0.6594, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7596.0311\n",
      "Epoch: 6684, Loss: 0.6580, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7597.1624\n",
      "Epoch: 6685, Loss: 0.6579, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7598.2945\n",
      "Epoch: 6686, Loss: 0.6542, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7599.4273\n",
      "Epoch: 6687, Loss: 0.6545, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7600.5630\n",
      "Epoch: 6688, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7601.7063\n",
      "Epoch: 6689, Loss: 0.6560, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7602.8444\n",
      "Epoch: 6690, Loss: 0.6545, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7603.9877\n",
      "Epoch: 6691, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7605.1191\n",
      "Epoch: 6692, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7606.2518\n",
      "Epoch: 6693, Loss: 0.6545, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7607.3866\n",
      "Epoch: 6694, Loss: 0.6559, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7608.5172\n",
      "Epoch: 6695, Loss: 0.6566, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7609.6494\n",
      "Epoch: 6696, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7610.7816\n",
      "Epoch: 6697, Loss: 0.6559, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7611.9134\n",
      "Epoch: 6698, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7613.0437\n",
      "Epoch: 6699, Loss: 0.6571, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7614.1757\n",
      "Epoch: 6700, Loss: 0.6624, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7615.3115\n",
      "Epoch: 6701, Loss: 0.6613, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7616.4491\n",
      "Epoch: 6702, Loss: 0.6658, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7617.5882\n",
      "Epoch: 6703, Loss: 0.6647, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7618.7273\n",
      "Epoch: 6704, Loss: 0.6591, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7619.8588\n",
      "Epoch: 6705, Loss: 0.6580, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7620.9945\n",
      "Epoch: 6706, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7622.1261\n",
      "Epoch: 6707, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7623.2603\n",
      "Epoch: 6708, Loss: 0.6562, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7624.3887\n",
      "Epoch: 6709, Loss: 0.6549, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7625.5179\n",
      "Epoch: 6710, Loss: 0.6548, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7626.6499\n",
      "Epoch: 6711, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7627.7792\n",
      "Epoch: 6712, Loss: 0.6574, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7628.9116\n",
      "Epoch: 6713, Loss: 0.6569, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7630.0472\n",
      "Epoch: 6714, Loss: 0.6571, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7631.1873\n",
      "Epoch: 6715, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7632.3234\n",
      "Epoch: 6716, Loss: 0.6575, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7633.4616\n",
      "Epoch: 6717, Loss: 0.6575, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7634.5984\n",
      "Epoch: 6718, Loss: 0.6572, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7635.7330\n",
      "Epoch: 6719, Loss: 0.6588, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7636.8612\n",
      "Epoch: 6720, Loss: 0.6570, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7637.9915\n",
      "Epoch: 6721, Loss: 0.6577, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7639.1229\n",
      "Epoch: 6722, Loss: 0.6592, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7640.2565\n",
      "Epoch: 6723, Loss: 0.6625, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7641.3856\n",
      "Epoch: 6724, Loss: 0.6640, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7642.5180\n",
      "Epoch: 6725, Loss: 0.6638, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7643.6510\n",
      "Epoch: 6726, Loss: 0.6627, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7644.7830\n",
      "Epoch: 6727, Loss: 0.6638, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7645.9173\n",
      "Epoch: 6728, Loss: 0.6628, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7647.0523\n",
      "Epoch: 6729, Loss: 0.6624, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7648.1904\n",
      "Epoch: 6730, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7649.3229\n",
      "Epoch: 6731, Loss: 0.6617, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7650.4788\n",
      "Epoch: 6732, Loss: 0.6595, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7651.6105\n",
      "Epoch: 6733, Loss: 0.6571, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7652.7438\n",
      "Epoch: 6734, Loss: 0.6577, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7653.8840\n",
      "Epoch: 6735, Loss: 0.6576, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7655.0138\n",
      "Epoch: 6736, Loss: 0.6576, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7656.1441\n",
      "Epoch: 6737, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7657.2760\n",
      "Epoch: 6738, Loss: 0.6569, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7658.4106\n",
      "Epoch: 6739, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7659.5449\n",
      "Epoch: 6740, Loss: 0.6599, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7660.6775\n",
      "Epoch: 6741, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7661.8240\n",
      "Epoch: 6742, Loss: 0.6602, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7662.9579\n",
      "Epoch: 6743, Loss: 0.6574, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7664.0938\n",
      "Epoch: 6744, Loss: 0.6634, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7665.2310\n",
      "Epoch: 6745, Loss: 0.6618, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7666.3670\n",
      "Epoch: 6746, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7667.4966\n",
      "Epoch: 6747, Loss: 0.6612, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7668.6303\n",
      "Epoch: 6748, Loss: 0.6601, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7669.7592\n",
      "Epoch: 6749, Loss: 0.6577, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7670.8863\n",
      "Epoch: 6750, Loss: 0.6563, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7672.0254\n",
      "Epoch: 6751, Loss: 0.6558, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7673.1581\n",
      "Epoch: 6752, Loss: 0.6562, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7674.2914\n",
      "Epoch: 6753, Loss: 0.6542, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7675.4322\n",
      "Epoch: 6754, Loss: 0.6552, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7676.5701\n",
      "Epoch: 6755, Loss: 0.6537, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7677.7081\n",
      "Epoch: 6756, Loss: 0.6537, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7678.8433\n",
      "Epoch: 6757, Loss: 0.6515, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7679.9805\n",
      "Epoch: 6758, Loss: 0.6492, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7681.1125\n",
      "Epoch: 6759, Loss: 0.6511, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7682.2487\n",
      "Epoch: 6760, Loss: 0.6540, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7683.3765\n",
      "Epoch: 6761, Loss: 0.6533, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7684.5082\n",
      "Epoch: 6762, Loss: 0.6521, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7685.6406\n",
      "Epoch: 6763, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7686.7689\n",
      "Epoch: 6764, Loss: 0.6505, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7687.9029\n",
      "Epoch: 6765, Loss: 0.6551, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7689.0392\n",
      "Epoch: 6766, Loss: 0.6538, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7690.1752\n",
      "Epoch: 6767, Loss: 0.6589, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7691.3078\n",
      "Epoch: 6768, Loss: 0.6600, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7692.4451\n",
      "Epoch: 6769, Loss: 0.6611, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7693.5856\n",
      "Epoch: 6770, Loss: 0.6599, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7694.7241\n",
      "Epoch: 6771, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7695.8585\n",
      "Epoch: 6772, Loss: 0.6598, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7696.9904\n",
      "Epoch: 6773, Loss: 0.6612, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7698.1211\n",
      "Epoch: 6774, Loss: 0.6649, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7699.2513\n",
      "Epoch: 6775, Loss: 0.6635, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7700.3811\n",
      "Epoch: 6776, Loss: 0.6610, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7701.5155\n",
      "Epoch: 6777, Loss: 0.6664, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7702.6465\n",
      "Epoch: 6778, Loss: 0.6648, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7703.7772\n",
      "Epoch: 6779, Loss: 0.6634, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7704.9185\n",
      "Epoch: 6780, Loss: 0.6616, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7706.0575\n",
      "Epoch: 6781, Loss: 0.6606, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7707.1940\n",
      "Epoch: 6782, Loss: 0.6618, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7708.3340\n",
      "Epoch: 6783, Loss: 0.6591, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7709.4641\n",
      "Epoch: 6784, Loss: 0.6588, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7710.6041\n",
      "Epoch: 6785, Loss: 0.6578, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7711.7388\n",
      "Epoch: 6786, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7712.8718\n",
      "Epoch: 6787, Loss: 0.6583, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7714.0004\n",
      "Epoch: 6788, Loss: 0.6576, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7715.1417\n",
      "Epoch: 6789, Loss: 0.6554, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7716.2713\n",
      "Epoch: 6790, Loss: 0.6584, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7717.4018\n",
      "Epoch: 6791, Loss: 0.6614, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7718.5341\n",
      "Epoch: 6792, Loss: 0.6580, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7719.6702\n",
      "Epoch: 6793, Loss: 0.6613, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7720.8076\n",
      "Epoch: 6794, Loss: 0.6631, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7721.9432\n",
      "Epoch: 6795, Loss: 0.6628, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7723.0805\n",
      "Epoch: 6796, Loss: 0.6619, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7724.2215\n",
      "Epoch: 6797, Loss: 0.6592, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7725.3677\n",
      "Epoch: 6798, Loss: 0.6597, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7726.5011\n",
      "Epoch: 6799, Loss: 0.6611, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7727.6340\n",
      "Epoch: 6800, Loss: 0.6617, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7728.7677\n",
      "Epoch: 6801, Loss: 0.6654, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7729.8998\n",
      "Epoch: 6802, Loss: 0.6650, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7731.0330\n",
      "Epoch: 6803, Loss: 0.6607, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7732.1638\n",
      "Epoch: 6804, Loss: 0.6610, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7733.2975\n",
      "Epoch: 6805, Loss: 0.6599, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7734.4289\n",
      "Epoch: 6806, Loss: 0.6590, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7735.5614\n",
      "Epoch: 6807, Loss: 0.6590, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7736.7033\n",
      "Epoch: 6808, Loss: 0.6597, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7737.8411\n",
      "Epoch: 6809, Loss: 0.6613, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7738.9729\n",
      "Epoch: 6810, Loss: 0.6589, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7740.1147\n",
      "Epoch: 6811, Loss: 0.6516, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7741.2535\n",
      "Epoch: 6812, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7742.3821\n",
      "Epoch: 6813, Loss: 0.6511, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7743.5138\n",
      "Epoch: 6814, Loss: 0.6516, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7744.6446\n",
      "Epoch: 6815, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7745.7763\n",
      "Epoch: 6816, Loss: 0.6501, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7746.9104\n",
      "Epoch: 6817, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7748.0475\n",
      "Epoch: 6818, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7749.1792\n",
      "Epoch: 6819, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7750.3180\n",
      "Epoch: 6820, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7751.4583\n",
      "Epoch: 6821, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7752.5908\n",
      "Epoch: 6822, Loss: 0.6540, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7753.7286\n",
      "Epoch: 6823, Loss: 0.6590, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7754.8704\n",
      "Epoch: 6824, Loss: 0.6567, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7756.0010\n",
      "Epoch: 6825, Loss: 0.6544, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7757.1264\n",
      "Epoch: 6826, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7758.2673\n",
      "Epoch: 6827, Loss: 0.6524, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7759.3958\n",
      "Epoch: 6828, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7760.5320\n",
      "Epoch: 6829, Loss: 0.6484, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7761.6612\n",
      "Epoch: 6830, Loss: 0.6493, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7762.7924\n",
      "Epoch: 6831, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7763.9231\n",
      "Epoch: 6832, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7765.0558\n",
      "Epoch: 6833, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7766.1936\n",
      "Epoch: 6834, Loss: 0.6484, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7767.3291\n",
      "Epoch: 6835, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7768.4663\n",
      "Epoch: 6836, Loss: 0.6517, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7769.6046\n",
      "Epoch: 6837, Loss: 0.6533, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7770.7354\n",
      "Epoch: 6838, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7771.8648\n",
      "Epoch: 6839, Loss: 0.6516, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7772.9946\n",
      "Epoch: 6840, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7774.1247\n",
      "Epoch: 6841, Loss: 0.6513, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7775.2577\n",
      "Epoch: 6842, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7776.3873\n",
      "Epoch: 6843, Loss: 0.6529, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7777.5216\n",
      "Epoch: 6844, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7778.6559\n",
      "Epoch: 6845, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7779.7939\n",
      "Epoch: 6846, Loss: 0.6526, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7780.9267\n",
      "Epoch: 6847, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7782.0621\n",
      "Epoch: 6848, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7783.1983\n",
      "Epoch: 6849, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7784.3361\n",
      "Epoch: 6850, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7785.4736\n",
      "Epoch: 6851, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7786.6066\n",
      "Epoch: 6852, Loss: 0.6534, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7787.7412\n",
      "Epoch: 6853, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7788.8717\n",
      "Epoch: 6854, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7790.0062\n",
      "Epoch: 6855, Loss: 0.6510, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7791.1377\n",
      "Epoch: 6856, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7792.2697\n",
      "Epoch: 6857, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7793.4003\n",
      "Epoch: 6858, Loss: 0.6540, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7794.5310\n",
      "Epoch: 6859, Loss: 0.6533, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7795.6607\n",
      "Epoch: 6860, Loss: 0.6529, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7796.7942\n",
      "Epoch: 6861, Loss: 0.6514, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7797.9309\n",
      "Epoch: 6862, Loss: 0.6523, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7799.0680\n",
      "Epoch: 6863, Loss: 0.6558, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7800.2052\n",
      "Epoch: 6864, Loss: 0.6535, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7801.3412\n",
      "Epoch: 6865, Loss: 0.6548, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7802.4751\n",
      "Epoch: 6866, Loss: 0.6559, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7803.6082\n",
      "Epoch: 6867, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7804.7391\n",
      "Epoch: 6868, Loss: 0.6545, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7805.8677\n",
      "Epoch: 6869, Loss: 0.6599, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7806.9995\n",
      "Epoch: 6870, Loss: 0.6635, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7808.1346\n",
      "Epoch: 6871, Loss: 0.6611, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7809.2658\n",
      "Epoch: 6872, Loss: 0.6578, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7810.3973\n",
      "Epoch: 6873, Loss: 0.6574, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7811.5299\n",
      "Epoch: 6874, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7812.6748\n",
      "Epoch: 6875, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7813.8152\n",
      "Epoch: 6876, Loss: 0.6589, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7814.9503\n",
      "Epoch: 6877, Loss: 0.6591, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7816.0859\n",
      "Epoch: 6878, Loss: 0.6579, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7817.2201\n",
      "Epoch: 6879, Loss: 0.6599, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7818.3534\n",
      "Epoch: 6880, Loss: 0.6573, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7819.4826\n",
      "Epoch: 6881, Loss: 0.6557, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7820.6159\n",
      "Epoch: 6882, Loss: 0.6549, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7821.7486\n",
      "Epoch: 6883, Loss: 0.6547, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7822.8784\n",
      "Epoch: 6884, Loss: 0.6564, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7824.0213\n",
      "Epoch: 6885, Loss: 0.6525, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7825.1524\n",
      "Epoch: 6886, Loss: 0.6528, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7826.2904\n",
      "Epoch: 6887, Loss: 0.6542, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7827.4247\n",
      "Epoch: 6888, Loss: 0.6545, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7828.5596\n",
      "Epoch: 6889, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7829.7022\n",
      "Epoch: 6890, Loss: 0.6555, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7830.8377\n",
      "Epoch: 6891, Loss: 0.6585, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7831.9704\n",
      "Epoch: 6892, Loss: 0.6594, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7833.1029\n",
      "Epoch: 6893, Loss: 0.6583, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7834.2366\n",
      "Epoch: 6894, Loss: 0.6580, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7835.3685\n",
      "Epoch: 6895, Loss: 0.6581, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7836.4999\n",
      "Epoch: 6896, Loss: 0.6580, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7837.6301\n",
      "Epoch: 6897, Loss: 0.6579, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7838.7647\n",
      "Epoch: 6898, Loss: 0.6579, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7839.8981\n",
      "Epoch: 6899, Loss: 0.6585, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7841.0317\n",
      "Epoch: 6900, Loss: 0.6588, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7842.1671\n",
      "Epoch: 6901, Loss: 0.6583, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7843.3015\n",
      "Epoch: 6902, Loss: 0.6594, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7844.4484\n",
      "Epoch: 6903, Loss: 0.6564, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7845.5837\n",
      "Epoch: 6904, Loss: 0.6563, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7846.7277\n",
      "Epoch: 6905, Loss: 0.6590, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7847.8639\n",
      "Epoch: 6906, Loss: 0.6606, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7848.9979\n",
      "Epoch: 6907, Loss: 0.6611, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7850.1296\n",
      "Epoch: 6908, Loss: 0.6605, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7851.2614\n",
      "Epoch: 6909, Loss: 0.6636, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7852.3923\n",
      "Epoch: 6910, Loss: 0.6619, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7853.5224\n",
      "Epoch: 6911, Loss: 0.6615, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7854.6511\n",
      "Epoch: 6912, Loss: 0.6582, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7855.7852\n",
      "Epoch: 6913, Loss: 0.6567, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7856.9204\n",
      "Epoch: 6914, Loss: 0.6560, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7858.0592\n",
      "Epoch: 6915, Loss: 0.6568, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7859.1954\n",
      "Epoch: 6916, Loss: 0.6548, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7860.3319\n",
      "Epoch: 6917, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7861.4671\n",
      "Epoch: 6918, Loss: 0.6541, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7862.6031\n",
      "Epoch: 6919, Loss: 0.6504, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7863.7369\n",
      "Epoch: 6920, Loss: 0.6493, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7864.8695\n",
      "Epoch: 6921, Loss: 0.6492, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7866.0038\n",
      "Epoch: 6922, Loss: 0.6493, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7867.1423\n",
      "Epoch: 6923, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7868.2744\n",
      "Epoch: 6924, Loss: 0.6495, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7869.4045\n",
      "Epoch: 6925, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7870.5331\n",
      "Epoch: 6926, Loss: 0.6527, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7871.6675\n",
      "Epoch: 6927, Loss: 0.6523, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7872.8048\n",
      "Epoch: 6928, Loss: 0.6526, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7873.9431\n",
      "Epoch: 6929, Loss: 0.6521, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7875.0866\n",
      "Epoch: 6930, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7876.2222\n",
      "Epoch: 6931, Loss: 0.6482, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7877.3561\n",
      "Epoch: 6932, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7878.4969\n",
      "Epoch: 6933, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7879.6280\n",
      "Epoch: 6934, Loss: 0.6512, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7880.7596\n",
      "Epoch: 6935, Loss: 0.6506, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7881.8929\n",
      "Epoch: 6936, Loss: 0.6491, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7883.0206\n",
      "Epoch: 6937, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7884.1487\n",
      "Epoch: 6938, Loss: 0.6514, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7885.2830\n",
      "Epoch: 6939, Loss: 0.6500, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7886.4128\n",
      "Epoch: 6940, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7887.5423\n",
      "Epoch: 6941, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7888.6812\n",
      "Epoch: 6942, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7889.8134\n",
      "Epoch: 6943, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7890.9488\n",
      "Epoch: 6944, Loss: 0.6448, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7892.0820\n",
      "Epoch: 6945, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7893.2227\n",
      "Epoch: 6946, Loss: 0.6487, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7894.3635\n",
      "Epoch: 6947, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7895.4928\n",
      "Epoch: 6948, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7896.6242\n",
      "Epoch: 6949, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7897.7557\n",
      "Epoch: 6950, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7898.8883\n",
      "Epoch: 6951, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7900.0214\n",
      "Epoch: 6952, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7901.1522\n",
      "Epoch: 6953, Loss: 0.6492, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7902.2881\n",
      "Epoch: 6954, Loss: 0.6487, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7903.4237\n",
      "Epoch: 6955, Loss: 0.6466, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7904.5718\n",
      "Epoch: 6956, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7905.7093\n",
      "Epoch: 6957, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7906.8426\n",
      "Epoch: 6958, Loss: 0.6511, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7907.9795\n",
      "Epoch: 6959, Loss: 0.6537, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7909.1114\n",
      "Epoch: 6960, Loss: 0.6552, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7910.2465\n",
      "Epoch: 6961, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7911.3833\n",
      "Epoch: 6962, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7912.5131\n",
      "Epoch: 6963, Loss: 0.6545, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7913.6465\n",
      "Epoch: 6964, Loss: 0.6577, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7914.7835\n",
      "Epoch: 6965, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7915.9156\n",
      "Epoch: 6966, Loss: 0.6543, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7917.0446\n",
      "Epoch: 6967, Loss: 0.6537, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7918.1771\n",
      "Epoch: 6968, Loss: 0.6529, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7919.3095\n",
      "Epoch: 6969, Loss: 0.6512, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7920.4443\n",
      "Epoch: 6970, Loss: 0.6502, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7921.5758\n",
      "Epoch: 6971, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7922.7161\n",
      "Epoch: 6972, Loss: 0.6532, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7923.8593\n",
      "Epoch: 6973, Loss: 0.6507, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7924.9883\n",
      "Epoch: 6974, Loss: 0.6501, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 7926.1173\n",
      "Epoch: 6975, Loss: 0.6512, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7927.2469\n",
      "Epoch: 6976, Loss: 0.6539, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7928.3803\n",
      "Epoch: 6977, Loss: 0.6537, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7929.5103\n",
      "Epoch: 6978, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7930.6416\n",
      "Epoch: 6979, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7931.7747\n",
      "Epoch: 6980, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7932.9045\n",
      "Epoch: 6981, Loss: 0.6594, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7934.0382\n",
      "Epoch: 6982, Loss: 0.6596, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7935.1744\n",
      "Epoch: 6983, Loss: 0.6590, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7936.3102\n",
      "Epoch: 6984, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7937.4392\n",
      "Epoch: 6985, Loss: 0.6607, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7938.5744\n",
      "Epoch: 6986, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7939.7102\n",
      "Epoch: 6987, Loss: 0.6602, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7940.8412\n",
      "Epoch: 6988, Loss: 0.6632, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7941.9748\n",
      "Epoch: 6989, Loss: 0.6619, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7943.1059\n",
      "Epoch: 6990, Loss: 0.6594, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 7944.2409\n",
      "Epoch: 6991, Loss: 0.6596, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7945.3738\n",
      "Epoch: 6992, Loss: 0.6606, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7946.5045\n",
      "Epoch: 6993, Loss: 0.6605, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7947.6351\n",
      "Epoch: 6994, Loss: 0.6620, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7948.7691\n",
      "Epoch: 6995, Loss: 0.6638, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7949.9044\n",
      "Epoch: 6996, Loss: 0.6642, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7951.0386\n",
      "Epoch: 6997, Loss: 0.6653, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7952.1727\n",
      "Epoch: 6998, Loss: 0.6652, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7953.3064\n",
      "Epoch: 6999, Loss: 0.6676, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7954.4483\n",
      "Epoch: 7000, Loss: 0.6712, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7955.5808\n",
      "Epoch: 7001, Loss: 0.6712, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7956.7099\n",
      "Epoch: 7002, Loss: 0.6681, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7957.8412\n",
      "Epoch: 7003, Loss: 0.6652, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7958.9701\n",
      "Epoch: 7004, Loss: 0.6653, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7960.1035\n",
      "Epoch: 7005, Loss: 0.6653, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7961.2344\n",
      "Epoch: 7006, Loss: 0.6662, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7962.3646\n",
      "Epoch: 7007, Loss: 0.6654, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7963.4982\n",
      "Epoch: 7008, Loss: 0.6678, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7964.6424\n",
      "Epoch: 7009, Loss: 0.6680, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7965.7832\n",
      "Epoch: 7010, Loss: 0.6731, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7966.9183\n",
      "Epoch: 7011, Loss: 0.6715, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7968.0561\n",
      "Epoch: 7012, Loss: 0.6722, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7969.1945\n",
      "Epoch: 7013, Loss: 0.6728, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7970.3269\n",
      "Epoch: 7014, Loss: 0.6757, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7971.4597\n",
      "Epoch: 7015, Loss: 0.6761, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7972.5923\n",
      "Epoch: 7016, Loss: 0.6728, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7973.7253\n",
      "Epoch: 7017, Loss: 0.6737, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7974.8575\n",
      "Epoch: 7018, Loss: 0.6768, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 7975.9919\n",
      "Epoch: 7019, Loss: 0.6832, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7977.1301\n",
      "Epoch: 7020, Loss: 0.6794, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7978.2604\n",
      "Epoch: 7021, Loss: 0.6801, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7979.3954\n",
      "Epoch: 7022, Loss: 0.6810, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7980.5296\n",
      "Epoch: 7023, Loss: 0.6750, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7981.6645\n",
      "Epoch: 7024, Loss: 0.6741, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 7982.8023\n",
      "Epoch: 7025, Loss: 0.6720, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7983.9381\n",
      "Epoch: 7026, Loss: 0.6721, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 7985.0743\n",
      "Epoch: 7027, Loss: 0.6690, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7986.2062\n",
      "Epoch: 7028, Loss: 0.6684, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 7987.3383\n",
      "Epoch: 7029, Loss: 0.6671, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 7988.4679\n",
      "Epoch: 7030, Loss: 0.6675, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7989.5989\n",
      "Epoch: 7031, Loss: 0.6648, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7990.7299\n",
      "Epoch: 7032, Loss: 0.6646, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 7991.8617\n",
      "Epoch: 7033, Loss: 0.6614, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7992.9876\n",
      "Epoch: 7034, Loss: 0.6627, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7994.1205\n",
      "Epoch: 7035, Loss: 0.6620, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7995.2589\n",
      "Epoch: 7036, Loss: 0.6613, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7996.3877\n",
      "Epoch: 7037, Loss: 0.6591, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 7997.5238\n",
      "Epoch: 7038, Loss: 0.6597, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7998.6604\n",
      "Epoch: 7039, Loss: 0.6567, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 7999.7945\n",
      "Epoch: 7040, Loss: 0.6572, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 8000.9252\n",
      "Epoch: 7041, Loss: 0.6577, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 8002.0581\n",
      "Epoch: 7042, Loss: 0.6572, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 8003.1913\n",
      "Epoch: 7043, Loss: 0.6641, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8004.3231\n",
      "Epoch: 7044, Loss: 0.6627, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8005.4520\n",
      "Epoch: 7045, Loss: 0.6626, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8006.5902\n",
      "Epoch: 7046, Loss: 0.6628, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8007.7232\n",
      "Epoch: 7047, Loss: 0.6597, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8008.8599\n",
      "Epoch: 7048, Loss: 0.6577, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8010.0035\n",
      "Epoch: 7049, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8011.1386\n",
      "Epoch: 7050, Loss: 0.6592, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8012.2702\n",
      "Epoch: 7051, Loss: 0.6590, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8013.4072\n",
      "Epoch: 7052, Loss: 0.6600, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 8014.5403\n",
      "Epoch: 7053, Loss: 0.6609, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 8015.6690\n",
      "Epoch: 7054, Loss: 0.6602, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 8016.7981\n",
      "Epoch: 7055, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8017.9292\n",
      "Epoch: 7056, Loss: 0.6601, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8019.0605\n",
      "Epoch: 7057, Loss: 0.6643, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8020.1943\n",
      "Epoch: 7058, Loss: 0.6637, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8021.3354\n",
      "Epoch: 7059, Loss: 0.6659, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8022.4682\n",
      "Epoch: 7060, Loss: 0.6677, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 8023.5991\n",
      "Epoch: 7061, Loss: 0.6674, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 8024.7405\n",
      "Epoch: 7062, Loss: 0.6671, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 8025.8784\n",
      "Epoch: 7063, Loss: 0.6621, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8027.0135\n",
      "Epoch: 7064, Loss: 0.6620, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 8028.1501\n",
      "Epoch: 7065, Loss: 0.6610, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 8029.2866\n",
      "Epoch: 7066, Loss: 0.6609, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 8030.4229\n",
      "Epoch: 7067, Loss: 0.6620, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 8031.5589\n",
      "Epoch: 7068, Loss: 0.6641, Train_Acc: 0.5769, TEST_Acc: 0.6500, Time: 8032.6922\n",
      "Epoch: 7069, Loss: 0.6629, Train_Acc: 0.5769, TEST_Acc: 0.6533, Time: 8033.8282\n",
      "Epoch: 7070, Loss: 0.6612, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 8034.9657\n",
      "Epoch: 7071, Loss: 0.6618, Train_Acc: 0.5769, TEST_Acc: 0.6467, Time: 8036.0978\n",
      "Epoch: 7072, Loss: 0.6610, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 8037.2333\n",
      "Epoch: 7073, Loss: 0.6591, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8038.3696\n",
      "Epoch: 7074, Loss: 0.6578, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8039.5052\n",
      "Epoch: 7075, Loss: 0.6591, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8040.6402\n",
      "Epoch: 7076, Loss: 0.6585, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8041.7817\n",
      "Epoch: 7077, Loss: 0.6554, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8042.9287\n",
      "Epoch: 7078, Loss: 0.6579, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 8044.0638\n",
      "Epoch: 7079, Loss: 0.6570, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 8045.1980\n",
      "Epoch: 7080, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 8046.3272\n",
      "Epoch: 7081, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 8047.4581\n",
      "Epoch: 7082, Loss: 0.6522, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 8048.5881\n",
      "Epoch: 7083, Loss: 0.6534, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 8049.7241\n",
      "Epoch: 7084, Loss: 0.6523, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8050.8598\n",
      "Epoch: 7085, Loss: 0.6536, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 8051.9934\n",
      "Epoch: 7086, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 8053.1285\n",
      "Epoch: 7087, Loss: 0.6535, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8054.2697\n",
      "Epoch: 7088, Loss: 0.6463, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8055.4067\n",
      "Epoch: 7089, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8056.5456\n",
      "Epoch: 7090, Loss: 0.6479, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8057.6805\n",
      "Epoch: 7091, Loss: 0.6559, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8058.8169\n",
      "Epoch: 7092, Loss: 0.6525, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8059.9560\n",
      "Epoch: 7093, Loss: 0.6536, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8061.0886\n",
      "Epoch: 7094, Loss: 0.6533, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8062.2208\n",
      "Epoch: 7095, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 8063.3509\n",
      "Epoch: 7096, Loss: 0.6526, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8064.4861\n",
      "Epoch: 7097, Loss: 0.6500, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8065.6164\n",
      "Epoch: 7098, Loss: 0.6506, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8066.7462\n",
      "Epoch: 7099, Loss: 0.6510, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8067.8833\n",
      "Epoch: 7100, Loss: 0.6507, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8069.0169\n",
      "Epoch: 7101, Loss: 0.6510, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8070.1485\n",
      "Epoch: 7102, Loss: 0.6513, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8071.2818\n",
      "Epoch: 7103, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8072.4198\n",
      "Epoch: 7104, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8073.5595\n",
      "Epoch: 7105, Loss: 0.6517, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8074.6991\n",
      "Epoch: 7106, Loss: 0.6505, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8075.8333\n",
      "Epoch: 7107, Loss: 0.6492, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8076.9637\n",
      "Epoch: 7108, Loss: 0.6490, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8078.0970\n",
      "Epoch: 7109, Loss: 0.6490, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8079.2273\n",
      "Epoch: 7110, Loss: 0.6506, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8080.3604\n",
      "Epoch: 7111, Loss: 0.6514, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8081.4928\n",
      "Epoch: 7112, Loss: 0.6527, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8082.6258\n",
      "Epoch: 7113, Loss: 0.6511, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8083.7636\n",
      "Epoch: 7114, Loss: 0.6525, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8084.9026\n",
      "Epoch: 7115, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8086.0492\n",
      "Epoch: 7116, Loss: 0.6532, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8087.1862\n",
      "Epoch: 7117, Loss: 0.6555, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8088.3220\n",
      "Epoch: 7118, Loss: 0.6526, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8089.4584\n",
      "Epoch: 7119, Loss: 0.6512, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8090.5914\n",
      "Epoch: 7120, Loss: 0.6516, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8091.7237\n",
      "Epoch: 7121, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8092.8544\n",
      "Epoch: 7122, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8093.9886\n",
      "Epoch: 7123, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8095.1227\n",
      "Epoch: 7124, Loss: 0.6490, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8096.2524\n",
      "Epoch: 7125, Loss: 0.6492, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8097.3865\n",
      "Epoch: 7126, Loss: 0.6507, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8098.5188\n",
      "Epoch: 7127, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8099.6553\n",
      "Epoch: 7128, Loss: 0.6484, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8100.7987\n",
      "Epoch: 7129, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8101.9335\n",
      "Epoch: 7130, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8103.0693\n",
      "Epoch: 7131, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8104.2103\n",
      "Epoch: 7132, Loss: 0.6468, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8105.3442\n",
      "Epoch: 7133, Loss: 0.6490, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8106.4751\n",
      "Epoch: 7134, Loss: 0.6491, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8107.6108\n",
      "Epoch: 7135, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8108.7419\n",
      "Epoch: 7136, Loss: 0.6522, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8109.8692\n",
      "Epoch: 7137, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8111.0018\n",
      "Epoch: 7138, Loss: 0.6557, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8112.1317\n",
      "Epoch: 7139, Loss: 0.6552, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8113.2626\n",
      "Epoch: 7140, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8114.3946\n",
      "Epoch: 7141, Loss: 0.6560, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8115.5284\n",
      "Epoch: 7142, Loss: 0.6562, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8116.6712\n",
      "Epoch: 7143, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8117.8086\n",
      "Epoch: 7144, Loss: 0.6584, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8118.9455\n",
      "Epoch: 7145, Loss: 0.6583, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8120.0821\n",
      "Epoch: 7146, Loss: 0.6598, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8121.2243\n",
      "Epoch: 7147, Loss: 0.6594, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8122.3561\n",
      "Epoch: 7148, Loss: 0.6614, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8123.4859\n",
      "Epoch: 7149, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8124.6168\n",
      "Epoch: 7150, Loss: 0.6599, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8125.7475\n",
      "Epoch: 7151, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8126.8780\n",
      "Epoch: 7152, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8128.0115\n",
      "Epoch: 7153, Loss: 0.6589, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8129.1503\n",
      "Epoch: 7154, Loss: 0.6541, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8130.2804\n",
      "Epoch: 7155, Loss: 0.6546, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8131.4146\n",
      "Epoch: 7156, Loss: 0.6605, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8132.5496\n",
      "Epoch: 7157, Loss: 0.6601, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8133.6825\n",
      "Epoch: 7158, Loss: 0.6592, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8134.8180\n",
      "Epoch: 7159, Loss: 0.6605, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8135.9571\n",
      "Epoch: 7160, Loss: 0.6632, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8137.0944\n",
      "Epoch: 7161, Loss: 0.6609, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8138.2262\n",
      "Epoch: 7162, Loss: 0.6615, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8139.3627\n",
      "Epoch: 7163, Loss: 0.6630, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8140.5004\n",
      "Epoch: 7164, Loss: 0.6606, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8141.6299\n",
      "Epoch: 7165, Loss: 0.6623, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8142.7648\n",
      "Epoch: 7166, Loss: 0.6621, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8143.8965\n",
      "Epoch: 7167, Loss: 0.6597, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8145.0342\n",
      "Epoch: 7168, Loss: 0.6622, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8146.1696\n",
      "Epoch: 7169, Loss: 0.6592, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8147.3028\n",
      "Epoch: 7170, Loss: 0.6581, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8148.4380\n",
      "Epoch: 7171, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8149.5730\n",
      "Epoch: 7172, Loss: 0.6607, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8150.7137\n",
      "Epoch: 7173, Loss: 0.6614, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8151.8526\n",
      "Epoch: 7174, Loss: 0.6602, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8152.9833\n",
      "Epoch: 7175, Loss: 0.6525, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8154.1144\n",
      "Epoch: 7176, Loss: 0.6524, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8155.2525\n",
      "Epoch: 7177, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8156.3896\n",
      "Epoch: 7178, Loss: 0.6522, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8157.5208\n",
      "Epoch: 7179, Loss: 0.6536, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8158.6517\n",
      "Epoch: 7180, Loss: 0.6536, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8159.7859\n",
      "Epoch: 7181, Loss: 0.6564, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8160.9241\n",
      "Epoch: 7182, Loss: 0.6596, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8162.0660\n",
      "Epoch: 7183, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8163.2014\n",
      "Epoch: 7184, Loss: 0.6545, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8164.3372\n",
      "Epoch: 7185, Loss: 0.6543, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8165.4751\n",
      "Epoch: 7186, Loss: 0.6504, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8166.6126\n",
      "Epoch: 7187, Loss: 0.6504, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8167.7447\n",
      "Epoch: 7188, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8168.8742\n",
      "Epoch: 7189, Loss: 0.6515, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8170.0022\n",
      "Epoch: 7190, Loss: 0.6527, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8171.1321\n",
      "Epoch: 7191, Loss: 0.6510, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8172.2618\n",
      "Epoch: 7192, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8173.4128\n",
      "Epoch: 7193, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8174.5442\n",
      "Epoch: 7194, Loss: 0.6488, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8175.6796\n",
      "Epoch: 7195, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8176.8153\n",
      "Epoch: 7196, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8177.9491\n",
      "Epoch: 7197, Loss: 0.6487, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8179.0813\n",
      "Epoch: 7198, Loss: 0.6488, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8180.2167\n",
      "Epoch: 7199, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8181.3556\n",
      "Epoch: 7200, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8182.4879\n",
      "Epoch: 7201, Loss: 0.6459, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8183.6345\n",
      "Epoch: 7202, Loss: 0.6492, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8184.7683\n",
      "Epoch: 7203, Loss: 0.6512, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8185.8993\n",
      "Epoch: 7204, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8187.0308\n",
      "Epoch: 7205, Loss: 0.6506, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8188.1605\n",
      "Epoch: 7206, Loss: 0.6482, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8189.2935\n",
      "Epoch: 7207, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8190.4393\n",
      "Epoch: 7208, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8191.5757\n",
      "Epoch: 7209, Loss: 0.6479, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8192.7139\n",
      "Epoch: 7210, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8193.8535\n",
      "Epoch: 7211, Loss: 0.6492, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8194.9899\n",
      "Epoch: 7212, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8196.1267\n",
      "Epoch: 7213, Loss: 0.6516, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8197.2591\n",
      "Epoch: 7214, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8198.3936\n",
      "Epoch: 7215, Loss: 0.6514, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8199.5308\n",
      "Epoch: 7216, Loss: 0.6547, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8200.6646\n",
      "Epoch: 7217, Loss: 0.6532, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8201.7957\n",
      "Epoch: 7218, Loss: 0.6533, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8202.9285\n",
      "Epoch: 7219, Loss: 0.6551, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8204.0613\n",
      "Epoch: 7220, Loss: 0.6540, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8205.1993\n",
      "Epoch: 7221, Loss: 0.6538, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8206.3380\n",
      "Epoch: 7222, Loss: 0.6545, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8207.4809\n",
      "Epoch: 7223, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8208.6140\n",
      "Epoch: 7224, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8209.7496\n",
      "Epoch: 7225, Loss: 0.6544, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8210.8885\n",
      "Epoch: 7226, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8212.0264\n",
      "Epoch: 7227, Loss: 0.6547, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8213.1568\n",
      "Epoch: 7228, Loss: 0.6540, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8214.2942\n",
      "Epoch: 7229, Loss: 0.6533, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8215.4307\n",
      "Epoch: 7230, Loss: 0.6521, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8216.5692\n",
      "Epoch: 7231, Loss: 0.6524, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8217.7017\n",
      "Epoch: 7232, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8218.8299\n",
      "Epoch: 7233, Loss: 0.6507, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8219.9596\n",
      "Epoch: 7234, Loss: 0.6542, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8221.0884\n",
      "Epoch: 7235, Loss: 0.6545, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8222.2223\n",
      "Epoch: 7236, Loss: 0.6523, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8223.3559\n",
      "Epoch: 7237, Loss: 0.6512, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8224.4899\n",
      "Epoch: 7238, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8225.6290\n",
      "Epoch: 7239, Loss: 0.6538, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8226.7784\n",
      "Epoch: 7240, Loss: 0.6510, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8227.9140\n",
      "Epoch: 7241, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8229.0490\n",
      "Epoch: 7242, Loss: 0.6517, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8230.1845\n",
      "Epoch: 7243, Loss: 0.6517, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8231.3171\n",
      "Epoch: 7244, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8232.4464\n",
      "Epoch: 7245, Loss: 0.6525, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8233.5771\n",
      "Epoch: 7246, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8234.7064\n",
      "Epoch: 7247, Loss: 0.6534, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8235.8414\n",
      "Epoch: 7248, Loss: 0.6542, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8236.9769\n",
      "Epoch: 7249, Loss: 0.6526, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8238.1216\n",
      "Epoch: 7250, Loss: 0.6532, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8239.2585\n",
      "Epoch: 7251, Loss: 0.6512, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8240.3947\n",
      "Epoch: 7252, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8241.5298\n",
      "Epoch: 7253, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8242.6710\n",
      "Epoch: 7254, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8243.8041\n",
      "Epoch: 7255, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8244.9368\n",
      "Epoch: 7256, Loss: 0.6568, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8246.0697\n",
      "Epoch: 7257, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8247.2032\n",
      "Epoch: 7258, Loss: 0.6588, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8248.3454\n",
      "Epoch: 7259, Loss: 0.6582, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8249.4813\n",
      "Epoch: 7260, Loss: 0.6581, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8250.6136\n",
      "Epoch: 7261, Loss: 0.6601, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8251.7463\n",
      "Epoch: 7262, Loss: 0.6584, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8252.8851\n",
      "Epoch: 7263, Loss: 0.6604, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8254.0209\n",
      "Epoch: 7264, Loss: 0.6609, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8255.1569\n",
      "Epoch: 7265, Loss: 0.6602, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8256.2885\n",
      "Epoch: 7266, Loss: 0.6608, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8257.4268\n",
      "Epoch: 7267, Loss: 0.6613, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8258.5639\n",
      "Epoch: 7268, Loss: 0.6644, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8259.6972\n",
      "Epoch: 7269, Loss: 0.6609, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8260.8330\n",
      "Epoch: 7270, Loss: 0.6595, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8261.9646\n",
      "Epoch: 7271, Loss: 0.6594, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8263.0990\n",
      "Epoch: 7272, Loss: 0.6602, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8264.2374\n",
      "Epoch: 7273, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8265.3685\n",
      "Epoch: 7274, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8266.5026\n",
      "Epoch: 7275, Loss: 0.6595, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8267.6412\n",
      "Epoch: 7276, Loss: 0.6606, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8268.7838\n",
      "Epoch: 7277, Loss: 0.6643, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8269.9277\n",
      "Epoch: 7278, Loss: 0.6624, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8271.0631\n",
      "Epoch: 7279, Loss: 0.6620, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8272.2001\n",
      "Epoch: 7280, Loss: 0.6628, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8273.3348\n",
      "Epoch: 7281, Loss: 0.6642, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8274.4682\n",
      "Epoch: 7282, Loss: 0.6657, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8275.6054\n",
      "Epoch: 7283, Loss: 0.6670, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8276.7434\n",
      "Epoch: 7284, Loss: 0.6649, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8277.8746\n",
      "Epoch: 7285, Loss: 0.6627, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8279.0041\n",
      "Epoch: 7286, Loss: 0.6617, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8280.1431\n",
      "Epoch: 7287, Loss: 0.6616, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8281.2760\n",
      "Epoch: 7288, Loss: 0.6626, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8282.4095\n",
      "Epoch: 7289, Loss: 0.6646, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8283.5412\n",
      "Epoch: 7290, Loss: 0.6636, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8284.6812\n",
      "Epoch: 7291, Loss: 0.6599, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8285.8131\n",
      "Epoch: 7292, Loss: 0.6607, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8286.9471\n",
      "Epoch: 7293, Loss: 0.6570, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8288.0859\n",
      "Epoch: 7294, Loss: 0.6573, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8289.2183\n",
      "Epoch: 7295, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8290.3529\n",
      "Epoch: 7296, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8291.4911\n",
      "Epoch: 7297, Loss: 0.6477, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8292.6220\n",
      "Epoch: 7298, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8293.7590\n",
      "Epoch: 7299, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8294.8937\n",
      "Epoch: 7300, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8296.0262\n",
      "Epoch: 7301, Loss: 0.6494, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8297.1582\n",
      "Epoch: 7302, Loss: 0.6504, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8298.3010\n",
      "Epoch: 7303, Loss: 0.6501, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8299.4392\n",
      "Epoch: 7304, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8300.5841\n",
      "Epoch: 7305, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8301.7215\n",
      "Epoch: 7306, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8302.8574\n",
      "Epoch: 7307, Loss: 0.6407, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8303.9891\n",
      "Epoch: 7308, Loss: 0.6402, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8305.1211\n",
      "Epoch: 7309, Loss: 0.6399, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8306.2527\n",
      "Epoch: 7310, Loss: 0.6390, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8307.3883\n",
      "Epoch: 7311, Loss: 0.6381, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8308.5211\n",
      "Epoch: 7312, Loss: 0.6369, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8309.6559\n",
      "Epoch: 7313, Loss: 0.6362, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8310.7892\n",
      "Epoch: 7314, Loss: 0.6367, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8311.9235\n",
      "Epoch: 7315, Loss: 0.6365, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8313.0574\n",
      "Epoch: 7316, Loss: 0.6354, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8314.1936\n",
      "Epoch: 7317, Loss: 0.6355, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8315.3279\n",
      "Epoch: 7318, Loss: 0.6343, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8316.4619\n",
      "Epoch: 7319, Loss: 0.6356, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8317.6001\n",
      "Epoch: 7320, Loss: 0.6362, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8318.7357\n",
      "Epoch: 7321, Loss: 0.6338, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8319.8681\n",
      "Epoch: 7322, Loss: 0.6341, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8320.9950\n",
      "Epoch: 7323, Loss: 0.6349, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8322.1293\n",
      "Epoch: 7324, Loss: 0.6327, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8323.2580\n",
      "Epoch: 7325, Loss: 0.6341, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8324.3960\n",
      "Epoch: 7326, Loss: 0.6363, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8325.5412\n",
      "Epoch: 7327, Loss: 0.6367, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8326.6700\n",
      "Epoch: 7328, Loss: 0.6365, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8327.8094\n",
      "Epoch: 7329, Loss: 0.6368, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8328.9441\n",
      "Epoch: 7330, Loss: 0.6372, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8330.0803\n",
      "Epoch: 7331, Loss: 0.6383, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8331.2152\n",
      "Epoch: 7332, Loss: 0.6383, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8332.3553\n",
      "Epoch: 7333, Loss: 0.6364, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8333.4878\n",
      "Epoch: 7334, Loss: 0.6361, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8334.6266\n",
      "Epoch: 7335, Loss: 0.6362, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8335.7613\n",
      "Epoch: 7336, Loss: 0.6382, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 8336.8988\n",
      "Epoch: 7337, Loss: 0.6372, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8338.0311\n",
      "Epoch: 7338, Loss: 0.6358, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8339.1623\n",
      "Epoch: 7339, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8340.2998\n",
      "Epoch: 7340, Loss: 0.6356, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8341.4310\n",
      "Epoch: 7341, Loss: 0.6391, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8342.5634\n",
      "Epoch: 7342, Loss: 0.6399, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8343.6983\n",
      "Epoch: 7343, Loss: 0.6411, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8344.8330\n",
      "Epoch: 7344, Loss: 0.6408, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8345.9771\n",
      "Epoch: 7345, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8347.1147\n",
      "Epoch: 7346, Loss: 0.6411, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8348.2544\n",
      "Epoch: 7347, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8349.3855\n",
      "Epoch: 7348, Loss: 0.6407, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8350.5204\n",
      "Epoch: 7349, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8351.6512\n",
      "Epoch: 7350, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8352.7801\n",
      "Epoch: 7351, Loss: 0.6408, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8353.9127\n",
      "Epoch: 7352, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8355.0458\n",
      "Epoch: 7353, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8356.1815\n",
      "Epoch: 7354, Loss: 0.6413, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8357.3103\n",
      "Epoch: 7355, Loss: 0.6434, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8358.4499\n",
      "Epoch: 7356, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8359.5873\n",
      "Epoch: 7357, Loss: 0.6467, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8360.7242\n",
      "Epoch: 7358, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8361.8584\n",
      "Epoch: 7359, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8362.9983\n",
      "Epoch: 7360, Loss: 0.6455, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8364.1343\n",
      "Epoch: 7361, Loss: 0.6455, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8365.2658\n",
      "Epoch: 7362, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8366.4019\n",
      "Epoch: 7363, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8367.5342\n",
      "Epoch: 7364, Loss: 0.6479, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8368.6689\n",
      "Epoch: 7365, Loss: 0.6495, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8369.8039\n",
      "Epoch: 7366, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8370.9331\n",
      "Epoch: 7367, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8372.0662\n",
      "Epoch: 7368, Loss: 0.6488, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8373.2015\n",
      "Epoch: 7369, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8374.3366\n",
      "Epoch: 7370, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8375.4707\n",
      "Epoch: 7371, Loss: 0.6535, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8376.6084\n",
      "Epoch: 7372, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8377.7438\n",
      "Epoch: 7373, Loss: 0.6595, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8378.8783\n",
      "Epoch: 7374, Loss: 0.6579, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8380.0089\n",
      "Epoch: 7375, Loss: 0.6572, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8381.1463\n",
      "Epoch: 7376, Loss: 0.6569, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8382.2783\n",
      "Epoch: 7377, Loss: 0.6535, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8383.4122\n",
      "Epoch: 7378, Loss: 0.6533, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8384.5477\n",
      "Epoch: 7379, Loss: 0.6566, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8385.6757\n",
      "Epoch: 7380, Loss: 0.6580, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8386.8143\n",
      "Epoch: 7381, Loss: 0.6575, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8387.9511\n",
      "Epoch: 7382, Loss: 0.6563, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8389.0895\n",
      "Epoch: 7383, Loss: 0.6547, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8390.2293\n",
      "Epoch: 7384, Loss: 0.6539, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8391.3666\n",
      "Epoch: 7385, Loss: 0.6545, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8392.5021\n",
      "Epoch: 7386, Loss: 0.6574, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8393.6393\n",
      "Epoch: 7387, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8394.7816\n",
      "Epoch: 7388, Loss: 0.6532, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8395.9127\n",
      "Epoch: 7389, Loss: 0.6544, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8397.0475\n",
      "Epoch: 7390, Loss: 0.6517, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8398.1770\n",
      "Epoch: 7391, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8399.3090\n",
      "Epoch: 7392, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8400.4508\n",
      "Epoch: 7393, Loss: 0.6501, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8401.5803\n",
      "Epoch: 7394, Loss: 0.6503, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8402.7097\n",
      "Epoch: 7395, Loss: 0.6492, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8403.8421\n",
      "Epoch: 7396, Loss: 0.6469, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8404.9746\n",
      "Epoch: 7397, Loss: 0.6469, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8406.1052\n",
      "Epoch: 7398, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8407.2372\n",
      "Epoch: 7399, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8408.3744\n",
      "Epoch: 7400, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8409.5093\n",
      "Epoch: 7401, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8410.6475\n",
      "Epoch: 7402, Loss: 0.6513, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8411.7856\n",
      "Epoch: 7403, Loss: 0.6521, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8412.9245\n",
      "Epoch: 7404, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8414.0574\n",
      "Epoch: 7405, Loss: 0.6502, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8415.1921\n",
      "Epoch: 7406, Loss: 0.6512, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8416.3202\n",
      "Epoch: 7407, Loss: 0.6527, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8417.4526\n",
      "Epoch: 7408, Loss: 0.6532, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8418.5954\n",
      "Epoch: 7409, Loss: 0.6548, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8419.7256\n",
      "Epoch: 7410, Loss: 0.6523, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8420.8602\n",
      "Epoch: 7411, Loss: 0.6536, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8422.0056\n",
      "Epoch: 7412, Loss: 0.6544, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8423.1416\n",
      "Epoch: 7413, Loss: 0.6543, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8424.2732\n",
      "Epoch: 7414, Loss: 0.6521, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8425.4064\n",
      "Epoch: 7415, Loss: 0.6521, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8426.5395\n",
      "Epoch: 7416, Loss: 0.6504, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8427.6687\n",
      "Epoch: 7417, Loss: 0.6503, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8428.8012\n",
      "Epoch: 7418, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8429.9335\n",
      "Epoch: 7419, Loss: 0.6543, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8431.0643\n",
      "Epoch: 7420, Loss: 0.6555, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8432.1961\n",
      "Epoch: 7421, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8433.3383\n",
      "Epoch: 7422, Loss: 0.6534, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8434.4698\n",
      "Epoch: 7423, Loss: 0.6540, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8435.6063\n",
      "Epoch: 7424, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8436.7405\n",
      "Epoch: 7425, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8437.8718\n",
      "Epoch: 7426, Loss: 0.6507, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8439.0083\n",
      "Epoch: 7427, Loss: 0.6500, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8440.1398\n",
      "Epoch: 7428, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8441.2733\n",
      "Epoch: 7429, Loss: 0.6507, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8442.4048\n",
      "Epoch: 7430, Loss: 0.6506, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8443.5310\n",
      "Epoch: 7431, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8444.6674\n",
      "Epoch: 7432, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8445.8053\n",
      "Epoch: 7433, Loss: 0.6500, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8446.9414\n",
      "Epoch: 7434, Loss: 0.6501, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8448.0752\n",
      "Epoch: 7435, Loss: 0.6491, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8449.2123\n",
      "Epoch: 7436, Loss: 0.6485, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8450.3461\n",
      "Epoch: 7437, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8451.4833\n",
      "Epoch: 7438, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8452.6185\n",
      "Epoch: 7439, Loss: 0.6470, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8453.7583\n",
      "Epoch: 7440, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8454.8932\n",
      "Epoch: 7441, Loss: 0.6482, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8456.0382\n",
      "Epoch: 7442, Loss: 0.6471, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8457.1700\n",
      "Epoch: 7443, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8458.3012\n",
      "Epoch: 7444, Loss: 0.6511, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8459.4313\n",
      "Epoch: 7445, Loss: 0.6502, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8460.5624\n",
      "Epoch: 7446, Loss: 0.6493, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8461.6922\n",
      "Epoch: 7447, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8462.8244\n",
      "Epoch: 7448, Loss: 0.6516, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8463.9600\n",
      "Epoch: 7449, Loss: 0.6504, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8465.0958\n",
      "Epoch: 7450, Loss: 0.6503, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8466.2335\n",
      "Epoch: 7451, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8467.3678\n",
      "Epoch: 7452, Loss: 0.6494, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8468.5032\n",
      "Epoch: 7453, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8469.6385\n",
      "Epoch: 7454, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8470.7767\n",
      "Epoch: 7455, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8471.9072\n",
      "Epoch: 7456, Loss: 0.6507, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8473.0391\n",
      "Epoch: 7457, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8474.1735\n",
      "Epoch: 7458, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8475.3051\n",
      "Epoch: 7459, Loss: 0.6541, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8476.4333\n",
      "Epoch: 7460, Loss: 0.6526, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8477.5687\n",
      "Epoch: 7461, Loss: 0.6502, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8478.7004\n",
      "Epoch: 7462, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8479.8411\n",
      "Epoch: 7463, Loss: 0.6515, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8480.9762\n",
      "Epoch: 7464, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8482.1142\n",
      "Epoch: 7465, Loss: 0.6558, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8483.2513\n",
      "Epoch: 7466, Loss: 0.6558, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8484.3877\n",
      "Epoch: 7467, Loss: 0.6537, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8485.5237\n",
      "Epoch: 7468, Loss: 0.6546, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8486.6628\n",
      "Epoch: 7469, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8487.7991\n",
      "Epoch: 7470, Loss: 0.6548, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8488.9313\n",
      "Epoch: 7471, Loss: 0.6517, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8490.0668\n",
      "Epoch: 7472, Loss: 0.6539, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8491.2013\n",
      "Epoch: 7473, Loss: 0.6549, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8492.3368\n",
      "Epoch: 7474, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8493.4660\n",
      "Epoch: 7475, Loss: 0.6491, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8494.5962\n",
      "Epoch: 7476, Loss: 0.6473, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8495.7304\n",
      "Epoch: 7477, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8496.8629\n",
      "Epoch: 7478, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8498.0013\n",
      "Epoch: 7479, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8499.1460\n",
      "Epoch: 7480, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8500.2841\n",
      "Epoch: 7481, Loss: 0.6477, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8501.4272\n",
      "Epoch: 7482, Loss: 0.6490, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8502.5619\n",
      "Epoch: 7483, Loss: 0.6479, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8503.6955\n",
      "Epoch: 7484, Loss: 0.6463, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8504.8291\n",
      "Epoch: 7485, Loss: 0.6465, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8505.9572\n",
      "Epoch: 7486, Loss: 0.6456, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8507.0924\n",
      "Epoch: 7487, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8508.2237\n",
      "Epoch: 7488, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8509.3643\n",
      "Epoch: 7489, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8510.5023\n",
      "Epoch: 7490, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8511.6293\n",
      "Epoch: 7491, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8512.7675\n",
      "Epoch: 7492, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8513.9008\n",
      "Epoch: 7493, Loss: 0.6459, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8515.0398\n",
      "Epoch: 7494, Loss: 0.6448, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8516.1775\n",
      "Epoch: 7495, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8517.3134\n",
      "Epoch: 7496, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8518.4458\n",
      "Epoch: 7497, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8519.5815\n",
      "Epoch: 7498, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8520.7171\n",
      "Epoch: 7499, Loss: 0.6422, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8521.8463\n",
      "Epoch: 7500, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8522.9803\n",
      "Epoch: 7501, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8524.1093\n",
      "Epoch: 7502, Loss: 0.6443, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8525.2417\n",
      "Epoch: 7503, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8526.3741\n",
      "Epoch: 7504, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8527.5088\n",
      "Epoch: 7505, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8528.6447\n",
      "Epoch: 7506, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8529.7844\n",
      "Epoch: 7507, Loss: 0.6462, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8530.9232\n",
      "Epoch: 7508, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8532.0671\n",
      "Epoch: 7509, Loss: 0.6455, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8533.2055\n",
      "Epoch: 7510, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8534.3407\n",
      "Epoch: 7511, Loss: 0.6402, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8535.4812\n",
      "Epoch: 7512, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8536.6093\n",
      "Epoch: 7513, Loss: 0.6396, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8537.7424\n",
      "Epoch: 7514, Loss: 0.6397, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8538.8802\n",
      "Epoch: 7515, Loss: 0.6379, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8540.0188\n",
      "Epoch: 7516, Loss: 0.6384, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8541.1488\n",
      "Epoch: 7517, Loss: 0.6386, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8542.2875\n",
      "Epoch: 7518, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8543.4273\n",
      "Epoch: 7519, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8544.5667\n",
      "Epoch: 7520, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8545.7019\n",
      "Epoch: 7521, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8546.8361\n",
      "Epoch: 7522, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8547.9739\n",
      "Epoch: 7523, Loss: 0.6451, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8549.1037\n",
      "Epoch: 7524, Loss: 0.6448, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8550.2406\n",
      "Epoch: 7525, Loss: 0.6448, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8551.3723\n",
      "Epoch: 7526, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8552.5082\n",
      "Epoch: 7527, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8553.6427\n",
      "Epoch: 7528, Loss: 0.6439, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8554.7758\n",
      "Epoch: 7529, Loss: 0.6431, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8555.9080\n",
      "Epoch: 7530, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8557.0411\n",
      "Epoch: 7531, Loss: 0.6364, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8558.1799\n",
      "Epoch: 7532, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8559.3158\n",
      "Epoch: 7533, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8560.4513\n",
      "Epoch: 7534, Loss: 0.6462, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8561.5884\n",
      "Epoch: 7535, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8562.7273\n",
      "Epoch: 7536, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8563.8674\n",
      "Epoch: 7537, Loss: 0.6467, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8565.0018\n",
      "Epoch: 7538, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8566.1383\n",
      "Epoch: 7539, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8567.2682\n",
      "Epoch: 7540, Loss: 0.6373, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8568.4002\n",
      "Epoch: 7541, Loss: 0.6315, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8569.5330\n",
      "Epoch: 7542, Loss: 0.6305, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8570.6676\n",
      "Epoch: 7543, Loss: 0.6304, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8571.7993\n",
      "Epoch: 7544, Loss: 0.6306, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8572.9352\n",
      "Epoch: 7545, Loss: 0.6310, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8574.0762\n",
      "Epoch: 7546, Loss: 0.6310, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8575.2132\n",
      "Epoch: 7547, Loss: 0.6309, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8576.3504\n",
      "Epoch: 7548, Loss: 0.6307, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8577.4863\n",
      "Epoch: 7549, Loss: 0.6316, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8578.6242\n",
      "Epoch: 7550, Loss: 0.6295, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8579.7590\n",
      "Epoch: 7551, Loss: 0.6275, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8580.8923\n",
      "Epoch: 7552, Loss: 0.6283, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8582.0308\n",
      "Epoch: 7553, Loss: 0.6278, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8583.1619\n",
      "Epoch: 7554, Loss: 0.6256, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8584.2982\n",
      "Epoch: 7555, Loss: 0.6266, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8585.4307\n",
      "Epoch: 7556, Loss: 0.6272, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8586.5679\n",
      "Epoch: 7557, Loss: 0.6266, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8587.7017\n",
      "Epoch: 7558, Loss: 0.6250, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8588.8373\n",
      "Epoch: 7559, Loss: 0.6242, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8589.9755\n",
      "Epoch: 7560, Loss: 0.6234, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8591.1150\n",
      "Epoch: 7561, Loss: 0.6230, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8592.2547\n",
      "Epoch: 7562, Loss: 0.6217, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8593.3929\n",
      "Epoch: 7563, Loss: 0.6224, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8594.5305\n",
      "Epoch: 7564, Loss: 0.6223, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8595.6697\n",
      "Epoch: 7565, Loss: 0.6303, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8596.8049\n",
      "Epoch: 7566, Loss: 0.6301, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8597.9422\n",
      "Epoch: 7567, Loss: 0.6298, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8599.0770\n",
      "Epoch: 7568, Loss: 0.6311, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8600.2173\n",
      "Epoch: 7569, Loss: 0.6320, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8601.3493\n",
      "Epoch: 7570, Loss: 0.6327, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 8602.4814\n",
      "Epoch: 7571, Loss: 0.6332, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8603.6109\n",
      "Epoch: 7572, Loss: 0.6338, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8604.7476\n",
      "Epoch: 7573, Loss: 0.6340, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8605.8905\n",
      "Epoch: 7574, Loss: 0.6349, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8607.0322\n",
      "Epoch: 7575, Loss: 0.6374, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8608.1743\n",
      "Epoch: 7576, Loss: 0.6383, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8609.3144\n",
      "Epoch: 7577, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8610.4459\n",
      "Epoch: 7578, Loss: 0.6397, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8611.5853\n",
      "Epoch: 7579, Loss: 0.6410, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8612.7173\n",
      "Epoch: 7580, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8613.8547\n",
      "Epoch: 7581, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8614.9852\n",
      "Epoch: 7582, Loss: 0.6403, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8616.1199\n",
      "Epoch: 7583, Loss: 0.6402, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8617.2528\n",
      "Epoch: 7584, Loss: 0.6410, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8618.3899\n",
      "Epoch: 7585, Loss: 0.6406, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8619.5261\n",
      "Epoch: 7586, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8620.6633\n",
      "Epoch: 7587, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8621.7994\n",
      "Epoch: 7588, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8622.9392\n",
      "Epoch: 7589, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8624.0768\n",
      "Epoch: 7590, Loss: 0.6401, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8625.2106\n",
      "Epoch: 7591, Loss: 0.6399, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8626.3450\n",
      "Epoch: 7592, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8627.4794\n",
      "Epoch: 7593, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8628.6125\n",
      "Epoch: 7594, Loss: 0.6424, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8629.7524\n",
      "Epoch: 7595, Loss: 0.6417, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8630.8859\n",
      "Epoch: 7596, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8632.0222\n",
      "Epoch: 7597, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8633.1484\n",
      "Epoch: 7598, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8634.2770\n",
      "Epoch: 7599, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8635.4058\n",
      "Epoch: 7600, Loss: 0.6396, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8636.5320\n",
      "Epoch: 7601, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8637.6702\n",
      "Epoch: 7602, Loss: 0.6473, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8638.8022\n",
      "Epoch: 7603, Loss: 0.6366, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8639.9344\n",
      "Epoch: 7604, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8641.0693\n",
      "Epoch: 7605, Loss: 0.6413, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8642.2030\n",
      "Epoch: 7606, Loss: 0.6411, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8643.3333\n",
      "Epoch: 7607, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8644.4661\n",
      "Epoch: 7608, Loss: 0.6410, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8645.5999\n",
      "Epoch: 7609, Loss: 0.6413, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8646.7333\n",
      "Epoch: 7610, Loss: 0.6402, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8647.8636\n",
      "Epoch: 7611, Loss: 0.6396, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8648.9980\n",
      "Epoch: 7612, Loss: 0.6391, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8650.1381\n",
      "Epoch: 7613, Loss: 0.6393, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8651.2803\n",
      "Epoch: 7614, Loss: 0.6395, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8652.4071\n",
      "Epoch: 7615, Loss: 0.6376, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8653.5463\n",
      "Epoch: 7616, Loss: 0.6368, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8654.6888\n",
      "Epoch: 7617, Loss: 0.6373, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8655.8217\n",
      "Epoch: 7618, Loss: 0.6383, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8656.9540\n",
      "Epoch: 7619, Loss: 0.6375, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8658.0851\n",
      "Epoch: 7620, Loss: 0.6393, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8659.2173\n",
      "Epoch: 7621, Loss: 0.6390, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8660.3606\n",
      "Epoch: 7622, Loss: 0.6408, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8661.4932\n",
      "Epoch: 7623, Loss: 0.6434, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8662.6355\n",
      "Epoch: 7624, Loss: 0.6435, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8663.7749\n",
      "Epoch: 7625, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8664.9104\n",
      "Epoch: 7626, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8666.0505\n",
      "Epoch: 7627, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 8667.1876\n",
      "Epoch: 7628, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8668.3250\n",
      "Epoch: 7629, Loss: 0.6408, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8669.4607\n",
      "Epoch: 7630, Loss: 0.6369, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8670.5946\n",
      "Epoch: 7631, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8671.7273\n",
      "Epoch: 7632, Loss: 0.6332, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8672.8582\n",
      "Epoch: 7633, Loss: 0.6338, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8673.9965\n",
      "Epoch: 7634, Loss: 0.6342, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8675.1312\n",
      "Epoch: 7635, Loss: 0.6338, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8676.2642\n",
      "Epoch: 7636, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8677.3982\n",
      "Epoch: 7637, Loss: 0.6363, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8678.5324\n",
      "Epoch: 7638, Loss: 0.6366, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8679.6710\n",
      "Epoch: 7639, Loss: 0.6381, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8680.8052\n",
      "Epoch: 7640, Loss: 0.6379, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8681.9424\n",
      "Epoch: 7641, Loss: 0.6393, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8683.0837\n",
      "Epoch: 7642, Loss: 0.6382, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8684.2262\n",
      "Epoch: 7643, Loss: 0.6382, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8685.3644\n",
      "Epoch: 7644, Loss: 0.6395, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8686.5033\n",
      "Epoch: 7645, Loss: 0.6390, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8687.6377\n",
      "Epoch: 7646, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8688.7721\n",
      "Epoch: 7647, Loss: 0.6421, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8689.9051\n",
      "Epoch: 7648, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8691.0427\n",
      "Epoch: 7649, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8692.1737\n",
      "Epoch: 7650, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8693.3014\n",
      "Epoch: 7651, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8694.4438\n",
      "Epoch: 7652, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8695.5751\n",
      "Epoch: 7653, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8696.7136\n",
      "Epoch: 7654, Loss: 0.6434, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8697.8484\n",
      "Epoch: 7655, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8698.9890\n",
      "Epoch: 7656, Loss: 0.6451, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8700.1276\n",
      "Epoch: 7657, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8701.2648\n",
      "Epoch: 7658, Loss: 0.6465, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8702.3960\n",
      "Epoch: 7659, Loss: 0.6466, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8703.5300\n",
      "Epoch: 7660, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8704.6690\n",
      "Epoch: 7661, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8705.8002\n",
      "Epoch: 7662, Loss: 0.6455, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8706.9326\n",
      "Epoch: 7663, Loss: 0.6462, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8708.0672\n",
      "Epoch: 7664, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8709.2066\n",
      "Epoch: 7665, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8710.3423\n",
      "Epoch: 7666, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8711.4739\n",
      "Epoch: 7667, Loss: 0.6459, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8712.6114\n",
      "Epoch: 7668, Loss: 0.6463, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8713.7466\n",
      "Epoch: 7669, Loss: 0.6465, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8714.8809\n",
      "Epoch: 7670, Loss: 0.6504, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8716.0261\n",
      "Epoch: 7671, Loss: 0.6511, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8717.1620\n",
      "Epoch: 7672, Loss: 0.6512, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8718.2941\n",
      "Epoch: 7673, Loss: 0.6528, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8719.4271\n",
      "Epoch: 7674, Loss: 0.6513, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8720.5597\n",
      "Epoch: 7675, Loss: 0.6490, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8721.7006\n",
      "Epoch: 7676, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8722.8374\n",
      "Epoch: 7677, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8723.9699\n",
      "Epoch: 7678, Loss: 0.6490, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8725.1025\n",
      "Epoch: 7679, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8726.2385\n",
      "Epoch: 7680, Loss: 0.6474, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8727.3763\n",
      "Epoch: 7681, Loss: 0.6493, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8728.5118\n",
      "Epoch: 7682, Loss: 0.6504, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8729.6484\n",
      "Epoch: 7683, Loss: 0.6525, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8730.7803\n",
      "Epoch: 7684, Loss: 0.6538, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8731.9167\n",
      "Epoch: 7685, Loss: 0.6540, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8733.0541\n",
      "Epoch: 7686, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8734.1876\n",
      "Epoch: 7687, Loss: 0.6526, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8735.3192\n",
      "Epoch: 7688, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8736.4526\n",
      "Epoch: 7689, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8737.5895\n",
      "Epoch: 7690, Loss: 0.6471, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8738.7221\n",
      "Epoch: 7691, Loss: 0.6470, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8739.8515\n",
      "Epoch: 7692, Loss: 0.6457, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8740.9818\n",
      "Epoch: 7693, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8742.1114\n",
      "Epoch: 7694, Loss: 0.6410, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8743.2507\n",
      "Epoch: 7695, Loss: 0.6401, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8744.3883\n",
      "Epoch: 7696, Loss: 0.6398, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8745.5247\n",
      "Epoch: 7697, Loss: 0.6388, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8746.6640\n",
      "Epoch: 7698, Loss: 0.6396, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8747.8007\n",
      "Epoch: 7699, Loss: 0.6409, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8748.9394\n",
      "Epoch: 7700, Loss: 0.6390, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8750.0695\n",
      "Epoch: 7701, Loss: 0.6373, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8751.2055\n",
      "Epoch: 7702, Loss: 0.6368, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8752.3389\n",
      "Epoch: 7703, Loss: 0.6344, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8753.4706\n",
      "Epoch: 7704, Loss: 0.6337, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8754.5995\n",
      "Epoch: 7705, Loss: 0.6376, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8755.7468\n",
      "Epoch: 7706, Loss: 0.6391, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8756.8819\n",
      "Epoch: 7707, Loss: 0.6384, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8758.0229\n",
      "Epoch: 7708, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8759.1671\n",
      "Epoch: 7709, Loss: 0.6393, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8760.3088\n",
      "Epoch: 7710, Loss: 0.6400, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8761.4493\n",
      "Epoch: 7711, Loss: 0.6410, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8762.5878\n",
      "Epoch: 7712, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8763.7229\n",
      "Epoch: 7713, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8764.8602\n",
      "Epoch: 7714, Loss: 0.6401, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8765.9962\n",
      "Epoch: 7715, Loss: 0.6402, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8767.1274\n",
      "Epoch: 7716, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8768.2633\n",
      "Epoch: 7717, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8769.3984\n",
      "Epoch: 7718, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8770.5381\n",
      "Epoch: 7719, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8771.6695\n",
      "Epoch: 7720, Loss: 0.6477, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8772.8068\n",
      "Epoch: 7721, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8773.9514\n",
      "Epoch: 7722, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8775.0896\n",
      "Epoch: 7723, Loss: 0.6459, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8776.2259\n",
      "Epoch: 7724, Loss: 0.6448, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8777.3599\n",
      "Epoch: 7725, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8778.4998\n",
      "Epoch: 7726, Loss: 0.6466, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8779.6385\n",
      "Epoch: 7727, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8780.7763\n",
      "Epoch: 7728, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8781.9147\n",
      "Epoch: 7729, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8783.0521\n",
      "Epoch: 7730, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8784.1856\n",
      "Epoch: 7731, Loss: 0.6505, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8785.3206\n",
      "Epoch: 7732, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8786.4502\n",
      "Epoch: 7733, Loss: 0.6492, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8787.5803\n",
      "Epoch: 7734, Loss: 0.6494, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8788.7187\n",
      "Epoch: 7735, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8789.8543\n",
      "Epoch: 7736, Loss: 0.6477, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8790.9998\n",
      "Epoch: 7737, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8792.1359\n",
      "Epoch: 7738, Loss: 0.6467, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8793.2744\n",
      "Epoch: 7739, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8794.4109\n",
      "Epoch: 7740, Loss: 0.6470, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8795.5452\n",
      "Epoch: 7741, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8796.6769\n",
      "Epoch: 7742, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8797.8107\n",
      "Epoch: 7743, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8798.9424\n",
      "Epoch: 7744, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8800.0769\n",
      "Epoch: 7745, Loss: 0.6443, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8801.2096\n",
      "Epoch: 7746, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8802.3409\n",
      "Epoch: 7747, Loss: 0.6462, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8803.4749\n",
      "Epoch: 7748, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8804.6112\n",
      "Epoch: 7749, Loss: 0.6492, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8805.7508\n",
      "Epoch: 7750, Loss: 0.6538, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8806.8996\n",
      "Epoch: 7751, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8808.0391\n",
      "Epoch: 7752, Loss: 0.6512, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8809.1773\n",
      "Epoch: 7753, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8810.3091\n",
      "Epoch: 7754, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8811.4461\n",
      "Epoch: 7755, Loss: 0.6500, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8812.5822\n",
      "Epoch: 7756, Loss: 0.6463, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8813.7196\n",
      "Epoch: 7757, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8814.8504\n",
      "Epoch: 7758, Loss: 0.6484, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8815.9862\n",
      "Epoch: 7759, Loss: 0.6466, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8817.1183\n",
      "Epoch: 7760, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8818.2507\n",
      "Epoch: 7761, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8819.3873\n",
      "Epoch: 7762, Loss: 0.6462, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8820.5226\n",
      "Epoch: 7763, Loss: 0.6491, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8821.6607\n",
      "Epoch: 7764, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8822.8011\n",
      "Epoch: 7765, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8823.9377\n",
      "Epoch: 7766, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8825.0782\n",
      "Epoch: 7767, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8826.2119\n",
      "Epoch: 7768, Loss: 0.6366, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8827.3437\n",
      "Epoch: 7769, Loss: 0.6358, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8828.4773\n",
      "Epoch: 7770, Loss: 0.6351, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8829.6108\n",
      "Epoch: 7771, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8830.7422\n",
      "Epoch: 7772, Loss: 0.6376, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8831.8749\n",
      "Epoch: 7773, Loss: 0.6363, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8833.0074\n",
      "Epoch: 7774, Loss: 0.6349, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8834.1427\n",
      "Epoch: 7775, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8835.2870\n",
      "Epoch: 7776, Loss: 0.6335, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8836.4306\n",
      "Epoch: 7777, Loss: 0.6333, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8837.5691\n",
      "Epoch: 7778, Loss: 0.6333, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8838.7066\n",
      "Epoch: 7779, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8839.8462\n",
      "Epoch: 7780, Loss: 0.6355, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8840.9815\n",
      "Epoch: 7781, Loss: 0.6338, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8842.1215\n",
      "Epoch: 7782, Loss: 0.6306, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8843.2611\n",
      "Epoch: 7783, Loss: 0.6376, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8844.3912\n",
      "Epoch: 7784, Loss: 0.6373, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8845.5226\n",
      "Epoch: 7785, Loss: 0.6383, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8846.6552\n",
      "Epoch: 7786, Loss: 0.6370, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8847.7858\n",
      "Epoch: 7787, Loss: 0.6369, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8848.9198\n",
      "Epoch: 7788, Loss: 0.6370, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8850.0594\n",
      "Epoch: 7789, Loss: 0.6367, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8851.1975\n",
      "Epoch: 7790, Loss: 0.6348, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8852.3369\n",
      "Epoch: 7791, Loss: 0.6358, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8853.4704\n",
      "Epoch: 7792, Loss: 0.6372, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8854.6152\n",
      "Epoch: 7793, Loss: 0.6371, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8855.7457\n",
      "Epoch: 7794, Loss: 0.6375, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8856.8895\n",
      "Epoch: 7795, Loss: 0.6382, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8858.0251\n",
      "Epoch: 7796, Loss: 0.6374, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8859.1581\n",
      "Epoch: 7797, Loss: 0.6388, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8860.2922\n",
      "Epoch: 7798, Loss: 0.6374, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8861.4276\n",
      "Epoch: 7799, Loss: 0.6365, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8862.5644\n",
      "Epoch: 7800, Loss: 0.6359, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8863.6925\n",
      "Epoch: 7801, Loss: 0.6364, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8864.8285\n",
      "Epoch: 7802, Loss: 0.6337, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8865.9672\n",
      "Epoch: 7803, Loss: 0.6321, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8867.1044\n",
      "Epoch: 7804, Loss: 0.6330, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8868.2457\n",
      "Epoch: 7805, Loss: 0.6333, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8869.3856\n",
      "Epoch: 7806, Loss: 0.6335, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8870.5172\n",
      "Epoch: 7807, Loss: 0.6356, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8871.6516\n",
      "Epoch: 7808, Loss: 0.6359, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8872.7870\n",
      "Epoch: 7809, Loss: 0.6367, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8873.9210\n",
      "Epoch: 7810, Loss: 0.6365, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8875.0627\n",
      "Epoch: 7811, Loss: 0.6360, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8876.1987\n",
      "Epoch: 7812, Loss: 0.6369, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8877.3372\n",
      "Epoch: 7813, Loss: 0.6376, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8878.4791\n",
      "Epoch: 7814, Loss: 0.6401, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8879.6151\n",
      "Epoch: 7815, Loss: 0.6386, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8880.7535\n",
      "Epoch: 7816, Loss: 0.6377, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8881.8914\n",
      "Epoch: 7817, Loss: 0.6366, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8883.0269\n",
      "Epoch: 7818, Loss: 0.6354, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8884.1649\n",
      "Epoch: 7819, Loss: 0.6357, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8885.3059\n",
      "Epoch: 7820, Loss: 0.6344, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8886.4394\n",
      "Epoch: 7821, Loss: 0.6363, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8887.5775\n",
      "Epoch: 7822, Loss: 0.6366, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8888.7181\n",
      "Epoch: 7823, Loss: 0.6372, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8889.8508\n",
      "Epoch: 7824, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8890.9872\n",
      "Epoch: 7825, Loss: 0.6379, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8892.1275\n",
      "Epoch: 7826, Loss: 0.6377, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8893.2634\n",
      "Epoch: 7827, Loss: 0.6345, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 8894.3981\n",
      "Epoch: 7828, Loss: 0.6346, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8895.5357\n",
      "Epoch: 7829, Loss: 0.6350, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8896.6717\n",
      "Epoch: 7830, Loss: 0.6365, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8897.8096\n",
      "Epoch: 7831, Loss: 0.6375, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8898.9489\n",
      "Epoch: 7832, Loss: 0.6388, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8900.0962\n",
      "Epoch: 7833, Loss: 0.6391, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8901.2322\n",
      "Epoch: 7834, Loss: 0.6402, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8902.3723\n",
      "Epoch: 7835, Loss: 0.6394, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8903.5036\n",
      "Epoch: 7836, Loss: 0.6400, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8904.6349\n",
      "Epoch: 7837, Loss: 0.6388, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8905.7698\n",
      "Epoch: 7838, Loss: 0.6389, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8906.9054\n",
      "Epoch: 7839, Loss: 0.6374, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8908.0398\n",
      "Epoch: 7840, Loss: 0.6390, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8909.1706\n",
      "Epoch: 7841, Loss: 0.6391, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8910.3127\n",
      "Epoch: 7842, Loss: 0.6374, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8911.4498\n",
      "Epoch: 7843, Loss: 0.6374, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8912.5892\n",
      "Epoch: 7844, Loss: 0.6364, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8913.7316\n",
      "Epoch: 7845, Loss: 0.6362, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8914.8683\n",
      "Epoch: 7846, Loss: 0.6356, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8916.0066\n",
      "Epoch: 7847, Loss: 0.6362, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8917.1381\n",
      "Epoch: 7848, Loss: 0.6346, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8918.2704\n",
      "Epoch: 7849, Loss: 0.6354, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8919.4028\n",
      "Epoch: 7850, Loss: 0.6351, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8920.5351\n",
      "Epoch: 7851, Loss: 0.6346, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8921.6752\n",
      "Epoch: 7852, Loss: 0.6338, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8922.8058\n",
      "Epoch: 7853, Loss: 0.6344, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8923.9369\n",
      "Epoch: 7854, Loss: 0.6350, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8925.0694\n",
      "Epoch: 7855, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 8926.2061\n",
      "Epoch: 7856, Loss: 0.6347, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8927.3511\n",
      "Epoch: 7857, Loss: 0.6346, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8928.4862\n",
      "Epoch: 7858, Loss: 0.6345, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8929.6223\n",
      "Epoch: 7859, Loss: 0.6339, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8930.7657\n",
      "Epoch: 7860, Loss: 0.6333, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8931.9066\n",
      "Epoch: 7861, Loss: 0.6334, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8933.0454\n",
      "Epoch: 7862, Loss: 0.6331, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8934.1812\n",
      "Epoch: 7863, Loss: 0.6327, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8935.3138\n",
      "Epoch: 7864, Loss: 0.6347, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8936.4491\n",
      "Epoch: 7865, Loss: 0.6337, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8937.5833\n",
      "Epoch: 7866, Loss: 0.6337, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8938.7169\n",
      "Epoch: 7867, Loss: 0.6338, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8939.8499\n",
      "Epoch: 7868, Loss: 0.6343, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8940.9852\n",
      "Epoch: 7869, Loss: 0.6354, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8942.1243\n",
      "Epoch: 7870, Loss: 0.6358, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8943.2661\n",
      "Epoch: 7871, Loss: 0.6338, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8944.4051\n",
      "Epoch: 7872, Loss: 0.6351, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8945.5469\n",
      "Epoch: 7873, Loss: 0.6364, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8946.6792\n",
      "Epoch: 7874, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8947.8141\n",
      "Epoch: 7875, Loss: 0.6390, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8948.9504\n",
      "Epoch: 7876, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8950.0835\n",
      "Epoch: 7877, Loss: 0.6378, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8951.2138\n",
      "Epoch: 7878, Loss: 0.6360, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8952.3468\n",
      "Epoch: 7879, Loss: 0.6370, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8953.4852\n",
      "Epoch: 7880, Loss: 0.6354, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8954.6196\n",
      "Epoch: 7881, Loss: 0.6367, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8955.7533\n",
      "Epoch: 7882, Loss: 0.6355, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8956.8884\n",
      "Epoch: 7883, Loss: 0.6360, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 8958.0256\n",
      "Epoch: 7884, Loss: 0.6352, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8959.1629\n",
      "Epoch: 7885, Loss: 0.6377, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8960.3019\n",
      "Epoch: 7886, Loss: 0.6391, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8961.4352\n",
      "Epoch: 7887, Loss: 0.6396, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8962.5721\n",
      "Epoch: 7888, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8963.7043\n",
      "Epoch: 7889, Loss: 0.6400, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8964.8471\n",
      "Epoch: 7890, Loss: 0.6387, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8965.9799\n",
      "Epoch: 7891, Loss: 0.6402, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8967.1167\n",
      "Epoch: 7892, Loss: 0.6409, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8968.2495\n",
      "Epoch: 7893, Loss: 0.6406, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8969.3851\n",
      "Epoch: 7894, Loss: 0.6411, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8970.5150\n",
      "Epoch: 7895, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8971.6484\n",
      "Epoch: 7896, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8972.7858\n",
      "Epoch: 7897, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8973.9227\n",
      "Epoch: 7898, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8975.0636\n",
      "Epoch: 7899, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 8976.2022\n",
      "Epoch: 7900, Loss: 0.6414, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8977.3333\n",
      "Epoch: 7901, Loss: 0.6410, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8978.4634\n",
      "Epoch: 7902, Loss: 0.6388, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8979.6006\n",
      "Epoch: 7903, Loss: 0.6403, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8980.7347\n",
      "Epoch: 7904, Loss: 0.6388, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8981.8625\n",
      "Epoch: 7905, Loss: 0.6405, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 8982.9955\n",
      "Epoch: 7906, Loss: 0.6421, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8984.1314\n",
      "Epoch: 7907, Loss: 0.6414, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8985.2699\n",
      "Epoch: 7908, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8986.4056\n",
      "Epoch: 7909, Loss: 0.6403, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8987.5406\n",
      "Epoch: 7910, Loss: 0.6383, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8988.6772\n",
      "Epoch: 7911, Loss: 0.6394, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8989.8150\n",
      "Epoch: 7912, Loss: 0.6397, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8990.9557\n",
      "Epoch: 7913, Loss: 0.6394, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8992.0941\n",
      "Epoch: 7914, Loss: 0.6405, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8993.2322\n",
      "Epoch: 7915, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8994.3618\n",
      "Epoch: 7916, Loss: 0.6424, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8995.5052\n",
      "Epoch: 7917, Loss: 0.6403, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 8996.6384\n",
      "Epoch: 7918, Loss: 0.6406, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 8997.7723\n",
      "Epoch: 7919, Loss: 0.6390, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 8998.9053\n",
      "Epoch: 7920, Loss: 0.6390, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9000.0400\n",
      "Epoch: 7921, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9001.1753\n",
      "Epoch: 7922, Loss: 0.6422, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9002.3143\n",
      "Epoch: 7923, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9003.4507\n",
      "Epoch: 7924, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9004.5913\n",
      "Epoch: 7925, Loss: 0.6408, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9005.7276\n",
      "Epoch: 7926, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9006.8702\n",
      "Epoch: 7927, Loss: 0.6382, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9008.0027\n",
      "Epoch: 7928, Loss: 0.6377, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9009.1325\n",
      "Epoch: 7929, Loss: 0.6365, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 9010.2660\n",
      "Epoch: 7930, Loss: 0.6361, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9011.3988\n",
      "Epoch: 7931, Loss: 0.6359, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9012.5335\n",
      "Epoch: 7932, Loss: 0.6364, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9013.6678\n",
      "Epoch: 7933, Loss: 0.6366, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9014.8003\n",
      "Epoch: 7934, Loss: 0.6354, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9015.9375\n",
      "Epoch: 7935, Loss: 0.6373, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9017.0721\n",
      "Epoch: 7936, Loss: 0.6368, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9018.2053\n",
      "Epoch: 7937, Loss: 0.6395, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9019.3485\n",
      "Epoch: 7938, Loss: 0.6398, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9020.4892\n",
      "Epoch: 7939, Loss: 0.6391, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9021.6211\n",
      "Epoch: 7940, Loss: 0.6395, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9022.7533\n",
      "Epoch: 7941, Loss: 0.6397, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9023.8916\n",
      "Epoch: 7942, Loss: 0.6391, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9025.0251\n",
      "Epoch: 7943, Loss: 0.6376, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9026.1577\n",
      "Epoch: 7944, Loss: 0.6366, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9027.2905\n",
      "Epoch: 7945, Loss: 0.6351, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9028.4278\n",
      "Epoch: 7946, Loss: 0.6379, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9029.5583\n",
      "Epoch: 7947, Loss: 0.6354, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9030.6915\n",
      "Epoch: 7948, Loss: 0.6342, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9031.8298\n",
      "Epoch: 7949, Loss: 0.6337, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9032.9691\n",
      "Epoch: 7950, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9034.1044\n",
      "Epoch: 7951, Loss: 0.6380, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9035.2409\n",
      "Epoch: 7952, Loss: 0.6390, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9036.3810\n",
      "Epoch: 7953, Loss: 0.6393, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9037.5101\n",
      "Epoch: 7954, Loss: 0.6411, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9038.6456\n",
      "Epoch: 7955, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 9039.7793\n",
      "Epoch: 7956, Loss: 0.6414, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 9040.9173\n",
      "Epoch: 7957, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9042.0512\n",
      "Epoch: 7958, Loss: 0.6422, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9043.1823\n",
      "Epoch: 7959, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9044.3126\n",
      "Epoch: 7960, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9045.4449\n",
      "Epoch: 7961, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9046.5930\n",
      "Epoch: 7962, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 9047.7278\n",
      "Epoch: 7963, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9048.8668\n",
      "Epoch: 7964, Loss: 0.6443, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9050.0036\n",
      "Epoch: 7965, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9051.1427\n",
      "Epoch: 7966, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9052.2843\n",
      "Epoch: 7967, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9053.4259\n",
      "Epoch: 7968, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9054.5582\n",
      "Epoch: 7969, Loss: 0.6439, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9055.6952\n",
      "Epoch: 7970, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9056.8308\n",
      "Epoch: 7971, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9057.9623\n",
      "Epoch: 7972, Loss: 0.6435, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9059.0972\n",
      "Epoch: 7973, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9060.2268\n",
      "Epoch: 7974, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9061.3666\n",
      "Epoch: 7975, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9062.5102\n",
      "Epoch: 7976, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9063.6510\n",
      "Epoch: 7977, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9064.7926\n",
      "Epoch: 7978, Loss: 0.6421, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9065.9328\n",
      "Epoch: 7979, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9067.0681\n",
      "Epoch: 7980, Loss: 0.6451, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9068.1991\n",
      "Epoch: 7981, Loss: 0.6435, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9069.3305\n",
      "Epoch: 7982, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9070.4643\n",
      "Epoch: 7983, Loss: 0.6456, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9071.6021\n",
      "Epoch: 7984, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9072.7488\n",
      "Epoch: 7985, Loss: 0.6469, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9073.8794\n",
      "Epoch: 7986, Loss: 0.6463, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9075.0112\n",
      "Epoch: 7987, Loss: 0.6485, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9076.1481\n",
      "Epoch: 7988, Loss: 0.6477, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9077.2790\n",
      "Epoch: 7989, Loss: 0.6471, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9078.4179\n",
      "Epoch: 7990, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9079.5591\n",
      "Epoch: 7991, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9080.6990\n",
      "Epoch: 7992, Loss: 0.6500, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9081.8309\n",
      "Epoch: 7993, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9082.9703\n",
      "Epoch: 7994, Loss: 0.6515, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9084.1217\n",
      "Epoch: 7995, Loss: 0.6545, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9085.2508\n",
      "Epoch: 7996, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9086.3809\n",
      "Epoch: 7997, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9087.5121\n",
      "Epoch: 7998, Loss: 0.6545, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9088.6451\n",
      "Epoch: 7999, Loss: 0.6544, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9089.7790\n",
      "Epoch: 8000, Loss: 0.6524, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9090.9122\n",
      "Epoch: 8001, Loss: 0.6535, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9092.0543\n",
      "Epoch: 8002, Loss: 0.6527, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9093.1876\n",
      "Epoch: 8003, Loss: 0.6515, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9094.3342\n",
      "Epoch: 8004, Loss: 0.6514, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9095.4715\n",
      "Epoch: 8005, Loss: 0.6514, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9096.6062\n",
      "Epoch: 8006, Loss: 0.6517, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9097.7369\n",
      "Epoch: 8007, Loss: 0.6501, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9098.8753\n",
      "Epoch: 8008, Loss: 0.6482, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9100.0100\n",
      "Epoch: 8009, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9101.1448\n",
      "Epoch: 8010, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9102.2818\n",
      "Epoch: 8011, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9103.4129\n",
      "Epoch: 8012, Loss: 0.6491, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9104.5499\n",
      "Epoch: 8013, Loss: 0.6494, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9105.6862\n",
      "Epoch: 8014, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9106.8227\n",
      "Epoch: 8015, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9107.9590\n",
      "Epoch: 8016, Loss: 0.6410, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9109.0923\n",
      "Epoch: 8017, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9110.2313\n",
      "Epoch: 8018, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9111.3648\n",
      "Epoch: 8019, Loss: 0.6443, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9112.4998\n",
      "Epoch: 8020, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9113.6311\n",
      "Epoch: 8021, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9114.7675\n",
      "Epoch: 8022, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9115.9056\n",
      "Epoch: 8023, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9117.0391\n",
      "Epoch: 8024, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9118.1686\n",
      "Epoch: 8025, Loss: 0.6435, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9119.3008\n",
      "Epoch: 8026, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9120.4337\n",
      "Epoch: 8027, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9121.5629\n",
      "Epoch: 8028, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9122.6972\n",
      "Epoch: 8029, Loss: 0.6495, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9123.8323\n",
      "Epoch: 8030, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9124.9657\n",
      "Epoch: 8031, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9126.1052\n",
      "Epoch: 8032, Loss: 0.6513, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9127.2426\n",
      "Epoch: 8033, Loss: 0.6505, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9128.3727\n",
      "Epoch: 8034, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9129.5048\n",
      "Epoch: 8035, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9130.6366\n",
      "Epoch: 8036, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9131.7691\n",
      "Epoch: 8037, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9132.9002\n",
      "Epoch: 8038, Loss: 0.6485, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9134.0319\n",
      "Epoch: 8039, Loss: 0.6455, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9135.1621\n",
      "Epoch: 8040, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9136.2906\n",
      "Epoch: 8041, Loss: 0.6482, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9137.4293\n",
      "Epoch: 8042, Loss: 0.6493, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9138.5647\n",
      "Epoch: 8043, Loss: 0.6485, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9139.7001\n",
      "Epoch: 8044, Loss: 0.6485, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9140.8393\n",
      "Epoch: 8045, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9141.9734\n",
      "Epoch: 8046, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9143.1077\n",
      "Epoch: 8047, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9144.2437\n",
      "Epoch: 8048, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9145.3787\n",
      "Epoch: 8049, Loss: 0.6501, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9146.5114\n",
      "Epoch: 8050, Loss: 0.6493, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9147.6420\n",
      "Epoch: 8051, Loss: 0.6515, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9148.7808\n",
      "Epoch: 8052, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9149.9152\n",
      "Epoch: 8053, Loss: 0.6533, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9151.0478\n",
      "Epoch: 8054, Loss: 0.6525, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9152.1844\n",
      "Epoch: 8055, Loss: 0.6544, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9153.3213\n",
      "Epoch: 8056, Loss: 0.6532, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9154.4601\n",
      "Epoch: 8057, Loss: 0.6553, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9155.5968\n",
      "Epoch: 8058, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9156.7358\n",
      "Epoch: 8059, Loss: 0.6533, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9157.8684\n",
      "Epoch: 8060, Loss: 0.6512, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9158.9947\n",
      "Epoch: 8061, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9160.1319\n",
      "Epoch: 8062, Loss: 0.6511, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9161.2641\n",
      "Epoch: 8063, Loss: 0.6507, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9162.3980\n",
      "Epoch: 8064, Loss: 0.6487, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9163.5273\n",
      "Epoch: 8065, Loss: 0.6493, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9164.6607\n",
      "Epoch: 8066, Loss: 0.6485, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9165.7927\n",
      "Epoch: 8067, Loss: 0.6474, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9166.9223\n",
      "Epoch: 8068, Loss: 0.6470, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9168.0631\n",
      "Epoch: 8069, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9169.2015\n",
      "Epoch: 8070, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9170.3445\n",
      "Epoch: 8071, Loss: 0.6456, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9171.4785\n",
      "Epoch: 8072, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9172.6194\n",
      "Epoch: 8073, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9173.7538\n",
      "Epoch: 8074, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9174.8924\n",
      "Epoch: 8075, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9176.0278\n",
      "Epoch: 8076, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9177.1601\n",
      "Epoch: 8077, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9178.2888\n",
      "Epoch: 8078, Loss: 0.6434, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9179.4173\n",
      "Epoch: 8079, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9180.5529\n",
      "Epoch: 8080, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9181.6940\n",
      "Epoch: 8081, Loss: 0.6457, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9182.8273\n",
      "Epoch: 8082, Loss: 0.6443, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9183.9612\n",
      "Epoch: 8083, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9185.0998\n",
      "Epoch: 8084, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9186.2343\n",
      "Epoch: 8085, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9187.3713\n",
      "Epoch: 8086, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9188.5031\n",
      "Epoch: 8087, Loss: 0.6474, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9189.6330\n",
      "Epoch: 8088, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9190.7714\n",
      "Epoch: 8089, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9191.8994\n",
      "Epoch: 8090, Loss: 0.6448, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9193.0345\n",
      "Epoch: 8091, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9194.1697\n",
      "Epoch: 8092, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9195.3031\n",
      "Epoch: 8093, Loss: 0.6448, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9196.4388\n",
      "Epoch: 8094, Loss: 0.6459, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9197.5729\n",
      "Epoch: 8095, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9198.7066\n",
      "Epoch: 8096, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9199.8492\n",
      "Epoch: 8097, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9200.9846\n",
      "Epoch: 8098, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9202.1242\n",
      "Epoch: 8099, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9203.2622\n",
      "Epoch: 8100, Loss: 0.6469, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9204.3897\n",
      "Epoch: 8101, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9205.5253\n",
      "Epoch: 8102, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9206.6559\n",
      "Epoch: 8103, Loss: 0.6462, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9207.7876\n",
      "Epoch: 8104, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9208.9156\n",
      "Epoch: 8105, Loss: 0.6459, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9210.0490\n",
      "Epoch: 8106, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9211.1803\n",
      "Epoch: 8107, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9212.3120\n",
      "Epoch: 8108, Loss: 0.6410, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9213.4494\n",
      "Epoch: 8109, Loss: 0.6422, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9214.5941\n",
      "Epoch: 8110, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9215.7328\n",
      "Epoch: 8111, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9216.8747\n",
      "Epoch: 8112, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9218.0078\n",
      "Epoch: 8113, Loss: 0.6431, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9219.1396\n",
      "Epoch: 8114, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9220.2721\n",
      "Epoch: 8115, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9221.3998\n",
      "Epoch: 8116, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9222.5272\n",
      "Epoch: 8117, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9223.6644\n",
      "Epoch: 8118, Loss: 0.6459, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9224.8032\n",
      "Epoch: 8119, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9225.9343\n",
      "Epoch: 8120, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9227.0728\n",
      "Epoch: 8121, Loss: 0.6381, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9228.2077\n",
      "Epoch: 8122, Loss: 0.6387, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 9229.3429\n",
      "Epoch: 8123, Loss: 0.6394, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9230.4803\n",
      "Epoch: 8124, Loss: 0.6434, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9231.6181\n",
      "Epoch: 8125, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9232.7521\n",
      "Epoch: 8126, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9233.8835\n",
      "Epoch: 8127, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9235.0313\n",
      "Epoch: 8128, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9236.1669\n",
      "Epoch: 8129, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9237.3007\n",
      "Epoch: 8130, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9238.4315\n",
      "Epoch: 8131, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9239.5622\n",
      "Epoch: 8132, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9240.6954\n",
      "Epoch: 8133, Loss: 0.6455, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9241.8284\n",
      "Epoch: 8134, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9242.9625\n",
      "Epoch: 8135, Loss: 0.6408, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9244.0947\n",
      "Epoch: 8136, Loss: 0.6391, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9245.2288\n",
      "Epoch: 8137, Loss: 0.6400, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9246.3682\n",
      "Epoch: 8138, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9247.5083\n",
      "Epoch: 8139, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9248.6416\n",
      "Epoch: 8140, Loss: 0.6422, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9249.7752\n",
      "Epoch: 8141, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9250.9080\n",
      "Epoch: 8142, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9252.0383\n",
      "Epoch: 8143, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9253.1678\n",
      "Epoch: 8144, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9254.3002\n",
      "Epoch: 8145, Loss: 0.6473, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9255.4306\n",
      "Epoch: 8146, Loss: 0.6506, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9256.5664\n",
      "Epoch: 8147, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9257.7023\n",
      "Epoch: 8148, Loss: 0.6493, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9258.8341\n",
      "Epoch: 8149, Loss: 0.6485, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9259.9703\n",
      "Epoch: 8150, Loss: 0.6492, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9261.1092\n",
      "Epoch: 8151, Loss: 0.6473, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9262.2458\n",
      "Epoch: 8152, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9263.3832\n",
      "Epoch: 8153, Loss: 0.6471, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9264.5226\n",
      "Epoch: 8154, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9265.6573\n",
      "Epoch: 8155, Loss: 0.6502, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9266.7911\n",
      "Epoch: 8156, Loss: 0.6517, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9267.9273\n",
      "Epoch: 8157, Loss: 0.6517, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9269.0650\n",
      "Epoch: 8158, Loss: 0.6539, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9270.1899\n",
      "Epoch: 8159, Loss: 0.6559, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9271.3224\n",
      "Epoch: 8160, Loss: 0.6566, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9272.4584\n",
      "Epoch: 8161, Loss: 0.6544, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9273.5954\n",
      "Epoch: 8162, Loss: 0.6543, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9274.7461\n",
      "Epoch: 8163, Loss: 0.6542, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9275.8767\n",
      "Epoch: 8164, Loss: 0.6567, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9277.0129\n",
      "Epoch: 8165, Loss: 0.6595, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9278.1518\n",
      "Epoch: 8166, Loss: 0.6585, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9279.2925\n",
      "Epoch: 8167, Loss: 0.6588, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9280.4311\n",
      "Epoch: 8168, Loss: 0.6579, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9281.5627\n",
      "Epoch: 8169, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9282.6947\n",
      "Epoch: 8170, Loss: 0.6548, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9283.8356\n",
      "Epoch: 8171, Loss: 0.6503, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9284.9693\n",
      "Epoch: 8172, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9286.0971\n",
      "Epoch: 8173, Loss: 0.6493, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9287.2302\n",
      "Epoch: 8174, Loss: 0.6502, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9288.3635\n",
      "Epoch: 8175, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9289.4994\n",
      "Epoch: 8176, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9290.6378\n",
      "Epoch: 8177, Loss: 0.6490, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9291.7739\n",
      "Epoch: 8178, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9292.9101\n",
      "Epoch: 8179, Loss: 0.6477, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9294.0558\n",
      "Epoch: 8180, Loss: 0.6484, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9295.1933\n",
      "Epoch: 8181, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9296.3353\n",
      "Epoch: 8182, Loss: 0.6493, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9297.4675\n",
      "Epoch: 8183, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9298.6018\n",
      "Epoch: 8184, Loss: 0.6485, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9299.7367\n",
      "Epoch: 8185, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9300.8759\n",
      "Epoch: 8186, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9302.0112\n",
      "Epoch: 8187, Loss: 0.6504, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9303.1402\n",
      "Epoch: 8188, Loss: 0.6532, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9304.2707\n",
      "Epoch: 8189, Loss: 0.6515, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9305.4106\n",
      "Epoch: 8190, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9306.5538\n",
      "Epoch: 8191, Loss: 0.6532, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9307.6853\n",
      "Epoch: 8192, Loss: 0.6524, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9308.8211\n",
      "Epoch: 8193, Loss: 0.6522, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9309.9549\n",
      "Epoch: 8194, Loss: 0.6522, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9311.0973\n",
      "Epoch: 8195, Loss: 0.6529, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9312.2341\n",
      "Epoch: 8196, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9313.3740\n",
      "Epoch: 8197, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9314.5075\n",
      "Epoch: 8198, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9315.6405\n",
      "Epoch: 8199, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9316.7753\n",
      "Epoch: 8200, Loss: 0.6500, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9317.9107\n",
      "Epoch: 8201, Loss: 0.6503, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9319.0447\n",
      "Epoch: 8202, Loss: 0.6493, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9320.1823\n",
      "Epoch: 8203, Loss: 0.6488, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 9321.3225\n",
      "Epoch: 8204, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 9322.4654\n",
      "Epoch: 8205, Loss: 0.6469, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9323.6023\n",
      "Epoch: 8206, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9324.7394\n",
      "Epoch: 8207, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 9325.8785\n",
      "Epoch: 8208, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9327.0104\n",
      "Epoch: 8209, Loss: 0.6463, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9328.1433\n",
      "Epoch: 8210, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9329.2750\n",
      "Epoch: 8211, Loss: 0.6521, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9330.4044\n",
      "Epoch: 8212, Loss: 0.6516, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9331.5371\n",
      "Epoch: 8213, Loss: 0.6522, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9332.6680\n",
      "Epoch: 8214, Loss: 0.6536, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9333.8067\n",
      "Epoch: 8215, Loss: 0.6524, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9334.9422\n",
      "Epoch: 8216, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9336.0802\n",
      "Epoch: 8217, Loss: 0.6507, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9337.2197\n",
      "Epoch: 8218, Loss: 0.6507, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9338.3558\n",
      "Epoch: 8219, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 9339.4951\n",
      "Epoch: 8220, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 9340.6304\n",
      "Epoch: 8221, Loss: 0.6473, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 9341.7652\n",
      "Epoch: 8222, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9342.9020\n",
      "Epoch: 8223, Loss: 0.6474, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9344.0342\n",
      "Epoch: 8224, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9345.1650\n",
      "Epoch: 8225, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9346.2979\n",
      "Epoch: 8226, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9347.4285\n",
      "Epoch: 8227, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9348.5612\n",
      "Epoch: 8228, Loss: 0.6485, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9349.6949\n",
      "Epoch: 8229, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9350.8331\n",
      "Epoch: 8230, Loss: 0.6488, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9351.9713\n",
      "Epoch: 8231, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9353.1084\n",
      "Epoch: 8232, Loss: 0.6488, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 9354.2521\n",
      "Epoch: 8233, Loss: 0.6494, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 9355.3954\n",
      "Epoch: 8234, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9356.5319\n",
      "Epoch: 8235, Loss: 0.6494, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 9357.6674\n",
      "Epoch: 8236, Loss: 0.6513, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9358.8009\n",
      "Epoch: 8237, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9359.9370\n",
      "Epoch: 8238, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9361.0718\n",
      "Epoch: 8239, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9362.2037\n",
      "Epoch: 8240, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9363.3341\n",
      "Epoch: 8241, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9364.4637\n",
      "Epoch: 8242, Loss: 0.6439, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9365.6099\n",
      "Epoch: 8243, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9366.7473\n",
      "Epoch: 8244, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9367.8845\n",
      "Epoch: 8245, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9369.0248\n",
      "Epoch: 8246, Loss: 0.6469, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9370.1615\n",
      "Epoch: 8247, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9371.3027\n",
      "Epoch: 8248, Loss: 0.6474, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9372.4376\n",
      "Epoch: 8249, Loss: 0.6494, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9373.5719\n",
      "Epoch: 8250, Loss: 0.6512, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9374.7087\n",
      "Epoch: 8251, Loss: 0.6589, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9375.8529\n",
      "Epoch: 8252, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9376.9835\n",
      "Epoch: 8253, Loss: 0.6598, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9378.1151\n",
      "Epoch: 8254, Loss: 0.6606, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9379.2482\n",
      "Epoch: 8255, Loss: 0.6570, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9380.3825\n",
      "Epoch: 8256, Loss: 0.6644, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9381.5198\n",
      "Epoch: 8257, Loss: 0.6609, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9382.6553\n",
      "Epoch: 8258, Loss: 0.6614, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9383.7893\n",
      "Epoch: 8259, Loss: 0.6613, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9384.9254\n",
      "Epoch: 8260, Loss: 0.6617, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9386.0709\n",
      "Epoch: 8261, Loss: 0.6613, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9387.2098\n",
      "Epoch: 8262, Loss: 0.6605, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9388.3459\n",
      "Epoch: 8263, Loss: 0.6582, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9389.4749\n",
      "Epoch: 8264, Loss: 0.6573, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9390.6099\n",
      "Epoch: 8265, Loss: 0.6581, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9391.7443\n",
      "Epoch: 8266, Loss: 0.6595, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9392.8745\n",
      "Epoch: 8267, Loss: 0.6557, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9394.0067\n",
      "Epoch: 8268, Loss: 0.6576, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9395.1450\n",
      "Epoch: 8269, Loss: 0.6560, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9396.2863\n",
      "Epoch: 8270, Loss: 0.6546, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9397.4304\n",
      "Epoch: 8271, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9398.5663\n",
      "Epoch: 8272, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9399.7026\n",
      "Epoch: 8273, Loss: 0.6533, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9400.8390\n",
      "Epoch: 8274, Loss: 0.6572, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9401.9695\n",
      "Epoch: 8275, Loss: 0.6567, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9403.1027\n",
      "Epoch: 8276, Loss: 0.6555, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9404.2346\n",
      "Epoch: 8277, Loss: 0.6575, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9405.3653\n",
      "Epoch: 8278, Loss: 0.6587, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9406.4977\n",
      "Epoch: 8279, Loss: 0.6576, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9407.6423\n",
      "Epoch: 8280, Loss: 0.6581, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9408.7762\n",
      "Epoch: 8281, Loss: 0.6575, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9409.9097\n",
      "Epoch: 8282, Loss: 0.6571, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9411.0493\n",
      "Epoch: 8283, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9412.1843\n",
      "Epoch: 8284, Loss: 0.6580, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9413.3203\n",
      "Epoch: 8285, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9414.4574\n",
      "Epoch: 8286, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9415.6008\n",
      "Epoch: 8287, Loss: 0.6593, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9416.7361\n",
      "Epoch: 8288, Loss: 0.6596, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9417.8721\n",
      "Epoch: 8289, Loss: 0.6588, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9419.0124\n",
      "Epoch: 8290, Loss: 0.6613, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9420.1437\n",
      "Epoch: 8291, Loss: 0.6612, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9421.2772\n",
      "Epoch: 8292, Loss: 0.6585, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9422.4102\n",
      "Epoch: 8293, Loss: 0.6573, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9423.5456\n",
      "Epoch: 8294, Loss: 0.6589, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9424.6788\n",
      "Epoch: 8295, Loss: 0.6607, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9425.8191\n",
      "Epoch: 8296, Loss: 0.6583, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9426.9542\n",
      "Epoch: 8297, Loss: 0.6578, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9428.0901\n",
      "Epoch: 8298, Loss: 0.6557, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9429.2284\n",
      "Epoch: 8299, Loss: 0.6565, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9430.3719\n",
      "Epoch: 8300, Loss: 0.6574, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9431.5043\n",
      "Epoch: 8301, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9432.6391\n",
      "Epoch: 8302, Loss: 0.6555, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9433.7719\n",
      "Epoch: 8303, Loss: 0.6549, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9434.9034\n",
      "Epoch: 8304, Loss: 0.6552, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9436.0384\n",
      "Epoch: 8305, Loss: 0.6537, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9437.1676\n",
      "Epoch: 8306, Loss: 0.6521, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9438.2995\n",
      "Epoch: 8307, Loss: 0.6531, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9439.4357\n",
      "Epoch: 8308, Loss: 0.6541, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9440.5687\n",
      "Epoch: 8309, Loss: 0.6539, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9441.7048\n",
      "Epoch: 8310, Loss: 0.6529, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9442.8414\n",
      "Epoch: 8311, Loss: 0.6548, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9443.9754\n",
      "Epoch: 8312, Loss: 0.6555, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9445.1130\n",
      "Epoch: 8313, Loss: 0.6561, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9446.2499\n",
      "Epoch: 8314, Loss: 0.6555, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9447.3865\n",
      "Epoch: 8315, Loss: 0.6547, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9448.5215\n",
      "Epoch: 8316, Loss: 0.6546, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9449.6555\n",
      "Epoch: 8317, Loss: 0.6545, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9450.7909\n",
      "Epoch: 8318, Loss: 0.6523, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9451.9302\n",
      "Epoch: 8319, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9453.0616\n",
      "Epoch: 8320, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9454.1907\n",
      "Epoch: 8321, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9455.3205\n",
      "Epoch: 8322, Loss: 0.6487, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9456.4573\n",
      "Epoch: 8323, Loss: 0.6482, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9457.5973\n",
      "Epoch: 8324, Loss: 0.6469, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9458.7336\n",
      "Epoch: 8325, Loss: 0.6448, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9459.8686\n",
      "Epoch: 8326, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9461.0108\n",
      "Epoch: 8327, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9462.1463\n",
      "Epoch: 8328, Loss: 0.6462, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9463.2864\n",
      "Epoch: 8329, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9464.4216\n",
      "Epoch: 8330, Loss: 0.6474, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9465.5537\n",
      "Epoch: 8331, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9466.6904\n",
      "Epoch: 8332, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9467.8236\n",
      "Epoch: 8333, Loss: 0.6439, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9468.9559\n",
      "Epoch: 8334, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9470.0889\n",
      "Epoch: 8335, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9471.2224\n",
      "Epoch: 8336, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9472.3529\n",
      "Epoch: 8337, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9473.4933\n",
      "Epoch: 8338, Loss: 0.6457, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9474.6304\n",
      "Epoch: 8339, Loss: 0.6451, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9475.7723\n",
      "Epoch: 8340, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9476.9117\n",
      "Epoch: 8341, Loss: 0.6339, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9478.0474\n",
      "Epoch: 8342, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9479.1842\n",
      "Epoch: 8343, Loss: 0.6382, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9480.3181\n",
      "Epoch: 8344, Loss: 0.6400, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9481.4514\n",
      "Epoch: 8345, Loss: 0.6409, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9482.5898\n",
      "Epoch: 8346, Loss: 0.6394, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 9483.7221\n",
      "Epoch: 8347, Loss: 0.6377, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9484.8565\n",
      "Epoch: 8348, Loss: 0.6381, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9485.9882\n",
      "Epoch: 8349, Loss: 0.6373, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9487.1198\n",
      "Epoch: 8350, Loss: 0.6360, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9488.2504\n",
      "Epoch: 8351, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9489.3883\n",
      "Epoch: 8352, Loss: 0.6346, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9490.5263\n",
      "Epoch: 8353, Loss: 0.6363, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 9491.6651\n",
      "Epoch: 8354, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 9492.8007\n",
      "Epoch: 8355, Loss: 0.6376, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 9493.9402\n",
      "Epoch: 8356, Loss: 0.6358, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9495.0770\n",
      "Epoch: 8357, Loss: 0.6341, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9496.2142\n",
      "Epoch: 8358, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9497.3443\n",
      "Epoch: 8359, Loss: 0.6377, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9498.4777\n",
      "Epoch: 8360, Loss: 0.6357, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9499.6083\n",
      "Epoch: 8361, Loss: 0.6354, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9500.7394\n",
      "Epoch: 8362, Loss: 0.6342, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9501.8727\n",
      "Epoch: 8363, Loss: 0.6346, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9503.0047\n",
      "Epoch: 8364, Loss: 0.6342, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9504.1393\n",
      "Epoch: 8365, Loss: 0.6339, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9505.2814\n",
      "Epoch: 8366, Loss: 0.6342, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9506.4218\n",
      "Epoch: 8367, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9507.5611\n",
      "Epoch: 8368, Loss: 0.6352, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9508.6975\n",
      "Epoch: 8369, Loss: 0.6352, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9509.8365\n",
      "Epoch: 8370, Loss: 0.6357, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9510.9696\n",
      "Epoch: 8371, Loss: 0.6371, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9512.1013\n",
      "Epoch: 8372, Loss: 0.6358, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9513.2303\n",
      "Epoch: 8373, Loss: 0.6358, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9514.3620\n",
      "Epoch: 8374, Loss: 0.6334, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9515.4979\n",
      "Epoch: 8375, Loss: 0.6336, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9516.6292\n",
      "Epoch: 8376, Loss: 0.6332, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9517.7620\n",
      "Epoch: 8377, Loss: 0.6332, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9518.8924\n",
      "Epoch: 8378, Loss: 0.6333, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9520.0299\n",
      "Epoch: 8379, Loss: 0.6317, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9521.1640\n",
      "Epoch: 8380, Loss: 0.6313, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9522.3015\n",
      "Epoch: 8381, Loss: 0.6306, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9523.4410\n",
      "Epoch: 8382, Loss: 0.6302, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9524.5749\n",
      "Epoch: 8383, Loss: 0.6299, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9525.7125\n",
      "Epoch: 8384, Loss: 0.6307, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9526.8444\n",
      "Epoch: 8385, Loss: 0.6310, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9527.9906\n",
      "Epoch: 8386, Loss: 0.6312, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9529.1261\n",
      "Epoch: 8387, Loss: 0.6313, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9530.2631\n",
      "Epoch: 8388, Loss: 0.6421, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9531.3963\n",
      "Epoch: 8389, Loss: 0.6431, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9532.5311\n",
      "Epoch: 8390, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9533.6648\n",
      "Epoch: 8391, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9534.7976\n",
      "Epoch: 8392, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9535.9301\n",
      "Epoch: 8393, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9537.0652\n",
      "Epoch: 8394, Loss: 0.6414, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9538.2126\n",
      "Epoch: 8395, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9539.3518\n",
      "Epoch: 8396, Loss: 0.6410, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9540.4846\n",
      "Epoch: 8397, Loss: 0.6411, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9541.6165\n",
      "Epoch: 8398, Loss: 0.6413, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9542.7513\n",
      "Epoch: 8399, Loss: 0.6422, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9543.8857\n",
      "Epoch: 8400, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9545.0213\n",
      "Epoch: 8401, Loss: 0.6308, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9546.1530\n",
      "Epoch: 8402, Loss: 0.6314, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9547.2867\n",
      "Epoch: 8403, Loss: 0.6334, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9548.4157\n",
      "Epoch: 8404, Loss: 0.6343, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9549.5586\n",
      "Epoch: 8405, Loss: 0.6345, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9550.6963\n",
      "Epoch: 8406, Loss: 0.6336, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9551.8377\n",
      "Epoch: 8407, Loss: 0.6361, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9552.9747\n",
      "Epoch: 8408, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9554.1133\n",
      "Epoch: 8409, Loss: 0.6456, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9555.2494\n",
      "Epoch: 8410, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9556.3848\n",
      "Epoch: 8411, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9557.5157\n",
      "Epoch: 8412, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9558.6492\n",
      "Epoch: 8413, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9559.7876\n",
      "Epoch: 8414, Loss: 0.6451, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9560.9190\n",
      "Epoch: 8415, Loss: 0.6448, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9562.0476\n",
      "Epoch: 8416, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9563.1794\n",
      "Epoch: 8417, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9564.3112\n",
      "Epoch: 8418, Loss: 0.6451, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9565.4466\n",
      "Epoch: 8419, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9566.5824\n",
      "Epoch: 8420, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9567.7265\n",
      "Epoch: 8421, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9568.8618\n",
      "Epoch: 8422, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9569.9975\n",
      "Epoch: 8423, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9571.1283\n",
      "Epoch: 8424, Loss: 0.6477, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 9572.2633\n",
      "Epoch: 8425, Loss: 0.6471, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 9573.3942\n",
      "Epoch: 8426, Loss: 0.6474, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9574.5267\n",
      "Epoch: 8427, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9575.6613\n",
      "Epoch: 8428, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9576.7923\n",
      "Epoch: 8429, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9577.9293\n",
      "Epoch: 8430, Loss: 0.6470, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9579.0641\n",
      "Epoch: 8431, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9580.1947\n",
      "Epoch: 8432, Loss: 0.6477, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9581.3296\n",
      "Epoch: 8433, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9582.4619\n",
      "Epoch: 8434, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9583.6001\n",
      "Epoch: 8435, Loss: 0.6473, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9584.7357\n",
      "Epoch: 8436, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9585.8766\n",
      "Epoch: 8437, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9587.0119\n",
      "Epoch: 8438, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9588.1488\n",
      "Epoch: 8439, Loss: 0.6457, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9589.2801\n",
      "Epoch: 8440, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9590.4152\n",
      "Epoch: 8441, Loss: 0.6451, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9591.5450\n",
      "Epoch: 8442, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9592.6822\n",
      "Epoch: 8443, Loss: 0.6465, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9593.8184\n",
      "Epoch: 8444, Loss: 0.6469, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9594.9550\n",
      "Epoch: 8445, Loss: 0.6487, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9596.0875\n",
      "Epoch: 8446, Loss: 0.6500, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9597.2271\n",
      "Epoch: 8447, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9598.3686\n",
      "Epoch: 8448, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9599.5057\n",
      "Epoch: 8449, Loss: 0.6558, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9600.6406\n",
      "Epoch: 8450, Loss: 0.6535, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9601.7779\n",
      "Epoch: 8451, Loss: 0.6547, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9602.9261\n",
      "Epoch: 8452, Loss: 0.6580, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9604.0588\n",
      "Epoch: 8453, Loss: 0.6586, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9605.1894\n",
      "Epoch: 8454, Loss: 0.6560, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9606.3229\n",
      "Epoch: 8455, Loss: 0.6558, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9607.4543\n",
      "Epoch: 8456, Loss: 0.6568, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9608.5876\n",
      "Epoch: 8457, Loss: 0.6567, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9609.7191\n",
      "Epoch: 8458, Loss: 0.6556, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9610.8532\n",
      "Epoch: 8459, Loss: 0.6546, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9611.9875\n",
      "Epoch: 8460, Loss: 0.6528, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9613.1239\n",
      "Epoch: 8461, Loss: 0.6554, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9614.2647\n",
      "Epoch: 8462, Loss: 0.6548, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9615.4028\n",
      "Epoch: 8463, Loss: 0.6525, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9616.5383\n",
      "Epoch: 8464, Loss: 0.6537, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9617.6748\n",
      "Epoch: 8465, Loss: 0.6535, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9618.8077\n",
      "Epoch: 8466, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9619.9431\n",
      "Epoch: 8467, Loss: 0.6524, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9621.0741\n",
      "Epoch: 8468, Loss: 0.6527, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9622.2020\n",
      "Epoch: 8469, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9623.3344\n",
      "Epoch: 8470, Loss: 0.6516, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9624.4711\n",
      "Epoch: 8471, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9625.6074\n",
      "Epoch: 8472, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9626.7396\n",
      "Epoch: 8473, Loss: 0.6517, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9627.8809\n",
      "Epoch: 8474, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9629.0212\n",
      "Epoch: 8475, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9630.1584\n",
      "Epoch: 8476, Loss: 0.6504, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9631.2939\n",
      "Epoch: 8477, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9632.4331\n",
      "Epoch: 8478, Loss: 0.6495, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9633.5686\n",
      "Epoch: 8479, Loss: 0.6493, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9634.7026\n",
      "Epoch: 8480, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9635.8369\n",
      "Epoch: 8481, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9636.9636\n",
      "Epoch: 8482, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9638.0987\n",
      "Epoch: 8483, Loss: 0.6491, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9639.2270\n",
      "Epoch: 8484, Loss: 0.6507, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9640.3609\n",
      "Epoch: 8485, Loss: 0.6506, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9641.4929\n",
      "Epoch: 8486, Loss: 0.6491, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9642.6301\n",
      "Epoch: 8487, Loss: 0.6493, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9643.7657\n",
      "Epoch: 8488, Loss: 0.6525, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9644.9044\n",
      "Epoch: 8489, Loss: 0.6528, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9646.0444\n",
      "Epoch: 8490, Loss: 0.6466, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9647.1859\n",
      "Epoch: 8491, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9648.3263\n",
      "Epoch: 8492, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9649.4604\n",
      "Epoch: 8493, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9650.5945\n",
      "Epoch: 8494, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9651.7281\n",
      "Epoch: 8495, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9652.8609\n",
      "Epoch: 8496, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9653.9949\n",
      "Epoch: 8497, Loss: 0.6422, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9655.1283\n",
      "Epoch: 8498, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9656.2619\n",
      "Epoch: 8499, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9657.4081\n",
      "Epoch: 8500, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9658.5560\n",
      "Epoch: 8501, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9659.6914\n",
      "Epoch: 8502, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9660.8258\n",
      "Epoch: 8503, Loss: 0.6409, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9661.9665\n",
      "Epoch: 8504, Loss: 0.6411, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9663.1005\n",
      "Epoch: 8505, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9664.2349\n",
      "Epoch: 8506, Loss: 0.6408, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9665.3634\n",
      "Epoch: 8507, Loss: 0.6397, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9666.4994\n",
      "Epoch: 8508, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9667.6358\n",
      "Epoch: 8509, Loss: 0.6417, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9668.7642\n",
      "Epoch: 8510, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9669.9008\n",
      "Epoch: 8511, Loss: 0.6431, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9671.0370\n",
      "Epoch: 8512, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9672.1702\n",
      "Epoch: 8513, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9673.3074\n",
      "Epoch: 8514, Loss: 0.6434, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9674.4555\n",
      "Epoch: 8515, Loss: 0.6451, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9675.5957\n",
      "Epoch: 8516, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9676.7358\n",
      "Epoch: 8517, Loss: 0.6435, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9677.8863\n",
      "Epoch: 8518, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9679.0265\n",
      "Epoch: 8519, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9680.1591\n",
      "Epoch: 8520, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9681.2924\n",
      "Epoch: 8521, Loss: 0.6431, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9682.4261\n",
      "Epoch: 8522, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9683.5591\n",
      "Epoch: 8523, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9684.6913\n",
      "Epoch: 8524, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9685.8245\n",
      "Epoch: 8525, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9686.9557\n",
      "Epoch: 8526, Loss: 0.6417, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9688.0913\n",
      "Epoch: 8527, Loss: 0.6410, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9689.2334\n",
      "Epoch: 8528, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9690.3713\n",
      "Epoch: 8529, Loss: 0.6459, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9691.5049\n",
      "Epoch: 8530, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9692.6418\n",
      "Epoch: 8531, Loss: 0.6462, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9693.7777\n",
      "Epoch: 8532, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9694.9114\n",
      "Epoch: 8533, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9696.0411\n",
      "Epoch: 8534, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9697.1727\n",
      "Epoch: 8535, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9698.3063\n",
      "Epoch: 8536, Loss: 0.6394, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9699.4372\n",
      "Epoch: 8537, Loss: 0.6395, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9700.5773\n",
      "Epoch: 8538, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9701.7082\n",
      "Epoch: 8539, Loss: 0.6414, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9702.8406\n",
      "Epoch: 8540, Loss: 0.6417, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9703.9782\n",
      "Epoch: 8541, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9705.1162\n",
      "Epoch: 8542, Loss: 0.6410, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9706.2533\n",
      "Epoch: 8543, Loss: 0.6405, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9707.3895\n",
      "Epoch: 8544, Loss: 0.6405, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9708.5298\n",
      "Epoch: 8545, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9709.6631\n",
      "Epoch: 8546, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9710.7976\n",
      "Epoch: 8547, Loss: 0.6407, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9711.9347\n",
      "Epoch: 8548, Loss: 0.6400, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9713.0683\n",
      "Epoch: 8549, Loss: 0.6409, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9714.2013\n",
      "Epoch: 8550, Loss: 0.6407, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9715.3329\n",
      "Epoch: 8551, Loss: 0.6411, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9716.4778\n",
      "Epoch: 8552, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9717.6069\n",
      "Epoch: 8553, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9718.7547\n",
      "Epoch: 8554, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9719.8903\n",
      "Epoch: 8555, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9721.0253\n",
      "Epoch: 8556, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9722.1726\n",
      "Epoch: 8557, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9723.3114\n",
      "Epoch: 8558, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9724.4457\n",
      "Epoch: 8559, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9725.5791\n",
      "Epoch: 8560, Loss: 0.6431, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9726.7095\n",
      "Epoch: 8561, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9727.8432\n",
      "Epoch: 8562, Loss: 0.6435, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9728.9754\n",
      "Epoch: 8563, Loss: 0.6435, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9730.1074\n",
      "Epoch: 8564, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9731.2419\n",
      "Epoch: 8565, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9732.3730\n",
      "Epoch: 8566, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9733.5128\n",
      "Epoch: 8567, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9734.6482\n",
      "Epoch: 8568, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9735.7830\n",
      "Epoch: 8569, Loss: 0.6431, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9736.9200\n",
      "Epoch: 8570, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9738.0603\n",
      "Epoch: 8571, Loss: 0.6406, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9739.2001\n",
      "Epoch: 8572, Loss: 0.6390, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9740.3337\n",
      "Epoch: 8573, Loss: 0.6417, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9741.4664\n",
      "Epoch: 8574, Loss: 0.6399, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9742.5937\n",
      "Epoch: 8575, Loss: 0.6388, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9743.7300\n",
      "Epoch: 8576, Loss: 0.6379, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9744.8665\n",
      "Epoch: 8577, Loss: 0.6366, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9746.0023\n",
      "Epoch: 8578, Loss: 0.6375, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9747.1367\n",
      "Epoch: 8579, Loss: 0.6394, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9748.2684\n",
      "Epoch: 8580, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9749.4050\n",
      "Epoch: 8581, Loss: 0.6375, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9750.5421\n",
      "Epoch: 8582, Loss: 0.6381, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9751.6817\n",
      "Epoch: 8583, Loss: 0.6394, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9752.8168\n",
      "Epoch: 8584, Loss: 0.6392, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9753.9530\n",
      "Epoch: 8585, Loss: 0.6383, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9755.1023\n",
      "Epoch: 8586, Loss: 0.6380, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9756.2351\n",
      "Epoch: 8587, Loss: 0.6379, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9757.3646\n",
      "Epoch: 8588, Loss: 0.6363, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9758.4967\n",
      "Epoch: 8589, Loss: 0.6362, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9759.6273\n",
      "Epoch: 8590, Loss: 0.6360, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9760.7635\n",
      "Epoch: 8591, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9761.8987\n",
      "Epoch: 8592, Loss: 0.6362, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9763.0327\n",
      "Epoch: 8593, Loss: 0.6381, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9764.1635\n",
      "Epoch: 8594, Loss: 0.6388, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9765.2980\n",
      "Epoch: 8595, Loss: 0.6382, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9766.4414\n",
      "Epoch: 8596, Loss: 0.6392, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9767.5802\n",
      "Epoch: 8597, Loss: 0.6398, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9768.7234\n",
      "Epoch: 8598, Loss: 0.6407, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9769.8623\n",
      "Epoch: 8599, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9771.0003\n",
      "Epoch: 8600, Loss: 0.6417, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9772.1383\n",
      "Epoch: 8601, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9773.2732\n",
      "Epoch: 8602, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9774.4079\n",
      "Epoch: 8603, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9775.5462\n",
      "Epoch: 8604, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9776.6869\n",
      "Epoch: 8605, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9777.8184\n",
      "Epoch: 8606, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9778.9541\n",
      "Epoch: 8607, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9780.0929\n",
      "Epoch: 8608, Loss: 0.6424, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 9781.2278\n",
      "Epoch: 8609, Loss: 0.6551, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 9782.3648\n",
      "Epoch: 8610, Loss: 0.6555, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 9783.5007\n",
      "Epoch: 8611, Loss: 0.6563, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9784.6371\n",
      "Epoch: 8612, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9785.7762\n",
      "Epoch: 8613, Loss: 0.6541, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9786.9070\n",
      "Epoch: 8614, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9788.0438\n",
      "Epoch: 8615, Loss: 0.6535, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9789.1761\n",
      "Epoch: 8616, Loss: 0.6513, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9790.3088\n",
      "Epoch: 8617, Loss: 0.6521, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9791.4403\n",
      "Epoch: 8618, Loss: 0.6528, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9792.5731\n",
      "Epoch: 8619, Loss: 0.6525, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9793.7114\n",
      "Epoch: 8620, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9794.8434\n",
      "Epoch: 8621, Loss: 0.6459, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9795.9831\n",
      "Epoch: 8622, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9797.1207\n",
      "Epoch: 8623, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9798.2601\n",
      "Epoch: 8624, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9799.4020\n",
      "Epoch: 8625, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9800.5442\n",
      "Epoch: 8626, Loss: 0.6466, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9801.6746\n",
      "Epoch: 8627, Loss: 0.6456, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9802.8109\n",
      "Epoch: 8628, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9803.9447\n",
      "Epoch: 8629, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9805.0786\n",
      "Epoch: 8630, Loss: 0.6466, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9806.2120\n",
      "Epoch: 8631, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9807.3434\n",
      "Epoch: 8632, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9808.4794\n",
      "Epoch: 8633, Loss: 0.6443, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9809.6260\n",
      "Epoch: 8634, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9810.7623\n",
      "Epoch: 8635, Loss: 0.6411, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9811.8952\n",
      "Epoch: 8636, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9813.0346\n",
      "Epoch: 8637, Loss: 0.6431, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9814.1715\n",
      "Epoch: 8638, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9815.3071\n",
      "Epoch: 8639, Loss: 0.6422, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 9816.4483\n",
      "Epoch: 8640, Loss: 0.6399, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9817.5820\n",
      "Epoch: 8641, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9818.7211\n",
      "Epoch: 8642, Loss: 0.6424, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9819.8631\n",
      "Epoch: 8643, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9821.0029\n",
      "Epoch: 8644, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9822.1341\n",
      "Epoch: 8645, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9823.2704\n",
      "Epoch: 8646, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9824.4053\n",
      "Epoch: 8647, Loss: 0.6408, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9825.5400\n",
      "Epoch: 8648, Loss: 0.6399, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9826.6766\n",
      "Epoch: 8649, Loss: 0.6397, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9827.8185\n",
      "Epoch: 8650, Loss: 0.6407, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9828.9547\n",
      "Epoch: 8651, Loss: 0.6402, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9830.0962\n",
      "Epoch: 8652, Loss: 0.6417, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9831.2407\n",
      "Epoch: 8653, Loss: 0.6406, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9832.3802\n",
      "Epoch: 8654, Loss: 0.6409, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9833.5134\n",
      "Epoch: 8655, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9834.6435\n",
      "Epoch: 8656, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9835.7783\n",
      "Epoch: 8657, Loss: 0.6417, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9836.9184\n",
      "Epoch: 8658, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9838.0523\n",
      "Epoch: 8659, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9839.1844\n",
      "Epoch: 8660, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9840.3160\n",
      "Epoch: 8661, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9841.4491\n",
      "Epoch: 8662, Loss: 0.6435, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9842.5892\n",
      "Epoch: 8663, Loss: 0.6401, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9843.7321\n",
      "Epoch: 8664, Loss: 0.6375, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9844.8655\n",
      "Epoch: 8665, Loss: 0.6376, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9846.0057\n",
      "Epoch: 8666, Loss: 0.6380, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9847.1439\n",
      "Epoch: 8667, Loss: 0.6392, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9848.2768\n",
      "Epoch: 8668, Loss: 0.6394, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9849.4079\n",
      "Epoch: 8669, Loss: 0.6402, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9850.5409\n",
      "Epoch: 8670, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9851.6707\n",
      "Epoch: 8671, Loss: 0.6457, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9852.8146\n",
      "Epoch: 8672, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9853.9503\n",
      "Epoch: 8673, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9855.0887\n",
      "Epoch: 8674, Loss: 0.6399, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9856.2185\n",
      "Epoch: 8675, Loss: 0.6457, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9857.3525\n",
      "Epoch: 8676, Loss: 0.6467, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9858.4911\n",
      "Epoch: 8677, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9859.6253\n",
      "Epoch: 8678, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9860.7589\n",
      "Epoch: 8679, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9861.9002\n",
      "Epoch: 8680, Loss: 0.6443, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9863.0394\n",
      "Epoch: 8681, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9864.1759\n",
      "Epoch: 8682, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9865.3117\n",
      "Epoch: 8683, Loss: 0.6466, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9866.4419\n",
      "Epoch: 8684, Loss: 0.6456, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9867.5719\n",
      "Epoch: 8685, Loss: 0.6443, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9868.7072\n",
      "Epoch: 8686, Loss: 0.6435, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9869.8429\n",
      "Epoch: 8687, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9870.9746\n",
      "Epoch: 8688, Loss: 0.6462, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9872.1092\n",
      "Epoch: 8689, Loss: 0.6490, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9873.2438\n",
      "Epoch: 8690, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9874.3834\n",
      "Epoch: 8691, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9875.5246\n",
      "Epoch: 8692, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9876.6607\n",
      "Epoch: 8693, Loss: 0.6435, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 9877.7969\n",
      "Epoch: 8694, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9878.9254\n",
      "Epoch: 8695, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9880.0592\n",
      "Epoch: 8696, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9881.1907\n",
      "Epoch: 8697, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9882.3219\n",
      "Epoch: 8698, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9883.4522\n",
      "Epoch: 8699, Loss: 0.6400, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9884.5863\n",
      "Epoch: 8700, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9885.7300\n",
      "Epoch: 8701, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9886.8747\n",
      "Epoch: 8702, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9888.0139\n",
      "Epoch: 8703, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9889.1525\n",
      "Epoch: 8704, Loss: 0.6406, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9890.2933\n",
      "Epoch: 8705, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9891.4307\n",
      "Epoch: 8706, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9892.5679\n",
      "Epoch: 8707, Loss: 0.6398, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9893.7051\n",
      "Epoch: 8708, Loss: 0.6393, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9894.8423\n",
      "Epoch: 8709, Loss: 0.6395, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9895.9777\n",
      "Epoch: 8710, Loss: 0.6400, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9897.1089\n",
      "Epoch: 8711, Loss: 0.6396, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9898.2403\n",
      "Epoch: 8712, Loss: 0.6388, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9899.3724\n",
      "Epoch: 8713, Loss: 0.6394, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9900.5140\n",
      "Epoch: 8714, Loss: 0.6379, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9901.6468\n",
      "Epoch: 8715, Loss: 0.6379, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9902.7847\n",
      "Epoch: 8716, Loss: 0.6361, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9903.9268\n",
      "Epoch: 8717, Loss: 0.6348, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9905.0652\n",
      "Epoch: 8718, Loss: 0.6358, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9906.1995\n",
      "Epoch: 8719, Loss: 0.6350, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9907.3420\n",
      "Epoch: 8720, Loss: 0.6331, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9908.4762\n",
      "Epoch: 8721, Loss: 0.6340, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9909.6080\n",
      "Epoch: 8722, Loss: 0.6343, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9910.7375\n",
      "Epoch: 8723, Loss: 0.6335, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9911.8696\n",
      "Epoch: 8724, Loss: 0.6337, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9913.0024\n",
      "Epoch: 8725, Loss: 0.6338, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9914.1359\n",
      "Epoch: 8726, Loss: 0.6339, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9915.2684\n",
      "Epoch: 8727, Loss: 0.6344, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9916.4025\n",
      "Epoch: 8728, Loss: 0.6350, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9917.5400\n",
      "Epoch: 8729, Loss: 0.6360, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9918.6825\n",
      "Epoch: 8730, Loss: 0.6372, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9919.8200\n",
      "Epoch: 8731, Loss: 0.6378, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9920.9610\n",
      "Epoch: 8732, Loss: 0.6374, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9922.0982\n",
      "Epoch: 8733, Loss: 0.6371, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9923.2322\n",
      "Epoch: 8734, Loss: 0.6365, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 9924.3646\n",
      "Epoch: 8735, Loss: 0.6371, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 9925.4966\n",
      "Epoch: 8736, Loss: 0.6381, Train_Acc: 0.5769, TEST_Acc: 0.6100, Time: 9926.6294\n",
      "Epoch: 8737, Loss: 0.6367, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 9927.7612\n",
      "Epoch: 8738, Loss: 0.6397, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9928.9033\n",
      "Epoch: 8739, Loss: 0.6407, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9930.0353\n",
      "Epoch: 8740, Loss: 0.6401, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 9931.1762\n",
      "Epoch: 8741, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9932.3173\n",
      "Epoch: 8742, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9933.4533\n",
      "Epoch: 8743, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9934.5885\n",
      "Epoch: 8744, Loss: 0.6434, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9935.7253\n",
      "Epoch: 8745, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9936.8626\n",
      "Epoch: 8746, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9937.9931\n",
      "Epoch: 8747, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9939.1295\n",
      "Epoch: 8748, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9940.2620\n",
      "Epoch: 8749, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9941.3981\n",
      "Epoch: 8750, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9942.5307\n",
      "Epoch: 8751, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9943.6624\n",
      "Epoch: 8752, Loss: 0.6439, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9944.7958\n",
      "Epoch: 8753, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9945.9294\n",
      "Epoch: 8754, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9947.0631\n",
      "Epoch: 8755, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9948.1996\n",
      "Epoch: 8756, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9949.3404\n",
      "Epoch: 8757, Loss: 0.6457, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9950.4806\n",
      "Epoch: 8758, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9951.6224\n",
      "Epoch: 8759, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9952.7558\n",
      "Epoch: 8760, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9953.8886\n",
      "Epoch: 8761, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9955.0225\n",
      "Epoch: 8762, Loss: 0.6456, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9956.1633\n",
      "Epoch: 8763, Loss: 0.6448, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9957.2961\n",
      "Epoch: 8764, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9958.4293\n",
      "Epoch: 8765, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9959.5602\n",
      "Epoch: 8766, Loss: 0.6439, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9960.7053\n",
      "Epoch: 8767, Loss: 0.6435, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9961.8433\n",
      "Epoch: 8768, Loss: 0.6431, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9962.9784\n",
      "Epoch: 8769, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9964.1184\n",
      "Epoch: 8770, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9965.2556\n",
      "Epoch: 8771, Loss: 0.6439, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9966.3939\n",
      "Epoch: 8772, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9967.5321\n",
      "Epoch: 8773, Loss: 0.6390, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9968.6658\n",
      "Epoch: 8774, Loss: 0.6387, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9969.8044\n",
      "Epoch: 8775, Loss: 0.6381, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9970.9404\n",
      "Epoch: 8776, Loss: 0.6378, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9972.0711\n",
      "Epoch: 8777, Loss: 0.6368, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9973.2068\n",
      "Epoch: 8778, Loss: 0.6352, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9974.3413\n",
      "Epoch: 8779, Loss: 0.6355, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9975.4739\n",
      "Epoch: 8780, Loss: 0.6355, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9976.6029\n",
      "Epoch: 8781, Loss: 0.6345, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9977.7396\n",
      "Epoch: 8782, Loss: 0.6345, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9978.8778\n",
      "Epoch: 8783, Loss: 0.6321, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9980.0168\n",
      "Epoch: 8784, Loss: 0.6341, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9981.1569\n",
      "Epoch: 8785, Loss: 0.6347, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9982.2981\n",
      "Epoch: 8786, Loss: 0.6348, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9983.4393\n",
      "Epoch: 8787, Loss: 0.6347, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9984.5734\n",
      "Epoch: 8788, Loss: 0.6326, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9985.7041\n",
      "Epoch: 8789, Loss: 0.6327, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9986.8380\n",
      "Epoch: 8790, Loss: 0.6333, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 9987.9726\n",
      "Epoch: 8791, Loss: 0.6323, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 9989.1042\n",
      "Epoch: 8792, Loss: 0.6329, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9990.2398\n",
      "Epoch: 8793, Loss: 0.6332, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9991.3765\n",
      "Epoch: 8794, Loss: 0.6341, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9992.5137\n",
      "Epoch: 8795, Loss: 0.6351, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9993.6561\n",
      "Epoch: 8796, Loss: 0.6360, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9994.7999\n",
      "Epoch: 8797, Loss: 0.6368, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9995.9371\n",
      "Epoch: 8798, Loss: 0.6365, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9997.0755\n",
      "Epoch: 8799, Loss: 0.6376, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 9998.2099\n",
      "Epoch: 8800, Loss: 0.6397, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 9999.3438\n",
      "Epoch: 8801, Loss: 0.6402, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10000.4778\n",
      "Epoch: 8802, Loss: 0.6400, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10001.6116\n",
      "Epoch: 8803, Loss: 0.6399, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10002.7444\n",
      "Epoch: 8804, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10003.8751\n",
      "Epoch: 8805, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10005.0239\n",
      "Epoch: 8806, Loss: 0.6407, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10006.1569\n",
      "Epoch: 8807, Loss: 0.6407, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10007.2924\n",
      "Epoch: 8808, Loss: 0.6389, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10008.4314\n",
      "Epoch: 8809, Loss: 0.6396, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10009.5689\n",
      "Epoch: 8810, Loss: 0.6389, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10010.7058\n",
      "Epoch: 8811, Loss: 0.6389, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10011.8402\n",
      "Epoch: 8812, Loss: 0.6378, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10012.9725\n",
      "Epoch: 8813, Loss: 0.6382, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10014.1087\n",
      "Epoch: 8814, Loss: 0.6380, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10015.2488\n",
      "Epoch: 8815, Loss: 0.6397, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10016.3783\n",
      "Epoch: 8816, Loss: 0.6395, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10017.5134\n",
      "Epoch: 8817, Loss: 0.6403, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10018.6484\n",
      "Epoch: 8818, Loss: 0.6408, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10019.7794\n",
      "Epoch: 8819, Loss: 0.6402, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10020.9160\n",
      "Epoch: 8820, Loss: 0.6400, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10022.0581\n",
      "Epoch: 8821, Loss: 0.6413, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10023.1918\n",
      "Epoch: 8822, Loss: 0.6413, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10024.3242\n",
      "Epoch: 8823, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10025.4657\n",
      "Epoch: 8824, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10026.6116\n",
      "Epoch: 8825, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10027.7531\n",
      "Epoch: 8826, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10028.8876\n",
      "Epoch: 8827, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10030.0198\n",
      "Epoch: 8828, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10031.1507\n",
      "Epoch: 8829, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10032.2853\n",
      "Epoch: 8830, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10033.4140\n",
      "Epoch: 8831, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10034.5466\n",
      "Epoch: 8832, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10035.6823\n",
      "Epoch: 8833, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10036.8129\n",
      "Epoch: 8834, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10037.9569\n",
      "Epoch: 8835, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10039.0943\n",
      "Epoch: 8836, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10040.2333\n",
      "Epoch: 8837, Loss: 0.6470, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10041.3753\n",
      "Epoch: 8838, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10042.5084\n",
      "Epoch: 8839, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10043.6379\n",
      "Epoch: 8840, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10044.7733\n",
      "Epoch: 8841, Loss: 0.6471, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10045.9098\n",
      "Epoch: 8842, Loss: 0.6485, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10047.0470\n",
      "Epoch: 8843, Loss: 0.6467, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10048.1881\n",
      "Epoch: 8844, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10049.3203\n",
      "Epoch: 8845, Loss: 0.6484, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10050.4571\n",
      "Epoch: 8846, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10051.5961\n",
      "Epoch: 8847, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10052.7313\n",
      "Epoch: 8848, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10053.8706\n",
      "Epoch: 8849, Loss: 0.6487, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10055.0093\n",
      "Epoch: 8850, Loss: 0.6488, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10056.1493\n",
      "Epoch: 8851, Loss: 0.6485, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10057.2798\n",
      "Epoch: 8852, Loss: 0.6468, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10058.4095\n",
      "Epoch: 8853, Loss: 0.6467, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10059.5431\n",
      "Epoch: 8854, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10060.6763\n",
      "Epoch: 8855, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10061.8090\n",
      "Epoch: 8856, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10062.9440\n",
      "Epoch: 8857, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10064.0788\n",
      "Epoch: 8858, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10065.2098\n",
      "Epoch: 8859, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10066.3457\n",
      "Epoch: 8860, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10067.4795\n",
      "Epoch: 8861, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10068.6163\n",
      "Epoch: 8862, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10069.7558\n",
      "Epoch: 8863, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10070.8937\n",
      "Epoch: 8864, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 10072.0330\n",
      "Epoch: 8865, Loss: 0.6468, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10073.1643\n",
      "Epoch: 8866, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10074.3012\n",
      "Epoch: 8867, Loss: 0.6470, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10075.4320\n",
      "Epoch: 8868, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10076.5663\n",
      "Epoch: 8869, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10077.7105\n",
      "Epoch: 8870, Loss: 0.6451, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10078.8501\n",
      "Epoch: 8871, Loss: 0.6471, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10079.9886\n",
      "Epoch: 8872, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10081.1308\n",
      "Epoch: 8873, Loss: 0.6435, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10082.2727\n",
      "Epoch: 8874, Loss: 0.6431, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10083.4092\n",
      "Epoch: 8875, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10084.5499\n",
      "Epoch: 8876, Loss: 0.6396, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10085.6854\n",
      "Epoch: 8877, Loss: 0.6393, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10086.8238\n",
      "Epoch: 8878, Loss: 0.6395, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10087.9587\n",
      "Epoch: 8879, Loss: 0.6393, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10089.0951\n",
      "Epoch: 8880, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10090.2387\n",
      "Epoch: 8881, Loss: 0.6408, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10091.3797\n",
      "Epoch: 8882, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10092.5144\n",
      "Epoch: 8883, Loss: 0.6421, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10093.6490\n",
      "Epoch: 8884, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10094.7815\n",
      "Epoch: 8885, Loss: 0.6424, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10095.9143\n",
      "Epoch: 8886, Loss: 0.6417, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10097.0441\n",
      "Epoch: 8887, Loss: 0.6410, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10098.1812\n",
      "Epoch: 8888, Loss: 0.6396, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10099.3191\n",
      "Epoch: 8889, Loss: 0.6405, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10100.4561\n",
      "Epoch: 8890, Loss: 0.6392, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10101.5953\n",
      "Epoch: 8891, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10102.7389\n",
      "Epoch: 8892, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10103.8701\n",
      "Epoch: 8893, Loss: 0.6401, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10105.0028\n",
      "Epoch: 8894, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10106.1361\n",
      "Epoch: 8895, Loss: 0.6366, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10107.2684\n",
      "Epoch: 8896, Loss: 0.6364, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10108.4000\n",
      "Epoch: 8897, Loss: 0.6365, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10109.5301\n",
      "Epoch: 8898, Loss: 0.6373, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10110.6643\n",
      "Epoch: 8899, Loss: 0.6403, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10111.8063\n",
      "Epoch: 8900, Loss: 0.6417, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10112.9427\n",
      "Epoch: 8901, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10114.0830\n",
      "Epoch: 8902, Loss: 0.6414, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10115.2205\n",
      "Epoch: 8903, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10116.3589\n",
      "Epoch: 8904, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10117.4999\n",
      "Epoch: 8905, Loss: 0.6417, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10118.6343\n",
      "Epoch: 8906, Loss: 0.6421, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10119.7670\n",
      "Epoch: 8907, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10120.9020\n",
      "Epoch: 8908, Loss: 0.6417, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10122.0377\n",
      "Epoch: 8909, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10123.1733\n",
      "Epoch: 8910, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10124.3128\n",
      "Epoch: 8911, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10125.4449\n",
      "Epoch: 8912, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10126.5794\n",
      "Epoch: 8913, Loss: 0.6407, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10127.7157\n",
      "Epoch: 8914, Loss: 0.6422, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 10128.8556\n",
      "Epoch: 8915, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 10129.9896\n",
      "Epoch: 8916, Loss: 0.6422, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 10131.1296\n",
      "Epoch: 8917, Loss: 0.6422, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 10132.2633\n",
      "Epoch: 8918, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 10133.4036\n",
      "Epoch: 8919, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 10134.5389\n",
      "Epoch: 8920, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 10135.6721\n",
      "Epoch: 8921, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 10136.8019\n",
      "Epoch: 8922, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 10137.9365\n",
      "Epoch: 8923, Loss: 0.6448, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10139.0715\n",
      "Epoch: 8924, Loss: 0.6448, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10140.2056\n",
      "Epoch: 8925, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10141.3400\n",
      "Epoch: 8926, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10142.4852\n",
      "Epoch: 8927, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 10143.6210\n",
      "Epoch: 8928, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10144.7609\n",
      "Epoch: 8929, Loss: 0.6439, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10145.9038\n",
      "Epoch: 8930, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10147.0368\n",
      "Epoch: 8931, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10148.1728\n",
      "Epoch: 8932, Loss: 0.6439, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10149.3101\n",
      "Epoch: 8933, Loss: 0.6400, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 10150.4404\n",
      "Epoch: 8934, Loss: 0.6414, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 10151.5719\n",
      "Epoch: 8935, Loss: 0.6405, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10152.7077\n",
      "Epoch: 8936, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10153.8406\n",
      "Epoch: 8937, Loss: 0.6424, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10154.9752\n",
      "Epoch: 8938, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10156.1081\n",
      "Epoch: 8939, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10157.2431\n",
      "Epoch: 8940, Loss: 0.6400, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10158.3758\n",
      "Epoch: 8941, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6133, Time: 10159.5118\n",
      "Epoch: 8942, Loss: 0.6456, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 10160.6491\n",
      "Epoch: 8943, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10161.7839\n",
      "Epoch: 8944, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10162.9232\n",
      "Epoch: 8945, Loss: 0.6443, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10164.0627\n",
      "Epoch: 8946, Loss: 0.6422, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10165.1996\n",
      "Epoch: 8947, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10166.3340\n",
      "Epoch: 8948, Loss: 0.6469, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10167.4641\n",
      "Epoch: 8949, Loss: 0.6439, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10168.6019\n",
      "Epoch: 8950, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10169.7381\n",
      "Epoch: 8951, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10170.8659\n",
      "Epoch: 8952, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10172.0048\n",
      "Epoch: 8953, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10173.1389\n",
      "Epoch: 8954, Loss: 0.6431, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10174.2769\n",
      "Epoch: 8955, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10175.4122\n",
      "Epoch: 8956, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10176.5489\n",
      "Epoch: 8957, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10177.6851\n",
      "Epoch: 8958, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10178.8290\n",
      "Epoch: 8959, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10179.9667\n",
      "Epoch: 8960, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10181.1009\n",
      "Epoch: 8961, Loss: 0.6439, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10182.2315\n",
      "Epoch: 8962, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10183.3651\n",
      "Epoch: 8963, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10184.4992\n",
      "Epoch: 8964, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10185.6302\n",
      "Epoch: 8965, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10186.7627\n",
      "Epoch: 8966, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10187.8938\n",
      "Epoch: 8967, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10189.0327\n",
      "Epoch: 8968, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10190.1772\n",
      "Epoch: 8969, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10191.3170\n",
      "Epoch: 8970, Loss: 0.6459, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10192.4504\n",
      "Epoch: 8971, Loss: 0.6466, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10193.5882\n",
      "Epoch: 8972, Loss: 0.6511, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10194.7281\n",
      "Epoch: 8973, Loss: 0.6510, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10195.8595\n",
      "Epoch: 8974, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10196.9920\n",
      "Epoch: 8975, Loss: 0.6492, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10198.1243\n",
      "Epoch: 8976, Loss: 0.6500, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10199.2565\n",
      "Epoch: 8977, Loss: 0.6494, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10200.3902\n",
      "Epoch: 8978, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10201.5233\n",
      "Epoch: 8979, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10202.6593\n",
      "Epoch: 8980, Loss: 0.6448, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10203.7917\n",
      "Epoch: 8981, Loss: 0.6421, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10204.9231\n",
      "Epoch: 8982, Loss: 0.6413, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10206.0586\n",
      "Epoch: 8983, Loss: 0.6417, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10207.1952\n",
      "Epoch: 8984, Loss: 0.6435, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10208.3286\n",
      "Epoch: 8985, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10209.4638\n",
      "Epoch: 8986, Loss: 0.6411, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10210.6037\n",
      "Epoch: 8987, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10211.7388\n",
      "Epoch: 8988, Loss: 0.6392, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10212.8751\n",
      "Epoch: 8989, Loss: 0.6371, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10214.0075\n",
      "Epoch: 8990, Loss: 0.6369, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10215.1410\n",
      "Epoch: 8991, Loss: 0.6386, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10216.2744\n",
      "Epoch: 8992, Loss: 0.6396, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10217.4053\n",
      "Epoch: 8993, Loss: 0.6393, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10218.5375\n",
      "Epoch: 8994, Loss: 0.6394, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10219.6681\n",
      "Epoch: 8995, Loss: 0.6405, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10220.8031\n",
      "Epoch: 8996, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10221.9413\n",
      "Epoch: 8997, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10223.0842\n",
      "Epoch: 8998, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10224.2238\n",
      "Epoch: 8999, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10225.3636\n",
      "Epoch: 9000, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10226.4977\n",
      "Epoch: 9001, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10227.6310\n",
      "Epoch: 9002, Loss: 0.6434, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10228.7632\n",
      "Epoch: 9003, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10229.8995\n",
      "Epoch: 9004, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10231.0327\n",
      "Epoch: 9005, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10232.1657\n",
      "Epoch: 9006, Loss: 0.6513, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10233.3017\n",
      "Epoch: 9007, Loss: 0.6505, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10234.4380\n",
      "Epoch: 9008, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10235.5732\n",
      "Epoch: 9009, Loss: 0.6402, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10236.7106\n",
      "Epoch: 9010, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10237.8498\n",
      "Epoch: 9011, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10238.9897\n",
      "Epoch: 9012, Loss: 0.6409, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10240.1234\n",
      "Epoch: 9013, Loss: 0.6409, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10241.2609\n",
      "Epoch: 9014, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10242.3942\n",
      "Epoch: 9015, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10243.5324\n",
      "Epoch: 9016, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10244.6726\n",
      "Epoch: 9017, Loss: 0.6422, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10245.8079\n",
      "Epoch: 9018, Loss: 0.6413, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10246.9408\n",
      "Epoch: 9019, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10248.0730\n",
      "Epoch: 9020, Loss: 0.6413, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10249.2122\n",
      "Epoch: 9021, Loss: 0.6407, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10250.3457\n",
      "Epoch: 9022, Loss: 0.6401, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10251.4814\n",
      "Epoch: 9023, Loss: 0.6406, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10252.6175\n",
      "Epoch: 9024, Loss: 0.6397, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10253.7539\n",
      "Epoch: 9025, Loss: 0.6389, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10254.8967\n",
      "Epoch: 9026, Loss: 0.6396, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10256.0405\n",
      "Epoch: 9027, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10257.1739\n",
      "Epoch: 9028, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10258.3071\n",
      "Epoch: 9029, Loss: 0.6434, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10259.4430\n",
      "Epoch: 9030, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10260.5818\n",
      "Epoch: 9031, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10261.7186\n",
      "Epoch: 9032, Loss: 0.6536, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10262.8521\n",
      "Epoch: 9033, Loss: 0.6523, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10263.9901\n",
      "Epoch: 9034, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10265.1198\n",
      "Epoch: 9035, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10266.2631\n",
      "Epoch: 9036, Loss: 0.6409, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10267.3979\n",
      "Epoch: 9037, Loss: 0.6408, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10268.5352\n",
      "Epoch: 9038, Loss: 0.6408, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10269.6723\n",
      "Epoch: 9039, Loss: 0.6487, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10270.8116\n",
      "Epoch: 9040, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10271.9488\n",
      "Epoch: 9041, Loss: 0.6470, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10273.0801\n",
      "Epoch: 9042, Loss: 0.6469, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10274.2137\n",
      "Epoch: 9043, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10275.3473\n",
      "Epoch: 9044, Loss: 0.6462, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10276.4830\n",
      "Epoch: 9045, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10277.6216\n",
      "Epoch: 9046, Loss: 0.6456, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10278.7552\n",
      "Epoch: 9047, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10279.8863\n",
      "Epoch: 9048, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10281.0247\n",
      "Epoch: 9049, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10282.1580\n",
      "Epoch: 9050, Loss: 0.6422, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10283.2961\n",
      "Epoch: 9051, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10284.4301\n",
      "Epoch: 9052, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10285.5680\n",
      "Epoch: 9053, Loss: 0.6424, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10286.7024\n",
      "Epoch: 9054, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10287.8353\n",
      "Epoch: 9055, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10288.9758\n",
      "Epoch: 9056, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10290.1075\n",
      "Epoch: 9057, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10291.2453\n",
      "Epoch: 9058, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10292.3771\n",
      "Epoch: 9059, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10293.5133\n",
      "Epoch: 9060, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10294.6434\n",
      "Epoch: 9061, Loss: 0.6414, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10295.7761\n",
      "Epoch: 9062, Loss: 0.6413, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10296.9111\n",
      "Epoch: 9063, Loss: 0.6405, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10298.0420\n",
      "Epoch: 9064, Loss: 0.6402, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10299.1832\n",
      "Epoch: 9065, Loss: 0.6398, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10300.3158\n",
      "Epoch: 9066, Loss: 0.6403, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10301.4511\n",
      "Epoch: 9067, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10302.5853\n",
      "Epoch: 9068, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10303.7184\n",
      "Epoch: 9069, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10304.8496\n",
      "Epoch: 9070, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10305.9835\n",
      "Epoch: 9071, Loss: 0.6410, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10307.1158\n",
      "Epoch: 9072, Loss: 0.6414, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10308.2486\n",
      "Epoch: 9073, Loss: 0.6421, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10309.3854\n",
      "Epoch: 9074, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10310.5198\n",
      "Epoch: 9075, Loss: 0.6421, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10311.6538\n",
      "Epoch: 9076, Loss: 0.6410, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10312.7870\n",
      "Epoch: 9077, Loss: 0.6411, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10313.9233\n",
      "Epoch: 9078, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10315.0626\n",
      "Epoch: 9079, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10316.1983\n",
      "Epoch: 9080, Loss: 0.6434, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10317.3412\n",
      "Epoch: 9081, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10318.4731\n",
      "Epoch: 9082, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10319.6091\n",
      "Epoch: 9083, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10320.7462\n",
      "Epoch: 9084, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10321.8832\n",
      "Epoch: 9085, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10323.0138\n",
      "Epoch: 9086, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10324.1517\n",
      "Epoch: 9087, Loss: 0.6471, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10325.2854\n",
      "Epoch: 9088, Loss: 0.6463, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10326.4190\n",
      "Epoch: 9089, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10327.5530\n",
      "Epoch: 9090, Loss: 0.6459, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10328.6877\n",
      "Epoch: 9091, Loss: 0.6379, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10329.8292\n",
      "Epoch: 9092, Loss: 0.6358, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10330.9696\n",
      "Epoch: 9093, Loss: 0.6368, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10332.1144\n",
      "Epoch: 9094, Loss: 0.6382, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10333.2488\n",
      "Epoch: 9095, Loss: 0.6381, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10334.3813\n",
      "Epoch: 9096, Loss: 0.6361, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10335.5161\n",
      "Epoch: 9097, Loss: 0.6367, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10336.6489\n",
      "Epoch: 9098, Loss: 0.6392, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10337.7832\n",
      "Epoch: 9099, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10338.9156\n",
      "Epoch: 9100, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10340.0517\n",
      "Epoch: 9101, Loss: 0.6424, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10341.1849\n",
      "Epoch: 9102, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10342.3144\n",
      "Epoch: 9103, Loss: 0.6411, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10343.4538\n",
      "Epoch: 9104, Loss: 0.6407, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10344.5923\n",
      "Epoch: 9105, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10345.7263\n",
      "Epoch: 9106, Loss: 0.6522, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10346.8638\n",
      "Epoch: 9107, Loss: 0.6503, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10347.9985\n",
      "Epoch: 9108, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10349.1327\n",
      "Epoch: 9109, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10350.2687\n",
      "Epoch: 9110, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10351.4006\n",
      "Epoch: 9111, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10352.5339\n",
      "Epoch: 9112, Loss: 0.6470, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10353.6782\n",
      "Epoch: 9113, Loss: 0.6471, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10354.8161\n",
      "Epoch: 9114, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10355.9481\n",
      "Epoch: 9115, Loss: 0.6467, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10357.0800\n",
      "Epoch: 9116, Loss: 0.6482, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10358.2109\n",
      "Epoch: 9117, Loss: 0.6406, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10359.3460\n",
      "Epoch: 9118, Loss: 0.6397, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10360.4836\n",
      "Epoch: 9119, Loss: 0.6397, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10361.6238\n",
      "Epoch: 9120, Loss: 0.6405, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10362.7576\n",
      "Epoch: 9121, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10363.9021\n",
      "Epoch: 9122, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10365.0381\n",
      "Epoch: 9123, Loss: 0.6388, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10366.1735\n",
      "Epoch: 9124, Loss: 0.6387, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10367.3072\n",
      "Epoch: 9125, Loss: 0.6390, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10368.4391\n",
      "Epoch: 9126, Loss: 0.6393, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10369.5803\n",
      "Epoch: 9127, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10370.7128\n",
      "Epoch: 9128, Loss: 0.6382, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10371.8482\n",
      "Epoch: 9129, Loss: 0.6392, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10372.9804\n",
      "Epoch: 9130, Loss: 0.6399, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10374.1193\n",
      "Epoch: 9131, Loss: 0.6398, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10375.2562\n",
      "Epoch: 9132, Loss: 0.6366, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10376.3985\n",
      "Epoch: 9133, Loss: 0.6372, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10377.5357\n",
      "Epoch: 9134, Loss: 0.6383, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10378.6747\n",
      "Epoch: 9135, Loss: 0.6379, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10379.8103\n",
      "Epoch: 9136, Loss: 0.6381, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10380.9412\n",
      "Epoch: 9137, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10382.0715\n",
      "Epoch: 9138, Loss: 0.6382, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10383.2014\n",
      "Epoch: 9139, Loss: 0.6364, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10384.3366\n",
      "Epoch: 9140, Loss: 0.6361, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10385.4693\n",
      "Epoch: 9141, Loss: 0.6364, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10386.6043\n",
      "Epoch: 9142, Loss: 0.6363, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10387.7410\n",
      "Epoch: 9143, Loss: 0.6382, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10388.8721\n",
      "Epoch: 9144, Loss: 0.6392, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10390.0061\n",
      "Epoch: 9145, Loss: 0.6411, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10391.1418\n",
      "Epoch: 9146, Loss: 0.6409, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10392.2758\n",
      "Epoch: 9147, Loss: 0.6406, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10393.4149\n",
      "Epoch: 9148, Loss: 0.6402, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10394.5488\n",
      "Epoch: 9149, Loss: 0.6378, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10395.6810\n",
      "Epoch: 9150, Loss: 0.6364, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10396.8137\n",
      "Epoch: 9151, Loss: 0.6381, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10397.9476\n",
      "Epoch: 9152, Loss: 0.6370, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10399.0811\n",
      "Epoch: 9153, Loss: 0.6377, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10400.2158\n",
      "Epoch: 9154, Loss: 0.6393, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10401.3469\n",
      "Epoch: 9155, Loss: 0.6401, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10402.4781\n",
      "Epoch: 9156, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10403.6107\n",
      "Epoch: 9157, Loss: 0.6400, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10404.7484\n",
      "Epoch: 9158, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10405.8851\n",
      "Epoch: 9159, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10407.0231\n",
      "Epoch: 9160, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10408.1609\n",
      "Epoch: 9161, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10409.3065\n",
      "Epoch: 9162, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10410.4387\n",
      "Epoch: 9163, Loss: 0.6403, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10411.5744\n",
      "Epoch: 9164, Loss: 0.6402, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10412.7054\n",
      "Epoch: 9165, Loss: 0.6413, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10413.8466\n",
      "Epoch: 9166, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10414.9844\n",
      "Epoch: 9167, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10416.1273\n",
      "Epoch: 9168, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10417.2588\n",
      "Epoch: 9169, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10418.3947\n",
      "Epoch: 9170, Loss: 0.6516, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10419.5382\n",
      "Epoch: 9171, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10420.6762\n",
      "Epoch: 9172, Loss: 0.6487, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10421.8157\n",
      "Epoch: 9173, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10422.9524\n",
      "Epoch: 9174, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10424.0923\n",
      "Epoch: 9175, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10425.2305\n",
      "Epoch: 9176, Loss: 0.6504, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10426.3626\n",
      "Epoch: 9177, Loss: 0.6502, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10427.4941\n",
      "Epoch: 9178, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10428.6261\n",
      "Epoch: 9179, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10429.7603\n",
      "Epoch: 9180, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10430.9016\n",
      "Epoch: 9181, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10432.0344\n",
      "Epoch: 9182, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10433.1678\n",
      "Epoch: 9183, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10434.3024\n",
      "Epoch: 9184, Loss: 0.6510, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10435.4368\n",
      "Epoch: 9185, Loss: 0.6500, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10436.5769\n",
      "Epoch: 9186, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10437.7137\n",
      "Epoch: 9187, Loss: 0.6506, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10438.8647\n",
      "Epoch: 9188, Loss: 0.6517, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10440.0044\n",
      "Epoch: 9189, Loss: 0.6511, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10441.1423\n",
      "Epoch: 9190, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10442.2779\n",
      "Epoch: 9191, Loss: 0.6530, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10443.4076\n",
      "Epoch: 9192, Loss: 0.6518, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10444.5456\n",
      "Epoch: 9193, Loss: 0.6500, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10445.6775\n",
      "Epoch: 9194, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10446.8116\n",
      "Epoch: 9195, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10447.9463\n",
      "Epoch: 9196, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10449.0784\n",
      "Epoch: 9197, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10450.2085\n",
      "Epoch: 9198, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10451.3524\n",
      "Epoch: 9199, Loss: 0.6468, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10452.4907\n",
      "Epoch: 9200, Loss: 0.6471, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10453.6272\n",
      "Epoch: 9201, Loss: 0.6477, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10454.7691\n",
      "Epoch: 9202, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10455.9064\n",
      "Epoch: 9203, Loss: 0.6491, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10457.0383\n",
      "Epoch: 9204, Loss: 0.6503, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10458.1711\n",
      "Epoch: 9205, Loss: 0.6490, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10459.3036\n",
      "Epoch: 9206, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10460.4327\n",
      "Epoch: 9207, Loss: 0.6474, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10461.5711\n",
      "Epoch: 9208, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10462.7128\n",
      "Epoch: 9209, Loss: 0.6487, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10463.8472\n",
      "Epoch: 9210, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10464.9883\n",
      "Epoch: 9211, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10466.1219\n",
      "Epoch: 9212, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10467.2601\n",
      "Epoch: 9213, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10468.4032\n",
      "Epoch: 9214, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10469.5435\n",
      "Epoch: 9215, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10470.6756\n",
      "Epoch: 9216, Loss: 0.6422, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10471.8126\n",
      "Epoch: 9217, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10472.9484\n",
      "Epoch: 9218, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10474.0870\n",
      "Epoch: 9219, Loss: 0.6323, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10475.2282\n",
      "Epoch: 9220, Loss: 0.6333, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10476.3585\n",
      "Epoch: 9221, Loss: 0.6342, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10477.4873\n",
      "Epoch: 9222, Loss: 0.6331, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10478.6202\n",
      "Epoch: 9223, Loss: 0.6332, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10479.7532\n",
      "Epoch: 9224, Loss: 0.6329, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10480.8885\n",
      "Epoch: 9225, Loss: 0.6337, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10482.0182\n",
      "Epoch: 9226, Loss: 0.6338, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10483.1377\n",
      "Epoch: 9227, Loss: 0.6336, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10484.2613\n",
      "Epoch: 9228, Loss: 0.6347, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10485.3948\n",
      "Epoch: 9229, Loss: 0.6350, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10486.5270\n",
      "Epoch: 9230, Loss: 0.6354, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10487.6624\n",
      "Epoch: 9231, Loss: 0.6363, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10488.7951\n",
      "Epoch: 9232, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10489.9327\n",
      "Epoch: 9233, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10491.0695\n",
      "Epoch: 9234, Loss: 0.6356, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10492.2030\n",
      "Epoch: 9235, Loss: 0.6362, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10493.3351\n",
      "Epoch: 9236, Loss: 0.6350, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10494.4697\n",
      "Epoch: 9237, Loss: 0.6363, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10495.6154\n",
      "Epoch: 9238, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10496.7515\n",
      "Epoch: 9239, Loss: 0.6340, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10497.8906\n",
      "Epoch: 9240, Loss: 0.6358, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10499.0265\n",
      "Epoch: 9241, Loss: 0.6465, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10500.1669\n",
      "Epoch: 9242, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10501.3035\n",
      "Epoch: 9243, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10502.4306\n",
      "Epoch: 9244, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10503.5661\n",
      "Epoch: 9245, Loss: 0.6356, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10504.7094\n",
      "Epoch: 9246, Loss: 0.6451, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10505.8458\n",
      "Epoch: 9247, Loss: 0.6339, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10506.9815\n",
      "Epoch: 9248, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10508.1172\n",
      "Epoch: 9249, Loss: 0.6410, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10509.2485\n",
      "Epoch: 9250, Loss: 0.6318, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10510.3824\n",
      "Epoch: 9251, Loss: 0.6315, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10511.5181\n",
      "Epoch: 9252, Loss: 0.6332, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10512.6565\n",
      "Epoch: 9253, Loss: 0.6342, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10513.7904\n",
      "Epoch: 9254, Loss: 0.6342, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10514.9287\n",
      "Epoch: 9255, Loss: 0.6346, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10516.0726\n",
      "Epoch: 9256, Loss: 0.6342, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10517.2078\n",
      "Epoch: 9257, Loss: 0.6334, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10518.3470\n",
      "Epoch: 9258, Loss: 0.6336, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10519.4791\n",
      "Epoch: 9259, Loss: 0.6360, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10520.6172\n",
      "Epoch: 9260, Loss: 0.6343, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10521.7531\n",
      "Epoch: 9261, Loss: 0.6348, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10522.8873\n",
      "Epoch: 9262, Loss: 0.6339, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10524.0208\n",
      "Epoch: 9263, Loss: 0.6343, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10525.1513\n",
      "Epoch: 9264, Loss: 0.6339, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10526.2861\n",
      "Epoch: 9265, Loss: 0.6331, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10527.4254\n",
      "Epoch: 9266, Loss: 0.6329, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10528.5619\n",
      "Epoch: 9267, Loss: 0.6323, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10529.7017\n",
      "Epoch: 9268, Loss: 0.6330, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10530.8381\n",
      "Epoch: 9269, Loss: 0.6338, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10531.9758\n",
      "Epoch: 9270, Loss: 0.6341, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10533.1128\n",
      "Epoch: 9271, Loss: 0.6328, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10534.2461\n",
      "Epoch: 9272, Loss: 0.6333, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10535.3844\n",
      "Epoch: 9273, Loss: 0.6325, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10536.5148\n",
      "Epoch: 9274, Loss: 0.6341, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10537.6491\n",
      "Epoch: 9275, Loss: 0.6349, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10538.7893\n",
      "Epoch: 9276, Loss: 0.6347, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10539.9263\n",
      "Epoch: 9277, Loss: 0.6434, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10541.0614\n",
      "Epoch: 9278, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10542.1954\n",
      "Epoch: 9279, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10543.3302\n",
      "Epoch: 9280, Loss: 0.6443, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10544.4659\n",
      "Epoch: 9281, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10545.6020\n",
      "Epoch: 9282, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10546.7414\n",
      "Epoch: 9283, Loss: 0.6370, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10547.8802\n",
      "Epoch: 9284, Loss: 0.6382, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10549.0212\n",
      "Epoch: 9285, Loss: 0.6376, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10550.1563\n",
      "Epoch: 9286, Loss: 0.6378, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10551.2907\n",
      "Epoch: 9287, Loss: 0.6375, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10552.4206\n",
      "Epoch: 9288, Loss: 0.6367, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10553.5585\n",
      "Epoch: 9289, Loss: 0.6378, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10554.6871\n",
      "Epoch: 9290, Loss: 0.6379, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10555.8193\n",
      "Epoch: 9291, Loss: 0.6387, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10556.9540\n",
      "Epoch: 9292, Loss: 0.6388, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10558.0952\n",
      "Epoch: 9293, Loss: 0.6376, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10559.2363\n",
      "Epoch: 9294, Loss: 0.6388, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 10560.3887\n",
      "Epoch: 9295, Loss: 0.6399, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10561.5243\n",
      "Epoch: 9296, Loss: 0.6370, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10562.6628\n",
      "Epoch: 9297, Loss: 0.6364, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10563.8004\n",
      "Epoch: 9298, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10564.9425\n",
      "Epoch: 9299, Loss: 0.6351, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10566.0766\n",
      "Epoch: 9300, Loss: 0.6360, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10567.2097\n",
      "Epoch: 9301, Loss: 0.6342, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10568.3444\n",
      "Epoch: 9302, Loss: 0.6335, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10569.4760\n",
      "Epoch: 9303, Loss: 0.6347, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10570.6212\n",
      "Epoch: 9304, Loss: 0.6354, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10571.7557\n",
      "Epoch: 9305, Loss: 0.6368, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10572.8900\n",
      "Epoch: 9306, Loss: 0.6372, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10574.0246\n",
      "Epoch: 9307, Loss: 0.6374, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10575.1624\n",
      "Epoch: 9308, Loss: 0.6374, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10576.2998\n",
      "Epoch: 9309, Loss: 0.6379, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10577.4378\n",
      "Epoch: 9310, Loss: 0.6381, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10578.5733\n",
      "Epoch: 9311, Loss: 0.6381, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10579.7137\n",
      "Epoch: 9312, Loss: 0.6379, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10580.8469\n",
      "Epoch: 9313, Loss: 0.6389, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10581.9846\n",
      "Epoch: 9314, Loss: 0.6392, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10583.1217\n",
      "Epoch: 9315, Loss: 0.6396, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10584.2533\n",
      "Epoch: 9316, Loss: 0.6379, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10585.3838\n",
      "Epoch: 9317, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10586.5170\n",
      "Epoch: 9318, Loss: 0.6390, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10587.6541\n",
      "Epoch: 9319, Loss: 0.6389, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10588.7876\n",
      "Epoch: 9320, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10589.9244\n",
      "Epoch: 9321, Loss: 0.6439, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10591.0662\n",
      "Epoch: 9322, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10592.2101\n",
      "Epoch: 9323, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10593.3517\n",
      "Epoch: 9324, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10594.4987\n",
      "Epoch: 9325, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10595.6381\n",
      "Epoch: 9326, Loss: 0.6435, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10596.7717\n",
      "Epoch: 9327, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10597.9062\n",
      "Epoch: 9328, Loss: 0.6424, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10599.0418\n",
      "Epoch: 9329, Loss: 0.6398, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10600.1766\n",
      "Epoch: 9330, Loss: 0.6395, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10601.3075\n",
      "Epoch: 9331, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10602.4506\n",
      "Epoch: 9332, Loss: 0.6421, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10603.5850\n",
      "Epoch: 9333, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10604.7217\n",
      "Epoch: 9334, Loss: 0.6408, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10605.8595\n",
      "Epoch: 9335, Loss: 0.6412, Train_Acc: 0.5769, TEST_Acc: 0.6167, Time: 10606.9952\n",
      "Epoch: 9336, Loss: 0.6418, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10608.1364\n",
      "Epoch: 9337, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10609.2699\n",
      "Epoch: 9338, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10610.4074\n",
      "Epoch: 9339, Loss: 0.6414, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10611.5408\n",
      "Epoch: 9340, Loss: 0.6413, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10612.6770\n",
      "Epoch: 9341, Loss: 0.6407, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10613.8160\n",
      "Epoch: 9342, Loss: 0.6397, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10614.9478\n",
      "Epoch: 9343, Loss: 0.6400, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10616.0828\n",
      "Epoch: 9344, Loss: 0.6389, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10617.2171\n",
      "Epoch: 9345, Loss: 0.6388, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10618.3489\n",
      "Epoch: 9346, Loss: 0.6399, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10619.4830\n",
      "Epoch: 9347, Loss: 0.6393, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10620.6191\n",
      "Epoch: 9348, Loss: 0.6398, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10621.7567\n",
      "Epoch: 9349, Loss: 0.6386, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10622.8972\n",
      "Epoch: 9350, Loss: 0.6366, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10624.0318\n",
      "Epoch: 9351, Loss: 0.6367, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10625.1736\n",
      "Epoch: 9352, Loss: 0.6338, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10626.3110\n",
      "Epoch: 9353, Loss: 0.6339, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10627.4446\n",
      "Epoch: 9354, Loss: 0.6335, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10628.5790\n",
      "Epoch: 9355, Loss: 0.6337, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10629.7122\n",
      "Epoch: 9356, Loss: 0.6341, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10630.8464\n",
      "Epoch: 9357, Loss: 0.6330, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10631.9786\n",
      "Epoch: 9358, Loss: 0.6338, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10633.1152\n",
      "Epoch: 9359, Loss: 0.6343, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10634.2468\n",
      "Epoch: 9360, Loss: 0.6350, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10635.3885\n",
      "Epoch: 9361, Loss: 0.6352, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10636.5280\n",
      "Epoch: 9362, Loss: 0.6369, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10637.6641\n",
      "Epoch: 9363, Loss: 0.6386, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10638.8010\n",
      "Epoch: 9364, Loss: 0.6375, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10639.9386\n",
      "Epoch: 9365, Loss: 0.6378, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10641.0751\n",
      "Epoch: 9366, Loss: 0.6358, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10642.2083\n",
      "Epoch: 9367, Loss: 0.6341, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10643.3428\n",
      "Epoch: 9368, Loss: 0.6352, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10644.4764\n",
      "Epoch: 9369, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10645.6147\n",
      "Epoch: 9370, Loss: 0.6361, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10646.7525\n",
      "Epoch: 9371, Loss: 0.6369, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10647.8875\n",
      "Epoch: 9372, Loss: 0.6359, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10649.0215\n",
      "Epoch: 9373, Loss: 0.6363, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10650.1576\n",
      "Epoch: 9374, Loss: 0.6362, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10651.2965\n",
      "Epoch: 9375, Loss: 0.6369, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10652.4338\n",
      "Epoch: 9376, Loss: 0.6375, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10653.5719\n",
      "Epoch: 9377, Loss: 0.6389, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10654.7108\n",
      "Epoch: 9378, Loss: 0.6407, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10655.8515\n",
      "Epoch: 9379, Loss: 0.6393, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10656.9862\n",
      "Epoch: 9380, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10658.1199\n",
      "Epoch: 9381, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10659.2521\n",
      "Epoch: 9382, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10660.3862\n",
      "Epoch: 9383, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10661.5178\n",
      "Epoch: 9384, Loss: 0.6495, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10662.6548\n",
      "Epoch: 9385, Loss: 0.6503, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10663.7811\n",
      "Epoch: 9386, Loss: 0.6421, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10664.9159\n",
      "Epoch: 9387, Loss: 0.6414, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10666.0502\n",
      "Epoch: 9388, Loss: 0.6396, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10667.1901\n",
      "Epoch: 9389, Loss: 0.6404, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10668.3332\n",
      "Epoch: 9390, Loss: 0.6477, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10669.4725\n",
      "Epoch: 9391, Loss: 0.6378, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10670.6131\n",
      "Epoch: 9392, Loss: 0.6380, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10671.7450\n",
      "Epoch: 9393, Loss: 0.6394, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10672.8751\n",
      "Epoch: 9394, Loss: 0.6406, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10674.0085\n",
      "Epoch: 9395, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10675.1427\n",
      "Epoch: 9396, Loss: 0.6406, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10676.2746\n",
      "Epoch: 9397, Loss: 0.6403, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10677.4107\n",
      "Epoch: 9398, Loss: 0.6396, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10678.5545\n",
      "Epoch: 9399, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 10679.6903\n",
      "Epoch: 9400, Loss: 0.6377, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10680.8352\n",
      "Epoch: 9401, Loss: 0.6368, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 10681.9714\n",
      "Epoch: 9402, Loss: 0.6374, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 10683.1117\n",
      "Epoch: 9403, Loss: 0.6372, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 10684.2481\n",
      "Epoch: 9404, Loss: 0.6375, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 10685.3866\n",
      "Epoch: 9405, Loss: 0.6369, Train_Acc: 0.5769, TEST_Acc: 0.6433, Time: 10686.5281\n",
      "Epoch: 9406, Loss: 0.6384, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10687.6615\n",
      "Epoch: 9407, Loss: 0.6376, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10688.7968\n",
      "Epoch: 9408, Loss: 0.6377, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10689.9321\n",
      "Epoch: 9409, Loss: 0.6381, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10691.0661\n",
      "Epoch: 9410, Loss: 0.6379, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10692.2022\n",
      "Epoch: 9411, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10693.3363\n",
      "Epoch: 9412, Loss: 0.6395, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10694.4708\n",
      "Epoch: 9413, Loss: 0.6388, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10695.6078\n",
      "Epoch: 9414, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10696.7448\n",
      "Epoch: 9415, Loss: 0.6371, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10697.8831\n",
      "Epoch: 9416, Loss: 0.6375, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10699.0298\n",
      "Epoch: 9417, Loss: 0.6380, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10700.1727\n",
      "Epoch: 9418, Loss: 0.6382, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10701.3051\n",
      "Epoch: 9419, Loss: 0.6376, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10702.4390\n",
      "Epoch: 9420, Loss: 0.6373, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10703.5727\n",
      "Epoch: 9421, Loss: 0.6376, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10704.7101\n",
      "Epoch: 9422, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10705.8431\n",
      "Epoch: 9423, Loss: 0.6383, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10706.9842\n",
      "Epoch: 9424, Loss: 0.6381, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10708.1243\n",
      "Epoch: 9425, Loss: 0.6377, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10709.2628\n",
      "Epoch: 9426, Loss: 0.6375, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10710.4051\n",
      "Epoch: 9427, Loss: 0.6376, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10711.5454\n",
      "Epoch: 9428, Loss: 0.6362, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10712.6823\n",
      "Epoch: 9429, Loss: 0.6368, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10713.8188\n",
      "Epoch: 9430, Loss: 0.6363, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10714.9554\n",
      "Epoch: 9431, Loss: 0.6355, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10716.1022\n",
      "Epoch: 9432, Loss: 0.6341, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10717.2372\n",
      "Epoch: 9433, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10718.3724\n",
      "Epoch: 9434, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10719.5067\n",
      "Epoch: 9435, Loss: 0.6424, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10720.6438\n",
      "Epoch: 9436, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10721.7811\n",
      "Epoch: 9437, Loss: 0.6421, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10722.9122\n",
      "Epoch: 9438, Loss: 0.6423, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10724.0465\n",
      "Epoch: 9439, Loss: 0.6456, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10725.1810\n",
      "Epoch: 9440, Loss: 0.6469, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10726.3142\n",
      "Epoch: 9441, Loss: 0.6473, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10727.4526\n",
      "Epoch: 9442, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10728.5867\n",
      "Epoch: 9443, Loss: 0.6482, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10729.7239\n",
      "Epoch: 9444, Loss: 0.6396, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10730.8709\n",
      "Epoch: 9445, Loss: 0.6396, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10732.0183\n",
      "Epoch: 9446, Loss: 0.6408, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10733.1463\n",
      "Epoch: 9447, Loss: 0.6409, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10734.2803\n",
      "Epoch: 9448, Loss: 0.6421, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10735.4115\n",
      "Epoch: 9449, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10736.5472\n",
      "Epoch: 9450, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10737.6836\n",
      "Epoch: 9451, Loss: 0.6492, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10738.8202\n",
      "Epoch: 9452, Loss: 0.6387, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10739.9541\n",
      "Epoch: 9453, Loss: 0.6386, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10741.0886\n",
      "Epoch: 9454, Loss: 0.6383, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10742.2281\n",
      "Epoch: 9455, Loss: 0.6381, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10743.3669\n",
      "Epoch: 9456, Loss: 0.6384, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10744.5032\n",
      "Epoch: 9457, Loss: 0.6470, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10745.6392\n",
      "Epoch: 9458, Loss: 0.6462, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10746.7783\n",
      "Epoch: 9459, Loss: 0.6356, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10747.9137\n",
      "Epoch: 9460, Loss: 0.6333, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10749.0478\n",
      "Epoch: 9461, Loss: 0.6331, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10750.1835\n",
      "Epoch: 9462, Loss: 0.6346, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10751.3162\n",
      "Epoch: 9463, Loss: 0.6340, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10752.4442\n",
      "Epoch: 9464, Loss: 0.6334, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10753.5819\n",
      "Epoch: 9465, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10754.7168\n",
      "Epoch: 9466, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10755.8530\n",
      "Epoch: 9467, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10756.9892\n",
      "Epoch: 9468, Loss: 0.6431, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10758.1259\n",
      "Epoch: 9469, Loss: 0.6425, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10759.2650\n",
      "Epoch: 9470, Loss: 0.6414, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10760.4024\n",
      "Epoch: 9471, Loss: 0.6408, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10761.5369\n",
      "Epoch: 9472, Loss: 0.6408, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10762.6739\n",
      "Epoch: 9473, Loss: 0.6411, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10763.8091\n",
      "Epoch: 9474, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10764.9407\n",
      "Epoch: 9475, Loss: 0.6424, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10766.0735\n",
      "Epoch: 9476, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10767.2115\n",
      "Epoch: 9477, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10768.3459\n",
      "Epoch: 9478, Loss: 0.6416, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10769.4778\n",
      "Epoch: 9479, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10770.6094\n",
      "Epoch: 9480, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10771.7478\n",
      "Epoch: 9481, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10772.8871\n",
      "Epoch: 9482, Loss: 0.6411, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10774.0284\n",
      "Epoch: 9483, Loss: 0.6424, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10775.1742\n",
      "Epoch: 9484, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10776.3122\n",
      "Epoch: 9485, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10777.4493\n",
      "Epoch: 9486, Loss: 0.6419, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10778.5799\n",
      "Epoch: 9487, Loss: 0.6424, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10779.7149\n",
      "Epoch: 9488, Loss: 0.6422, Train_Acc: 0.5769, TEST_Acc: 0.6200, Time: 10780.8492\n",
      "Epoch: 9489, Loss: 0.6420, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10781.9826\n",
      "Epoch: 9490, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10783.1143\n",
      "Epoch: 9491, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10784.2514\n",
      "Epoch: 9492, Loss: 0.6355, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10785.3812\n",
      "Epoch: 9493, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10786.5254\n",
      "Epoch: 9494, Loss: 0.6353, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10787.6635\n",
      "Epoch: 9495, Loss: 0.6356, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10788.8021\n",
      "Epoch: 9496, Loss: 0.6384, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10789.9372\n",
      "Epoch: 9497, Loss: 0.6389, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10791.0763\n",
      "Epoch: 9498, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10792.2107\n",
      "Epoch: 9499, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10793.3421\n",
      "Epoch: 9500, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10794.4747\n",
      "Epoch: 9501, Loss: 0.6457, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10795.6118\n",
      "Epoch: 9502, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10796.7502\n",
      "Epoch: 9503, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10797.8849\n",
      "Epoch: 9504, Loss: 0.6435, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10799.0249\n",
      "Epoch: 9505, Loss: 0.6431, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10800.1563\n",
      "Epoch: 9506, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10801.2923\n",
      "Epoch: 9507, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10802.4271\n",
      "Epoch: 9508, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10803.5635\n",
      "Epoch: 9509, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10804.7012\n",
      "Epoch: 9510, Loss: 0.6359, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10805.8402\n",
      "Epoch: 9511, Loss: 0.6350, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10806.9815\n",
      "Epoch: 9512, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10808.1174\n",
      "Epoch: 9513, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10809.2539\n",
      "Epoch: 9514, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10810.3887\n",
      "Epoch: 9515, Loss: 0.6443, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10811.5233\n",
      "Epoch: 9516, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10812.6581\n",
      "Epoch: 9517, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10813.7918\n",
      "Epoch: 9518, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10814.9248\n",
      "Epoch: 9519, Loss: 0.6462, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10816.0575\n",
      "Epoch: 9520, Loss: 0.6385, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10817.1901\n",
      "Epoch: 9521, Loss: 0.6386, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10818.3287\n",
      "Epoch: 9522, Loss: 0.6394, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10819.4659\n",
      "Epoch: 9523, Loss: 0.6399, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10820.6023\n",
      "Epoch: 9524, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10821.7407\n",
      "Epoch: 9525, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10822.8775\n",
      "Epoch: 9526, Loss: 0.6471, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10824.0070\n",
      "Epoch: 9527, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10825.1418\n",
      "Epoch: 9528, Loss: 0.6455, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10826.2788\n",
      "Epoch: 9529, Loss: 0.6367, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10827.4119\n",
      "Epoch: 9530, Loss: 0.6463, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10828.5469\n",
      "Epoch: 9531, Loss: 0.6477, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10829.6872\n",
      "Epoch: 9532, Loss: 0.6457, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10830.8235\n",
      "Epoch: 9533, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10831.9574\n",
      "Epoch: 9534, Loss: 0.6455, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10833.0933\n",
      "Epoch: 9535, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10834.2297\n",
      "Epoch: 9536, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10835.3755\n",
      "Epoch: 9537, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10836.5114\n",
      "Epoch: 9538, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10837.6563\n",
      "Epoch: 9539, Loss: 0.6462, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10838.7996\n",
      "Epoch: 9540, Loss: 0.6465, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10839.9371\n",
      "Epoch: 9541, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10841.0669\n",
      "Epoch: 9542, Loss: 0.6443, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10842.2019\n",
      "Epoch: 9543, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10843.3337\n",
      "Epoch: 9544, Loss: 0.6448, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10844.4665\n",
      "Epoch: 9545, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10845.5979\n",
      "Epoch: 9546, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10846.7317\n",
      "Epoch: 9547, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10847.8662\n",
      "Epoch: 9548, Loss: 0.6434, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10849.0027\n",
      "Epoch: 9549, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10850.1484\n",
      "Epoch: 9550, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10851.2926\n",
      "Epoch: 9551, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10852.4306\n",
      "Epoch: 9552, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10853.5679\n",
      "Epoch: 9553, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10854.7039\n",
      "Epoch: 9554, Loss: 0.6443, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10855.8410\n",
      "Epoch: 9555, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10856.9737\n",
      "Epoch: 9556, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10858.1077\n",
      "Epoch: 9557, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10859.2426\n",
      "Epoch: 9558, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10860.3765\n",
      "Epoch: 9559, Loss: 0.6424, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10861.5192\n",
      "Epoch: 9560, Loss: 0.6415, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10862.6489\n",
      "Epoch: 9561, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10863.7792\n",
      "Epoch: 9562, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10864.9178\n",
      "Epoch: 9563, Loss: 0.6439, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10866.0533\n",
      "Epoch: 9564, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10867.1973\n",
      "Epoch: 9565, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10868.3337\n",
      "Epoch: 9566, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10869.4715\n",
      "Epoch: 9567, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10870.6052\n",
      "Epoch: 9568, Loss: 0.6421, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10871.7404\n",
      "Epoch: 9569, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10872.8824\n",
      "Epoch: 9570, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10874.0204\n",
      "Epoch: 9571, Loss: 0.6434, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10875.1551\n",
      "Epoch: 9572, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10876.2860\n",
      "Epoch: 9573, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10877.4167\n",
      "Epoch: 9574, Loss: 0.6457, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10878.5540\n",
      "Epoch: 9575, Loss: 0.6456, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10879.6871\n",
      "Epoch: 9576, Loss: 0.6457, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10880.8209\n",
      "Epoch: 9577, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10881.9621\n",
      "Epoch: 9578, Loss: 0.6439, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10883.1011\n",
      "Epoch: 9579, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10884.2393\n",
      "Epoch: 9580, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10885.3743\n",
      "Epoch: 9581, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10886.5058\n",
      "Epoch: 9582, Loss: 0.6443, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10887.6381\n",
      "Epoch: 9583, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10888.7705\n",
      "Epoch: 9584, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10889.9057\n",
      "Epoch: 9585, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10891.0400\n",
      "Epoch: 9586, Loss: 0.6434, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10892.1724\n",
      "Epoch: 9587, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10893.3062\n",
      "Epoch: 9588, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10894.4453\n",
      "Epoch: 9589, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10895.5846\n",
      "Epoch: 9590, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10896.7229\n",
      "Epoch: 9591, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 10897.8684\n",
      "Epoch: 9592, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10899.0108\n",
      "Epoch: 9593, Loss: 0.6429, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10900.1510\n",
      "Epoch: 9594, Loss: 0.6439, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10901.2869\n",
      "Epoch: 9595, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10902.4205\n",
      "Epoch: 9596, Loss: 0.6462, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10903.5575\n",
      "Epoch: 9597, Loss: 0.6459, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10904.6975\n",
      "Epoch: 9598, Loss: 0.6471, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10905.8326\n",
      "Epoch: 9599, Loss: 0.6483, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10906.9696\n",
      "Epoch: 9600, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10908.1014\n",
      "Epoch: 9601, Loss: 0.6494, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10909.2332\n",
      "Epoch: 9602, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10910.3654\n",
      "Epoch: 9603, Loss: 0.6503, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10911.5020\n",
      "Epoch: 9604, Loss: 0.6527, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10912.6406\n",
      "Epoch: 9605, Loss: 0.6516, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10913.7785\n",
      "Epoch: 9606, Loss: 0.6538, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10914.9193\n",
      "Epoch: 9607, Loss: 0.6540, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10916.0622\n",
      "Epoch: 9608, Loss: 0.6550, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10917.1979\n",
      "Epoch: 9609, Loss: 0.6555, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10918.3340\n",
      "Epoch: 9610, Loss: 0.6549, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10919.4695\n",
      "Epoch: 9611, Loss: 0.6552, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10920.6025\n",
      "Epoch: 9612, Loss: 0.6545, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10921.7367\n",
      "Epoch: 9613, Loss: 0.6532, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10922.8710\n",
      "Epoch: 9614, Loss: 0.6505, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10924.0011\n",
      "Epoch: 9615, Loss: 0.6493, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10925.1372\n",
      "Epoch: 9616, Loss: 0.6492, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10926.2704\n",
      "Epoch: 9617, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10927.4017\n",
      "Epoch: 9618, Loss: 0.6499, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10928.5428\n",
      "Epoch: 9619, Loss: 0.6494, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10929.6816\n",
      "Epoch: 9620, Loss: 0.6477, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10930.8198\n",
      "Epoch: 9621, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10931.9576\n",
      "Epoch: 9622, Loss: 0.6492, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10933.0974\n",
      "Epoch: 9623, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10934.2316\n",
      "Epoch: 9624, Loss: 0.6470, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10935.3687\n",
      "Epoch: 9625, Loss: 0.6468, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10936.5029\n",
      "Epoch: 9626, Loss: 0.6479, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10937.6400\n",
      "Epoch: 9627, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10938.7718\n",
      "Epoch: 9628, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10939.9068\n",
      "Epoch: 9629, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10941.0434\n",
      "Epoch: 9630, Loss: 0.6494, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10942.1735\n",
      "Epoch: 9631, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10943.3047\n",
      "Epoch: 9632, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10944.4445\n",
      "Epoch: 9633, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10945.5850\n",
      "Epoch: 9634, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10946.7225\n",
      "Epoch: 9635, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10947.8672\n",
      "Epoch: 9636, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10949.0039\n",
      "Epoch: 9637, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10950.1415\n",
      "Epoch: 9638, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10951.2729\n",
      "Epoch: 9639, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10952.4038\n",
      "Epoch: 9640, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10953.5387\n",
      "Epoch: 9641, Loss: 0.6459, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10954.6745\n",
      "Epoch: 9642, Loss: 0.6456, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10955.8088\n",
      "Epoch: 9643, Loss: 0.6446, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 10956.9443\n",
      "Epoch: 9644, Loss: 0.6471, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10958.0816\n",
      "Epoch: 9645, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10959.2248\n",
      "Epoch: 9646, Loss: 0.6465, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10960.3602\n",
      "Epoch: 9647, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10961.4973\n",
      "Epoch: 9648, Loss: 0.6455, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10962.6363\n",
      "Epoch: 9649, Loss: 0.6455, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10963.7730\n",
      "Epoch: 9650, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10964.9055\n",
      "Epoch: 9651, Loss: 0.6451, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10966.0391\n",
      "Epoch: 9652, Loss: 0.6469, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10967.1705\n",
      "Epoch: 9653, Loss: 0.6493, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10968.3051\n",
      "Epoch: 9654, Loss: 0.6489, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10969.4448\n",
      "Epoch: 9655, Loss: 0.6482, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10970.5802\n",
      "Epoch: 9656, Loss: 0.6474, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10971.7124\n",
      "Epoch: 9657, Loss: 0.6482, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10972.8458\n",
      "Epoch: 9658, Loss: 0.6497, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10973.9843\n",
      "Epoch: 9659, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10975.1203\n",
      "Epoch: 9660, Loss: 0.6507, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10976.2554\n",
      "Epoch: 9661, Loss: 0.6519, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10977.3962\n",
      "Epoch: 9662, Loss: 0.6501, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10978.5305\n",
      "Epoch: 9663, Loss: 0.6505, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10979.6731\n",
      "Epoch: 9664, Loss: 0.6494, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10980.8047\n",
      "Epoch: 9665, Loss: 0.6479, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10981.9391\n",
      "Epoch: 9666, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10983.0728\n",
      "Epoch: 9667, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10984.2038\n",
      "Epoch: 9668, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 10985.3404\n",
      "Epoch: 9669, Loss: 0.6451, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10986.4800\n",
      "Epoch: 9670, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 10987.6182\n",
      "Epoch: 9671, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10988.7561\n",
      "Epoch: 9672, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10989.8968\n",
      "Epoch: 9673, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 10991.0388\n",
      "Epoch: 9674, Loss: 0.6477, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10992.1782\n",
      "Epoch: 9675, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10993.3132\n",
      "Epoch: 9676, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10994.4438\n",
      "Epoch: 9677, Loss: 0.6488, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10995.5784\n",
      "Epoch: 9678, Loss: 0.6479, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10996.7104\n",
      "Epoch: 9679, Loss: 0.6481, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10997.8471\n",
      "Epoch: 9680, Loss: 0.6469, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 10998.9776\n",
      "Epoch: 9681, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11000.1143\n",
      "Epoch: 9682, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11001.2560\n",
      "Epoch: 9683, Loss: 0.6466, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11002.4022\n",
      "Epoch: 9684, Loss: 0.6467, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11003.5570\n",
      "Epoch: 9685, Loss: 0.6474, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11005.0797\n",
      "Epoch: 9686, Loss: 0.6457, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11006.7433\n",
      "Epoch: 9687, Loss: 0.6468, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11008.3148\n",
      "Epoch: 9688, Loss: 0.6470, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11009.8468\n",
      "Epoch: 9689, Loss: 0.6474, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11011.1622\n",
      "Epoch: 9690, Loss: 0.6466, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11012.3024\n",
      "Epoch: 9691, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11013.4461\n",
      "Epoch: 9692, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11014.5863\n",
      "Epoch: 9693, Loss: 0.6474, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11015.7252\n",
      "Epoch: 9694, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11016.8718\n",
      "Epoch: 9695, Loss: 0.6482, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11018.0143\n",
      "Epoch: 9696, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11019.1566\n",
      "Epoch: 9697, Loss: 0.6470, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11020.2997\n",
      "Epoch: 9698, Loss: 0.6476, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11021.4384\n",
      "Epoch: 9699, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11022.5805\n",
      "Epoch: 9700, Loss: 0.6496, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11023.7144\n",
      "Epoch: 9701, Loss: 0.6506, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11024.8507\n",
      "Epoch: 9702, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11025.9883\n",
      "Epoch: 9703, Loss: 0.6508, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11027.1242\n",
      "Epoch: 9704, Loss: 0.6509, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11028.2606\n",
      "Epoch: 9705, Loss: 0.6511, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11029.3979\n",
      "Epoch: 9706, Loss: 0.6504, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11030.5340\n",
      "Epoch: 9707, Loss: 0.6510, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11031.6696\n",
      "Epoch: 9708, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11032.8075\n",
      "Epoch: 9709, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11033.9488\n",
      "Epoch: 9710, Loss: 0.6528, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11035.0892\n",
      "Epoch: 9711, Loss: 0.6520, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 11036.2291\n",
      "Epoch: 9712, Loss: 0.6479, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11037.3641\n",
      "Epoch: 9713, Loss: 0.6474, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11038.5101\n",
      "Epoch: 9714, Loss: 0.6457, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11039.6475\n",
      "Epoch: 9715, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11040.7811\n",
      "Epoch: 9716, Loss: 0.6475, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11041.9207\n",
      "Epoch: 9717, Loss: 0.6468, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11043.0524\n",
      "Epoch: 9718, Loss: 0.6467, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11044.1934\n",
      "Epoch: 9719, Loss: 0.6485, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11045.3339\n",
      "Epoch: 9720, Loss: 0.6477, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11046.4711\n",
      "Epoch: 9721, Loss: 0.6521, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 11047.6103\n",
      "Epoch: 9722, Loss: 0.6516, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 11048.7567\n",
      "Epoch: 9723, Loss: 0.6510, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 11049.8941\n",
      "Epoch: 9724, Loss: 0.6490, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 11051.0326\n",
      "Epoch: 9725, Loss: 0.6478, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 11052.1705\n",
      "Epoch: 9726, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 11053.3216\n",
      "Epoch: 9727, Loss: 0.6473, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 11054.4778\n",
      "Epoch: 9728, Loss: 0.6486, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 11055.6214\n",
      "Epoch: 9729, Loss: 0.6482, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11057.3112\n",
      "Epoch: 9730, Loss: 0.6491, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11058.7148\n",
      "Epoch: 9731, Loss: 0.6484, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11059.8497\n",
      "Epoch: 9732, Loss: 0.6488, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11060.9956\n",
      "Epoch: 9733, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11062.1353\n",
      "Epoch: 9734, Loss: 0.6465, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11063.2790\n",
      "Epoch: 9735, Loss: 0.6469, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11064.4200\n",
      "Epoch: 9736, Loss: 0.6455, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11065.5619\n",
      "Epoch: 9737, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11066.7042\n",
      "Epoch: 9738, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11067.8431\n",
      "Epoch: 9739, Loss: 0.6456, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11068.9852\n",
      "Epoch: 9740, Loss: 0.6457, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11070.1199\n",
      "Epoch: 9741, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11071.2549\n",
      "Epoch: 9742, Loss: 0.6467, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11072.3875\n",
      "Epoch: 9743, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11073.5385\n",
      "Epoch: 9744, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11074.6760\n",
      "Epoch: 9745, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11075.8203\n",
      "Epoch: 9746, Loss: 0.6466, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11077.4751\n",
      "Epoch: 9747, Loss: 0.6474, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11078.6304\n",
      "Epoch: 9748, Loss: 0.6473, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11079.8059\n",
      "Epoch: 9749, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11080.9468\n",
      "Epoch: 9750, Loss: 0.6458, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11082.0884\n",
      "Epoch: 9751, Loss: 0.6473, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11083.2252\n",
      "Epoch: 9752, Loss: 0.6473, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11084.3683\n",
      "Epoch: 9753, Loss: 0.6470, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11085.5087\n",
      "Epoch: 9754, Loss: 0.6473, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11086.6500\n",
      "Epoch: 9755, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11087.7866\n",
      "Epoch: 9756, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11088.9268\n",
      "Epoch: 9757, Loss: 0.6442, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11090.0653\n",
      "Epoch: 9758, Loss: 0.6434, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11091.2132\n",
      "Epoch: 9759, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11092.3503\n",
      "Epoch: 9760, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11093.4962\n",
      "Epoch: 9761, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11094.6471\n",
      "Epoch: 9762, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11095.8053\n",
      "Epoch: 9763, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11097.1830\n",
      "Epoch: 9764, Loss: 0.6443, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11098.9376\n",
      "Epoch: 9765, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11100.1091\n",
      "Epoch: 9766, Loss: 0.6435, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11101.2532\n",
      "Epoch: 9767, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11102.3893\n",
      "Epoch: 9768, Loss: 0.6440, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11103.5267\n",
      "Epoch: 9769, Loss: 0.6438, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11104.6661\n",
      "Epoch: 9770, Loss: 0.6448, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11105.7997\n",
      "Epoch: 9771, Loss: 0.6436, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11106.9391\n",
      "Epoch: 9772, Loss: 0.6427, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11108.0756\n",
      "Epoch: 9773, Loss: 0.6437, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11109.2187\n",
      "Epoch: 9774, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11110.3680\n",
      "Epoch: 9775, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11111.5159\n",
      "Epoch: 9776, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11112.6794\n",
      "Epoch: 9777, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11114.0497\n",
      "Epoch: 9778, Loss: 0.6466, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11115.8085\n",
      "Epoch: 9779, Loss: 0.6469, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11117.0819\n",
      "Epoch: 9780, Loss: 0.6452, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11118.2341\n",
      "Epoch: 9781, Loss: 0.6462, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11119.3789\n",
      "Epoch: 9782, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11120.5179\n",
      "Epoch: 9783, Loss: 0.6466, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11121.6595\n",
      "Epoch: 9784, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11122.7977\n",
      "Epoch: 9785, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11123.9364\n",
      "Epoch: 9786, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11125.0771\n",
      "Epoch: 9787, Loss: 0.6456, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11126.2098\n",
      "Epoch: 9788, Loss: 0.6439, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 11127.3484\n",
      "Epoch: 9789, Loss: 0.6433, Train_Acc: 0.5769, TEST_Acc: 0.6400, Time: 11128.5080\n",
      "Epoch: 9790, Loss: 0.6426, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11129.6498\n",
      "Epoch: 9791, Loss: 0.6432, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11130.9090\n",
      "Epoch: 9792, Loss: 0.6428, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11132.4979\n",
      "Epoch: 9793, Loss: 0.6430, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11134.0134\n",
      "Epoch: 9794, Loss: 0.6447, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11135.1452\n",
      "Epoch: 9795, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11136.3028\n",
      "Epoch: 9796, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11137.4451\n",
      "Epoch: 9797, Loss: 0.6445, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11138.5798\n",
      "Epoch: 9798, Loss: 0.6441, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11139.7214\n",
      "Epoch: 9799, Loss: 0.6444, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11140.8616\n",
      "Epoch: 9800, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11142.0009\n",
      "Epoch: 9801, Loss: 0.6468, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11143.1435\n",
      "Epoch: 9802, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11144.2869\n",
      "Epoch: 9803, Loss: 0.6465, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11145.4274\n",
      "Epoch: 9804, Loss: 0.6480, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11146.5709\n",
      "Epoch: 9805, Loss: 0.6472, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11147.7187\n",
      "Epoch: 9806, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11148.8602\n",
      "Epoch: 9807, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11149.9981\n",
      "Epoch: 9808, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11151.1360\n",
      "Epoch: 9809, Loss: 0.6463, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11152.2676\n",
      "Epoch: 9810, Loss: 0.6468, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11153.4148\n",
      "Epoch: 9811, Loss: 0.6461, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11154.5541\n",
      "Epoch: 9812, Loss: 0.6464, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11155.7043\n",
      "Epoch: 9813, Loss: 0.6450, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11156.8382\n",
      "Epoch: 9814, Loss: 0.6451, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11157.9878\n",
      "Epoch: 9815, Loss: 0.6456, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11159.1330\n",
      "Epoch: 9816, Loss: 0.6449, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11160.4814\n",
      "Epoch: 9817, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11162.1605\n",
      "Epoch: 9818, Loss: 0.6451, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11163.3249\n",
      "Epoch: 9819, Loss: 0.6460, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11164.4877\n",
      "Epoch: 9820, Loss: 0.6467, Train_Acc: 0.5769, TEST_Acc: 0.6367, Time: 11165.6281\n",
      "Epoch: 9821, Loss: 0.6465, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11166.7682\n",
      "Epoch: 9822, Loss: 0.6459, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11167.9037\n",
      "Epoch: 9823, Loss: 0.6467, Train_Acc: 0.5769, TEST_Acc: 0.6333, Time: 11169.0444\n",
      "Epoch: 9824, Loss: 0.6498, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11170.1858\n",
      "Epoch: 9825, Loss: 0.6488, Train_Acc: 0.5769, TEST_Acc: 0.6300, Time: 11171.3249\n",
      "Epoch: 9826, Loss: 0.6467, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11172.4669\n",
      "Epoch: 9827, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11173.6213\n",
      "Epoch: 9828, Loss: 0.6453, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11174.7692\n",
      "Epoch: 9829, Loss: 0.6454, Train_Acc: 0.5769, TEST_Acc: 0.6267, Time: 11176.0590\n",
      "Epoch: 9830, Loss: 0.6443, Train_Acc: 0.5769, TEST_Acc: 0.6233, Time: 11177.8974\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f2e2c0399101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Use training data for optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# varidate after every epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Breast Histology Images\n",
    "# Classify IDC vs non IDC images\n",
    "#\n",
    "# https://www.kaggle.com/simjeg/lymphoma-subtype-classification-fl-vs-cll\n",
    "#\n",
    "# This dataset consists of 5547 breast histology images of size 50 x 50 x 3,\n",
    "# The goal is to classify cancerous images (IDC : invasive ductal carcinoma) vs non-IDC images.\n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def print_time(message, start_time):\n",
    "    print(\"*****   \" + message + \": {}  *****\".format(time.time() - start_time))\n",
    "\n",
    "\n",
    "def get_batch(all_data, all_labels, batch_size=16):\n",
    "    # // means divide and result is integer, / returns float\n",
    "    # rows_data = len(all_data) // batch_size\n",
    "    # rows_labels = len(all_labels) // batch_size\n",
    "\n",
    "    rtn_data = all_data.reshape(-1, batch_size, int(50*50*3))\n",
    "    rnt_labels = all_labels.reshape(-1, batch_size, 2)\n",
    "\n",
    "    return (rtn_data, rnt_labels)\n",
    "\n",
    "\n",
    "def conv2d(x, weight, bias, strides=1):\n",
    "    x = tf.nn.conv2d(x, weight, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, bias)\n",
    "\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "\n",
    "    x = tf.reshape(x, shape=[-1, 50, 50, 3])\n",
    "\n",
    "    # Convolution layer 1\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    print(\"conv1.get_shape(): \", conv1.get_shape())\n",
    "\n",
    "    # MAX POOLING\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    print(\"conv1.get_shape() after maxpool : \", conv1.get_shape())\n",
    "\n",
    "    # Convolution layer 2\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    print(\"conv2.get_shape(): \", conv2.get_shape())\n",
    "\n",
    "    # MAX POOLING\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    print(\"conv2.get_shape() after maxpool : \", conv2.get_shape())\n",
    "\n",
    "    # Convolution layer 3\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    print(\"conv3.get_shape(): \", conv3.get_shape())\n",
    "\n",
    "    # MAX POOLING\n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "    print(\"conv3.get_shape() after maxpool : \", conv3.get_shape())\n",
    "\n",
    "    # Fully connected layer\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Fully connected layer\n",
    "    fc2 = tf.reshape(fc1, [-1, weights['wd2'].get_shape().as_list()[0]])\n",
    "    fc2 = tf.add(tf.matmul(fc2, weights['wd2']), biases['bd2'])\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2, dropout)\n",
    "\n",
    "    out = tf.add(tf.matmul(fc2, weights['out']), biases['out'])\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "#\n",
    "#   Main\n",
    "#\n",
    "#\n",
    "######################################################################################################\n",
    "START_TIME = time.time()\n",
    "path = r'C:\\Users\\gtune\\OneDrive\\document_usk\\UCSC\\02_SecondQuater\\Deep_Learning_and_Artificial_Intelligence_with_TensorFlow\\Homework\\Final_Project\\data'\n",
    "\n",
    "X_data = np.load(\"X.npy\")\n",
    "Y_truth = np.load(\"Y.npy\")\n",
    "\n",
    "# print(X_data[0:10])\n",
    "# print(X_data.shape)\n",
    "# print(Y_truth[0:100])\n",
    "\n",
    "# print(np.array(np.where(Y_truth == 1)))\n",
    "\n",
    "train_data, test_data, train_Y, test_Y = \\\n",
    "    train_test_split(X_data, Y_truth, test_size=0.25, random_state=3)\n",
    "\n",
    "print(len(np.array(np.where(train_Y == 1)).ravel()))\n",
    "print(len(np.array(np.where(train_Y == 0)).ravel()))\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_Y.shape)\n",
    "\n",
    "# architecture hyper-parameter\n",
    "num_datapoints = len(train_data)\n",
    "learning_rate = 0.000005   # 0.001\n",
    "n_epoch = 10000\n",
    "batch_size = 52  # divisor of 4160 : 1, 2, 4, 5, 8, 10, 13, 16, 20, 26, 32, 40, 52, 64, 65, 80, 104, 130, 160, 208, 260, 320, 416, 520, 832, 1040, 2080, 4160\n",
    "\n",
    "n_input = 50*50*3\n",
    "n_classes = 2   # IDC and non-IDC\n",
    "dropout = 0.75\n",
    "\n",
    "# Normalization\n",
    "max_value = np.max(train_data)\n",
    "print('max_value -> {}'.format(max_value))\n",
    "\n",
    "train_data = np.array(train_data/max_value, dtype=np.float32)\n",
    "\n",
    "# data and Y(Label) reshaped\n",
    "onehot_train_Y = np.full((len(train_Y), n_classes), 0)\n",
    "onehot_train_Y[np.arange(0, len(train_Y)), train_Y] = 1\n",
    "train_data, onehot_train_Y = get_batch(train_data, onehot_train_Y, batch_size)\n",
    "\n",
    "test_data = test_data.reshape(-1, n_input)\n",
    "onehot_test_Y = np.full((len(test_Y), n_classes), 0)\n",
    "onehot_test_Y[np.arange(0, len(test_Y)), test_Y] = 1\n",
    "\n",
    "\n",
    "num_batches = num_datapoints // batch_size  # 10  # num_datapoints // batch_size\n",
    "\n",
    "print_time(\"num_batches\", START_TIME)\n",
    "\n",
    "# data_x, labels_y = get_batch(X_train, onehot_labels, batch_size)\n",
    "\n",
    "print(\"NO OF BATCHES:\", num_batches)\n",
    "print_time(\"NO OF BATCHES\", START_TIME)\n",
    "\n",
    "\n",
    "# tensorflow placeholder\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "Y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# initializer = tf.contrib.layers.variance_scaling_initializer(factor=2.0, seed=0)\n",
    "# initializer2 = tf.contrib.layers.variance_scaling_initializer(factor=2.0, seed=1)\n",
    "# initializer3 = tf.contrib.layers.variance_scaling_initializer(factor=2.0, seed=2)\n",
    "# initializer4 = tf.contrib.layers.variance_scaling_initializer(factor=2.0, seed=3)\n",
    "\n",
    "# wc 1,2  are filter\n",
    "'''\n",
    "weights = {\n",
    "    'wc1': tf.Variable(initializer([5, 5, 3, 32])),\n",
    "    'wc2': tf.Variable(initializer2([5, 5, 32, 32])),\n",
    "    'wd1': tf.Variable(initializer3([13*13*32, 1024])),\n",
    "    'out': tf.Variable(initializer4([1024, n_classes]))\n",
    "}\n",
    "'''\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 3, 36])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 36, 36])),\n",
    "    'wc3': tf.Variable(tf.random_normal([5, 5, 36, 36])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*36, 576])),\n",
    "    'wd2': tf.Variable(tf.random_normal([576, 1024])),\n",
    "#    'wd1': tf.Variable(tf.random_normal([7 * 7 * 32, 288])),9\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([36])),\n",
    "    'bc2': tf.Variable(tf.random_normal([36])),\n",
    "    'bc3': tf.Variable(tf.random_normal([36])),\n",
    "    'bd1': tf.Variable(tf.random_normal([576])),\n",
    "    'bd2': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Create the Model\n",
    "model = conv_net(X, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "train_min = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Evaluate the model\n",
    "correct_model = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_model, tf.float32))\n",
    "\n",
    "# Initialing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Set config\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "# os.environ[\"KMP_BLOCKTIME\"] = \"30\"\n",
    "# os.environ[\"KMP_SETTINGS\"] = \"1\"\n",
    "# os.environ[\"KMP_AFFINITY\"] = \"granularity=fine,verbose,compact,1,0\"\n",
    "\n",
    "# Tensorflow Session\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        for i in range(num_batches):\n",
    "            # for _ in range(1):\n",
    "\n",
    "            batch_x = train_data[i]\n",
    "            batch_y = onehot_train_Y[i]\n",
    "\n",
    "            # Use training data for optimization\n",
    "            sess.run(train_min, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n",
    "\n",
    "        # varidate after every epoch\n",
    "        batch_x = train_data[0]\n",
    "        batch_y = onehot_train_Y[0]\n",
    "\n",
    "        losscalc, accuracycalc = sess.run([loss, accuracy], feed_dict={X:batch_x, Y:batch_y, keep_prob:1.0})\n",
    "        test_accuracycalc = sess.run(accuracy, feed_dict={X: test_data[0:300], Y: onehot_test_Y[0:300], keep_prob: 1.0})\n",
    "\n",
    "        print(\"Epoch: %d, Loss: %0.4f, Train_Acc: %0.4f, TEST_Acc: %0.4f, Time: %0.4f\" % (epoch, losscalc, accuracycalc, test_accuracycalc, time.time() - START_TIME))\n",
    "\n",
    "        # when train accuracy is over 95%, program end\n",
    "        if accuracycalc >= 0.95:\n",
    "            break\n",
    "\n",
    "    # display the accuracy of using testing data\n",
    "    accuracycalc = sess.run(accuracy, feed_dict={X: test_data, Y: onehot_test_Y, keep_prob: 1.0})\n",
    "\n",
    "    print(\"                  Testing accuracy: %0.4f, Time: %0.4f\" % (accuracycalc, time.time() - START_TIME))\n",
    "\n",
    "\n",
    "print_time(\"END\", START_TIME)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Untitled0.ipynb",
   "provenance": [
    {
     "file_id": "1B8mwfFJWeY9JRcfZEImsBnbJ2h3-m076",
     "timestamp": 1553982949665
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
